<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[redis主从复制]]></title>
    <url>%2F2020%2F04%2F30%2Fredis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[首先在redis中的主从复制推荐至少3个节点。 什么是主从复制主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master/leader)，后者称为从节点(slave/follower)；数据的复制是单向的，只能由主节点到从节点。 默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。 主节点可以进行读写操作 从节点只能进行读操作 主从复制的作用 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。 如何使用主从复制从节点开启主从复制，有3种方式： 配置文件：在从服务器的配置文件中加入：slaveof &lt; masterip &gt; &lt; masterport &gt; 启动命令：redis-server启动命令后加入 –slaveof &lt; masterip &gt; &lt; masterport &gt; 客户端命令：Redis服务器启动后，直接通过客户端执行命令：slaveof &lt; masterip &gt; &lt; masterport &gt;，则该Redis实例成为从节点。 在Redis客户端通过info replication可以查看与复制相关的状态，对于了解主从节点的当前状态，以及解决出现的问题都会有帮助。 断开主从复制通过slaveof &lt; masterip &gt; &lt; masterport &gt;命令建立主从复制关系以后，可以通过slaveof no one断开。 从节点断开复制后，不会删除已有的数据，只是不再接受主节点新的数据变化，而且从节点断开后，会变成主节点 主从复制详解主从复制节点宕机原则谋朝篡位 案例一假设有主节点A，同时从节点B和C 如果使用的是配置文件配置的主从复制其中A节点宕机了，这个时候B节点和C节点都还是从节点，并不会升级为主节点。 如果A节点又恢复了，这个时候A节点会同步从节点中的数据。 如果从节点宕机了，并不会影响其他节点的使用，这就是高可用，如果从节点恢复了，也会同步其他节点中的数据。 如果使用的是命令的方式配置主从复制其中A节点宕机了，这个时候B节点和C节点都还是从节点，并不会升级为主节点。 如果A节点又恢复了，这个时候A节点会同步从节点中的数据。 如果从节点宕机了，并不会影响其他节点的使用，这就是高可用，如果从节点恢复了，因为从节点是命令的方式配置的，所以从节点会变成主节点，也就是说不会同步，这个时候需要我们手动配置为从节点 方案二 这个时候A是主节点，B相当于兼任了从节点和主节点（实际上仍然只能读不能写），C是B的从节点。 如果B使用了slaveof no one这个命令，那么A节点就不在于B和C节点相联系。 主从复制的实现原理主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段； 连接建立阶段step1：保存主节点信息从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。 slaveof**是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行。** step2：建立socket连接从节点每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。 如果连接成功： 从节点：为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。 主节点：接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。 step3：发送ping命令从节点成为主节点的客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。 从节点发送ping命令后，可能出现3种情况： （1）返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。 （2）超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。 （3）返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。 step4：身份验证如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。 从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。 如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。 step5：发送从节点端口信息身份验证之后，从节点会向主节点发送其监听的端口号，主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。 数据同步阶段主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。 具体执行的方式是：从节点向主节点发送psync命令，开始同步。 数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制。 在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端。原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。 命令传播阶段数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。 在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。 延迟与不一致：命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。 repl-disable-tcp-nodelay no：该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为yes；多数情况使用默认值no。 【数据同步阶段】全量复制和部分复制在Redis2.8以前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制； 在Redis2.8以后，从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。 全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。 部分复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。 全量复制Redis通过psync命令进行全量复制的过程如下： （1）从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行全量复制； （2）主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令 （3）主节点的bgsave执行完成后，将RDB文件发送给从节点；从节点首先清除自己的旧数据，然后载入接收的RDB文件，将数据库状态更新至主节点执行bgsave时的数据库状态 （4）主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态 （5）如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态 通过全量复制的过程可以看出，全量复制是非常重型的操作： （1）主节点通过bgsave命令fork子进程进行RDB持久化，该过程是非常消耗CPU、内存(页表复制)、硬盘IO的； （2）主节点通过网络将RDB文件发送给从节点，对主从节点的带宽都会带来很大的消耗 （3）从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgrewriteaof，也会带来额外的消耗 部分复制由于全量复制在主节点数据量较大时效率太低，因此Redis2.8开始提供部分复制，用于处理网络中断时的数据同步。 部分复制的实现，依赖于三个重要的概念：复制偏移量，复制积压缓冲区，服务器运行ID 复制偏移量主节点和从节点分别维护一个复制偏移量（offset），代表的是主节点向从节点传递的字节数；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。 offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。例如，如果主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传递给从节点。而offset为501-1000的数据存储的位置，就是下面要介绍的复制积压缓冲区。 复制积压缓冲区复制积压缓冲区是由主节点维护的、固定长度的、先进先出(FIFO)队列，默认大小1MB；当主节点开始有从节点时创建，其作用是备份主节点最近发送给从节点的数据。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。 在命令传播阶段，主节点除了将写命令发送给从节点，还会发送一份给复制积压缓冲区，作为写命令的备份；除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。 由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)；例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。 从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制： 如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制； 如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>主从复制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java动态性的理解]]></title>
    <url>%2F2020%2F04%2F28%2Fjava%E5%8A%A8%E6%80%81%E6%80%A7%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[什么是动态语言动态类型语言和静态类型语言两者的区别就在于对类型的检查是在编译期还是在运行期。 而且动态语言可以在运行的时候改变其结构。 java语言的动态性java 语言的动态性体现在面向对象设计方法中的扩展，允许程序动态的装入过程中需要的类， java编译器不是将对实例变量和成员函数的引用编译为数值引用，而是将符号引用信息在字节码中保存后传递给解释器，再由解释器在完成动态连接类后，将符号引用信息转换为数据偏移量。存储器生成的对象不在编译过程中决定，而是延迟到运行时由解释器确定。这样，对类中变量和方法进行更新时就不至于影响现存的代码。解释执行字节码时，这种符号信息的查找和转换过程仅在一个新的名字出现时才进行一次，随后代码便可以全速执行。 通俗的来讲就是一个引用所指向的对象生成和存储，不是在编译时完成的，而是在字节码去解释执行时完成的，也就是动态多态。]]></content>
      <tags>
        <tag>java</tag>
        <tag>动态性</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F28%2Fjvm%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%80%E5%A4%A9-%E8%87%AA%E5%8A%A8%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[title: jvm学习第一天-自动内存管理date: 2020-03-14 17:35:56tags: jvm java 虚拟机 运行时数据区域 方法区 堆 虚拟机栈 本地方法栈 程序计数器 其中前两个是线程共享的，后三个是线程独有的 程序计数器 程序计数器是一个记录着当前线程所执行的字节码的行号指示器。 如果线程执行的是一个java方法，那么这个计数器就表示正在执行的虚拟机字节码地址 如果这个线程执行的是本地（Native）方法，那么这个计数器的值为空 虚拟机栈栈与堆的区别栈是一种运行时结构，堆是一种存储结构 虚拟机栈特点 和程序计数器一样是线程私有的 会产生oom错误，前提是虚拟机栈可以动态扩展（hospot虚拟机不支持动态扩展，但是Classic虚拟机支持） StackOverFlowError错误 不需要GC（垃圾回收） 栈的生命周期和线程相同 虚拟机栈运行过程每个方法被执行的时候，java虚拟机都会在虚拟机栈创建一个栈帧，当然，每个方法结束后都会移除该栈帧，也就是说在栈顶的栈帧一定是当前执行的方法的栈帧. 在编译程序代码的时候，栈帧中需要多大的局部变量表内存，多深的操作数栈都已经完全确定了。 因此一个栈帧需要分配多少内存，不会受到程序运行期变量数据的影响，而仅仅取决于具体的虚拟机实现。 栈帧 栈帧包含局部变量表，操作数栈，动态连接，方法出口等信息 两个栈帧的数据共享 局部变量表的共享 在概念模型中，两个不同栈帧作为不同方法的虚拟机栈的元素，是完全相互独立的，但是大多虚拟机的实现里都会进行一些优化处理，两个栈帧出现一部分重叠，这样做不仅节约了一些空间，更重要的是进行方法调用时就可以直接共用一部分数据。 局部变量表存放了编译期可知的各种java虚拟机基本数据类型和对象引用类型（reference），也有可能是指向对象的起始地址或者代表一个对象的句柄 局部变量表在编译期间确定大小 变量槽局部变量的存储使用变量槽表示，其中long和double使用两个变量槽 在方法运行期间不会改变局部变量表的大小，（大小指的是不会改变变量槽的数量） 1234567891011Slot复用 为了尽可能节省栈帧空间，局部变量表中的Slot是可以重用的，也就是说当PC计数器的指令指已经超出了某个变量的作用域（执行完毕），那这个变量对应的Slot就可以交给其他变量使用。优点 ： 节省栈帧空间。 缺点 ： 影响到系统的垃圾收集行为。（如大方法占用较多的Slot，执行完该方法的作用域后没有对Slot赋值或者清空设置null值，垃圾回收器便不能及时的回收该内存。） 变量槽的复用当一个变量超出了他的作用域范围，那么这个变量的位置可以被复用. 演示1234567public void test()&#123; int a=1; &#123; int b=a; &#125; int c=2; &#125; 加入上述代码不存在复用的情况下应该是4个局部变量，但是由于b的作用域范围超出了，所以b的变量槽就被c所复用。也就是数上述代码分配的局部变量长度为3 异常如果线程请求的栈深度大于虚拟机所允许的深度，则会抛出StackOverFlowError异常，如果虚拟机栈容量可以动态扩展，当栈扩展无法申请到新的内存的时候会抛出OutOfMemoryError异常 操作数栈是一个后入先出的栈，和局部变量表一样，在编译时候他的最大深度被写入到了Code属性的max_stacks数据项中，其中32位数据占用容量为1,64位操作数占用容量为2 本地方法栈 本地方法栈和虚拟机栈功能是非常类似的，异常也是非常类似，本地方法栈就是执行一些（Native）的本地方法 在Hot-Spot虚拟机中将虚拟机栈和本地方法栈合二为一 JAVA堆java堆是虚拟机所管理的内存中最大的一块。（注意是虚拟机管理） 作用存放对象实例和数组 java对象实例几乎都在这上面存放（注意几乎） 特点 java堆被所有的线程所共享 java堆在物理上可以是不连续的，但是在逻辑上应该被视为连续的 堆大小是可以固定的，也是可以设置大小的（通过-Xmx和-Xms设置）,也是可以自动扩展的 如果java虚拟机没有完成实例分配，并且堆也无法在扩展时，java虚拟机将会抛出OutOfMemoryError异常 在java中对象一定是在堆中分配吗？在Java虚拟机中，对象是在Java堆中分配内存的，这是一个普遍的常识。但是，有一种特殊情况，那就是如果经过逃逸分析后发现，一个对象并没有逃逸出方法的话，那么就可能被优化成栈上分配。这样就无需在堆上分配内存，也无须进行垃圾回收了。 方法区和java堆一样是各个线程共享的内存区域，他用于存储已经被虚拟机加载的类型信息，常量，静态变量，即时编译器编译后的代码缓存等数据，这里也是需要垃圾回收的。 在JDK8之前，Hospot虚拟机采用永久代来实现方法区，原因就是可以吧垃圾收集器的分代设计扩展到方法区，但是容易导致内存溢出的问题，在JDK8之后使用元空间实现。 运行时常量池运行时常量池是方法区的一部分。Class文件中除了有类的版本，字段，方法，接口等描述信息外，还有一项就是常量池。并且常量池相对于Class文件的另一个重要特征就是具备动态性 用于存放编译期生成的各种字面量与符号引用，这些内容在类加载后存放到方法区的运行时常量池中。 常量池无法申请到内存时会抛出OutOfMemoryError异常 直接内存在JDK1.4中加入了NIO类，引入了基于通道与缓冲区的I/O方式，可以使用Native函数直接分配堆外内存，避免了在java堆中和Native中来回复制数据，如果无法动态扩展时就会出现OutOfMemoryError溢异常 对象的内存布局一个Java对象在内存中包括对象头、实例数据和补齐填充3个部分： 对象头 Mark Word：包含一系列的标记位，比如轻量级锁的标记位，偏向锁标记位等等。在32位系统占4字节，在64位系统中占8字节； Class Pointer：用来指向对象对应的Class对象（其对应的元数据对象）的内存地址。在32位系统占4字节，在64位系统中占8字节； Length：如果是数组对象，还有一个保存数组长度的空间，占4个字节； 对象实际数据对象实际数据包括了对象的所有成员变量，其大小由各个成员变量的大小决定，比如：byte和boolean是1个字节，short和char是2个字节，int和float是4个字节，long和double是8个字节，reference是4个字节（64位系统中是8个字节）。 Primitive Type Memory Required(bytes) boolean 1 byte 1 short 2 char 2 int 4 float 4 long 8 double 8 对于reference类型来说，在32位系统上占用4bytes, 在64位系统上占用8bytes。 对齐填充Java对象占用空间是8字节对齐的，即所有Java对象占用bytes数必须是8的倍数。例如，一个包含两个属性的对象：int和byte，这个对象需要占用8+4+1=13个字节，这时就需要加上大小为3字节的padding进行8字节对齐，最终占用大小为16个字节。 注意：以上对64位操作系统的描述是未开启指针压缩的情况，关于指针压缩会在下文中介绍。 对象头占用空间大小这里说明一下32位系统和64位系统中对象所占用内存空间的大小： 在32位系统下，存放Class Pointer的空间大小是4字节，MarkWord是4字节，对象头为8字节; 在64位系统下，存放Class Pointer的空间大小是8字节，MarkWord是8字节，对象头为16字节; 64位开启指针压缩的情况下，存放Class Pointer的空间大小是4字节，MarkWord是8字节，对象头为12字节; 如果是数组对象，对象头的大小为：数组对象头8字节+数组长度4字节+对齐4字节=16字节。其中对象引用占4字节（未开启指针压缩的64位为8字节），数组MarkWord为4字节（64位未开启指针压缩的为8字节）; 静态属性不算在对象大小内。 指针压缩从上文的分析中可以看到，64位JVM消耗的内存会比32位的要多大约1.5倍，这是因为对象指针在64位JVM下有更宽的寻址。对于那些将要从32位平台移植到64位的应用来说，平白无辜多了1/2的内存占用，这是开发者不愿意看到的。 从JDK 1.6 update14开始，64位的JVM正式支持了 -XX:+UseCompressedOops 这个可以压缩指针，起到节约内存占用的新参数。 什么是OOP？OOP的全称为：Ordinary Object Pointer，就是普通对象指针。启用CompressOops后，会压缩的对象： 每个Class的属性指针（静态成员变量）； 每个对象的属性指针； 普通对象数组的每个元素指针。 当然，压缩也不是所有的指针都会压缩，对一些特殊类型的指针，JVM是不会优化的，例如指向PermGen的Class对象指针、本地变量、堆栈元素、入参、返回值和NULL指针不会被压缩。 启用指针压缩在Java程序启动时增加JVM参数：-XX:+UseCompressedOops来启用。 注意：32位HotSpot VM是不支持UseCompressedOops参数的，只有64位HotSpot VM才支持。 本文中使用的是JDK 1.8，默认该参数就是开启的。 包装类型包装类（Boolean/Byte/Short/Character/Integer/Long/Double/Float）占用内存的大小等于对象头大小加上底层基础数据类型的大小。 包装类型的Retained Size占用情况如下： 数据类型 开启指针压缩 关闭指针压缩 Byte, Boolean 16 bytes 24 bytes Short, Character 16 bytes 24 bytes Integer, Float 16 bytes 24 bytes Long, Double 24 bytes 24 bytes 对象头解读我使用的环境是64位JDK1.8，并且开启了指针压缩 如果要查看对象头信息需要导入包 12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.8&lt;/version&gt;&lt;/dependency&gt; 例如代码 123456789101112public class Oop &#123; public static void main(String[] args) &#123; Ob ob = new Ob(); ob.hashCode(); System.out.println("hashCode="+Integer.toHexString(ob.hashCode()));//只有使用过了hashCodeMarkWord里面才会有hashCode System.out.println(ClassLayout.parseInstance(ob).toPrintable()); &#125;&#125;class Ob&#123; Long a; static int sa;&#125; 打印结果 123456789hashCode=6d6f6e28Ob object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 28 6e 6f (00000001 00101000 01101110 01101111) (1869490177) 4 4 (object header) 6d 00 00 00 (01101101 00000000 00000000 00000000) (109) 8 4 (object header) 43 c1 00 f8 (01000011 11000001 00000000 11111000) (-134168253) 12 4 java.lang.Long Ob.a nullInstance size: 16 bytesSpace losses: 0 bytes internal + 0 bytes external = 0 bytes total 由于存在大端和小端的读法，所以hashCode正好相反。 其中最后一个字节01字节码对应的二进制是00000001，根据图可知0 是cms_free，0000是分代年龄，01表明是无锁状态 对象的创建过程 当java虚拟机遇到字节码new的时候首先检查这个指令的参数能否在常量池中定位到一个类的符号引用。 并且检查这个符号的引用代表的类是否已经被加载、解析和初始化。 如果没有就执行类的加载、解析和初始化。 在类的加载检查通过后，虚拟机将会为新生对象分配内存。对象所需要内存的大小在类加载后便可完全确定。 在完成内存分配后虚拟机还要对对象进行必要的设计，例如这个对象是哪个类的实例，如何才能找到类的元数据信息，对象的哈希码，对象GC的年龄等。 之后在虚拟机的角度来看，一个新的对象已经产生了。但是还需要调用&lt; cinit &gt;和&lt; init &gt; 如何判断对象是否死亡有项研究表明，新生代中的内存有百分之98熬不过第一轮回收 引用计数法在对象的内部添加一个引用计数器，当一个地方引用它时计数器就加一；当引用失效时，计数器值就减一，（java虚拟机并不是使用这种方法来进行判定的） 特点优点虽然占用了一些额外内存空间，但是它原理很简单，判定效率也很高。 缺点如果两个对象的静态变量相互持有对方，并且这两个对象永远不会执行，那么上面的方法是无法回收这两个“垃圾的” 可达性分析算法（java和C#都是使用这个算法进行判断对象是否存活）通过一系列称为“GC Roots”的根对象作为起始节点集，然后根据引用关系向下搜索，搜索过程中所走过的路径被称为引用链，如果某个对象与GC Roots间没有任何引用链相连，那么这个对象不可能再次被使用。 过程如果对象在进行可达性分析发现并没有与GC Roots相连，那么将会第一次标记这个对象，在随后进行一次筛选，筛选的条件是看看对象是否有必要执行finalize()方法，（一个对象只能被执行一次finalize方法），如果对象没有覆盖该方法或该方法已经被调用过了，那么就没有必要执行，对象将会被回收，如果执行了finalize方法，且对象在方法中重新持有了对象的引用，那么这个对象可以被救活。 扩展finalize()如今已经被官方声明为不推荐使用语法，有些教科书上说这个方法适合做一些对象被回收时的清理工作，事实上这是个错误的，try-catch-finally比这个方法更适合做这些事情。 知道了哪些对象已经死亡，那么如何清理这些对象分代收集理论收集器应该讲java堆划分不同区域，然后回收对象依据其年龄（即对象熬过垃圾收集过程的次数）分配到不同的区域中 如果一个区域中的对象都是朝生熄灭的，那么我们把他们放在一起，称他们为“新生代” 如果都是一些年龄比较大的那么我们把他们放在一起，称他们为”老年代” 带来的问题对象不是孤立的，对象之间可能出现跨代引用，但是我们可以得知，如果一个老年代对象引用了一个新生代的对象，那么这个新生代的对象大概率会存活，因为老年代对象引用了他。 标记-清除算法第一个阶段标记所有需要回收的对象，标记完成后统一回收所有的对象，当然也可以标记不要要回收的对象，标记完成后统一回收没有标记的对象。 特点 执行效率不稳定，如果java堆中包含大量对象。而且大部分是需要被回收的，这时必须进行大量标记和清除动作，导致标记和清除过程随着对象数量增长而降低。 内存空间的碎片化问题，标记后会产生大量不连续的内存碎片。 标记-复制算法将内存按容量划分为大小相等的两块，每次使用只使用其中的一块，当其中的一块用完后，就把所有存活的对象复制到另一块上面，然后把原来的内存块全部清除。 特点优点 解决了标记-除算法内存空间碎片化问题 实现简单运行高效，分配内存时按顺序分配即可 缺点 如果内存中多数对象都是存活的，那么这种算法复制时会产生大量的时间开销 内存浪费严重，将可用内存缩小了原来的一半 标记-整理算法和标记-清除算法一样，但是后续不是对可回收对象进行清理，而是让所有存活的对象都向内存空间一端移动，然后直接清理掉边界内存。 特点缺点 如果移动存活对象，尤其是在老年代这种每次回收都有大量对象存活的区域，移动并更新所有这些对象的敌法将会是一个消耗极大的操作。 而且这种移动对象必须全程暂停用户应用程序。 简单的介绍一下强引用,软引用,弱引用,虚引用无论是通过引用计数法判断对象引用数量，还是通过可达性分析法判断对象的引用链是否可达，判定对象的存活都与“引用”有关。 JDK1.2之前，Java中引用的定义很传统：如果reference类型的数据存储的数值代表的是另一块内存的起始地址，就称这块内存代表一个引用。 JDK1.2以后，Java对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用四种（引用强度逐渐减弱） 强引用(StrongReference)以前我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。当内存空 间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。 软引用(SoftReference)如果一个对象只具有软引用，那就类似于可有可无的生活用品。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA虚拟机就会把这个软引用加入到与之关联的引用队列中。 弱引用(WeakReference)如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 虚引用（PhantomReference）“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。 虚引用主要用来跟踪对象被垃圾回收的活动。 虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃 圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是 否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速JVM对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。 触发GC的条件 首先，GC堆内存分为三部分：Young Generation，Old Generation，Permanent Generation。 ​ Young Generation 分为：Eden , Survivor1 , Survivor2， 新创建的对象会分配在Eden区,在经历一次Minor GC后会被移到Survivor 1区，再经历一次Minor GC后会被移到Survivor 2区，如果Survivor空间不足，则会直接把存活对象复制到老年代，然后清空eden区,需要注意的是，一些大对象(长字符串或数组)可能会直接存放到老年代；升到老年代当空间不足的时候，会发生Full GC，或者小于时，查看是否设置了XX:+HandlePromotionFailure(允许担保失败)参数，若允许，则只会进行Minor GC，此时可以容忍内存分配失败；若不允许，强制Full GC。 触发MinorGC(Young GC) 虚拟机在进行minorGC之前会判断老年代最大的可用连续空间是否大于新生代的所有对象总空间 1、如果大于的话，直接执行minorGC 2、如果小于，判断是否开启HandlerPromotionFailure，没有开启直接FullGC 3、如果开启了HanlerPromotionFailure, JVM会判断老年代的最大连续内存空间是否大于历次晋升的大小，如果小于直接执行FullGC 4、如果大于的话，执行minorGC 触发FullGC 老年代空间不足 如果创建一个大对象，Eden区域当中放不下这个大对象，会直接保存在老年代当中，如果老年代空间也不足，就会触发Full GC。为了避免这种情况，最好就是不要创建太大的对象。 持久代空间不足 如果有持久代空间的话，系统当中需要加载的类，调用的方法很多，同时持久代当中没有足够的空间，就出触发一次Full GC YGC出现promotion failure promotion failure发生在Young GC, 如果Survivor区当中存活对象的年龄达到了设定值，会就将Survivor区当中的对象拷贝到老年代，如果老年代的空间不足，就会发生promotion failure， 接下去就会发生Full GC. 统计YGC发生时晋升到老年代的平均总大小大于老年代的空闲空间 在发生YGC是会判断，是否安全，这里的安全指的是，当前老年代空间可以容纳YGC晋升的对象的平均大小，如果不安全，就不会执行YGC,转而执行Full GC。 显示调用System.gc通知垃圾回收时 经典垃圾收集器Serial收集器Serial收集器是最基础、历史最悠久的收集器，曾经（在JDK1.3.1之前）是HotSpot虚拟机新生代收集器的唯一选择，时至今日，垃圾收集器的不断改进，不断出新，Serial依然在我们的垃圾收集器的选项里面。 特点 优点：简单高效，拥有很高的单线程收集效率 缺点：收集过程需要暂停所有线程 使用算法：复制算法 适用范围：新生代 应用：Client模式下的默认新生代收集器 1对于Serial收集器缺点有一个比较有意思的故事：Serial收集器的运行过程需要暂停应用程序所有线程（Stop The World），它带给用户的恶劣体验。早期HotSpot虚拟机的设计者们表示完全理解，但也同时表示非常委屈：“你妈妈在给你打扫房间的时候，肯定也会让你老老实实地在椅子上或者房间外待着，如果她一边打扫，你一边乱扔纸屑，这房间还能打扫完？”这确实是一个合情合理的矛盾，虽然垃圾收集这项工作听起来和打扫房间属于一个工种，但实际上肯定还要比打扫房间复杂得多！（现在的垃圾收集器一样需要停顿，只是都做到了毫秒级） 使用该垃圾收集器 -XX:+UseSerialGC使用之前我们可以去查看一下，当前虚拟机是否使用的Serial，如果是我们不需要去更改，如果不是则添加参数：-XX:+UseSerialGC。 ParNew收集器ParNew收集器实质上是Serial收集器的多线程并行版本 ParNew收集器的特点：优点：在多CPU时，比Serial效率高。 缺点：收集过程暂停所有应用程序线程，单CPU时比Serial效率差。 使用算法：复制算法 适用范围：新生代 应用：运行在Server模式下的虚拟机中首选的新生代收集器使用ParNew收集器 -XX:+UseParNewGC Parallel Scavenge收集器Parallel Scavenge收集器也是一款新生代收集器，它同样是基于标记-复制算法实现的收集器，也是能够并行收集的多线程收集器……Parallel Scavenge的诸多特性从表面上看和ParNew非常相似，Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput）。所谓吞吐量就是处理器用于运行用户代码的时间与处理器总消耗时间的比值。 吞吐量 = 运行用户代码时间/运行用户代码时间 + 运行垃圾收集器时间。 比如虚拟机总共运行了100分钟，垃圾收集时间用了1分钟，吞吐量=(100-1)/100=99%。 若吞吐量越大，意味着垃圾收集的时间越短，则用户代码可以充分利用CPU资源，尽快完成程序的运算任务。 吞吐量我们可以自行控制？吞吐量我们从上面的描述可以看到，他是一个比值。那么我们自然能够通过调整比值的参数来影响吞吐量。主要涉及的命令有一下两个 -XX:MaxGCPauseMillis 控制最大的垃圾收集时间-XX:GCTimeRatio 直接设置吞吐量的大小根据吞吐量对应的计算公式我们可以看到，当我们的垃圾收集停顿时间变短的时候（垃圾收集停顿是一个大于0的毫秒数），我们的吞吐量在增大。不过大家不要异想天开地认为如果把这个参数的值设置得更小一点就能使得系统的垃圾收集速度变得更快，当我们把这个参数设置的更小的时候，它对应的能够有效收集的时间或者空间会变小。假若停顿时间为100ms能够收集500M的堆空间，那么50ms能够收集的空间可能会低于250M的堆空间。垃圾收集器的有效工作时间变短，收集垃圾的效率并不一定提高，同时对应的也只能相对的调整我们的吞吐量。 使用Parallel Scavenge收集器 -XX:+UseParallelGCSerial Old收集器Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用标记-整理算法。这个收集器的主要意义也是供客户端模式下的HotSpot虚拟机使用。 Parallel Old收集器Parallel Old收集器是Parallel Scavenge收集器的老年代版本，使用多线程和”标记-整理算法”进行垃圾回收。 CMS收集器 CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为四个步骤，包括： 1）初始标记（CMS initial mark）2）并发标记（CMS concurrent mark）3）重新标记（CMS remark）4）并发清除（CMS concurrent sweep）由于整个过程中，并发标记和并发清除，收集器线程可以与用户线程一起工作，所以总体上来说，CMS收集器的内存回收过程是与用户线程一起并发地执行的。 CMS收集器特点：优点：并发收集、低停顿缺点：产生大量空间碎片、并发阶段会降低吞吐量 使用CMS收集器 -XX:+UseConcMarkSweepGCGarbage First收集器Garbage First（简称G1）收集器是垃圾收集器技术发展历史上的里程碑式的成果，它是一款主要面向服务端应用的垃圾收集器 使用G1收集器时，Java堆的内存布局与就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。 G1收集器的运作过程大致可划分为以下四个步骤：初始标记（Initial Marking）并发标记（Concurrent Marking）最终标记（Final Marking）筛选回收（Live Data Counting and Evacuation） 判断是否需要使用G1收集器？（1）50%以上的堆被存活对象占用（2）对象分配和晋升的速度变化非常大（3）垃圾回收时间比较长使用Garbage First收集器 -XX:+UseG1G]]></content>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal详解]]></title>
    <url>%2F2020%2F04%2F18%2FThreadLocal%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[ThreadLocal简介 多线程访问同一个共享变量的时候容易产生并发问题，为了保证线程安全除了使用锁的方式，使用ThreadLocal达到线程隔离的效果，也是一种不错的方案 功能 传递数据，因为同一个线程在任何情况下获取到的都是同一个对象 线程隔离，不同线程拿到的对象都是该线程放进去的对象 演示12345678910111213141516171819202122232425262728public class ThreadLocalTest &#123; public static void main(String[] args) &#123; Threadmsg threadmsg = new Threadmsg(); for (int i = 0; i &lt;100 ; i++) &#123; new Thread(()-&gt;&#123; threadmsg.setName(Thread.currentThread().getName()); try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+"取出---&gt;"+threadmsg.getName()); &#125;).start(); &#125; &#125;&#125;class Threadmsg&#123; private ThreadLocal&lt;String&gt; threadLocal=new ThreadLocal&lt;&gt;(); private String name; public String getName() &#123; return threadLocal.get(); &#125; public void setName(String name) &#123; threadLocal.set(name); &#125;&#125; 最后实现了线程隔离 使用synchronized实现线程隔离1234567891011121314151617181920212223242526272829public class ThreadLocalTest &#123; public static void main(String[] args) &#123; Threadmsg threadmsg = new Threadmsg(); for (int i = 0; i &lt;100 ; i++) &#123; new Thread(()-&gt;&#123; synchronized(ThreadLocalTest.class)&#123; threadmsg.setName(Thread.currentThread().getName()); try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+"取出---&gt;"+threadmsg.getName()); &#125; &#125;).start(); &#125; &#125;&#125;class Threadmsg&#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name=name; &#125;&#125; ThreadLocal与Synchronized的区别相同：ThreadLocal和线程同步机制都是为了解决多线程中相同变量的访问冲突问题。不同：Synchronized同步机制采用了“以时间换空间”的方式，仅提供一份变量，让不同的线程排队访问；而ThreadLocal采用了“以空间换时间”的方式，每一个线程都提供了一份变量，因此可以同时访问而互不影响。 以时间换空间-&gt;即枷锁方式，某个区域代码或变量只有一份节省了内存，但是会形成很多线程等待现象，因此浪费了时间而节省了空间。以空间换时间-&gt;为每一个线程提供一份变量，多开销一些内存，但是呢线程不用等待，可以一起执行而相互之间没有影响。 小结：ThreadLocal是解决线程安全问题一个很好的思路，它通过为每个线程提供一个独立的变量副本解决了变量并发访问的冲突问题。在很多情况下，ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。 常用方法 方法 作用 public ThreadLocal&lt; T &gt;() 构造方法 public T get() 获取当前线程绑定的数据 public void set(T value) 把value绑定给当前线程 public void remove() 移除当前线程绑定的数据 ThreadLocal原理Thread类中有两个变量threadLocals和inheritableThreadLocals，二者都是ThreadLocal内部类ThreadLocalMap类型的变量，我们通过查看内部内ThreadLocalMap可以发现实际上它类似于一个HashMap。 在默认情况下，每个线程中的这两个变量都为null 123456ThreadLocal.ThreadLocalMap threadLocals = null;/* * InheritableThreadLocal values pertaining to this thread. This map is * maintained by the InheritableThreadLocal class. */ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; 当线程第一次调用ThreadLocal的set或者get方法的时候才会创建他们。除此之外，和我所想的不同的是，每个线程的本地变量不是存放在ThreadLocal实例中，而是放在调用线程的ThreadLocals变量里面。也就是说，ThreadLocal类型的本地变量是存放在具体的线程空间上，其本身相当于一个装载本地变量的工具壳，通过set方法将value添加到调用线程的threadLocals中，当调用线程调用get方法时候能够从它的threadLocals中取出变量。如果调用线程一直不终止，那么这个本地变量将会一直存放在他的threadLocals中，所以不使用本地变量的时候需要调用remove方法将threadLocals中删除不用的本地变量。 ThreadLocal set()方法123456789101112public void set(T value) &#123; //获取当前线程实例 Thread t = Thread.currentThread(); //获取当前线程的ThreadLocalMap ThreadLocalMap map = getMap(t); //map存在直接设置 if (map != null) //存入的key是ThreadLocal的实例对象 map.set(this, value); else//map不存在则创建map。将value设置到map createMap(t, value);&#125; 源码解析： 获取当前线程的成员变量Map Map不为空：重新将ThreadLocal对象作为key和Value副本放入Map中 Map为空：对线程成员变量ThreadLocalMap进行初始化创建，并将ThreadLocal对象和Value副本放入Map中 ThreadLocal get()方法12345678910111213141516171819202122232425262728public T get() &#123; //获取当前线程实例 Thread t = Thread.currentThread(); //拿到当前线程实例的ThreadLocalMap ThreadLocalMap map = getMap(t); //如果map不为空就查找map中本地变量的值 if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; //如果map为空，或者Entry为null，则初始化当前线程的threadLocals变量 return setInitialValue();&#125;private T setInitialValue() &#123; T value = initialValue();//获取null Thread t = Thread.currentThread();//拿到当前线程 ThreadLocalMap map = getMap(t); //判断map是否存在 if (map != null)//存在设置value为null map.set(this, value); else//不存在创建map,并设置value为null createMap(t, value); return value;&#125; 源码解析： 获取当前线程的ThreadLocalMap对象threadLocals（实际储存副本值的Map） Map不为空的话，从Map中获取线程储存的K-V Entry结点，然后从Entry结点中获取Value副本值返回 Map为空的话，返回初始值null，之后还需向Map中添加value为null的键值对，避免空指针异常 remove()方法1234567 public void remove() &#123;//获取当前线程绑定的threadLocals ThreadLocalMap m = getMap(Thread.currentThread()); //如果map不为null，就移除当前线程中指定ThreadLocal实例的本地变量 if (m != null) m.remove(this); &#125; ThreadLocalMap详解 ThreadLocalMap提供了一种为ThreadLocal定制的高效实现，并且自带一种基于弱引用的垃圾清理机制。 存储结构（Entry节点）ThreadLocalMap这个map并没有实现java提供的map，而是作者直接开发了一套map。 123456789static class Entry extends WeakReference&lt;java.lang.ThreadLocal&lt;?&gt;&gt; &#123; // 往ThreadLocal里实际塞入的值 Object value; Entry(java.lang.ThreadLocal&lt;?&gt; k, Object v) &#123;//传入的类型只能是ThreadLocal类型 super(k); value = v; &#125;&#125; Entry便是ThreadLocalMap里定义的节点，它继承了WeakReference类，定义了一个类型为Object的value，用于存放塞到ThreadLocal里的值。说明这是一个弱引用 为什么要用弱引用呢？因为如果这里使用普通的key-value形式来定义存储结构，实质上就会造成节点的生命周期与线程强绑定，只要线程没有销毁，那么节点在GC分析中一直处于可达状态，没办法被回收，而程序本身也无法判断是否可以清理节点。弱引用是Java中四档引用的第三档，比软引用更加弱一些，如果一个对象没有强引用链可达，那么一般活不过下一次GC。当某个ThreadLocal已经没有强引用可达，则随着它被垃圾回收，在ThreadLocalMap里对应的Entry的键值会失效，这为ThreadLocalMap本身的垃圾清理提供了便利。 成员变量12345678910111213141516171819/** * 初始容量，必须为2的幂 */private static final int INITIAL_CAPACITY = 16;/** * Entry表，大小必须为2的幂 */private Entry[] table;/** * 表里entry的个数 */private int size = 0;/** * 重新分配表大小的阈值，默认为0 */private int threshold; 可以看到，ThreadLocalMap维护了一个Entry表或者说Entry数组，并且要求表的大小必须为2的幂，同时记录表里面entry的个数以及下一次需要扩容的阈值。显然这里会产生一个问题，为什么必须是2的幂？ 1234567891011121314151617181920/** * 设置resize阈值以维持最坏2/3的装载因子 */private void setThreshold(int len) &#123; threshold = len * 2 / 3;&#125;/** * 环形意义的下一个索引 */private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0);&#125;/** * 环形意义的上一个索引 */private static int prevIndex(int i, int len) &#123; return ((i - 1 &gt;= 0) ? i - 1 : len - 1);&#125; ThreadLocal需要维持一个最坏2/3的负载因子，对于负载因子相信应该不会陌生，在HashMap中就有这个概念。ThreadLocal有两个方法用于得到上一个/下一个索引，注意这里实际上是环形意义下的上一个与下一个,由于ThreadLocalMap使用线性探测法来解决散列冲突，所以实际上Entry[]数组在程序逻辑上是作为一个环形存在的。 ThreadLocalMap维护了Entry环形数组，数组中元素Entry的逻辑上的key为某个ThreadLocal对象（实际上是指向该ThreadLocal对象的弱引用），value为代码中该线程往该ThreadLoacl变量实际塞入的值。 构造方法12345678910111213141516/** * 构造一个包含firstKey和firstValue的map。 * ThreadLocalMap是惰性构造的，所以只有当至少要往里面放一个元素的时候才会构建它。 */ThreadLocalMap(java.lang.ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; // 初始化table数组 table = new Entry[INITIAL_CAPACITY]; // 用firstKey的threadLocalHashCode与初始大小16取模得到哈希值 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); // 初始化该节点 table[i] = new Entry(firstKey, firstValue); // 设置节点表大小为1 size = 1; // 设定扩容阈值 setThreshold(INITIAL_CAPACITY);&#125; 这个构造函数在set和get的时候都可能会被间接调用以初始化线程的ThreadLocalMap。 哈希函数重点看一下上面构造函数中的int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);这一行代码。 ThreadLocal类中有一个被final修饰的类型为int的threadLocalHashCode，它在该ThreadLocal被构造的时候就会生成，相当于一个ThreadLocal的ID。 12345678/* * 生成hash code间隙为这个魔数，可以让生成出来的值或者说ThreadLocal的ID较为均匀地分布在2的幂大小的数组中。 */private static final int HASH_INCREMENT = 0x61c88647;private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125; getEntry方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; // 根据key这个ThreadLocal的ID来获取索引，也即哈希值 int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; // 对应的entry存在且未失效且弱引用指向的ThreadLocal就是key，则命中返回 if (e != null &amp;&amp; e.get() == key) &#123; return e; &#125; else &#123; // 因为用的是线性探测，所以往后找还是有可能能够找到目标Entry的。 return getEntryAfterMiss(key, i, e); &#125;&#125;/* * 调用getEntry未直接命中的时候调用此方法 */private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; // 基于线性探测法不断向后探测直到遇到空entry。 while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 找到目标 if (k == key) &#123; return e; &#125; if (k == null) &#123; // 该entry对应的ThreadLocal已经被回收，调用expungeStaleEntry来清理无效的entry expungeStaleEntry(i); &#125; else &#123; // 环形意义下往后面走 i = nextIndex(i, len); &#125; e = tab[i]; &#125; return null;&#125;/** * 这个函数是ThreadLocal中核心清理函数，它做的事情很简单： * 就是从staleSlot开始遍历，将无效（弱引用指向对象被回收）清理，即对应entry中的value置为null，将指向这个entry的table[i]置为null，直到扫到空entry。 * 另外，在过程中还会对非空的entry作rehash。 * 可以说这个函数的作用就是从staleSlot开始清理连续段中的slot（断开强引用，rehash slot等） */private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // 因为entry对应的ThreadLocal已经被回收，value设为null，显式断开强引用 tab[staleSlot].value = null; // 显式设置该entry为null，以便垃圾回收 tab[staleSlot] = null; size--; Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 清理对应ThreadLocal已经被回收的entry if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; /* * 对于还没有被回收的情况，需要做一次rehash。 * * 如果对应的ThreadLocal的ID对len取模出来的索引h不为当前位置i， * 则从h向后线性探测到第一个空的slot，把当前的entry给挪过去。 */ int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; /* * 在原代码的这里有句注释值得一提，原注释如下： * * Unlike Knuth 6.4 Algorithm R, we must scan until * null because multiple entries could have been stale. * * 这段话提及了Knuth高德纳的著作TAOCP（《计算机程序设计艺术》）的6.4章节（散列） * 中的R算法。R算法描述了如何从使用线性探测的散列表中删除一个元素。 * R算法维护了一个上次删除元素的index，当在非空连续段中扫到某个entry的哈希值取模后的索引 * 还没有遍历到时，会将该entry挪到index那个位置，并更新当前位置为新的index， * 继续向后扫描直到遇到空的entry。 * * ThreadLocalMap因为使用了弱引用，所以其实每个slot的状态有三种也即 * 有效（value未回收），无效（value已回收），空（entry==null）。 * 正是因为ThreadLocalMap的entry有三种状态，所以不能完全套高德纳原书的R算法。 * * 因为expungeStaleEntry函数在扫描过程中还会对无效slot清理将之转为空slot， * 如果直接套用R算法，可能会出现具有相同哈希值的entry之间断开（中间有空entry）。 */ while (tab[h] != null) &#123; h = nextIndex(h, len); &#125; tab[h] = e; &#125; &#125; &#125; // 返回staleSlot之后第一个空的slot索引 return i;&#125; 我们来回顾一下从ThreadLocal读一个值可能遇到的情况：根据入参threadLocal的threadLocalHashCode对表容量取模得到index 如果index对应的slot就是要读的threadLocal，则直接返回结果 调用getEntryAfterMiss线性探测，过程中每碰到无效slot，调用expungeStaleEntry进行段清理；如果找到了key，则返回结果entry 没有找到key，返回null set方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len - 1); // 线性探测 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 找到对应的entry if (k == key) &#123; e.value = value; return; &#125; // 替换失效的entry if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) &#123; rehash(); &#125;&#125;private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; // 向前扫描，查找最前的一个无效slot int slotToExpunge = staleSlot; for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) &#123; if (e.get() == null) &#123; slotToExpunge = i; &#125; &#125; // 向后遍历table for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 找到了key，将其与无效的slot交换 if (k == key) &#123; // 更新对应slot的value值 e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; /* * 如果在整个扫描过程中（包括函数一开始的向前扫描与i之前的向后扫描） * 找到了之前的无效slot则以那个位置作为清理的起点， * 否则则以当前的i作为清理起点 */ if (slotToExpunge == staleSlot) &#123; slotToExpunge = i; &#125; // 从slotToExpunge开始做一次连续段的清理，再做一次启发式清理 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; // 如果当前的slot已经无效，并且向前扫描过程中没有无效slot，则更新slotToExpunge为当前位置 if (k == null &amp;&amp; slotToExpunge == staleSlot) &#123; slotToExpunge = i; &#125; &#125; // 如果key在table中不存在，则在原地放一个即可 tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // 在探测过程中如果发现任何无效slot，则做一次清理（连续段清理+启发式清理） if (slotToExpunge != staleSlot) &#123; cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); &#125;&#125;/** * 启发式地清理slot, * i对应entry是非无效（指向的ThreadLocal没被回收，或者entry本身为空） * n是用于控制控制扫描次数的 * 正常情况下如果log n次扫描没有发现无效slot，函数就结束了 * 但是如果发现了无效的slot，将n置为table的长度len，做一次连续段的清理 * 再从下一个空的slot开始继续扫描 * * 这个函数有两处地方会被调用，一处是插入的时候可能会被调用，另外个是在替换无效slot的时候可能会被调用， * 区别是前者传入的n为元素个数，后者为table的容量 */private boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; Entry[] tab = table; int len = tab.length; do &#123; // i在任何情况下自己都不会是一个无效slot，所以从下一个开始判断 i = nextIndex(i, len); Entry e = tab[i]; if (e != null &amp;&amp; e.get() == null) &#123; // 扩大扫描控制因子 n = len; removed = true; // 清理一个连续段 i = expungeStaleEntry(i); &#125; &#125; while ((n &gt;&gt;&gt;= 1) != 0); return removed;&#125;private void rehash() &#123; // 做一次全量清理 expungeStaleEntries(); /* * 因为做了一次清理，所以size很可能会变小。 * ThreadLocalMap这里的实现是调低阈值来判断是否需要扩容， * threshold默认为len*2/3，所以这里的threshold - threshold / 4相当于len/2 */ if (size &gt;= threshold - threshold / 4) &#123; resize(); &#125;&#125;/* * 做一次全量清理 */private void expungeStaleEntries() &#123; Entry[] tab = table; int len = tab.length; for (int j = 0; j &lt; len; j++) &#123; Entry e = tab[j]; if (e != null &amp;&amp; e.get() == null) &#123; /* * 个人觉得这里可以取返回值，如果大于j的话取了用，这样也是可行的。 * 因为expungeStaleEntry执行过程中是把连续段内所有无效slot都清理了一遍了。 */ expungeStaleEntry(j); &#125; &#125;&#125;/** * 扩容，因为需要保证table的容量len为2的幂，所以扩容即扩大2倍 */private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; &#125; else &#123; // 线性探测来存放Entry int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) &#123; h = nextIndex(h, newLen); &#125; newTab[h] = e; count++; &#125; &#125; &#125; setThreshold(newLen); size = count; table = newTab;&#125; 我们来回顾一下ThreadLocal的set方法可能会有的情况 探测过程中slot都不无效，并且顺利找到key所在的slot，直接替换即可 探测过程中发现有无效slot，调用replaceStaleEntry，效果是最终一定会把key和value放在这个slot，并且会尽可能清理无效slot 在replaceStaleEntry过程中，如果找到了key，则做一个swap把它放到那个无效slot中，value置为新值 在replaceStaleEntry过程中，没有找到key，直接在无效slot原地放entry 探测没有发现key，则在连续段末尾的后一个空位置放上entry，这也是线性探测法的一部分。放完后，做一次启发式清理，如果没清理出去key，并且当前table大小已经超过阈值了，则做一次rehash，rehash函数会调用一次全量清理slot方法也即expungeStaleEntries，如果完了之后table大小超过了threshold - threshold / 4，则进行扩容2倍 ThreadLocal与内存泄露关于ThreadLocal是否会引起内存泄漏也是一个比较有争议性的问题，其实就是要看对内存泄漏的准确定义是什么。认为ThreadLocal会引起内存泄漏的说法是因为如果一个ThreadLocal对象被回收了，我们往里面放的value对于【当前线程-&gt;当前线程的threadLocals(ThreadLocal.ThreadLocalMap对象）-&gt;Entry数组-&gt;某个entry.value】这样一条强引用链是可达的，因此value不会被回收。认为ThreadLocal不会引起内存泄漏的说法是因为ThreadLocal.ThreadLocalMap源码实现中自带一套自我清理的机制。 之所以有关于内存泄露的讨论是因为在有线程复用如线程池的场景中，一个线程的寿命很长，大对象长期不被回收影响系统运行效率与安全。如果线程不会复用，用完即销毁了也不会有ThreadLocal引发内存泄露的问题。《Effective Java》一书中的第6条对这种内存泄露称为unintentional object retention(无意识的对象保留）。 当我们仔细读过ThreadLocalMap的源码，我们可以推断，如果在使用的ThreadLocal的过程中，显式地进行remove是个很好的编码习惯，这样是不会引起内存泄漏。那么如果没有显式地进行remove呢？只能说如果对应线程之后调用ThreadLocal的get和set方法都有很高的概率会顺便清理掉无效对象，断开value强引用，从而大对象被收集器回收。 但无论如何，我们应该考虑到何时调用ThreadLocal的remove方法。一个比较熟悉的场景就是对于一个请求一个线程的server如tomcat，在代码中对web api作一个切面，存放一些如用户名等用户信息，在连接点方法结束后，再显式调用remove。]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程总结]]></title>
    <url>%2F2020%2F04%2F15%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[这篇文章只会梳理一下知识，并不会详细讲解每个知识点 上下文切换什么是上下文切换 CPU通过实践片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务的从保存到再加载的过程就是一次上下文切换。 如何减少上下文切换 无锁并发编程。多线程竞争锁时，会引起上下文切换，所以我们可以避免使用锁，例如使用hash算法隔离不同线程的数据。 使用CAS算法，例如java的Atomic包的CAS算法来更新数据，就不需要加锁 使用最少线程。避免创建不需要的线程。 合理使用volatile变量实现多线程，volatile变量比synchronized的使用成本和执行成本更低，而且也不会引起线程的上下文切换和调度。 协程，在单线程里实现多任务的调度，并在单线程里面维持多个任务间的切换。 为什么单线程不一定比多线程慢在多线程的情况下，由于线程间的争抢，难免引入锁的机制，所以相比较单线程由于存在上下文切换，所以以至于单线程不一定比多线程慢。 在并发编程中，将代码执行速度加快的原则是将代码中串行执行的部分变成并发执行，但是如果将某段代码串行改成并发执行，由于受限于资源仍在串行执行，这个时候多线程不仅不会变快，反而会变慢 并发中关注的两个问题线程之间如何通信和线程之间如何同步 线程之间的通信机制有两种共享内存和消息传递 锁如何避免死锁 避免一个线程同时获取多个锁 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源 尝试使用定时锁，使用lock.tryLock(timeout)来代替使用内部锁机制 对于数据库锁，必须保证加锁和解锁必须在一个数据库连接里面，否则会出现解锁失败的情况 volatile volatile是轻量级的synchronizd，它可以保证共享变量的可见性，但不能保证该变量的原子性，并且volatile不会引起线程的上下文切换 》 volatile 官方定义java语言规范第3版对于volatile的定义如下： java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致的更新，线程应该确保通过排它锁单独获取这个变量。 为什么能保证可见性呢凡是被volatile修饰的变量，要求每个线程在取的时候都必须到主内存中去取，写也要强制写入到主内存中。 JAVA内存模型为什么要进行指令重排序？ 在执行程序时，为了提高性能，编译期和处理器常常会对指令做重排序。 例如(只是大概演示重排序的作用，实际上可能并不是如此)1234x=0;y=0;x1=y;y1=x; 有如上代码如果没有指令重排序的话需要花费4条指令的时间 如果进行了重排序可以同时让两个处理器执行 CPU1 CPU2 x=0 y=0 x1=y y1=x 那么就可以不影响结果的情况下花费两个指令的时间。 指令重排序的种类 编译期优化的重排序 指令集并行的重排序，现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应及其指令的执行顺序 内存系统的重排序 源代码—&gt;编译期优化重排序—&gt;指令级并行重排序—-&gt;内存系统重排序—&gt;最终执行的指令 happens-before简介 在JSR-133中使用happens-before的概念来阐述操作之间的内存可见性，如果一个操作执行的结构需要对另一个操作可见，那么这两个操作必须满足happens-before关系，这两个操作可以是同一个线程也可以是不同线程。 happens-before规则 程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。 监视器锁规则：对于一个锁的解锁，happens-before于随后对于这个锁的加锁 volatile变量规则：对于一个volatile域的写，happens-before于任意后续这个volatile域的读 传递性：如果a happens-before b，且b happens-before c，那么a happens-before c。 注意 两个操作之间具有happens-before关系，并不意味着前一个操作一定在后一个操作之前！。而是前一个操作的结果对于后一个操作可见。]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper环境搭建]]></title>
    <url>%2F2020%2F04%2F14%2Fzookeeper%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Mysql锁详解]]></title>
    <url>%2F2020%2F04%2F13%2FMysql%E9%94%81%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[什么是锁 锁是计算机协调多个进程或线程并发访问某一资源的机制。锁保证数据并发访问的一致性、有效性；锁冲突也是影响数据库并发访问性能的一个重要因素。锁是Mysql在服务器层和存储引擎层的的并发控制。 加锁是消耗资源的，锁的各种操作，包括获得锁、检测锁是否是否已解除、释放锁等。 锁的分类按照锁的机制分类 共享锁（读锁）：其他事物可以读，但是不能写 排他锁（写锁）：其他事物不能读取，也不能写。 按照锁的粒度分类表锁（偏读）MyISAM 和 MEMORY 存储引擎采用的是表级锁（table-level locking） 行锁（偏写）InnoDB 存储引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。 页锁BDB 存储引擎采用的是页面锁（page-level locking），但也支持表级锁 MyISAM 表锁读锁演示表结构123456789101112131415-- 表，注意表的存储引擎CREATE TABLE myLock( id INT NOT NULL primary key auto_increment, `name` VARCHAR(30))engine myisam; -- 向表中插入数据INSERT INTO myLock(name) VALUES('a');INSERT INTO myLock(name) VALUES('b');INSERT INTO myLock(name) VALUES('c');INSERT INTO myLock(name) VALUES('d');INSERT INTO myLock(name) VALUES('e');INSERT INTO myLock(name) VALUES('f');INSERT INTO myLock(name) VALUES('g'); 常用sql语法123456-- 查看所有表的锁状态SHOW OPEN TABLES;-- 加锁lock table &lt;表名&gt; read(write),&lt;表名&gt; read(write);-- 解除所有的锁UNLOCK tables; 首先我们开启两个会话 首先我们在黑窗口上给myLock加一把读锁（共享锁） 读然后我们在黑窗口中查找myLock表中的数据 1SELECT * FROM myLock; 我们可以看到能读取出数据 接下来我们开一个新的窗口，直接读myLock这个表 我们可以看到确实是可以读本表的，也就是确实是一个共享锁 读其他表我这个数据库中还有一个其他表，这个表其实是随意了，因为不影响结果 黑窗口读取其他表 1SELECT * FROM user; 我们可以看到，上锁的那个会话在没有释放锁之前是不能读取其他表的，那么其他会话可以么？ 很显然，其他会话可以读取。 那如果我们还可以使用关联查询么？虽然不能读取其他表，我们投机取巧使用关联查询呢？ 很显然也是不可用的。 如果加了表锁那么就没有办法使用关联查询了么？ 我们给user表也加一个锁，在试试关联查询 很显然，如果想使用关联查询，那么所有被查询的表都要被加上锁 这里有个坑，加锁的时候要一步到位。 1234567-- 第一种情况lock table myLock read;lock table user read;-- 第二种情况lock table myLock read,user read;-- 情况是不等价的，第一种情况在第二次给user添加锁的时候会释放myLock的锁 那么其他会话可以使用关联查询么？ 从上面可以看出可以使用关联查询。 写 我们可以看到，黑窗口在没有释放锁的时候，其他表在写操作会进入阻塞状态 当我们释放锁的时候，阻塞状态会立刻消失，从上面可以看出一共阻塞了45秒 MyISAM 表读锁总结 当我们使用了表读锁的时候，所有的线程都可以读，但是都不能写。 不是加锁的线程在写的时候会进入阻塞状态，来等待锁的释放 加锁的线程在不释放锁的时候是不能对没加锁的表进行查找的 如果当前线程使用了表读锁，而且还想进行关联查询，那么要对所有的表进行加锁 MyISAM 表读锁总结 一个线程开启了一个写锁，那么这个锁就是该线程独占的，其他线程对该表的操作都会处于阻塞状态 写一个线程开启了一个表写锁，那么这个线程不能操作其他没有加锁的表 InnoDB加锁方法： 意向锁是 InnoDB 自动加的， 不需用户干预。 对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB 会自动给涉及数据集加排他锁（X)； 对于普通 SELECT 语句，InnoDB 不会加任何锁； 事务可以通过以下语句显式给记录集加共享锁或排他锁： 共享锁（S）：SELECT * FROM table_name WHERE … LOCK IN SHARE MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。 排他锁（X)：SELECT * FROM table_name WHERE … FOR UPDATE。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁 隐式锁定： InnoDB在事务执行过程中，使用两阶段锁协议： 随时都可以执行锁定，InnoDB会根据隔离级别在需要的时候自动加锁； 锁只有在执行commit或者rollback的时候才会释放，并且所有的锁都是在同一时刻被释放。 显式锁定 ： 12select ... lock in share mode //共享锁 select ... for update //排他锁 select for update： 在执行这个 select 查询语句的时候，会将对应的索引访问条目进行上排他锁（X 锁），也就是说这个语句对应的锁就相当于update带来的效果。 select *** for update 的使用场景：为了让自己查到的数据确保是最新数据，并且查到后的数据只允许自己来修改的时候，需要用到 for update 子句。 select lock in share mode ：in share mode 子句的作用就是将查找到的数据加上一个 share 锁，这个就是表示其他的事务只能对这些数据进行简单的select 操作，并不能够进行 DML 操作。select *** lock in share mode 使用场景：为了确保自己查到的数据没有被其他的事务正在修改，也就是说确保查到的数据是最新的数据，并且不允许其他人来修改数据。但是自己不一定能够修改数据，因为有可能其他的事务也对这些数据 使用了 in share mode 的方式上了 S 锁。 性能影响：select for update 语句，相当于一个 update 语句。在业务繁忙的情况下，如果事务没有及时的commit或者rollback 可能会造成其他事务长时间的等待，从而影响数据库的并发使用效率。select lock in share mode 语句是一个给查找的数据上一个共享锁（S 锁）的功能，它允许其他的事务也对该数据上S锁，但是不能够允许对该数据进行修改。如果不及时的commit 或者rollback 也可能会造成大量的事务等待。 for update 和 lock in share mode 的区别： 前一个上的是排他锁（X 锁），一旦一个事务获取了这个锁，其他的事务是没法在这些数据上执行 for update ；后一个是共享锁，多个事务可以同时的对相同数据执行 lock in share mode。 InnoDB锁模式：InnoDB 实现了以下两种类型的行锁： 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。 排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。 为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁： 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。 InnoDB行锁首先行锁是innodb默认的锁，但是在筛选条件里面没有索引字段时就会把整个表锁住. 行锁读锁：允许其他线程上读锁，但是不允许上写锁。 演示黑窗口开启一个事务修改id为1， 另一个窗口同样修改id为2的,结构可以修改成功，如果这两个窗口修改的是同一条数据，那么后修改的会进入阻塞状态，说明是一个行锁。 InnoDB 行锁实现方式： InnoDB 行锁是通过给索引上的索引项加锁来实现的，这一点 MySQL 与 Oracle 不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB 这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁！ 不论是使用主键索引、唯一索引或普通索引，InnoDB 都会使用行锁来对数据加锁。 只有执行计划真正使用了索引，才能使用行锁：即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。因此，在分析锁冲突时， 别忘了检查 SQL 的执行计划（可以通过 explain 检查 SQL 的执行计划），以确认是否真正使用了索引。 由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然多个session是访问不同行的记录， 但是如果是使用相同的索引键， 是会出现锁冲突的（后使用这些索引的session需要等待先使用索引的session释放锁后，才能获取锁）。 应用设计的时候要注意这一点。 锁退化到表锁请注意这个表结构只有id有索引，并且吧这个表的引擎改为InnoDB InnoDB默认的行锁可以使得操作不同行时不会产生相互影响、不会阻塞，从而很好的解决了多事务和并发的问题。但是，那得基于一个前提，即 Where 条件中使用上了索引；反之，如果没有使用上索引，则是全表扫描、全部阻塞。 首先黑窗口一开启一个事务，并且where条件使用一个非索引字段来修改 此时另一个窗口也修改其中的任意一条非同行数据 发现另一个窗口处于阻塞状态。 还有一个隐藏问题如果我们的name字段也有索引那么 12update myLock set id=111 where name="b"//使用到了索引update myLock set id=111 where name=b//没有使用到索引，还是会行锁变表锁 因为涉及到了自动类型转换导致没有使用到索引 总结 更新的时候没有索引或者索引失效时，InnoDB 的行锁变表锁 原因：Mysql 的行锁是通过索引实现的！ 间隙锁间隙锁（Gap Lock）是Innodb在可重复读提交下为了解决幻读问题时引入的锁机制， 幻读的问题存在是因为新增或者更新操作，这时如果进行范围查询的时候（加锁查询），会出现不一致的问题，这时使用不同的行锁已经没有办法满足要求，需要对一定范围内的数据进行加锁，间隙锁就是解决这类问题的。在可重复读隔离级别下，数据库是通过行锁和间隙锁共同组成的（next-key lock），来实现的 加锁规则 加锁的基本单位是（next-key lock)他是前开后闭原则 插叙过程中访问的对象会增加锁 索引上的等值查询–给唯一索引加锁的时候，next-key lock升级为行锁 索引上的等值查询–向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁 唯一索引上的范围查询会访问到不满足条件的第一个值为止 间隙的范围根据检索条件向下寻找最靠近检索条件的记录值A作为左区间，向上寻找最靠近检索条件的记录值B作为右区间，即锁定的间隙为（A，B)。 number 1 2 3 4 5 6 6 6 11id 1 3 5 7 9 10 11 12 23 number 1 2 3 4 5 6 6 6 11 id 1 3 5 7 9 10 11 12 23 select * from t where number=6;那么间隙锁锁定的间隙为：（5，11），所以你再想插入5到11之间的数就会被阻塞。 更需要你注意的是，当你再执行update t set number = 6 where id = 1也会被阻塞。这是为什么？你想想看，要保证每次查询number=6的数据行数不变，如果你将另外一条数据修改成了6，岂不会多了一条？所以此时不会允许任何一条数据被修改成6。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>锁</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[停止线程的方式]]></title>
    <url>%2F2020%2F04%2F12%2F%E5%81%9C%E6%AD%A2%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[方式一使用stop暴力停止 注意该方式以经被弃用，因为它有很大弊端 1234567891011121314public class Thread04 &#123; public static void main(String[] args) &#123; MyThread04 myThread = new MyThread04(); myThread.start(); myThread.stop(); &#125;&#125;class MyThread04 extends Thread&#123; @Override public void run()&#123; while (true)&#123; &#125; &#125;&#125; 弊端 强行停止线程则有可能使一些清理性的工作得不到完成 对锁定的对象进行“解锁“，可能导致数据得不到同步处理，出现数据不一致问题 强行停止导致数据不一样问题1234567891011121314151617181920212223242526272829303132333435public class Thread04 &#123; public static void main(String[] args) throws InterruptedException &#123; MyThread004 myThread = new MyThread004(); myThread.start(); Thread.sleep(500); myThread.stop(); System.out.println(myThread.toString()); &#125;&#125;class MyThread004 extends Thread&#123; String accound="123456"; String password="123456"; @Override public synchronized void run()&#123; while (true)&#123; accound="abc"; try &#123; Thread.sleep(50000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; password="abc"; &#125; &#125; @Override public synchronized String toString() &#123; return "MyThread004&#123;" + "accound='" + accound + '\'' + ", password='" + password + '\'' + '&#125;'; &#125;&#125; 1MyThread004&#123;accound='abc', password='123456'&#125; 由于accound和password在没有完全完成被赋值操作的时候就被强行停止了，所以引发了不一致问题。 方式二使用return1234567891011121314151617181920public class Thread04 &#123; public static void main(String[] args) throws InterruptedException &#123; MyThread04 myThread = new MyThread04(); myThread.start(); Thread.sleep(500); System.out.println(myThread.toString()); myThread.interrupt(); &#125;&#125;class MyThread04 extends Thread&#123; @Override public void run()&#123; while (true)&#123; if(this.isInterrupted())&#123; System.out.println("线程已经停止"); return; &#125; &#125; &#125;&#125; 方式三沉睡中暂停123456789101112131415161718192021public class Thread07 &#123; public static void main(String[] args) throws InterruptedException &#123; MyThread07 myThread = new MyThread07(); myThread.start(); Thread.sleep(200); myThread.interrupt(); &#125;&#125;class MyThread07 extends Thread&#123; @Override public void run()&#123; try &#123; System.out.println(Thread.currentThread().getName()+"开始执行"); Thread.sleep(200000); System.out.println(Thread.currentThread().getName()+"执行完毕"); &#125; catch (InterruptedException e) &#123; System.out.println(Thread.currentThread().getName()+"停止执行"); e.printStackTrace(); &#125; &#125;&#125; 方式四异常停止123456789101112131415161718192021public class Thread07 &#123; public static void main(String[] args) throws InterruptedException &#123; MyThread07 myThread = new MyThread07(); myThread.start(); Thread.sleep(200); myThread.interrupt(); &#125;&#125;class MyThread07 extends Thread&#123; @Override public void run()&#123; try &#123; System.out.println(Thread.currentThread().getName()+"开始执行");// Thread.sleep(200000); throw new RuntimeException("hh"); &#125; catch (Exception e) &#123; System.out.println(Thread.currentThread().getName()+"停止执行"); e.printStackTrace(); &#125; &#125;&#125; 总结 推荐使用return的方式来停止线程，个人觉得这种方式更可控 不行还可以使用异常的方式来停止线程，因为我们使用这种方式可以在finally块中解决stop强行停止线程带来的弊端 强烈不推荐使用stop强行停止，因为代价太大。]]></content>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
        <tag>线程停止</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Thread中interrupted()方法和isInterrupted()方法区别]]></title>
    <url>%2F2020%2F04%2F12%2FThread%E4%B8%ADinterrupted-%E6%96%B9%E6%B3%95%E5%92%8CisInterrupted-%E6%96%B9%E6%B3%95%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[源代码对比123456public boolean isInterrupted() &#123; return isInterrupted(false);&#125;public static boolean interrupted() &#123; return currentThread().isInterrupted(true);&#125; isInterrupted是非静态的 interrupted是静态的，而且本质上是调用了当前线程中的isInterrupted 方法，不过传入了一个参数true 区别 当我们调用线程停止方法interrupt()方法停止当前线程的时候他并没有停止，而是在做了一个标记，也就说这个标记说明当前线程已经停止了，但是实际上线程还没有停止。 interrupted()是静态方法：内部实现是调用的当前线程的isInterrupted()，并且会重置当前线程的中断状态 isInterrupted()是实例方法，是调用该方法的对象所表示的那个线程的isInterrupted()，不会重置当前线程的中断状态 演示1234567891011public class Thread03 &#123; public static void main(String[] args) throws InterruptedException &#123; Thread.sleep(200); Thread.currentThread().interrupt();//更改了中断为为true System.out.println(Thread.currentThread().isInterrupted());//直接返回true System.out.println(Thread.currentThread().isInterrupted());//直接返回true System.out.println(Thread.interrupted());//更改标志位状态为false,但是返回true System.out.println(Thread.interrupted());//返回false System.out.println(Thread.currentThread().isInterrupted());//直接返回true &#125;&#125; 总结 isInterrupted不会更改中断标志位 interrupted如果发现标志位和实际状态不一致就会更改其状态，并且返回原有状态 interrupted返回的是当前执行该方法的状态，isInterrupted返回的是该线程的状态。]]></content>
      <tags>
        <tag>thread</tag>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[震惊！！！final修饰的变量可以被修改]]></title>
    <url>%2F2020%2F04%2F11%2F%E9%9C%87%E6%83%8A%EF%BC%81%EF%BC%81%EF%BC%81final%E4%BF%AE%E9%A5%B0%E7%9A%84%E5%8F%98%E9%87%8F%E5%8F%AF%E4%BB%A5%E8%A2%AB%E4%BF%AE%E6%94%B9%2F</url>
    <content type="text"><![CDATA[震惊！！！final修饰的变量可以被修改首先先看一段代码 1234567891011121314151617181920public class Final &#123; public static void main(String[] args) throws IllegalAccessException &#123; Hh hh=new Hh(); Field[] declaredFields = hh.getClass().getDeclaredFields(); for (Field declaredField : declaredFields) &#123; System.out.println(declaredField.getInt(hh)); System.out.println("反射修改前-----------"); declaredField.setAccessible(true); declaredField.set(hh, 456); System.out.println("反射修改后-----------"); System.out.println(declaredField.getInt(hh)); &#125; &#125;&#125;class Hh&#123; final int age=18; public int getAge()&#123; return age; &#125;&#125; 运行结构 123418反射修改前-----------反射修改后-----------456 怎么样是不是震撼到你了 先别慌，在看一段代码 1234567891011121314151617181920public class Final &#123; public static void main(String[] args) throws IllegalAccessException &#123; Hh hh=new Hh(); Field[] declaredFields = hh.getClass().getDeclaredFields(); for (Field declaredField : declaredFields) &#123; System.out.println(hh.getAge());//这里由反射获取改成了调用get方法获取 System.out.println("反射修改前-----------"); declaredField.setAccessible(true); declaredField.set(hh, 456); System.out.println("反射修改后-----------"); System.out.println(hh.getAge());//同理 &#125; &#125;&#125;class Hh&#123; final int age=18; public int getAge()&#123; return age; &#125;&#125; 123418反射修改前-----------反射修改后-----------18 咦，不是说好了反射改final的值么，怎么又不能修改了，你这不是骗人么？ 其实上述的代码确实是通过反射该了final修饰的值，至于为啥结果还是18原因是java编译的时候做了优化，我们反编译一下第二段代码就明白了 12345678910class Hh &#123; final int age = 18; Hh() &#123; &#125; public int getAge() &#123; return 18;//这里编译的时候被编译期进行常量替换了 &#125;&#125; 如何才能保证不被替换呢？当我们使用引用类型的时候就可以保证不被编译期进行常量替换 比如：1234567891011121314151617181920public class Final &#123; public static void main(String[] args) throws IllegalAccessException &#123; Hh hh=new Hh(); Field[] declaredFields = hh.getClass().getDeclaredFields(); for (Field declaredField : declaredFields) &#123; System.out.println(hh.getAge()); System.out.println("反射修改前-----------"); declaredField.setAccessible(true); declaredField.set(hh, 456); System.out.println("反射修改后-----------"); System.out.println(hh.getAge()); &#125; &#125;&#125;class Hh&#123; final Integer age=18; public int getAge()&#123; return age; &#125;&#125; 123418反射修改前-----------反射修改后-----------456 反编译一下刚才的代码 12345678910class Hh &#123; final Integer age = 18; Hh() &#123; &#125; public int getAge() &#123; return this.age; &#125;&#125; 总结 final修饰的变量确实能够被反射修改 被修饰的变量不能被static final修饰，否则就算反射他爸爸也无力回天（当然反射没有爸爸） 原因我也不知道，先占个坑，回头懂了在说。]]></content>
      <tags>
        <tag>java</tag>
        <tag>final</tag>
        <tag>未完成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap详解]]></title>
    <url>%2F2020%2F04%2F09%2FHashMap%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[前言JDK 1.8 对 HashMap 进行了比较大的优化，底层实现由之前的 “数组+链表” 改为 “数组+链表+红黑树”， JDK 1.8 的 HashMap 的数据结构采用红黑树+数组+链表实现，当链表节点较少时仍然是以链表存在，当链表节点较多时（大于8）会进行扩容，当扩容后的数组大于等于64的时候会转为红黑树。 流程详解继承体系 Map 所有的双列集合实现的抽象类，注意，他是一个抽象类不是接口，详情参考JDK1.8文档。 AbstractMap 提供了Map要实现的最小接口 Cloneable 标记接口，实现了这个接口才能被克隆 Serializable 标记接口，实现了这个接口才能被序列化 成员变量123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // table默认容量大小 16 /** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. */ static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//table最大容量 1073741824 /** * The load factor used when none specified in constructor. */ static final float DEFAULT_LOAD_FACTOR = 0.75f;//负载因子 /** * The bin count threshold for using a tree rather than list for a * bin. Bins are converted to trees when adding an element to a * bin with at least this many nodes. The value must be greater * than 2 and should be at least 8 to mesh with assumptions in * tree removal about conversion back to plain bins upon * shrinkage. */ static final int TREEIFY_THRESHOLD = 8;//链表转换红黑树的阈值 /** * The bin count threshold for untreeifying a (split) bin during a * resize operation. Should be less than TREEIFY_THRESHOLD, and at * most 6 to mesh with shrinkage detection under removal. */ static final int UNTREEIFY_THRESHOLD = 6;//红黑树退化成链表的阈值 /** * The smallest table capacity for which bins may be treeified. * (Otherwise the table is resized if too many nodes in a bin.) * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts * between resizing and treeification thresholds. */ static final int MIN_TREEIFY_CAPACITY = 64;//转换红黑树最小table长度 transient Node&lt;K,V&gt;[] table;//实际存储个个红黑树根节点或链表头部的数组。 /** * Holds cached entrySet(). Note that AbstractMap fields are used * for keySet() and values(). */ transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; /** * The number of key-value mappings contained in this map. */ transient int size;//元素的个数，包含所有的节点 /** * The number of times this HashMap has been structurally modified * Structural modifications are those that change the number of mappings in * the HashMap or otherwise modify its internal structure (e.g., * rehash). This field is used to make iterators on Collection-views of * the HashMap fail-fast. (See ConcurrentModificationException). */ transient int modCount;//并发修改标记 /** * The next size value at which to resize (capacity * load factor). * * @serial */ // (The javadoc description is true upon serialization. // Additionally, if the table array has not been allocated, this // field holds the initial array capacity, or zero signifying // DEFAULT_INITIAL_CAPACITY.) int threshold; /** * The load factor for the hash table. * * @serial */ final float loadFactor; 构造方法1234567891011121314151617181920public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // 使用默认0.75的装填因子&#125;public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);//使用指定大小的table容量和默认0.75装填因子&#125;public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0)//检查设定table容量是否合法 throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY)//设定table容量是否超过最大容量 initialCapacity = MAXIMUM_CAPACITY;//超过就使最大容量为1&lt;&lt;30 1073741824 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor))//判断装填因子是否合法 throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);//根据设定的大小创建大于等于给定容量2的n次幂的数组容量大小&#125; 总结 当我们创建一个HashMap对象时，并没有确定容器的大小。 当我们第一次添加元素的时候才会实际的分配容器大小 默认容量是16 当我们使用HashMap的时候最好使用有参构造方法提前分配容量来避免频繁的扩容带来的性能问题 HashMap中节点数少于8个的时候是一个链表，但是当节点数大于8的时候会检查当前table的容量是否小于64，否则扩容2倍，否则将链表结构转换为红黑树结构 当一颗红黑树节点数少于6个的时候红黑树会退化成链表。（原因就是树节点TreeNode的空间消耗比Node节点空间消耗更大，后面会详细解释） 前置方法计算哈希值12345678910// 代码1static final int hash(Object key) &#123; // 计算key的hash值 int h; // 1.先拿到key的hashCode值; //2.将hashCode的高16和低16位异或 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;int n = tab.length;//获取当前table元素的长度// 将(tab.length - 1) 与 hash值进行&amp;运算int index = (n - 1) &amp; hash;//相当于hash值对长度取余数 index=hash%n; 在HashMap中是允许key为null的，当key为null的时候根据低6行的三元运算符可以得知是0 hash值无符号右移并且和自身异或就是为了高16位和低16位都能参与运算，进而减少hash碰撞，（因为当hash值特别小的时候在JDK之前只有低16位参与运算，容易导致hash碰撞） int index = (n - 1) &amp; hash;其实就是相当于index=hash%n;(这里采用这种方式是因为位运算效率更高，mod运算是非常消耗计算机性能的) 扩容12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 老表的容量不为0，即老表不为空 if (oldCap &gt; 0) &#123; // 判断老表的容量是否超过最大容量值：如果超过则将阈值设置为Integer.MAX_VALUE，并直接返回老表, // 此时oldCap * 2比Integer.MAX_VALUE大，因此无法进行重新分布，只是单纯的将阈值扩容到最大 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //将newCap赋值为oldCap的2倍，如果newCap&lt;最大容量并且oldCap&gt;=16, 则将新阈值设置为原来的两倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; // 如果老表的容量为0, 老表的阈值大于0, 是因为初始容量被放入阈值，则将新表的容量设置为老表的阈值 else if (oldThr &gt; 0) newCap = oldThr; else &#123; // 老表的容量为0, 老表的阈值为0，这种情况是没有传初始容量的new方法创建的空表，将阈值和容量设置为默认值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 如果新表的阈值为空, 则通过新的容量*负载因子获得阈值 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; // 将当前阈值设置为刚计算出来的新的阈值，定义新表，容量为刚计算出来的新容量，将table设置为新定义的表。 threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 如果老表不为空，则需遍历所有节点，将节点赋值给新表 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; // 将索引值为j的老表头节点赋值给e oldTab[j] = null; // 将老表的节点设置为空, 以便垃圾收集器回收空间 // 如果e.next为空, 则代表老表的该位置只有1个节点，计算新表的索引位置, 直接将该节点放在该位置 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; // 如果是红黑树节点，则进行红黑树的重hash分布(跟链表的hash分布基本相同) else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order // 如果是普通的链表节点，则进行普通的重hash分布 Node&lt;K,V&gt; loHead = null, loTail = null; // 存储索引位置为:“原索引位置”的节点 Node&lt;K,V&gt; hiHead = null, hiTail = null; // 存储索引位置为:“原索引位置+oldCap”的节点 Node&lt;K,V&gt; next; do &#123; next = e.next; // 如果e的hash值与老表的容量进行与运算为0,则扩容后的索引位置跟老表的索引位置一样 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) // 如果loTail为空, 代表该节点为第一个节点 loHead = e; // 则将loHead赋值为第一个节点 else loTail.next = e; // 否则将节点添加在loTail后面 loTail = e; // 并将loTail赋值为新增的节点 &#125; //如果e的hash值与老表的容量进行与运算为1,则扩容后的索引位置为:老表的索引位置＋oldCap else &#123; if (hiTail == null) // 如果hiTail为空, 代表该节点为第一个节点 hiHead = e; // 则将hiHead赋值为第一个节点 else hiTail.next = e; // 否则将节点添加在hiTail后面 hiTail = e; // 并将hiTail赋值为新增的节点 &#125; &#125; while ((e = next) != null); //如果loTail不为空（说明老表的数据有分布到新表上“原索引位置”的节点），则将最后一个节点 // 的next设为空，并将新表上索引位置为“原索引位置”的节点设置为对应的头节点 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 如果hiTail不为空（说明老表的数据有分布到新表上“原索引+oldCap位置”的节点），则将最后 // 一个节点的next设为空，并将新表上索引位置为“原索引+oldCap”的节点设置为对应的头节点 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 如果当前table的长度已经最大，那么就无法扩容，直接调整扩容阈值到最大 如果可以扩容，那么就扩容两倍 扩容后需要调整节点的重新计算每个元素的hash,但是在jdk1.8中使用了很巧妙的方式（索引=原来索引+旧数组容量||原来索引） 值得注意的是，单纯的扩容也可以减少hash冲突，因为扩容后需要对节点进行重新（hash 值与老表的容量进行位与运算为 1则索引等于原来索引+旧数组容量）hash可能会导致某些节点调整桶的位置 put添加方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public V put(K key, V value) &#123;//put方法实际调用的是putVal方法 //传入key的hash值，这个时候还未做取模运算 return putVal(hash(key), key, value, false, true); &#125; //onlyIfAbsent true的时候不更改现有的值 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果是第一次添加元素 if ((tab = table) == null || (n = tab.length) == 0) //扩容，并且获取第一次扩容的后大小 n = (tab = resize()).length; //判断插入的桶位置是否是空 if ((p = tab[i = (n - 1) &amp; hash]) == null) //说明当前节点是该桶内的第一个节点 tab[i] = newNode(hash, key, value, null); else &#123; //说明该桶内有其他元素 Node&lt;K,V&gt; e; K k; //判断p节点的key和hash值是否跟传入的相等，如果相等（比较内容是否相等）, 则p节点即为要查找的目标节点，将p节点赋值给e节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //判断p节点是否是红黑树类型的节点，如果是就调用红黑树方法查找 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //作为链表结构查找，如果找到了相同节点就覆盖，没有找到就在末尾追加一个节点 for (int binCount = 0; ; ++binCount) &#123; //没有找到 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) //统计节点是否超过了7个也就是》=8，treeifyBin方法中检查table的大小，如果table大小小于64则进行二倍扩容，否则调整为红黑树结构 treeifyBin(tab, hash); break; &#125; p.next = newNode(hash, key, value, null); //如果e节点存在hash值和key值都与传入的相同，则e节点即为目标节点，跳出循环 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //如果找到的节点的value值不相等,就覆盖 if (e != null) &#123; V oldValue = e.value;//暂存旧的value值 if (!onlyIfAbsent || oldValue == null)//value值不相等 e.value = value;//覆盖 afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; 如果是第一次添加，就扩容到默认容量16 如果计算的索引的位置是null,那么就把当前节点作为第一个节点 如果计算的索引的位置不是null，且key相等，那么就覆盖该节点的value 如果计算的索引的位置不是null，且key不相等，那么就在相应链表或者红黑树上插入该节点 获取元素1234567891011121314151617181920212223242526272829303132public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 1.对table进行校验：table不为空 &amp;&amp; table长度大于0 &amp;&amp; // table索引位置(使用table.length - 1和hash值进行位与运算)的节点不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 2.检查first节点的hash值和key是否和入参的一样，如果一样则first即为目标节点，直接返回first节点 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 3.如果first不是目标节点，并且first的next节点不为空则继续遍历 if ((e = first.next) != null) &#123; if (first instanceof TreeNode) // 4.如果是红黑树节点，则调用红黑树的查找目标节点方法getTreeNode return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; // 5.执行链表节点的查找，向下遍历链表, 直至找到节点的key和入参的key相等时,返回该节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; // 6.找不到符合的返回空 return null;&#125; 找到了就返回 没有找到就返回null HashMap 和 Hashtable 的区别 HashMap 和 Hashtable 的区别 HashMap 允许 key 和 value 为 null，Hashtable 不允许。 HashMap 的默认初始容量为 16，Hashtable 为 11。 HashMap 的扩容为原来的 2 倍，Hashtable 的扩容为原来的 2 倍加 1。 HashMap 是非线程安全的，Hashtable是线程安全的。 HashMap 的 hash 值重新计算过，Hashtable 直接使用 hashCode。 HashMap 去掉了 Hashtable 中的 contains 方法。 HashMap 继承自 AbstractMap 类，Hashtable 继承自 Dictionary 类。 总结 HashMap 的底层是个 Node 数组（Node&lt;K,V&gt;[] table），在数组的具体索引位置，如果存在多个节点，则可能是以链表或红黑树的形式存在。 增加、删除、查找键值对时，定位到哈希桶数组的位置是很关键的一步，源码中是通过下面3个操作来完成这一步：1）拿到 key 的 hashCode 值；2）将 hashCode 的高位参与运算，重新计算 hash 值；3）将计算出来的 hash 值与 “table.length - 1” 进行 &amp; 运算。 HashMap 的默认初始容量（capacity）是 16，capacity 必须为 2 的幂次方；默认负载因子（load factor）是 0.75；实际能存放的节点个数（threshold，即触发扩容的阈值）= capacity * load factor。 HashMap 在触发扩容后，阈值会变为原来的 2 倍，并且会对所有节点进行重 hash 分布，重 hash 分布后节点的新分布位置只可能有两个：“原索引位置” 或 “原索引+oldCap位置”。例如 capacity 为16，索引位置 5 的节点扩容后，只可能分布在新表 “索引位置5” 和 “索引位置21（5+16）”。 导致 HashMap 扩容后，同一个索引位置的节点重 hash 最多分布在两个位置的根本原因是：1）table的长度始终为 2 的 n 次方；2）索引位置的计算方法为 “(table.length - 1) &amp; hash”。HashMap 扩容是一个比较耗时的操作，定义 HashMap 时尽量给个接近的初始容量值。 HashMap 有 threshold 属性和 loadFactor 属性，但是没有 capacity 属性。初始化时，如果传了初始化容量值，该值是存在 threshold 变量，并且 Node 数组是在第一次 put 时才会进行初始化，初始化时会将此时的 threshold 值作为新表的 capacity 值，然后用 capacity 和 loadFactor 计算新表的真正 threshold 值。 当同一个索引位置的节点在增加后达到 9 个时，并且此时数组的长度大于等于 64，则会触发链表节点（Node）转红黑树节点（TreeNode），转成红黑树节点后，其实链表的结构还存在，通过 next 属性维持。链表节点转红黑树节点的具体方法为源码中的 treeifyBin 方法。而如果数组长度小于64，则不会触发链表转红黑树，而是会进行扩容。 当同一个索引位置的节点在移除后达到 6 个时，并且该索引位置的节点为红黑树节点，会触发红黑树节点转链表节点。红黑树节点转链表节点的具体方法为源码中的 untreeify 方法。 HashMap 在 JDK 1.8 之后不再有死循环的问题，JDK 1.8 之前存在死循环的根本原因是在扩容后同一索引位置的节点顺序会反掉。 HashMap 是非线程安全的，在并发场景下使用 ConcurrentHashMap 来代替。]]></content>
      <tags>
        <tag>容器</tag>
        <tag>hash</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql索引优化]]></title>
    <url>%2F2020%2F04%2F05%2Fmysql%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[索引mysql中一张表最多能有多少个索引？16个索引，在innodb引擎中每个索引最大长度255个字节 复合索引在mysql中，复合索引是一个节点，这个节点按照创建复合索引的顺序组合成一个索引. 比如： 1CREATE INDEX inx_a_b_c ON &lt;表名&gt;(a,b,c); 就创建了复合索引，每个B-数的节点是由a+b+c拼接而成。 其实这相当于建立了三个索引，分别是：1、单列索引（列a） 2、复合索引（列a, 列b） 3、复合索引（列a，列b，列c）。 最左匹配原则对于复合索引:Mysql从左到右的使用索引中的字段，一个查询可以只使用索引中的一部份，但只能是最左侧部分。例如索引是key index (a,b,c). 可以支持a | a,b| a,b,c 3种组合进行查找，但不支持 b,c进行查找 .当最左侧字段是常量引用时，索引就十分有效。下面用几个例子对比查询条件的不同对性能影响. 比如123456create table test( a int, b int, c int, KEY a(a,b,c)); WHERE后面的SQL语句 解释 WHERE a=1 AND b=1 AND c=1 使用了复合主键，abc都进行了匹配 WHERE a=1 AND c=1 使用了复合主键，a进行了匹配 WHERE b=1 AND c=1 没有使用主键 WHERE a=1 AND b&gt;1 AND c=1 使用了复合主键，ab进行了匹配 例子表结构 12345678create TABLE `emp`( `id` INT(11) NOT NULL AUTO_INCREMENT, empno INT NOT NULL, `name` VARCHAR(30) DEFAULT NULL, age INT(3) DEFAULT NULL, deptld INT(11) DEFAULT NULL, PRIMARY KEY(id))ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4; 其中SQL_NO_CACHE是取消缓存，利于观察结果的正确性 12345678910111213141516171819202122232425262728293031323334-- 查询EXPLAIN SELECT SQL_NO_CACHE * FROM emp WHERE emp.age=32;-- 创建age索引优化CREATE INDEX idx_age ON emp(age);DROP INdex idx_age on emp;-- 模糊查询优化,在不创建索引的情况下两行执行速度相当，如果创建了name索引那么1比2快，给SQL使用函数会导致SQL失效，LIKE前面有百分号索引也会失效EXPLAIN SELECT SQL_NO_CACHE * FROM emp WHERE emp.`name` LIKE "abc%";EXPLAIN SELECT SQL_NO_CACHE * FROM emp WHERE LEFT(emp.name,3)='abc';CREATE INDEX idx_name ON emp(name);DROP INDEX idx_name on emp;-- 范围查询右侧字段索引失效EXPLAIN SELECT SQL_NO_CACHE * FROM emp WHERE emp.age=32 AND emp.deptld&gt;20 AND emp.name="abc";-- 创建索引CREATE INDEX idx_age_deptid_name ON emp(age,deptld,name);DROP INdex idx_age_deptid_name on emp;-- 优化索引还要调整查询顺序CREATE INDEX idx_age_name_deptid ON emp(age,name,deptld);EXPLAIN SELECT SQL_NO_CACHE * FROM emp WHERE emp.age=32 AND emp.name="abc" AND emp.deptld&gt;20;DROP INdex idx_age_name_deptid on emp;-- 不等于的情况会导致索引失效EXPLAIN SELECT SQL_NO_CACHE * FROM emp WHERE emp.name&lt;&gt;"abc";-- 错误优化CREATE INDEX idx_name ON emp(name);DROP INDEX idx_name;-- IS NULL 和IS NOT NULL IS 不会使用索引-- 数据类型错误也不会使用索引，比如name=123因为name不是INT类型，所以索引失效，所以avabean对象和mysql数据库类型必须完全相同。 索引失效的情况 如果查询条件用or，必须or条件中的每个列都加上索引，否则无效。（尽量使用union代替） 复合索引未用左列字段; like以%开头; 需要类型转换; where中索引列有运算; where中索引列使用了函数; 如果mysql觉得全表扫描更快时（数据少） 关联查询优化 保证被驱动表的join字段有索引 left join时，选择小表为驱动表，大表为被驱动表，因为驱动表一定要做全表扫描。 inner join时，mysql会自己帮你把小结果集的表选为驱动表 子查询尽量不要放在被驱动表。因为子查询会生成虚拟表导致有可能使用不到索引 能够直接关联查询，尽量不用子查询。 ORDER BY优化在使用ORDER BY时，需要添加限定条件，否则ORDER BY会出现using filesort 在排序的时候所有的条件要么是升序，要么是降序，否则不使用索引 123456789101112131415drop table if exists test;create table test(id int primary key auto_increment,c1 varchar(10),c2 varchar(10),c3 varchar(10),c4 varchar(10),c5 varchar(10)) ENGINE=INNODB default CHARSET=utf8;insert into test(c1,c2,c3,c4,c5) values('a1','a2','a3','a4','a5');insert into test(c1,c2,c3,c4,c5) values('b1','b2','b3','b4','b5');insert into test(c1,c2,c3,c4,c5) values('c1','c2','c3','c4','c5');insert into test(c1,c2,c3,c4,c5) values('d1','d2','d3','d4','d5');insert into test(c1,c2,c3,c4,c5) values('e1','e2','e3','e4','e5'); 创建索引 1CREATE INDEX idx_c1234 on test(c1,c2,c3,c4); EXPLAIN SELECT * FROM test WHEREc1&gt;’a1’ ORDER BY C1; ①在c1,c2,c3,c4上创建了索引，直接在c1上使用范围，导致了索引失效，全表扫描：type=ALL，ref=Null。因为此时c1主要用于排序，并不是查询。 ②使用c1进行排序，出现了Using filesort。 ③解决方法：使用覆盖索引。 EXPLAIN SELECT c2 FROM test WHERE c1&gt;’a1’ ORDER BY C1; 分析 因为需要的结果是c2，所以只需要在非聚簇索引查询就可以知道结果. EXPLAIN SELECT c1 FROM test WHERE c1&gt;’a1’ ORDER BY c1,c2; 分析 排序时按照索引的顺序，所以不会出现Using filesort。 EXPLAIN SELECT c1 FROM test WHERE c1&gt;’a1’ ORDER BY c2; 出现了Using filesort。原因：排序用的c2，与索引的创建顺序不一致，对比Case1.1可知，排序时少了c1（带头大哥），因此出现Using filesort。 EXPLAIN SELECT c1 FROM test WHERE c1&gt;’a1’ ORDER BY c2,c1; 分析： 出现了Using filesort。因为排序索引列与索引创建的顺序相反，从而产生了重排，也就出现了Using filesort。 EXPLAIN SELECT c1 FROM test WHERE c2&gt;’a1’ ORDER BY c1;分析： 排序使用了索引顺序（带头大哥在），因此不会出现Using filesort。 EXPLAIN SELECT c1 FROM test WHERE c1&gt;’a1’ ORDER BY c1 DESC,c2 ASC;]]></content>
      <tags>
        <tag>优化</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysqlExplain查询语句执行计划]]></title>
    <url>%2F2020%2F04%2F05%2FmysqlExplain%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"><![CDATA[是什么在日常工作中，我们会有时会开慢查询去记录一些执行时间比较久的SQL语句，找出这些SQL语句并不意味着完事了，些时我们常常用到explain这个命令来查看一个这些SQL语句的执行计划，查看该SQL语句有没有使用上了索引，有没有做全表扫描，这都可以通过explain命令来查看。所以我们深入了解MySQL的基于开销的优化器，还可以获得很多可能被优化器考虑到的访问策略的细节，以及当运行SQL语句时哪种策略预计会被优化器采用。 有什么用 表的读取顺序 数据读取操作的操作类型 哪些索引可以使用 哪些索引被实际使用 表之间的引用 每张表有多少行被优化器查询 怎么用explain + sql语句 字段分析 ID(重要)select查询的序列号，是一组数字，表示的是查询中执行select子句或者是操作表的顺序。 id相同，执行顺序由上至下 id不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 id相同不同，同时存在 id相同的可以认为是一组，同一组中从上往下执行，所有组中id大的优先执行 总结总而言之，相同顺序执行，不同大号先执行。 select_type表示示查询中每个select子句的类型 SIMPLE(简单SELECT，不使用UNION或子查询等) PRIMARY(子查询中最外层查询，查询中若包含任何复杂的子部分，最外层的select被标记为PRIMARY) DERIVED(派生表的SELECT, FROM子句的子查询) SUBQUERY(子查询中的第一个SELECT，结果不依赖于外部查询) DEPENDENT SUBQUERY(子查询中的第一个SELECT，依赖于外部查询) UNCACHEABLE SUBQUERY(一个子查询的结果不能被缓存，必须重新评估外链接的第一行) UNION(UNION中的第二个或后面的SELECT语句) DEPENDENT UNION(UNION中的第二个或后面的SELECT语句，取决于外面的查询) UNION RESULT(UNION的结果，union语句中第二个select开始后面所有select) table(重要)显示这一步所访问数据库中表名称（显示这一行的数据是关于哪张表的），有时不是真实的表名字，可能是简称，例如上面的e，d，也可能是第几步执行的结果的简称 partitions 代表分区表中的命中情况，非分区表，该项为null type(重要)对表访问方式，表示MySQL在表中找到所需行的方式，又称“访问类型”。 常用的类型有： ALL、index、range、 ref、eq_ref、const、system、NULL（从左到右，性能从差到好） ALL：Full Table Scan， MySQL将遍历全表以找到匹配的行 index: Full Index Scan，index与ALL区别为index类型只遍历索引树 range:只检索给定范围的行，使用一个索引来选择行 ref: 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 eq_ref: 类似ref，区别就在 使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件 const、system: 当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量，system是const类型的特例，当查询的表只有一行的情况下，使用system NULL: MySQL在优化过程中分解语句 ，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。 possible_keys指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用（该查询可以利用的索引，如果没有任何索引显示 null） Key（重要）key列显示MySQL实际决定使用的键（索引），必然包含在possible_keys中 key_len单位是字节 表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度（key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的） 不损失精确性的情况下，长度越短越好 ，如果查询使用的是复合索引，那么越长越好。 ref列与索引的比较，表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 rows（重要）表示MySQL估计未来找到所需要的行而要读取的行数 Extra(重要)这一列包含的是不适合在其他列显示的额为信息 Using index 表示此值Mysql将使用覆盖索引，以避免访问表。 Using where:不用读取表中所有信息，仅通过索引就可以获取所需数据，这发生在对表的全部的请求列都是同一个索引的部分的时候，表示mysql服务器将在存储引擎检索行后再进行过滤 Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询，常见 group by ; order by Using join buffer：改值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。 Impossible where：这个值强调了where语句会导致没有符合条件的行（通过收集统计信息不可能存在结果）。 Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>数据库</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL索引详解]]></title>
    <url>%2F2020%2F04%2F01%2FMySQL%E7%B4%A2%E5%BC%95%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[索引 索引就是一种排好序的快速查找数据结构 索引的分类单值索引即一个索引只包含单个列，一个表可以有多个单列索引（建议一张表索引不要超过5个优先考虑复合索引） 唯一索引索引列的值必须唯一，但允许有空值 复合索引即一个索引包含多个列 索引的基本语法创建CREATE [UNIQUE] INDEX indexName ON mytable(columnname(length)); 删除ALTER mytable ADD [UNIQUE] INDEX [indexName] ON(columnname(length)); 查看DROP INDEX [indexName] ON mytable; 查看一个表的索引信息show index from [tableName]; 索引的优缺点优点 提高数据检索效率，降低数据库IO成本 通过索引列对数据排序，降低数据排序成本，降低CPU的消耗 缺点 实际上索引也是一张表，该表保存了主键和索引字段，并指向实体表的记录,所以索引列也是要占用空间的 虽然索引大大提高了查询速度，同时却会降低更新表的速度,如果对表INSERT,UPDATE和DELETE。 因为更新表时，MySQL不仅要不存数据，还要保存一下索引文件每次更新添加了索引列的字段， 都会调整因为更新所带来的键值变化后的索引信息 索引只是提高效率的一个因素，如果你的MySQL有大数据量的表，就需要花时间研究建立优秀的索引，或优化查询语句 索引的使用场景什么时候需要使用索引 主键自动建立唯一索引 频繁作为查询的条件的字段应该创建索引 查询中与其他表关联的字段，外键关系建立索引 频繁更新的字段不适合创建索引(因为每次更新不单单是更新了记录还会更新索引，加重IO负担) Where条件里用不到的字段不创建索引 单间/组合索引的选择问题，who？（在高并发下倾向创建组合索引） 查询中排序的字段，排序字段若通过索引去访问将大大提高排序的速度 查询中统计或者分组字段 什么时候不需要使用索引 表记录太少(因为数据量太少，索引并不能起到很好效果) 经常增删改的表(因为每次更新不单单是更新了记录还会更新索引，加重IO负担) 数据重复且分布平均的表字段，因此应该只为经常查询和经常排序的数据列建立索引。 注意，如果某个数据列包含许多重复的内容，为它建立索引就没有太大的实际效果。(应该尽可能的让非重复字段的数量/总数量的结果接近1) 什么是聚簇索引和回表聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据 非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因 总结 聚簇索引叶节点存储着行数据 非聚簇索引即普通索引只是存储着聚簇索引的key. 聚簇索引具有唯一性由于聚簇索引是将数据跟索引结构放到一块，因此一个表仅有一个聚簇索引 聚簇索引默认是主键，如果表中没有定义主键，InnoDB 会选择一个唯一的非空索引代替。如果没有这样的索引，InnoDB 会隐式定义一个主键来作为聚簇索引。 演示假如有一张表有三个字段，分别是学号（唯一主键），姓名，和性别 然后我们创建姓名为非聚簇索引 当我们使用select * from where id=”1”;时 上面就是一个聚簇索引，当我们查询id=1的时候就通过聚簇索引查询到对应的行数据 当我们使用select * from where name=”a”;时 查询的是我们创建的索引，我们创建的这颗非聚簇索引并不存储行数据，而是存储聚簇索引的主键值 因为我们查询的是 * . 所以我们在查询普通索引的时候发现a对应的主键是1，于是乎我们需要到聚簇索引找到我们想要的信息，需要重新查找，这个操作就称为回表。 然后我们拿到主键是1，查询到对应的行。 索引覆盖当我们使用select namerom where name=”a”;时 因为普通索引就存储着我们想要的信息，所以就无需回表，这就提高了查询效率 优化我们利用这个回表的特性，创建一些联合索引，就可以避免回表的操作，这样就可以实现查询的优化 分析： 虽然排序的字段列与索引顺序一样，且order by默认升序，这里c2 desc变成了降序，导致与索引的排序方式不同，从而产生Using filesort。 总结①MySQL支持两种方式的排序filesort和index，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低。 ②order by满足两种情况会使用Using index。 1.order by语句使用索引最左前列。 2.使用where子句与order by子句条件列组合满足索引最左前列。 ③尽量在索引列上完成排序，遵循索引建立（索引创建的顺序）时的最佳左前缀法则。 ④如果order by的条件不在索引列上，就会产生Using filesort。 1.filesort有两种排序算法：双路排序和单路排序。 双路排序：在MySQL4.1之前使用双路排序，就是两次磁盘扫描，得到最终数据。读取行指针和order by列，对他们进行排序，然后扫描已经排好序的列表，按照列表中的值重新从列表中读取对应的数据输出。即从磁盘读取排序字段，在buffer进行排序，再从磁盘取其他字段。 如果使用双路排序，取一批数据要对磁盘进行两次扫描，众所周知，I/O操作是很耗时的，因此在MySQL4.1以后，出现了改进的算法：单路排序。 单路排序：从磁盘中查询所需的列，按照order by列在buffer中对它们进行排序，然后扫描排序后的列表进行输出。它的效率更高一些，避免了第二次读取数据，并且把随机I/O变成了顺序I/O，但是会使用更多的空间，因为它把每一行都保存在内存中了。 2.单路排序出现的问题。 当读取数据超过sort_buffer的容量时，就会导致多次读取数据，并创建临时表，最后多路合并，产生多次I/O，反而增加其I/O运算。 解决方式： a.增加sort_buffer_size参数的设置。 b.增大max_length_for_sort_data参数的设置。 ⑤提升order by速度的方式： 1.在使用order by时，不要用select *，只查询所需的字段。 因为当查询字段过多时，会导致sort_buffer不够，从而使用多路排序或进行多次I/O操作。 2.尝试提高sort_buffer_size。 3.尝试提高max_length_for_sort_data。 GROUP BY优化 如果GROUP BY 的列没有索引,产生临时表. 如果GROUP BY时,SELECT的列不止GROUP BY列一个,并且GROUP BY的列不是主键 ,产生临时表. 如果GROUP BY的列有索引,ORDER BY的列没索引.产生临时表. 如果GROUP BY的列和ORDER BY的列不一样,即使都有索引也会产生临时表. 如果GROUP BY或ORDER BY的列不是来自JOIN语句第一个表.会产生临时表. 如果DISTINCT 和 ORDER BY的列没有索引,产生临时表.]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql数据结构B+树详解]]></title>
    <url>%2F2020%2F03%2F30%2Fmysql%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84B%2B%E6%A0%91%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[为什么要使用B+树数据结构的种类 数组 栈 队列 链表 树 散列表 堆 图 我们都知道这些数据结构，但是对于mysql来说，需要选用一个更合适的数据结构 首先这个数据结构要满足查找增删快特点 显然满足这个条件的只有数和散列表了，那么接下来我们先讨论树，在后来会在讨论mysql和散列表的 二叉树学过数据结构的都知道二叉树的特点 若左子树不空，则左子树上所有节点的值均小于它的根节点的值 若右子树不空，则右子树上所有节点的值均大于它的根节点的值 它的左、右子树也分别为二叉排序数（递归定义） 但是二叉树有个很大的缺陷，就是如果插入的数据是有序的，那么会导致二叉树的层数增多，极端的情况下以至于退化成一个链表（当然你可以理解我类似链表的情况） 也就是查询时间复杂度从O(logn)退化到了O(n) 很显然，mysql不能使用这种数据结构来实现，因为我们平时在使用数据库的时候主键自增是一个很常用的需求，所以就有了二叉树的改进版本平衡二叉树 平衡二叉树它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。平衡二叉树的常用实现方法有红黑树、AVL、替罪羊树等。 最小二叉平衡树的节点的公式如下 F(n)=F(n-1)+F(n-2)+1 这个类似于一个递归的数列，可以参考Fibonacci数列，1是根节点，F(n-1)是左子树的节点数量，F(n-2)是右子树的节点数量。 特点平衡树的旋转我们这里就不细说了，我们主要介绍为什么mysql没有使用平衡树 假如我们一张数据库表有数据1000万条数据，那么使用平衡树需要多少层呢（即需要查询多少次）？ 假设很理想的情况下需要log2(1000万+1)向上取整数层即为24层,看起来效率还可以，但是我们不要忘记一点就是，数据库文件肯定是存储到本机磁盘的，也就说说这如果查找到的记录在叶节点，那么我们需要对磁盘读24次，那么这样还是很慢的，接下来我们能不能在缩减磁盘IO的次数呢？这样是不是就能更快的提高查找速度了呢？（接下里就引入了B树这个东东） B树如果我们把二叉树的每个节点存储数量由一个改成多个是不是就能极大的减少二叉树的乘数呢？ 比如之前有6个节点的二叉树（插入顺序都是从大到小） 我们改成每个节点存储5个元素的B树 我们可以看到层数缩减到了2层也就是说如果我们能合理的设置每个节点存储元素的个数,那么我们就可以在不牺牲性能的情况下极大的减少磁盘IO的次数,(因为数据库的索引特别大，所以一般索引也是存储到本地磁盘上的)。 到目前一切显得似乎都那么完美，但是如果mysql如果使用B树的话也有一个很大的缺点，就是mysql除了每次只查询一条数据，但是mysql还要支持条件查询啊，假如我们需要找到所有大于3的节点 是不是首先通过004找到了002之后到了003这个节点，然后回到父节点的父节点004，然后在先序遍历右子树，是不是特别浪费性能呢?，那么我们能不能也解决这个问题呢？（接下来我们就讲解B+树）,mysql的innodb使用的数据结构 B+树如果我们把B树的叶节点串起来不就好了么，这样不就能满足上面的那个查询条件了么，当然我们不能只是连接起来，我们还需要把非叶节点进行调整，也就是说真实数据存放在叶节点，非叶节点可以理解为我们的主键 到目前为止，已经满足了mysql对数据结构的所有需求，可以还有一点不明白如果我们查询小于5的怎么查找呢，你上面图的结构只是前面的叶节点指向后面的叶节点，其实在mysql中实现的这个是个双向连接，这样就满足了向前后向后，（把图中的箭头理解为双向箭头） 哈希表其实哈希表在mysql的 innodb中也有使用的 上面的那个BTREE就是B+数 下面的就是HASH 但是一般都是用B+数 原因看完我这个文章应该懂为啥有哈希并且大多使用的是B+数 原因就是哈希结构查询速度是O(1)（在不考虑哈希碰撞等等一些问题） 也就是说有些业务场景是需要使用到的。 那为什么大多没有使用哈希呢，他那么快（秒男），其实也是因为他内部是无序的，如果遇见了条件查询，那么哈希的速度慢上了天，速度约为O（n）。 完结散花؏؏☝ᖗ乛◡乛ᖘ☝؏؏ 后期可能还会更新哦！]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>数据结构</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql数据结构B+树详解]]></title>
    <url>%2F2020%2F03%2F30%2Fmysql%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84B-%E6%A0%91%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[为什么要使用B+树数据结构的种类 数组 栈 队列 链表 树 散列表 堆 图 我们都知道这些数据结构，但是对于mysql来说，需要选用一个更合适的数据结构 首先这个数据结构要满足查找增删快特点 显然满足这个条件的只有数和散列表了，那么接下来我们先讨论树，在后来会在讨论mysql和散列表的 二叉树学过数据结构的都知道二叉树的特点 若左子树不空，则左子树上所有节点的值均小于它的根节点的值 若右子树不空，则右子树上所有节点的值均大于它的根节点的值 它的左、右子树也分别为二叉排序数（递归定义） 但是二叉树有个很大的缺陷，就是如果插入的数据是有序的，那么会导致二叉树的层数增多，极端的情况下以至于退化成一个链表（当然你可以理解我类似链表的情况） 也就是查询时间复杂度从O(logn)退化到了O(n) 很显然，mysql不能使用这种数据结构来实现，因为我们平时在使用数据库的时候主键自增是一个很常用的需求，所以就有了二叉树的改进版本平衡二叉树 平衡二叉树它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。平衡二叉树的常用实现方法有红黑树、AVL、替罪羊树等。 最小二叉平衡树的节点的公式如下 F(n)=F(n-1)+F(n-2)+1 这个类似于一个递归的数列，可以参考Fibonacci数列，1是根节点，F(n-1)是左子树的节点数量，F(n-2)是右子树的节点数量。 特点平衡树的旋转我们这里就不细说了，我们主要介绍为什么mysql没有使用平衡树 假如我们一张数据库表有数据1000万条数据，那么使用平衡树需要多少层呢（即需要查询多少次）？ 假设很理想的情况下需要log2(1000万+1)向上取整数层即为24层,看起来效率还可以，但是我们不要忘记一点就是，数据库文件肯定是存储到本机磁盘的，也就说说这如果查找到的记录在叶节点，那么我们需要对磁盘读24次，那么这样还是很慢的，接下来我们能不能在缩减磁盘IO的次数呢？这样是不是就能更快的提高查找速度了呢？（接下里就引入了B树这个东东） B树如果我们把二叉树的每个节点存储数量由一个改成多个是不是就能极大的减少二叉树的乘数呢？ 比如之前有6个节点的二叉树（插入顺序都是从大到小） 我们改成每个节点存储5个元素的B树 我们可以看到层数缩减到了2层也就是说如果我们能合理的设置每个节点存储元素的个数,那么我们就可以在不牺牲性能的情况下极大的减少磁盘IO的次数,(因为数据库的索引特别大，所以一般索引也是存储到本地磁盘上的)。 到目前一切显得似乎都那么完美，但是如果mysql如果使用B树的话也有一个很大的缺点，就是mysql除了每次只查询一条数据，但是mysql还要支持条件查询啊，假如我们需要找到所有大于3的节点 是不是首先通过004找到了002之后到了003这个节点，然后回到父节点的父节点004，然后在先序遍历右子树，是不是特别浪费性能呢?，那么我们能不能也解决这个问题呢？（接下来我们就讲解B+树）,mysql的innodb使用的数据结构 B+树如果我们把B树的叶节点串起来不就好了么，这样不就能满足上面的那个查询条件了么，当然我们不能只是连接起来，我们还需要把非叶节点进行调整，也就是说真实数据存放在叶节点，非叶节点可以理解为我们的主键 到目前为止，已经满足了mysql对数据结构的所有需求，可以还有一点不明白如果我们查询小于5的怎么查找呢，你上面图的结构只是前面的叶节点指向后面的叶节点，其实在mysql中实现的这个是个双向连接，这样就满足了向前后向后，（把图中的箭头理解为双向箭头） 哈希表其实哈希表在mysql的 innodb中也有使用的 上面的那个BTREE就是B+数 下面的就是HASH 但是一般都是用B+数 原因看完我这个文章应该懂为啥有哈希并且大多使用的是B+数 原因就是哈希结构查询速度是O(1)（在不考虑哈希碰撞等等一些问题） 也就是说有些业务场景是需要使用到的。 那为什么大多没有使用哈希呢，他那么快（秒男），其实也是因为他内部是无序的，如果遇见了条件查询，那么哈希的速度慢上了天，速度约为O（n）。 完结散花؏؏☝ᖗ乛◡乛ᖘ☝؏؏ 后期可能还会更新哦！]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>数据结构</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis事务详解]]></title>
    <url>%2F2020%2F03%2F29%2FRedis%E4%BA%8B%E5%8A%A1%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Redis事务的概念： Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。 总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。 Redis事务没有隔离级别的概念： 批量操作在发送 EXEC 命令前被放入队列缓存，并不会被实际执行，也就不存在事务内的查询要看到事务里的更新，事务外查询不能看到。 Redis不保证原子性： Redis中，单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。 Redis事务的三个阶段： 开始事务 命令入队 执行事务 Redis事务相关命令： watch key1 key2 … : 监视一或多个key,如果在事务执行之前，被监视的key被其他命令改动，则事务被打断 （ 类似乐观锁 ） multi : 标记一个事务块的开始（ queued ） exec : 执行所有事务块的命令 （ 一旦执行exec后，之前加的监控锁都会被取消掉 ） discard : 取消事务，放弃事务块中的所有命令 unwatch : 取消watch对所有key的监控 案例演示正常执行 放弃事务 若在事务队列中存在命令性错误（类似于java编译性错误），则执行EXEC命令时，所有命令都不会执行 若在事务队列中存在语法性错误（类似于java的1/0的运行时异常），则执行EXEC命令时，其他正确命令会被执行，错误命令抛出异常。 Redis乐观锁实现(CAS)重点什么是CASCAS就是比较在交换，就是先获取一个值，然后在修改的时候比对这个值，如果这个值没有被改动，那么当前就是显存安全的，如果被改动了，那么就需要重新获取这个值，也就是进行一次自旋。 Redis的乐观锁在Redis中，可以使用一个监视器watch来实现。 原理123WATCH key//先获取key这个值//执行事务EXEC//提交事务的时候检查key的值是否被修改，被修改就失败。 案例演示案例一：使用watch检测balance，事务期间balance数据未变动，事务执行成功 案例二：使用watch检测balance，在开启事务后（标注1处），在新窗口执行标注2中的操作，更改balance的值，模拟其他客户端在事务执行期间更改watch监控的数据，然后再执行标注1后命令，执行EXEC后，事务未成功执行。 一但执行 EXEC 开启事务的执行后，无论事务使用执行成功， WARCH 对变量的监控都将被取消。 故当事务执行失败后，需重新执行WATCH命令对变量进行监控，并开启新的事务进行操作。 总结： watch指令类似于乐观锁，在事务提交时，如果watch监控的多个KEY中任何KEY的值已经被其他客户端更改，则使用EXEC执行事务时，事务队列将不会被执行，同时返回Nullmulti-bulk应答以通知调用者事务执行失败。]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[乐观锁和悲观锁以及锁升级详解]]></title>
    <url>%2F2020%2F03%2F28%2F%E4%B9%90%E8%A7%82%E9%94%81%E5%92%8C%E6%82%B2%E8%A7%82%E9%94%81%E4%BB%A5%E5%8F%8A%E9%94%81%E5%8D%87%E7%BA%A7%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[CASCAS概述和作用CAS的全成 Compare And Swap(比较相同再交换)。是现代CPU广泛支持的一种对内存中的共享数据进行操作的一种特殊指令。 CAS的作用CAS可以将比较和交换转换为原子操作，这个原子操作直接由CPU保证。CAS可以保证共享变量赋值时的原子操作。CAS操作依赖3个值：内存中的值V，旧的预估值X，要修改的新值B，如果旧的预估值X等于内存中的值V，就将新的值B保存到内存中。 CAS和volatile实现无锁并发1234567891011121314151617181920public class Demo01 &#123; public static void main(String[] args) throws InterruptedException &#123; AtomicInteger atomicInteger = new AtomicInteger(); Runnable mr = () -&gt; &#123; for (int i = 0; i &lt; 1000; i++) &#123; atomicInteger.incrementAndGet(); &#125; &#125;; ArrayList&lt;Thread&gt; ts = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 5; i++) &#123; Thread t = new Thread(mr); t.start(); ts.add(t); &#125; for (Thread t : ts) &#123; t.join(); &#125; System.out.println("number = " + atomicInteger.get()); &#125;&#125; AtomicInteger部分源码 1234567891011public final int getAndIncrement() &#123; return U.getAndAddInt(this, VALUE, 1);&#125;@HotSpotIntrinsicCandidatepublic final int getAndAddInt(Object o, long offset, int delta) &#123;//o对象地址，offset value在对象中的偏移值，delta要增加的结果 int v; do &#123; v = getIntVolatile(o, offset);//根据对象和偏移量获取value的值 &#125; while (!weakCompareAndSetInt(o, offset, v, v + delta));//比较预估值和内存中的结果是否相等，如果相等就更改结果为v+delta否则就循环重试 return v;&#125; 通过刚才AtomicInteger的源码我们可以看到，Unsafe类提供了原子操作。 Unsafe类介绍Unsafe类使Java拥有了像C语言的指针一样操作内存空间的能力，同时也带来了指针的问题。过度的使用Unsafe类会使得出错的几率变大，因此Java官方并不建议使用的，官方文档也几乎没有。Unsafe对象不能直接调用，只能通过反射获得。 乐观锁和悲观锁悲观锁从悲观的角度出发：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞。因此synchronized我们也将其称之为悲观锁。JDK中的ReentrantLock也是一种悲观锁。性能较差！ 乐观锁从乐观的角度出发:总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，就算改了也没关系，再重试即可。所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去修改这个数据，如何没有人修改则更新，如果有人修改则重试。CAS这种机制我们也可以将其称之为乐观锁。综合性能较好！ CAS获取共享变量时，为了保证该变量的可见性，需要使用volatile修饰。结合CAS和volatile可以实现无锁并发，适用于竞争不激烈、多核 CPU 的场景下。 因为没有使用 synchronized，所以线程不会陷入阻塞，这是效率提升的因素之一。 但如果竞争激烈，可以想到重试必然频繁发生，反而效率会受影响 总结CAS的作用Compare And Swap，CAS可以将比较和交换转换为原子操作，这个原子操作直接由处理器保证。 CAS的原理CAS需要3个值:内存地址V，旧的预期值A，要修改的新值B，如果内存地址V和旧的预期值A相等就修改内存地址值为B synchronized锁升级过程高效并发是从JDK 5到JDK 6的一个重要改进，HotSpot虛拟机开发团队在这个版本上花费了大量的精力去实现各种锁优化技术，包括偏向锁( Biased Locking )、轻量级锁( Lightweight Locking )和如适应性自旋(Adaptive Spinning)、锁消除( Lock Elimination)、锁粗化( Lock Coarsening )等，这些技术都是为了在线程之间更高效地共享数据，以及解决竞争问题，从而提高程序的执行效率。 过程无锁–&gt;偏向锁–&gt;轻量级锁–&gt;重量级锁 对象的内存布局在JVM中，对象在内存中的布局分为三块区域：对象头、实例数据和对齐填充。如下图所示： 对象头当一个线程尝试访问synchronized修饰的代码块时，它首先要获得锁，那么这个锁到底存在哪里呢？是存在锁对象的对象头中的。HotSpot采用instanceOopDesc和arrayOopDesc来描述对象头，arrayOopDesc对象用来描述数组类型。instanceOopDesc的定义的在Hotspot源码的 instanceOop.hpp 文件中，另外，arrayOopDesc的定义对应 arrayOop.hpp 123456789101112131415161718class instanceOopDesc : public oopDesc &#123;public: // aligned header size. static int header_size() &#123; return sizeof(instanceOopDesc)/HeapWordSize; &#125; // If compressed, the offset of the fields of the instance may not be aligned. static int base_offset_in_bytes() &#123; // offset computation code breaks if UseCompressedClassPointers // only is true return (UseCompressedOops &amp;&amp; UseCompressedClassPointers) ? klass_gap_offset_in_bytes() : sizeof(instanceOopDesc);&#125; static bool contains_field_offset(int offset, int nonstatic_field_size) &#123; int base_in_bytes = base_offset_in_bytes(); return (offset &gt;= base_in_bytes &amp;&amp; (offset-base_in_bytes) &lt; nonstatic_field_size * heapOopSize);&#125;&#125;; 从 instanceOopDesc代码中可以看到 instanceOopDesc继承自oopDesc，oopDesc的定义载Hotspot源码中的 oop.hpp 文件中。 12345678910111213class oopDesc &#123; friend class VMStructs;private: volatile markOop _mark; union _metadata &#123; Klass* _klass; narrowKlass _compressed_klass;&#125; _metadata; // Fast access to barrier set. Must be initialized. static BarrierSet* _bs; // 省略其他代码&#125;; 在普通实例对象中， oopDesc的定义包含两个成员，分别是 _mark 和 _metadata_mark 表示对象标记、属于markOop类型，也就是接下来要讲解的Mark World，它记录了对象和锁有关的信息_metadata 表示类元信息，类元信息存储的是对象指向它的类元数据(Klass)的首地址，其中Klass表示普通指针、 _compressed_klass 表示压缩类指针。对象头由两部分组成，一部分用于存储自身的运行时数据，称之为 Mark Word，另外一部分是类型指针，及对象指向它的类元数据的指针。 Mark WordMark Word用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等等，占用内存大小与虚拟机位长一致。Mark Word对应的类型是 markOop 。源码位于 markOop.hpp 中。 在 64位虚拟机下，Mark Word是64bit大小的，其存储结构如下： 在32位虚拟机下，Mark Word是32bit大小的，其存储结构如下： klass pointer这一部分用于存储对象的类型指针，该指针指向它的类元数据，JVM通过这个指针确定对象是哪个类的实例。该指针的位长度为JVM的一个字大小，即32位的JVM为32位，64位的JVM为64位。 如果应用的对象过多，使用64位的指针将浪费大量内存，统计而言，64位的JVM将会比32位的JVM多耗费50%的内存。为了节约内存可以使用选项 - XX:+UseCompressedOops 开启指针压缩，其中，oop即ordinaryobject pointer普通对象指针。开启该选项后，下列指针将压缩至32位： 每个Class的属性指针（即静态变量） 每个对象的属性指针（即对象变量） 普通对象数组的每个元素指针 当然，也不是所有的指针都会压缩，一些特殊类型的指针JVM不会优化，比如指向PermGen的Class对 象指针(JDK8中指向元空间的Class对象指针)、本地变量、堆栈元素、入参、返回值和NULL指针等。 对象头 = Mark Word + 类型指针（未开启指针压缩的情况下） 在32位系统中，Mark Word = 4 bytes，类型指针 = 4bytes，对象头 = 8 bytes = 64 bits； 在 64位系统中，Mark Word = 8 bytes，类型指针 = 8bytes，对象头 = 16 bytes = 128bits； 实例数据就是类中定义的成员变量。 对齐填充对齐填充并不是必然存在的，也没有什么特别的意义，他仅仅起着占位符的作用，由于HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说，就是对象的大小必须是8字节的整数倍。而对象头正好是8字节的倍数，因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 查看Java对象布局12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt;&lt;/dependency&gt; 总结Java对象由3部分组成，对象头，实例数据，对齐数据对象头分成两部分：Mark World + Klass pointer 偏向锁什么是偏向锁偏向锁是JDK 6中的重要引进，因为HotSpot作者经过研究实践发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低，引进了偏向锁。偏向锁的“偏”，就是偏心的“偏”、偏袒的“偏”，它的意思是这个锁会偏向于第一个获得它的线程，会在对象头存储锁偏向的线程ID，以后该线程进入和退出同步块时只需要检查是否为偏向锁、锁标志位以及ThreadID即可。 不过一旦出现多个线程竞争时必须撤销偏向锁，所以撤销偏向锁消耗的性能必须小于之前节省下来的CAS原子操作的性能消耗，不然就得不偿失了。 偏向锁原理当线程第一次访问同步块并获取锁时，偏向锁处理流程如下： 虚拟机将会把对象头中的标志位设为“01”，即偏向模式。 同时使用CAS操作把获取到这个锁的线程的ID记录在对象的Mark Word之中 ，如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作，偏向锁的效率高。 持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作，偏向锁的效率高。 偏向锁的撤销 偏向锁的撤销动作必须等待全局安全点 暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态 撤销偏向锁，恢复到无锁（标志位为 01）或轻量级锁（标志位为 00）的状态 偏向锁在 Java 6之后是默认启用的，但在应用程序启动几秒钟之后才激活，可以使用 -XX:BiasedLockingStartupDelay=0 参数关闭延迟，如果确定应用程序中所有锁通常情况下处于竞争状态，可以通过 XX: -UseBiasedLocking=false 参数关闭偏向锁。 偏向锁好处 偏向锁是在只有一个线程执行同步块时进一步提高性能，适用于一个线程反复获得同一锁的情况。偏向 锁可以提高带有同步但无竞争的程序性能。 它同样是一个带有效益权衡性质的优化，也就是说，它并不一定总是对程序运行有利，如果程序中大多 数的锁总是被多个不同的线程访问比如线程池，那偏向模式就是多余的。 在JDK5中偏向锁默认是关闭的，而到了JDK6中偏向锁已经默认开启。但在应用程序启动几秒钟之后才 激活，可以使用 - XX:BiasedLockingStartupDelay=0 参数关闭延迟，如果确定应用程序中所有锁通常 情况下处于竞争状态，可以通过 XX: -UseBiasedLocking=false 参数关闭偏向锁。 总结偏向锁的原理 当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设为“01”，即偏向模式。同时使用CAS操作把获取到这个锁的线程的ID记录在对象的Mark Word之中 ，如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作，偏向锁的效率高 偏向锁的好处 偏向锁是在只有一个线程执行同步块时进一步提高性能，适用于一个线程反复获得同一锁的情况。偏向锁可以提高带有同步但无竞争的程序性能。 轻量级锁什么是轻量级锁轻量级锁是JDK 6之中加入的新型锁机制，它名字中的“轻量级”是相对于使用monitor的传统锁而言的，因此传统的锁机制就称为“重量级”锁。首先需要强调一点的是，轻量级锁并不是用来代替重量级锁的。引入轻量级锁的目的：在多线程交替执行同步块的情况下，尽量避免重量级锁引起的性能消耗，但是如果多个线程在同一时刻进入临界区，会导致轻量级锁膨胀升级重量级锁，所以轻量级锁的出现并非是要替代重量级锁。 轻量级锁原理当关闭偏向锁功能或者多个线程竞争偏向锁导致偏向锁升级为轻量级锁，则会尝试获取轻量级锁，其步骤如下： 获取锁 判断当前对象是否处于无锁状态（hashcode、0、01），如果是，则JVM首先将在当前线程的栈帧 中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝（官方 把这份拷贝加了一个Displaced前缀，即Displaced Mark Word），将对象的Mark Word复制到栈 帧中的Lock Record中，将Lock Reocrd中的owner指向当前对象。 JVM利用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，如果成功表示竞争到 锁，则将锁标志位变成00，执行同步操作。 如果失败则判断当前对象的Mark Word是否指向当前线程的栈帧，如果是则表示当前线程已经持 有当前对象的锁，则直接执行同步代码块；否则只能说明该锁对象已经被其他线程抢占了，这时轻 量级锁需要膨胀为重量级锁，锁标志位变成10，后面等待的线程将会进入阻塞状态。 轻量级锁的释放轻量级锁的释放也是通过CAS操作来进行的，主要步骤如下： 取出在获取轻量级锁保存在Displaced Mark Word中的数据。 用CAS操作将取出的数据替换当前对象的Mark Word中，如果成功，则说明释放锁成功。 如果CAS操作替换失败，说明有其他线程尝试获取该锁，则需要将轻量级锁需要膨胀升级为重量级 锁。 对于轻量级锁，其性能提升的依据是“对于绝大部分的锁，在整个生命周期内都是不会存在竞争的”，如 果打破这个依据则除了互斥的开销外，还有额外的CAS操作，因此在有多线程竞争的情况下，轻量级锁 比重量级锁更慢。 #### 轻量级锁好处 在多线程交替执行同步块的情况下，可以避免重量级锁引起的性能消耗。总结轻量级锁的原理是什么将对象的Mark Word复制到栈帧中的Lock Recod中。Mark Word更新为指向Lock Record的指针。 轻量级锁好处是什么在多线程交替执行同步块的情况下，可以避免重量级锁引起的性能消耗。 自旋锁原理1234synchronized (Demo01.class) &#123; ... System.out.println("aaa");&#125; 前面我们讨论 monitor实现锁的时候，知道monitor会阻塞和唤醒线程，线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作，这些操作给系统的并发性能带来了很大的压力。同时，虚拟机的开发团队也注意到在许多应用上，共享数据的锁定状态只会持续很短的一段时间，为了这段时间阻塞和唤醒线程并不值得。如果物理机器有一个以上的处理器，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一下”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需让线程执行一个忙循环(自旋) , 这项技术就是所谓的自旋锁。 自旋锁在JDK 1.4.2中就已经引入 ，只不过默认是关闭的，可以使用-XX:+UseSpinning参数来开启，在JDK 6中 就已经改为默认开启了。自旋等待不能代替阻塞，且先不说对处理器数量的要求，自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，因此，如果锁被占用的时间很短，自旋等待的效果就会非常好，反之，如果锁被占用的时间很长。那么自旋的线程只会白白消耗处理器资源，而不会做任何有用的工作，反而会带来性 能上的浪费。因此，自旋等待的时间必须要有一定的限度，如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程了。自旋次数的默认值是10次，用户可以使用参数-XX : PreBlockSpin来更改。 适应性自旋锁在JDK 6中引入了自适应的自旋锁。自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间，比如100次循环。另外，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测就会越来越准确，虛拟机就会变得越来越“聪明”了 锁消除锁消除是指虚拟机即时编译器（JIT）在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。**锁消除的主要判定依据来源于逃逸分析的数据支持，如果判断在一段代码中，**堆上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行。变量是否逃逸，对于虚拟机来说需要使用数据流分析来确定，但是程序员自己应该是很清楚的，怎么会在明知道不存在数据争用的情况下要求同步呢?实际上有许多同步措施并不是程序员自己加入的，同步的代码在Java程序中的普遍程度也许超过了大部分读者的想象。下面这段非常简单的代码仅仅是输出3个字符串相加的结果，无论是源码字面上还是程序语义上都没有同步。 12345678public class Demo01 &#123; public static void main(String[] args) &#123; contactString("aa", "bb", "cc"); &#125; public static String contactString(String s1, String s2, String s3) &#123; return new StringBuffer().append(s1).append(s2).append(s3).toString(); &#125;&#125; StringBuffer的append ( ) 是一个同步方法，锁就是this也就是(new StringBuilder())。虚拟机发现它的动态作用域被限制在concatString( )方法内部。也就是说, new StringBuilder()对象的引用永远不会“逃逸”到concatString ( )方法之外，其他线程无法访问到它，因此，虽然这里有锁，但是可以被安全地消除掉，在即时编译之后，这段代码就会忽略掉所有的同步而直接执行了 锁粗化原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小，只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待锁的线程也能尽快拿到锁。大部分情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗 例子12345678910public class Demo01 &#123; static StringBuffer sb = new StringBuffer(); public static void main(String[] args) &#123; for (int i = 0; i &lt; 100; i++) &#123; sb.append("aa"); &#125; System.out.println(sb.toString()); &#125;&#125; 对于上述代码因为append有synchronized，所以会执行100次锁的获取和释放 JIT在遇见这种代码的时候会吧锁放到循环外部，这样就不需要频繁的获取锁了 总结每一个synchronized块都对应一个monitorenter和两个monitorexit，其实JIT编译器在执行动态编译时会对上面代码进行优化：若发现前后相邻的synchronized块使用的是同一个锁对象，那么它就会把这几个synchronized块给合并为一个较大的同步块，这样做的好处在于线程在执行这些代码时，就无需频繁申请与释放锁了，从而达到申请与释放锁一次，就可以执行完全部的同步代码块，从而提升了性能。 平时写代码如何对 synchronized优化减少synchronized的范围同步代码块中尽量短，减少同步代码块中代码的执行时间，减少锁的竞争。 123synchronized (Demo01.class) &#123; System.out.println("aaa");&#125; 降低 synchronized锁的粒度将一个锁拆分为多个锁提高并发度 123Hashtable hs = new Hashtable();hs.put("aa", "bb");hs.put("xx", "yy"); 读写分离读取时不加锁，写入和删除时加锁ConcurrentHashMap，CopyOnWriteArrayList和ConyOnWriteSet]]></content>
      <tags>
        <tag>java</tag>
        <tag>锁</tag>
        <tag>CAS</tag>
        <tag>乐观锁</tag>
        <tag>悲观锁</tag>
        <tag>偏向锁</tag>
        <tag>轻量级锁</tag>
        <tag>自旋锁</tag>
        <tag>锁消除</tag>
        <tag>锁粗化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[monitor详解]]></title>
    <url>%2F2020%2F03%2F28%2Fmonitor%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[准备JVM源码下载http://openjdk.java.net/ –&gt; Mercurial –&gt; jdk8 –&gt; hotspot –&gt; zip monitor监视器锁从上一篇synchronized详解文章可以看出,无论是synchronized代码块还是synchronized方法，其线程安全的语义实现最终依赖一个叫monitor的东西，那么这个神秘的东西是什么呢？ 在HotSpot虚拟机中，monitor是由ObjectMonitor实现的。其源码是用c++来实现的，位于HotSpot虚拟机源码ObjectMonitor.hpp文件中(src/share/vm/runtime/objectMonitor.hpp)。ObjectMonitor主要数据结构如下： 12345678910111213141516171819ObjectMonitor() &#123; _header = NULL; _count = 0; _waiters = 0, _recursions = 0;//线程的重入次数，也就是前面几篇文章我们所说的那个计数器 _object = NULL;//存储该monitor对象 _owner = NULL;//标识那个线程拥有这个monitor _WaitSet = NULL;//处于wait状态的线程，会被加入到这个_WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ;//多线程竞争锁时的单项列表 FreeNext = NULL ; _EntryList = NULL ;//处于等待block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; _previous_owner_tid = 0;&#125; _owner：初始时为NULL。当有线程占有该monitor时，owner标记为该线程的唯一标识。当线程 释放monitor时，owner又恢复为NULL。owner是一个临界资源，JVM是通过CAS操作来保证其线 程安全的。 cxq：竞争队列，所有请求锁的线程首先会被放在这个队列中（单向链接）。cxq是一个临界资 源，JVM通过CAS原子指令来修改_cxq队列。修改前_cxq的旧值填入了node的next字段，_cxq指 向新值（新线程）。因此_cxq是一个后进先出的stack（栈）。 EntryList：cxq队列中有资格成为候选资源的线程会被移动到该队列中。 WaitSet：因为调用wait方法而被阻塞的线程会被放在该队列中。 每一个Java对象都可以与一个监视器monitor关联，我们可以把它理解成为一把锁，当一个线程想要执 行一段被synchronized圈起来的同步方法或者代码块时，该线程得先获取到synchronized修饰的对象 对应的monitor。 我们的Java代码里不会显示地去创造这么一个monitor对象，我们也无需创建，事实上可以这么理解： monitor并不是随着对象创建而创建的。我们是通过synchronized修饰符告诉JVM需要为我们的某个对 象创建关联的monitor对象。每个线程都存在两个ObjectMonitor对象列表，分别为free和used列表。 同时JVM中也维护着global locklist。当线程需要ObjectMonitor对象时，首先从线程自身的free表中申 请，若存在则使用，若不存在则从global list中申请 monitor竞争执行monitorenter时，会调用InterpreterRuntime.cpp(位于：src/share/vm/interpreter/interpreterRuntime.cpp) 的 InterpreterRuntime::monitorenter函数。具体代码可参见HotSpot源码。 12345678910111213141516171819202122IRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* thread, BasicObjectLock* elem))#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endif if (PrintBiasedLockingStatistics) &#123; Atomic::inc(BiasedLocking::slow_path_entry_count_addr()); &#125; Handle h_obj(thread, elem-&gt;obj()); assert(Universe::heap()-&gt;is_in_reserved_or_null(h_obj()), "must be NULL or an object"); if (UseBiasedLocking) &#123; // Retry fast entry if bias is revoked to avoid unnecessary inflation ObjectSynchronizer::fast_enter(h_obj, elem-&gt;lock(), true, CHECK); &#125; else &#123; ObjectSynchronizer::slow_enter(h_obj, elem-&gt;lock(), CHECK); &#125; assert(Universe::heap()-&gt;is_in_reserved_or_null(elem-&gt;obj()), "must be NULL or an object");#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endifIRT_END 对于重量级锁，monitorenter函数中会调用 ObjectSynchronizer::slow_enter 最终调用 ObjectMonitor::enter（位于：src/share/vm/runtime/objectMonitor.cpp），源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263void ATTR ObjectMonitor::enter(TRAPS) &#123; // The following code is ordered to check the most common cases first // and to reduce RTS-&gt;RTO cache line upgrades on SPARC and IA32 processors. Thread * const Self = THREAD ; void * cur ; // 通过CAS操作尝试把monitor的_owner字段设置为当前线程 cur = Atomic::cmpxchg_ptr (Self， &amp;_owner， NULL) ; if (cur == NULL) &#123; // Either ASSERT _recursions == 0 or explicitly set _recursions = 0. assert (_recursions == 0 ， "invariant") ; assert (_owner == Self， "invariant") ; // CONSIDER: set or assert OwnerIsThread == 1 return ;&#125; // 线程重入，recursions++ if (cur == Self) &#123; // TODO-FIXME: check for integer overflow! BUGID 6557169. _recursions ++ ; return ;&#125; // 如果当前线程是第一次进入该monitor，设置_recursions为1，_owner为当前线程此处省略锁的自旋优化等操作，统一放在后面 synchronzied优化中说。以上代码的具体流程概括如下：1. 通过CAS尝试把monitor的owner字段设置为当前线程。2. 如果设置之前的owner指向当前线程，说明当前线程再次进入monitor，即重入锁，执行recursions ++ ，记录重入的次数。3. 如果当前线程是第一次进入该monitor，设置recursions为1，_owner为当前线程，该线程成功获得锁并返回。4. 如果获取锁失败，则等待锁的释放。monitor等待竞争失败等待调用的是ObjectMonitor对象的EnterI方法（位于：src/share/vm/runtime/objectMonitor.cpp），源码如下所示： if (Self-&gt;is_lock_owned ((address)cur)) &#123; assert (_recursions == 0， "internal state error"); _recursions = 1 ; // Commute owner from a thread-specific on-stack BasicLockObject address to // a full-fledged "Thread *". _owner = Self ; OwnerIsThread = 1 ; return ;&#125; // 省略一些代码 for (;;) &#123; jt-&gt;set_suspend_equivalent(); // cleared by handle_special_suspend_equivalent_condition() // or java_suspend_self() // 如果获取锁失败，则等待锁的释放； EnterI (THREAD) ; if (!ExitSuspendEquivalent(jt)) break ; // // We have acquired the contended monitor， but while we were // waiting another thread suspended us. We don't want to enter // the monitor while suspended because that would surprise the // thread that suspended us. // _recursions = 0 ; _succ = NULL ; exit (false， Self) ; jt-&gt;java_suspend_self();&#125; Self-&gt;set_current_pending_monitor(NULL);&#125; 此处省略锁的自旋优化等操作，统一放在后面 synchronzied优化中说。以上代码的具体流程概括如下： 通过CAS尝试把monitor的owner字段设置为当前线程。 如果设置之前的owner指向当前线程，说明当前线程再次进入monitor，即重入锁，执行recursions ++ ，记录重入的次数。 如果当前线程是第一次进入该monitor，设置recursions为1，_owner为当前线程，该线程成功获得锁并返回。 如果获取锁失败，则等待锁的释放。 monitor等待竞争失败等待调用的是ObjectMonitor对象的EnterI方法（位于：src/share/vm/runtime/objectMonitor.cpp），源码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263void ATTR ObjectMonitor::EnterI (TRAPS) &#123; Thread * Self = THREAD ; // Try the lock - TATAS if (TryLock (Self) &gt; 0) &#123; assert (_succ != Self , "invariant") ; assert (_owner == Self , "invariant") ; assert (_Responsible != Self , "invariant") ; return ; &#125; if (TrySpin (Self) &gt; 0) &#123; assert (_owner == Self , "invariant") ; assert (_succ != Self , "invariant") ; assert (_Responsible != Self , "invariant") ; return ; &#125; // 省略部分代码 // 当前线程被封装成ObjectWaiter对象node，状态设置成ObjectWaiter::TS_CXQ； ObjectWaiter node(Self) ; Self-&gt;_ParkEvent-&gt;reset() ; node._prev = (ObjectWaiter *) 0xBAD ; node.TState = ObjectWaiter::TS_CXQ ;// 通过CAS把node节点push到_cxq列表中 ObjectWaiter * nxt ; for (;;) &#123; node._next = nxt = _cxq ; if (Atomic::cmpxchg_ptr (&amp;node， &amp;_cxq， nxt) == nxt) break ; // Interference - the CAS failed because _cxq changed. Just retry. // As an optional optimization we retry the lock. if (TryLock (Self) &gt; 0) &#123; assert (_succ != Self ， "invariant") ; assert (_owner == Self ， "invariant") ; assert (_Responsible != Self ， "invariant") ; return ; &#125; &#125; // 省略部分代码 for (;;) &#123;// 线程在被挂起前做一下挣扎，看能不能获取到锁 if (TryLock (Self) &gt; 0) break ; assert (_owner != Self， "invariant") ; if ((SyncFlags &amp; 2) &amp;&amp; _Responsible == NULL) &#123; Atomic::cmpxchg_ptr (Self， &amp;_Responsible， NULL) ; &#125; // park self if (_Responsible == Self || (SyncFlags &amp; 1)) &#123; TEVENT (Inflated enter - park TIMED) ; Self-&gt;_ParkEvent-&gt;park ((jlong) RecheckInterval) ; // Increase the RecheckInterval， but clamp the value. RecheckInterval *= 8 ; if (RecheckInterval &gt; 1000) RecheckInterval = 1000 ; &#125; else &#123; TEVENT (Inflated enter - park UNTIMED) ; // 通过park将当前线程挂起，等待被唤醒 Self-&gt;_ParkEvent-&gt;park() ; &#125; if (TryLock(Self) &gt; 0) break ; // 省略部分代码 &#125; // 省略部分代码&#125; 当该线程被唤醒时，会从挂起的点继续执行，通过 ObjectMonitor::TryLock 尝试获取锁，TryLock方法实现如下： 123456789101112131415161718int ObjectMonitor::TryLock (Thread * Self) &#123; for (;;) &#123; void * own = _owner ; if (own != NULL) return 0 ; if (Atomic::cmpxchg_ptr (Self， &amp;_owner， NULL) == NULL) &#123; // Either guarantee _recursions == 0 or set _recursions = 0. assert (_recursions == 0， "invariant") ; assert (_owner == Self， "invariant") ; // CONSIDER: set or assert that OwnerIsThread == 1 return 1 ; &#125; // The lock had been free momentarily， but we lost the race to the lock. // Interference -- the CAS failed. // We can either return -1 or retry. // Retry doesn't make as much sense because the lock was just acquired. if (true) return -1 ; &#125;&#125; 以上代码的具体流程概括如下： 当前线程被封装成ObjectWaiter对象node，状态设置成ObjectWaiter::TS_CXQ。 在for循环中，通过CAS把node节点push到_cxq列表中，同一时刻可能有多个线程把自己的node节点push到_cxq列表中。 node节点push到_cxq列表之后，通过自旋尝试获取锁，如果还是没有获取到锁，则通过park将当前线程挂起，等待被唤醒。 当该线程被唤醒时，会从挂起的点继续执行，通过 ObjectMonitor::TryLock 尝试获取锁。 monitor释放当某个持有锁的线程执行完同步代码块时，会进行锁的释放，给其它线程机会执行同步代码，在HotSpot中，通过退出monitor的方式实现锁的释放，并通知被阻塞的线程，具体实现位于ObjectMonitor的exit方法中。（位于：src/share/vm/runtime/objectMonitor.cpp），源码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129void ATTR ObjectMonitor::exit(bool not_suspended， TRAPS) &#123; Thread * Self = THREAD ;// 省略部分代码 if (_recursions != 0) &#123; _recursions--; // this is simple recursive enter TEVENT (Inflated exit - recursive) ; return ; &#125;// 省略部分代码 ObjectWaiter * w = NULL ; int QMode = Knob_QMode ; // qmode = 2：直接绕过EntryList队列，从cxq队列中获取线程用于竞争锁 if (QMode == 2 &amp;&amp; _cxq != NULL) &#123; w = _cxq ; assert (w != NULL， "invariant") ; assert (w-&gt;TState == ObjectWaiter::TS_CXQ， "Invariant") ; ExitEpilog (Self， w) ; return ; &#125; // qmode =3：cxq队列插入EntryList尾部； if (QMode == 3 &amp;&amp; _cxq != NULL) &#123; w = _cxq ; for (;;) &#123; assert (w != NULL， "Invariant") ; ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr (NULL，&amp;_cxq， w) ; if (u == w) break ; w = u ; &#125; assert (w != NULL ， "invariant") ; ObjectWaiter * q = NULL ; ObjectWaiter * p ; for (p = w ; p != NULL ; p = p-&gt;_next) &#123; guarantee (p-&gt;TState == ObjectWaiter::TS_CXQ， "Invariant") ; p-&gt;TState = ObjectWaiter::TS_ENTER ; p-&gt;_prev = q ; q = p ; &#125; ObjectWaiter * Tail ; for (Tail = _EntryList ; Tail != NULL &amp;&amp; Tail-&gt;_next != NULL ; Tail =Tail-&gt;_next) ; if (Tail == NULL) &#123; _EntryList = w ; &#125; else &#123; Tail-&gt;_next = w ; w-&gt;_prev = Tail ; &#125; &#125; // qmode =4：cxq队列插入到_EntryList头部 if (QMode == 4 &amp;&amp; _cxq != NULL) &#123; w = _cxq ; for (;;) &#123; assert (w != NULL， "Invariant") ; ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr (NULL，&amp;_cxq， w) ; if (u == w) break ; w = u ; &#125; assert (w != NULL ， "invariant") ; ObjectWaiter * q = NULL ; ObjectWaiter * p ; for (p = w ; p != NULL ; p = p-&gt;_next) &#123; guarantee (p-&gt;TState == ObjectWaiter::TS_CXQ， "Invariant") ; p-&gt;TState = ObjectWaiter::TS_ENTER ; p-&gt;_prev = q ; q = p ; &#125; if (_EntryList != NULL) &#123; q-&gt;_next = _EntryList ; _EntryList-&gt;_prev = q ; &#125; _EntryList = w ; &#125; w = _EntryList ; if (w != NULL) &#123; assert (w-&gt;TState == ObjectWaiter::TS_ENTER， "invariant") ; ExitEpilog (Self， w) ; return ; &#125; w = _cxq ; if (w == NULL) continue ; for (;;) &#123; assert (w != NULL， "Invariant") ; ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr (NULL， &amp;_cxq，w) ; if (u == w) break ; w = u ; &#125; TEVENT (Inflated exit - drain cxq into EntryList) ; assert (w != NULL ， "invariant") ; assert (_EntryList == NULL ， "invariant") ; if (QMode == 1) &#123; // QMode == 1 : drain cxq to EntryList， reversing order // We also reverse the order of the list. ObjectWaiter * s = NULL ; ObjectWaiter * t = w ; ObjectWaiter * u = NULL ; while (t != NULL) &#123; guarantee (t-&gt;TState == ObjectWaiter::TS_CXQ， "invariant") ; t-&gt;TState = ObjectWaiter::TS_ENTER ; u = t-&gt;_next ; t-&gt;_prev = u ; t-&gt;_next = s ; s = t; t = u ; &#125; _EntryList = s ; assert (s != NULL， "invariant") ; &#125; else &#123; // QMode == 0 or QMode == 2 _EntryList = w ; ObjectWaiter * q = NULL ; ObjectWaiter * p ; for (p = w ; p != NULL ; p = p-&gt;_next) &#123; guarantee (p-&gt;TState == ObjectWaiter::TS_CXQ， "Invariant") ; p-&gt;TState = ObjectWaiter::TS_ENTER ; p-&gt;_prev = q ; q = p ; &#125; &#125; if (_succ != NULL) continue; w = _EntryList ; if (w != NULL) &#123; guarantee (w-&gt;TState == ObjectWaiter::TS_ENTER， "invariant") ; ExitEpilog (Self， w) ; return ; &#125; &#125;&#125; 退出同步代码块时会让_recursions减1，当_recursions的值减为0时，说明线程释放了锁。 根据不同的策略（由QMode指定），从cxq或EntryList中获取头节点，通过 ObjectMonitor::ExitEpilog 方法唤醒该节点封装的线程，唤醒操作最终由unpark完成，实现 如下： 12345678910111213141516171819void ObjectMonitor::ExitEpilog (Thread * Self， ObjectWaiter * Wakee) &#123; assert (_owner == Self， "invariant") ; _succ = Knob_SuccEnabled ? Wakee-&gt;_thread : NULL ; ParkEvent * Trigger = Wakee-&gt;_event ; Wakee = NULL ; // Drop the lock OrderAccess::release_store_ptr (&amp;_owner， NULL) ; OrderAccess::fence() ; // ST _owner vs LD inunpark() if (SafepointSynchronize::do_call_back()) &#123; TEVENT (unpark before SAFEPOINT) ; &#125; DTRACE_MONITOR_PROBE(contended__exit， this， object()， Self); Trigger-&gt;unpark() ; // 唤醒之前被pack()挂起的线程. // Maintain stats and report events to JVMTI if (ObjectMonitor::_sync_Parks != NULL) &#123; ObjectMonitor::_sync_Parks-&gt;inc() ; &#125;&#125; 被唤醒的线程，会回到 void ATTR ObjectMonitor::EnterI (TRAPS) 的第600行，继续执行monitor的竞争 123456789101112// park selfif (_Responsible == Self || (SyncFlags &amp; 1)) &#123; TEVENT (Inflated enter - park TIMED) ; Self-&gt;_ParkEvent-&gt;park ((jlong) RecheckInterval) ; // Increase the RecheckInterval， but clamp the value. RecheckInterval *= 8 ; if (RecheckInterval &gt; 1000) RecheckInterval = 1000 ;&#125; else &#123; TEVENT (Inflated enter - park UNTIMED) ; Self-&gt;_ParkEvent-&gt;park() ;&#125;if (TryLock(Self) &gt; 0) break ; monitor是重量级锁可以看到ObjectMonitor的函数调用中会涉及到Atomic::cmpxchg_ptr，Atomic::inc_ptr等内核函数，执行同步代码块，没有竞争到锁的对象会park()被挂起，竞争到锁的线程会unpark()唤醒。这个时候就会存在操作系统用户态和内核态的转换，这种切换会消耗大量的系统资源。所以synchronized是Java语言中是一个重量级(Heavyweight)的操作。]]></content>
      <tags>
        <tag>synchronized</tag>
        <tag>monitor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[synchronized详解]]></title>
    <url>%2F2020%2F03%2F26%2Fsynchronized%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[线程安全线程安全产生的原因 存在共享数据（也称临界资源） 操作共享数据的线程代码有多条 因此，引入了互斥锁的概念，即一个共享数据只能被一个线程访问，其他线程需要等待（阻塞），直至当前线程处理完毕释放该锁。 所以，synchronized方法就保证了同一时刻只有一个线程对方法或者代码块有共享数据的操作。而且，synchronized保证了一个线程对共享变量操作的变化被其他线程看到（可以替代volatile功能）。 Synchronized就是内置锁，是java语言特性提供的内置锁，其获得锁和释放锁是隐式的（进入代码块就是获得锁，走出代码就是释放锁）。java.util.concurrent.locks 包中的锁是显示锁，需要进行lock和unlock。 首先，synchronized可以修饰类、方法（实例方法和静态方法）和代码块（修饰代码块实现同步），区别就是作用范围的不同：修饰类的时候和修饰静态方法是一样的，都是给所有的对象加了同一把锁；修饰实例方法时作用范围就是整个函数，给当前实例加锁；修饰代码块时作用范围就是大括号内的内容，对给定的对象加锁。 其次，synchronized不能被继承，不能使用Synchronized关键字修饰接口方法；构造方法也不能用Synchronized。 synchronized的使用当synchronized作用于静态方法时，其锁就是当前类的class对象锁。由于静态成员不专属于任何一个实例对象，是类成员，因此通过class对象锁可以控制静态 成员的并发操作。 需要注意的是如果一个线程A调用一个实例对象的非static synchronized方法，而线程B需要调用这个实例对象所属类的静态 synchronized方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的class对象，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。 synchronized的可重入性可重入特性指同一个线程在获得这个锁后，可以再次获得该锁 12345678910111213141516171819/** * @author yang * @date 2020/3/26 下午 6:40 */public class Synchronized2 &#123; public static void main(String[] args) &#123; Runnable runnable=()-&gt;&#123; synchronized(Synchronized2.class)&#123; System.out.println(Thread.currentThread().getName()+"进入同步代码块一"); synchronized(Synchronized2.class)&#123; System.out.println(Thread.currentThread().getName()+"进入同步代码块二"); &#125; &#125; &#125;; new Thread(runnable,"线程一").start(); new Thread(runnable,"线程二").start(); &#125;&#125; 当线程一进入到第一个同步代码块的时候，synchronized的锁对象有一个计数器(recurslons变量),会记录线程获得几次锁，此时如果线程二发现该锁对象的计数器不为0，那么线程二就在外部等待。 可重入的好处 可以避免死锁 原因，如果同一个线程没有重入性，那么线程就会卡在第二次获得相同锁，那么就会死锁 可以让我们更好的封装代码。 总结synchronized是可重入锁，内部锁对象中会有一个计数器记录线程获取几次锁，在执行完同步代码块时，计数器的数量会-1，当计数器为0的时候，就意味着该线程释放了这个锁。 Synchronized不可中断特性lock是可中断锁，而synchronized 不是可中断锁 ​ 线程A和B都要获取对象O的锁定，假设A获取了对象O锁，B将等待A释放对O的锁定， ​ 如果使用 synchronized ，如果A不释放，B将一直等下去，不能被中断 ​ 如果 使用ReentrantLock，如果A不释放，可以使B在等待了足够长的时间以后，中断等待，而干别的事情 ​ ReentrantLock获取锁定与三种方式： lock(), 如果获取了锁立即返回，如果别的线程持有锁，当前线程则一直处于休眠状态，直到获取锁 tryLock(), 如果获取了锁立即返回true，如果别的线程正持有锁，立即返回false； tryLock(long timeout,TimeUnit unit)， 如果获取了锁定立即返回true，如果别的线程正持有锁，会等待参数给定的时间，在等待的过程中，如果获取了锁定，就返回true，如果等待超时，返回false； lockInterruptibly:如果获取了锁定立即返回，如果没有获取锁定，当前线程处于休眠状态，直到或者锁定，或者当前线程被别的线程中断 什么是不可中断一个线程获得锁后，另一个线程想要获得锁，必须处于阻塞或等待状态，如果一个线程不释放锁，第二个线程会一直阻塞或者等待，不可中断 Synchronized不可中断演示123456789101112131415161718192021222324252627282930public class Synchronized2 &#123; public static void main(String[] args) throws InterruptedException &#123; Runnable runnable=()-&gt;&#123; synchronized(Synchronized2.class)&#123; System.out.println(Thread.currentThread().getName()+"进入了同步代码块"); try &#123; Thread.sleep(99999999); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; Thread thread = new Thread(runnable); thread.start(); Thread.sleep(1000); Thread thread1 = new Thread(runnable); thread1.start(); Thread.sleep(1000); thread1.interrupt();//中断线程2 System.out.println(thread1.getName()+"状态为"+thread1.getState()); &#125;&#125;// 结果为//Thread-0进入了同步代码块//Thread-1状态为BLOCKED Loke 不可中断演示1234567891011121314151617181920212223242526272829public class Synchronized2 &#123; private static Lock loke=new ReentrantLock(); public static void main(String[] args) throws InterruptedException &#123; Runnable runnable=()-&gt;&#123; loke.lock(); System.out.println(Thread.currentThread().getName()+"进入了同步代码块"); try &#123; Thread.sleep(99999999); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; loke.unlock(); &#125;; Thread thread = new Thread(runnable); thread.start(); Thread.sleep(1000); Thread thread1 = new Thread(runnable); thread1.start(); Thread.sleep(1000); thread1.interrupt();//中断线程2 System.out.println(thread1.getName()+"状态为"+thread1.getState()); &#125;&#125;//Thread-0进入了同步代码块//Thread-1状态为WAITING Loke 可中断演示123456789101112131415161718192021222324252627282930313233343536public class Synchronized2 &#123; private static Lock loke=new ReentrantLock(); public static void main(String[] args) throws InterruptedException &#123; Runnable runnable=()-&gt;&#123; boolean b=false; try &#123; b = loke.tryLock(3, TimeUnit.SECONDS); if(b)&#123; System.out.println(Thread.currentThread().getName()+"进入了同步代码块"); Thread.sleep(99999999); &#125;else&#123; System.out.println("在指定时间内没有获取到锁,自动释放锁"); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; if(b)&#123; loke.unlock(); System.out.println("释放锁"); &#125; &#125; &#125;; Thread thread = new Thread(runnable); thread.start(); Thread.sleep(1000); Thread thread1 = new Thread(runnable); thread1.start(); Thread.sleep(1000); &#125;&#125;//结果//Thread-0进入了同步代码块//在指定时间内没有获取到锁,自动释放锁 Synchronized字节码解释有如下代码 1234567891011public class Synchronized3 &#123; public static void main(String[] args) &#123; synchronized (Synchronized3.class)&#123; System.out.println("1"); &#125; &#125; public static synchronized void method()&#123; System.out.println("2"); &#125;&#125; main方法其字节码指令 12345678910111213141516 0 ldc #2 &lt;thread/synchronized1/Synchronized3&gt; 2 dup 3 astore_1 4 monitorenter//同步代码块开始的地方 5 getstatic #3 &lt;java/lang/System.out&gt; 8 ldc #4 &lt;1&gt;10 invokevirtual #5 &lt;java/io/PrintStream.println&gt;13 aload_114 monitorexit//同步代码块结束的地方15 goto 23 (+8)18 astore_219 aload_120 monitorexit21 aload_222 athrow23 return monitorenter 每个对象都会和一个监视器monitor关联，监视器被占用时会被锁住，其他线程无法来获取该monitor 当JVM执行某个方法内部的monitorenter时，他会尝试去获取当前对象对应的monitor的所有权， monitor的重要成员变量owner：拥有锁的线程 recursions：记录获取锁的次数 执行流程 monitor才是真正的锁，执行monitorenter指令的时候，如果jvm在执行到monitorenter的时候没有关联monitor，虚拟机就会关联一个monitor对象（而且monitor是一个C++对象）， 然后把当前线程存入owner，recusions次数+1，如果这个时候有其他线程执行了这个monitorenter，那么这个线程会检查owner是不是自己，否则就进入阻塞状态 当执行到monitorexit这个指令的时候，会让recusions的次数减一，如果为零了那么就释放了这个锁。 问题分析我们发现这个同步代码块中14行和20行都执行了monitorexit指令，为什么呢？ 我们打开异常表发现，当5行到15行[5,15)这个区间如果发生了异常就会跳转到18行字节码指令，也就是说如果我们这个锁发生了异常，那么就意味着14行中monitorexit字节码不会执行，所以需要有二次释放。 结论Synchronized在遇见异常的时候会自动释放锁 method方法锁12345678 public static synchronized void method()&#123; System.out.println("2"); &#125;0 getstatic #3 &lt;java/lang/System.out&gt;3 ldc #6 &lt;2&gt;5 invokevirtual #5 &lt;java/io/PrintStream.println&gt;8 return 我们发现虽然使用了锁但是并没有monitorenter和monitorexit这两条指令，这是为什么呢？ 原因方法信息 上面方法的标记上有synchronized 那么会增加一个ACC_SYNCHRONIZED修饰，会隐式调用monitorenter和monitorexit，在执行前先调用monitorenter在执行后会monitorexit monitor监视器锁下一篇文章会详细解释 synchronized与Lock的区别 synchronized是一个关键字，Lock是一个接口（JDK1.5后） synchronized会自动释放锁，Lock必须手动释放锁 synchronized是不可中断的，Lock可以中断也可以不中断 通过Lock可以知道线程有没有拿到锁，但是synchronized不能 synchronized可以锁住方法和代码块，Lock只能锁住代码块 Lock可以使用读锁提高多线程读效率 synchronized是非公平锁，ReentrantLock是可以控制是否是公平锁]]></content>
      <tags>
        <tag>并发</tag>
        <tag>指令重排</tag>
        <tag>线程安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JMM内存模型]]></title>
    <url>%2F2020%2F03%2F26%2FJMM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Java内存模型——JMM什么是JMM内存模型 Java的并发采用的是共享内存模型 JMM定义了Java 虚拟机(JVM)在计算机内存(RAM)中的工作方式。JVM是整个计算机虚拟模型，所以JMM是隶属于JVM的。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。 jMM模型运行过程 在JVM内部，Java内存模型把内存分成了两部分：线程栈区和堆区 JVM中运行的每个线程都拥有自己的线程栈，线程栈包含了当前线程执行的方法调用相关信息，我们也把它称作调用栈。随着代码的不断执行，调用栈会不断变化。 共享变量大多指的是静态变量 JAVA内存模型中的重排序在执行程序时，为了提高性能，编译期和处理器常常会对指令做重排序 java重排序的规则 as-if-serial 不管如何重排序，都必须保证代码在单线程下的运行正确 运行过程带来的问题可见性问题假如我们我们有一个共享变量x，假设有两个线程，线程一执行的时候会复制一个变量副本到自己的工作内存，此时线程二也在使用共享变量x,假如说线程一修改了这个变量的值，并且向共享内存中写入了结果，但是由于线程二使用的是自己工作内存中的变量，那么无论如何线程二都看不到这个共享变量x的变化。 解决方案使用volatile可以保证有序性和共享性 有序性问题在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-LevelParallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 这样会导致程序在多线程情况下出现问题 解决方案使用volatile可以保证有序性和共享性 竞争现象如果线程A和线程B都共享了一个对象，其中A让自己工作内存中的变量加1，B也在工作内存中加1，如果正常情况下，主内存的值应该被加2，但是由于这两个操作是并行的，所以结果被加了1 解决方案使用synchronized进行同步 并发下重排序带来的问题123456789101112131415class ReorderExample&#123; int a=0; boolean flag=false; //线程A执行 public void writer()&#123; a=1; flag=true; &#125; //线程B执行 public void reader()&#123; if(flag)&#123; int i=a*a; &#125; &#125;&#125; 由于a=1和flag=true，没有数据依赖，那么这两条代码可能会被重排序。 假设线程A先执行了flag=true; 此时线程B进入判断发现为真计算i的结果就会为0，这个时候如果线程A由执行a=1,那么这就产生了并发下重排序问题。 解决方法一使用锁来同步 临界区内的代码可以重排序（但JMM不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。JMM会在退出临界区和进入临界区这两个关键时间点做一些特别处理，虽然线程A在临界区内做了重排序，但由于监视器互斥执行的特性，这里的线程B根本无法“观察”到线程A在临界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。 解决方法二基于happens-Before编程在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系 。 两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。 从JDK5开始，java使用happens-before概念来阐述操作间的内存可见性。 程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。 volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。 start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。 join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。 线程中断规则:对线程interrupt方法的调用happens-before于被中断线程的代码检测到中断事件的发生。 对于上述代码我们就可以使用volatile规则来保证 123456789101112131415class ReorderExample&#123; int a=0; volatile boolean flag=false; //线程A执行 public void writer()&#123; a=1; flag=true; &#125; //线程B执行 public void reader()&#123; if(flag)&#123;//保证读一定在写之后 int i=a*a; &#125; &#125;&#125; 内存屏障上述的volatile在java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序，从而让程序按我们预想的流程去执行。 1、保证特定操作的执行顺序。 2、影响某些数据（或则是某条指令的执行结果）的内存可见性。 但是这种方法是java编译器插入的，我们无法控制。]]></content>
  </entry>
  <entry>
    <title><![CDATA[并发编程中的三个问题]]></title>
    <url>%2F2020%2F03%2F26%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B8%AD%E7%9A%84%E4%B8%89%E4%B8%AA%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[可见性对于一个共享变量，一个线程的修改，对于另一个线程来说他不能立刻知道这个值已经被修改. 演示1234567891011121314151617181920/** * @author yang * @date 2020/3/26 下午 3:30 */public class LookThread &#123; public static boolean flag=true; public static void main(String[] args) throws InterruptedException &#123; new Thread(() -&gt; &#123; while (flag)&#123; //注意这里不要打印输出 &#125; &#125;).start(); Thread.sleep(1000);//为了效果更明显 flag=false; System.out.println("main函数修改了flag,但是对于另一个线程来说,他并看不见flag的改变"); &#125;&#125; 执行上面的程序你会发现程序不会停止运行，原因就是可见性问题。 运行过程带来的问题假如我们我们有一个共享变量x，假设有两个线程，线程一执行的时候会复制一个变量副本到自己的工作内存，此时线程二也在使用共享变量x,假如说线程一修改了这个变量的值，并且向共享内存中写入了结果，但是由于线程二使用的是自己工作内存中的变量，那么无论如何线程二都看不到这个共享变量x的变化。 解决方案方案一使用volatile可以保证有序性和共享性 1234567891011121314151617181920/** * @author yang * @date 2020/3/26 下午 3:30 */public class LookThread &#123; public static volatile boolean flag=true; public static void main(String[] args) throws InterruptedException &#123; new Thread(() -&gt; &#123; while (flag)&#123; //注意这里不要打印输出 &#125; &#125;).start(); Thread.sleep(1000);//为了效果更明显 flag=false; System.out.println("main函数修改了flag,但是对于另一个线程来说,他并看不见flag的改变"); &#125;&#125; 方案二使用synchronized 1234567891011121314151617181920212223/** * @author yang * @date 2020/3/26 下午 3:30 */public class LookThread &#123; public static boolean flag=true; static Object obj=new Object(); public static void main(String[] args) throws InterruptedException &#123; new Thread(() -&gt; &#123; while (flag)&#123; synchronized (obj)&#123; &#125; &#125; &#125;).start(); Thread.sleep(1000);//为了效果更明显 flag=false; System.out.println("main函数修改了flag,但是对于另一个线程来说,他并看不见flag的改变"); &#125;&#125; 解决分析volatile和synchronized都能起到刷新了共享内存的作用 原子性原子性（Atomiclty）：在一次或者多次操作中，要么所有的操作都执行，并且都执行不会受到其他因素的干扰而中断，要么所有的操作都不执行 触发原子性问题的条件 数据数据 多个线程争抢相同资源 违反原子性问题演示我们新建10个线程，每个线程都对同一个共享变量进行自增操作，其中每个线程执行10000，那么理想结果应该是10000 123456789101112131415161718192021222324252627282930313233343536package thread.synchronized1;import java.util.ArrayList;/** * @author yang * @date 2020/3/26 下午 3:45 */public class Atom01 &#123; private static int num=0; public static void main(String[] args) throws InterruptedException &#123; Runnable runnable=()-&gt;&#123; for (int i = 0; i &lt; 1000; i++) &#123; num++; &#125; &#125;; ArrayList&lt;Thread&gt; threads = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; threads.add(new Thread(runnable)); &#125; for (Thread thread : threads) &#123; thread.start(); &#125; //等待所有线程结束 for (Thread thread : threads) &#123; thread.join(); &#125; System.out.println(num); &#125;&#125; 上面打印的结果不一定是10000 原因分析这是lambad表达式的字节码 123456789101112 0 iconst_0 1 istore_0 2 iload_0 3 sipush 1000 6 if_icmpge 23 (+17) 9 getstatic #14 &lt;thread/synchronized1/Atom01.num&gt;12 iconst_113 iadd14 putstatic #14 &lt;thread/synchronized1/Atom01.num&gt;17 iinc 0 by 120 goto 2 (-18)23 return 其中最涉及num++的指令为（不准确，先做个标记，底下的字节码分析貌似不正确，到后期我在改，但大体分析是正确的） 1234 9 getstatic #14 &lt;thread/synchronized1/Atom01.num&gt; //获取静态字段12 iconst_1//把局1位置上的操作数栈，1位置的对应的值就是num的值13 iadd//指正14 putstatic #14 &lt;thread/synchronized1/Atom01.num&gt;//把操作数栈的结果保存到原来的位置。 也就是说执行自增这个代码需要4条字节码指令，而且这4条代码并不符合原子性操作，即线程一可以先执行，但是线程一执行的太慢，结果这期间其他线程已经执行了自增好多次，然后线程一又把它计算的结果又覆盖了，所以导致了这个问题的发生 使用synchronize解决原子性问题1234567891011121314151617181920212223242526272829303132333435363738package thread.synchronized1;import java.util.ArrayList;/** * @author yang * @date 2020/3/26 下午 3:45 */public class Atom01 &#123; private static int num=0; private static Object obj=new Object(); public static void main(String[] args) throws InterruptedException &#123; Runnable runnable=()-&gt;&#123; for (int i = 0; i &lt; 1000; i++) &#123; synchronized (obj.getClass())&#123; num++; &#125; &#125; &#125;; ArrayList&lt;Thread&gt; threads = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; threads.add(new Thread(runnable)); &#125; for (Thread thread : threads) &#123; thread.start(); &#125; //等待所有线程结束 for (Thread thread : threads) &#123; thread.join(); &#125; System.out.println(num); &#125;&#125; 有序性指令重排在说有序性之前，我们必须先来聊下指令重排，因为如果没有指令重拍的话，也就不存在有序性问题了。 指令重排是指编译器和处理器在不影响代码单线程执行结果的前提下，对源代码的指令进行重新排序执行。这种重排序执行是一种优化手段，目的是为了处理器内部的运算单元能尽量被充分利用，提升程序的整体运行效率。 为什么要重排序为了提高程序的执行效率，编译器和CPU会对程序中代码进行重排序。 as-if-serial语义as-if-serial语义的意思是：不管编译器和CPU如何重排序，必须保证在单线程情况下程序的结果是正确的。如果有数据有依赖关系，不能重排序。 12345678//可以这样：int a = 1;int b = 2;int c = a + b;//也可以重排序这样：int b = 2;int a = 1;int c = a + b; 12345678910111213141516171819202122232425262728293031import org.openjdk.jcstress.annotations.*;import org.openjdk.jcstress.infra.results.I_Result;/** * @author yang * @date 2020/3/26 下午 4:12 */@JCStressTest@Outcome(id=&#123;"1","4"&#125;,expect = Expect.ACCEPTABLE,desc = "ok")@Outcome(id="0",expect = Expect.ACCEPTABLE_INTERESTING,desc = "ERROR")@Statepublic class Test &#123; int num=0; boolean ready=false; @Actor public void actor1(I_Result r)&#123; if(ready)&#123; r.r1=num+num; &#125;else &#123; r.r1=1; &#125; &#125; @Actor public void acotr2(I_Result r)&#123; num=2; ready=true; &#125;&#125; 1mvn clean install//cake结果 情况1：先执行actor1,这时ready=false，所以结果为1. 情况2：执行到actor2，执行了num=2;和ready=true,线程1执行，这回进入if分支，结果为4。 情况3：线程2先执行actor2，只执行num=2;但没来得及执行ready=true，线程1执行，还是进入else分支 情况4：由于jvm指令重拍导致ready=true先执行，然后线程一进入if，结果为0]]></content>
      <tags>
        <tag>不准确</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java线程池第二天-java内置线程池]]></title>
    <url>%2F2020%2F03%2F26%2Fjava%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%AC%AC%E4%BA%8C%E5%A4%A9-java%E5%86%85%E7%BD%AE%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[ExecutorServiceExecutorService接口是java内置线程池接口 常用方法 方法 说明 List&lt; Runnable &gt; shutdownNow() 停止所有正在执行的任务，暂停处理正在等待的任务，并放回等待执行的任务列表 &lt; T &gt; Future &lt; T &gt; submit(Callable&lt; T &gt; task) 执行带返回值的任务，返回一个Future对象 Future&lt; ? &gt; submit(Runnable Task) 执行Runnable任务，并返回一个标识该任务的Future &lt; T &gt; Future&lt; T &gt; submit(Runnable task, T Result) 执行Runnable任务，并返回一个标识该任务的Future void shutdown() 启动一次顺序关闭，执行以前提交的任务，但不接受新任务]]></content>
      <tags>
        <tag>java</tag>
        <tag>自定义</tag>
        <tag>线程</tag>
        <tag>线程池</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java线程池第一天，自定义线程池]]></title>
    <url>%2F2020%2F03%2F26%2Fjava%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%AC%AC%E4%B8%80%E5%A4%A9%EF%BC%8C%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[什么是线程池线程池就是提前创建若干个线程，如果有任务需要处理，线程池里的线程就会处理任务，处理完之后线程并不会被销毁，而是等待下一个任务。由于创建和销毁线程都是消耗系统资源的，所以当你想要频繁的创建和销毁线程的时候就可以考虑使用线程池来提升系统的性能。 为什么使用线程池为了减少创建和销毁线程的次数，让每个线程可以多次使用,可根据系统情况调整执行的线程数量，防止消耗过多内存,所以我们可以使用线程池. 使用线程池的优势 线程池的重用 ​ 线程的创建和销毁的开销是巨大的，而通过线程池的重用大大减少了这些不必要的开销，当然既然少了这么多消费内存的开销，其线程执行速度也是突飞猛进的提升。 控制线程池的并发数 线程池可以对线程进行管理 线程池可以提供定时、定期、单线程、并发数控制等功能。比如通过ScheduledThreadPool线程池来执行S秒后，每隔N秒执行一次的任务。 可以让任务和线程分离 线程池工作流程1、如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务 2、如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列 3、如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务 4、如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常RejectExecutionException 参数解释 int corePoolSize 该线程池中核心线程数最大值 。线程池新建线程的时候，如果当前线程总数小于corePoolSize，则新建的是核心线程，如果超过corePoolSize，则新建的是非核心线程。核心线程默认情况下会一直存活在线程池中，即使这个核心线程啥也不干(闲置状态)。 int maximumPoolSize 该线程池中线程总数最大值线程总数 = 核心线程数 + 非核心线程数。 long keepAliveTime 该线程池中非核心线程闲置超时时长。一个非核心线程，如果不干活(闲置状态)的时长超过这个参数所设定的时长，就会被销毁掉。 TimeUnit unit keepAliveTime的单位，TimeUnit是一个枚举类型 BlockingQueue workQueue 该线程池中的任务队列。维护着等待执行的Runnable对象当所有的核心线程都在干活时，新添加的任务会被添加到这个队列中等待处理，如果队列满了，则新建非核心线程执行任务。]]></content>
      <tags>
        <tag>java</tag>
        <tag>自定义</tag>
        <tag>线程</tag>
        <tag>线程池</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NIO详解]]></title>
    <url>%2F2020%2F03%2F25%2FNIO%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[高并发量引起的问题一个使用传统阻塞I/O的系统,如果还是使用传统的一个请求对应一个线程这种模式,一旦有高并发的大量请求,就会有如下问题： 1、线程不够用, 就算使用了线程池复用线程也无济于事; 2、阻塞I/O模式下,会有大量的线程被阻塞,一直在等待数据,这个时候的线程被挂起,只能干等,CPU利用率很低,换句话说,系统的吞吐量差; 3、如果网络I/O堵塞或者有网络抖动或者网络故障等,线程的阻塞时间可能很长。整个系统也变的不可靠; 什么是NIOjava.nio全称java non-blocking IO（实际上是 new io），是指JDK 1.4 及以上版本里提供的新api（New IO） ，为所有的原始类型（boolean类型除外）提供缓存支持的数据容器，使用它可以提供非阻塞式的高伸缩性网络。 HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。 IO和NIO的区别原有的 IO 是面向流的、阻塞的，NIO 则是面向块的、非阻塞的。 怎么理解IO是面向流的、阻塞的java1.4以前的io模型，一连接对一个线程。 原始的IO是面向流的，不存在缓存的概念。Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区 Java IO的各种流是阻塞的，这意味着当一个线程调用read或 write方法时，该线程被阻塞，直到有一些数据被读取，或数据完全写入，该线程在此期间不能再干任何事情了。 阻塞I/O模型 怎么理解NIO是面向块的、非阻塞的NIO是面向缓冲区的。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性。 Java NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此，一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 通俗理解：NIO是可以做到用一个线程来处理多个操作的。假设有10000个请求过来,根据实际情况，可以分配50或者100个线程来处理。不像之前的阻塞IO那样，非得分配10000个。 NIO的核心实现在标准IO API中，你可以操作字节流和字符流，但在新IO中，你可以操作通道和缓冲，数据总是从通道被读取到缓冲中或者从缓冲写入到通道中。 NIO核心API Channel, Buffer, Selector 通道ChannelNIO的通道类似于流，但有些区别如下： 通道可以同时进行读写，而流只能读或者只能写 通道可以实现异步读写数据 通道可以从缓冲读数据，也可以写数据到缓冲 Channel的实现这些是Java NIO中最重要的通道的实现： FileChannel DatagramChannel SocketChannel ServerSocketChannel FileChannel 从文件中读写数据。 DatagramChannel 能通过UDP读写网络中的数据。 SocketChannel 能通过TCP读写网络中的数据。 ServerSocketChannel可以监听新进来的TCP连接，像Web服务器那样。对每一个新进来的连接都会创建一个SocketChannel。 基本的 Channel 示例下面是一个使用FileChannel读取数据到Buffer中的示例： 12345678910111213141516171819RandomAccessFile aFile = new RandomAccessFile("data/nio-data.txt", "rw");FileChannel inChannel = aFile.getChannel();ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buf);while (bytesRead != -1) &#123; System.out.println("Read " + bytesRead); buf.flip(); while(buf.hasRemaining())&#123; System.out.print((char) buf.get()); &#125; buf.clear(); bytesRead = inChannel.read(buf);&#125;aFile.close(); 缓存Buffer缓冲区本质上是一个可以写入数据的内存块，然后可以再次读取，该对象提供了一组方法，可以更轻松地使用内存块，使用缓冲区读取和写入数据通常遵循以下四个步骤： 写数据到缓冲区； 调用buffer.flip()方法； 从缓冲区中读取数据； 调用buffer.clear()或buffer.compat()方法； 当向buffer写入数据时，buffer会记录下写了多少数据，一旦要读取数据，需要通过flip()方法将Buffer从写模式切换到读模式，在读模式下可以读取之前写入到buffer的所有数据，一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。 Buffer在与Channel交互时，需要一些标志: buffer的大小/容量 - Capacity 作为一个内存块，Buffer有一个固定的大小值，用参数capacity表示。 当前读/写的位置 - Position 当写数据到缓冲时，position表示当前待写入的位置，position最大可为capacity – 1；当从缓冲读取数据时，position表示从当前位置读取。 信息末尾的位置 - limit 在写模式下，缓冲区的limit表示你最多能往Buffer里写多少数据； 写模式下，limit等于Buffer的capacity，意味着你还能从缓冲区获取多少数据。 缓冲区常用的操作 向缓冲区写数据： 从Channel写到Buffer； 通过Buffer的put方法写到Buffer中； 从缓冲区读取数据： 从Buffer中读取数据到Channel； 通过Buffer的get方法从Buffer中读取数据； flip方法： ​ 将Buffer从写模式切换到读模式，将position值重置为0，limit的值设置为之前position的值； clear方法 vs compact方法： ​ clear方法清空缓冲区；compact方法只会清空已读取的数据，而还未读取的数据继续保存在Buffer中； Buffer使用演示123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package nio;import java.nio.ByteBuffer;/** * @author yang * @date 2020/3/24 下午 3:31 *//** *position 当前位置 *limit 最大可读位置(后边的内容不可读) *capacity 总容量 * mark 暂存的posotion位置 * 0 &lt;= position &lt;= limit &lt;= capacity */public class NioTest &#123; public static void main(String[] args) &#123; ByteBuffer byteBuffer = ByteBuffer.allocate(1024);//分配非直接缓冲区 ByteBuffer byteBuffer = ByteBuffer.allocateDirect(1024);//分配直接缓冲区 getCapatity(byteBuffer); System.out.println("存入数据"); String str="abcd"; byteBuffer.put(str.getBytes()); getCapatity(byteBuffer); System.out.println("切换读取模式"); byteBuffer.flip(); getCapatity(byteBuffer); System.out.println("读取数据"); //虽然改变了position的位置但是,里面数据并没有被清空.里面的数据处于"被遗忘状态" byte[] bytes; byteBuffer.get(bytes=new byte[byteBuffer.limit()]); System.out.println("读取到的内容为"+new String(bytes,0,bytes.length)); getCapatity(byteBuffer); System.out.println("切换到写入模式"); byteBuffer.rewind(); getCapatity(byteBuffer); System.out.println("清空缓冲区"); //里面数据并没有被清空.里面的数据处于"被遗忘状态" byteBuffer.clear(); getCapatity(byteBuffer); byteBuffer.mark();//暂存标记 &#125; public static void getCapatity(ByteBuffer byteBuffer)&#123; System.out.println("----------capacity-----------"); System.out.println("position"+byteBuffer.position()); System.out.println("limit"+byteBuffer.limit()); System.out.println("capacity"+byteBuffer.capacity()); &#125;&#125; 注意只有ByteBuffer可以分配直接缓冲区 通道之间传输数据在Java NIO中，如果两个通道中有一个是FileChannel，那你可以直接将数据从一个channel（译者注：channel中文常译作通道）传输到另外一个channel。 transferFrom() FileChannel的transferFrom()方法可以将数据从源通道传输到FileChannel中（译者注：这个方法在JDK文档中的解释为将字节从给定的可读取字节通道传输到此通道的文件中）。下面是一个简单的例子： 12345678910RandomAccessFile fromFile = new RandomAccessFile("fromFile.txt", "rw");FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile("toFile.txt", "rw");FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();toChannel.transferFrom(position, count, fromChannel); 方法的输入参数position表示从position处开始向目标文件写入数据，count表示最多传输的字节数。如果源通道的剩余空间小于 count 个字节，则所传输的字节数要小于请求的字节数。此外要注意，在SoketChannel的实现中，SocketChannel只会传输此刻准备好的数据（可能不足count字节）。因此，SocketChannel可能不会将请求的所有数据(count个字节)全部传输到FileChannel中。 transferTo() transferTo()方法将数据从FileChannel传输到其他的channel中。下面是一个简单的例子： 12345678910RandomAccessFile fromFile = new RandomAccessFile("fromFile.txt", "rw");FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile("toFile.txt", "rw");FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();fromChannel.transferTo(position, count, toChannel); 是不是发现这个例子和前面那个例子特别相似？除了调用方法的FileChannel对象不一样外，其他的都一样。上面所说的关于SocketChannel的问题在transferTo()方法中同样存在。SocketChannel会一直传输数据直到目标buffer被填满。 FileChannelJava NIO中的FileChannel是一个连接到文件的通道。可以通过文件通道读写文件。 FileChannel无法设置为非阻塞模式，它总是运行在阻塞模式下。 打开FileChannel在使用FileChannel之前，必须先打开它。但是，我们无法直接打开一个FileChannel，需要通过使用一个InputStream、OutputStream或RandomAccessFile来获取一个FileChannel实例。下面是通过RandomAccessFile打开FileChannel的示例： 12RandomAccessFile aFile = new RandomAccessFile("data/nio-data.txt", "rw");FileChannel inChannel = aFile.getChannel(); 从FileChannel读取数据调用多个read()方法之一从FileChannel中读取数据。如： 12ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buf); 首先，分配一个Buffer。从FileChannel中读取的数据将被读到Buffer中。 然后，调用FileChannel.read()方法。该方法将数据从FileChannel读取到Buffer中。read()方法返回的int值表示了有多少字节被读到了Buffer中。如果返回-1，表示到了文件末尾。 向FileChannel写数据使用FileChannel.write()方法向FileChannel写数据，该方法的参数是一个Buffer。如： 1234567891011String newData = "New String to write to file..." + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) &#123; channel.write(buf);&#125; 注意FileChannel.write()是在while循环中调用的。因为无法保证write()方法一次能向FileChannel写入多少字节，因此需要重复调用write()方法，直到Buffer中已经没有尚未写入通道的字节。 关闭FileChannel用完FileChannel后必须将其关闭。如： 1channel.close(); FileChannel的position方法有时可能需要在FileChannel的某个特定位置进行数据的读/写操作。可以通过调用position()方法获取FileChannel的当前位置。 也可以通过调用position(long pos)方法设置FileChannel的当前位置。 这里有两个例子: 12long pos = channel.position();channel.position(pos +123); 如果将位置设置在文件结束符之后，然后试图从文件通道中读取数据，读方法将返回-1 —— 文件结束标志。 如果将位置设置在文件结束符之后，然后向通道中写数据，文件将撑大到当前位置并写入数据。这可能导致“文件空洞”，磁盘上物理文件中写入的数据间有空隙。 FileChannel的size方法FileChannel实例的size()方法将返回该实例所关联文件的大小。如: 1long fileSize = channel.size(); FileChannel的truncate方法可以使用FileChannel.truncate()方法截取一个文件。截取文件时，文件将中指定长度后面的部分将被删除。如： 1channel.truncate(1024); 这个例子截取文件的前1024个字节。 FileChannel的force方法FileChannel.force()方法将通道里尚未写入磁盘的数据强制写到磁盘上。出于性能方面的考虑，操作系统会将数据缓存在内存中，所以无法保证写入到FileChannel里的数据一定会即时写到磁盘上。要保证这一点，需要调用force()方法。 force()方法有一个boolean类型的参数，指明是否同时将文件元数据（权限信息等）写到磁盘上。 下面的例子同时将文件数据和元数据强制写到磁盘上： 1channel.force(true); 通道使用的Demo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package nio;import java.io.IOException;import java.nio.MappedByteBuffer;import java.nio.channels.FileChannel;import java.nio.channels.FileChannel.MapMode;import java.nio.file.Paths;import java.nio.file.StandardOpenOption;/** * @author yang * @date 2020/3/24 下午 4:55 */public class NioTest1 &#123; public static void main(String[] args) throws IOException &#123; int star= (int) System.currentTimeMillis(); run2("E:/java.zip","E:/1.zip"); int end= (int) System.currentTimeMillis(); System.out.println("一共耗时"+(end-star)+"纳秒"); &#125; /** * 直接缓冲区 */ public static void run2(String fromPath,String toPath) throws IOException &#123; FileChannel fromChanel=null; FileChannel toChanel=null; MappedByteBuffer map=null; MappedByteBuffer map1=null; try &#123; fromChanel = FileChannel.open(Paths.get(fromPath), StandardOpenOption.READ); toChanel = FileChannel.open(Paths.get(toPath), StandardOpenOption.WRITE,StandardOpenOption.READ,StandardOpenOption.CREATE); //生成内存映射文件 map = fromChanel.map(MapMode.READ_ONLY, 0, fromChanel.size()); map1 = toChanel.map(MapMode.READ_WRITE, 0, fromChanel.size()); //进行读写操作 byte[] bytes=new byte[map.limit()]; map.get(bytes); map1.put(bytes); &#125;catch (Exception e)&#123; System.out.println(e.getMessage()); &#125;finally &#123; fromChanel.close(); toChanel.close(); &#125; &#125; /** * 直接缓冲区,通道到通道 */ public static void run3(String fromPath,String toPath) throws IOException &#123; FileChannel fromChanel=null; FileChannel toChannel=null; fromChanel= FileChannel.open(Paths.get(fromPath), StandardOpenOption.READ); toChannel = FileChannel.open(Paths.get(toPath), StandardOpenOption.WRITE,StandardOpenOption.READ,StandardOpenOption.CREATE); fromChanel.transferTo(0, fromChanel.size(), toChannel); toChannel.close(); fromChanel.close(); &#125;&#125; SocketChannelJava NIO中的SocketChannel是一个连接到TCP网络套接字的通道。可以通过以下2种方式创建SocketChannel： 打开一个SocketChannel并连接到互联网上的某台服务器。 一个新连接到达ServerSocketChannel时，会创建一个SocketChannel。 打开 SocketChannel下面是SocketChannel的打开方式： 12SocketChannel socketChannel = SocketChannel.open();socketChannel.connect(new InetSocketAddress("http://jenkov.com", 80)); 关闭 SocketChannel当用完SocketChannel之后调用SocketChannel.close()关闭SocketChannel： 1socketChannel.close(); 从 SocketChannel 读取数据要从SocketChannel中读取数据，调用一个read()的方法之一。以下是例子： 12ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = socketChannel.read(buf); 首先，分配一个Buffer。从SocketChannel读取到的数据将会放到这个Buffer中。 然后，调用SocketChannel.read()。该方法将数据从SocketChannel 读到Buffer中。read()方法返回的int值表示读了多少字节进Buffer里。如果返回的是-1，表示已经读到了流的末尾（连接关闭了）。 写入 SocketChannel写数据到SocketChannel用的是SocketChannel.write()方法，该方法以一个Buffer作为参数。示例如下： 1234567891011String newData = System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) &#123; channel.write(buf);&#125; 注意SocketChannel.write()方法的调用是在一个while循环中的。Write()方法无法保证能写多少字节到SocketChannel。所以，我们重复调用write()直到Buffer没有要写的字节为止。 非阻塞模式可以设置 SocketChannel 为非阻塞模式（non-blocking mode）.设置之后，就可以在异步模式下调用connect(), read() 和write()了。 connect()如果SocketChannel在非阻塞模式下，此时调用connect()，该方法可能在连接建立之前就返回了。为了确定连接是否建立，可以调用finishConnect()的方法。像这样： 123456socketChannel.configureBlocking(false);socketChannel.connect(new InetSocketAddress("http://jenkov.com", 80));while(! socketChannel.finishConnect() )&#123; &#125; write()非阻塞模式下，write()方法在尚未写出任何内容时可能就返回了。所以需要在循环中调用write()。前面已经有例子了，这里就不赘述了。 read()非阻塞模式下,read()方法在尚未读取到任何数据时可能就返回了。所以需要关注它的int返回值，它会告诉你读取了多少字节。 非阻塞模式与选择器非阻塞模式与选择器搭配会工作的更好，通过将一或多个SocketChannel注册到Selector，可以询问选择器哪个通道已经准备好了读取，写入等。 ServerSocketChannelJava NIO中的 ServerSocketChannel 是一个可以监听新进来的TCP连接的通道, 就像标准IO中的ServerSocket一样。ServerSocketChannel类在 java.nio.channels包中。 这里有个例子： 12345678ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.socket().bind(new InetSocketAddress(9999));while(true)&#123; SocketChannel socketChannel = serverSocketChannel.accept();&#125; 打开 ServerSocketChannel通过调用 ServerSocketChannel.open() 方法来打开ServerSocketChannel.如： 1ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); 关闭 ServerSocketChannel通过调用ServerSocketChannel.close() 方法来关闭ServerSocketChannel. 如： 1serverSocketChannel.close(); 监听新进来的连接通过 ServerSocketChannel.accept() 方法监听新进来的连接。当 accept()方法返回的时候,它返回一个包含新进来的连接的 SocketChannel。因此, accept()方法会一直阻塞到有新连接到达。 通常不会仅仅只监听一个连接,在while循环中调用 accept()方法. 如下面的例子： 123while(true)&#123; SocketChannel socketChannel = serverSocketChannel.accept();&#125; 当然,也可以在while循环中使用除了true以外的其它退出准则。 非阻塞模式ServerSocketChannel可以设置成非阻塞模式。在非阻塞模式下，accept() 方法会立刻返回，如果还没有新进来的连接,返回的将是null。 因此，需要检查返回的SocketChannel是否是null. 12345678910111213ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.socket().bind(new InetSocketAddress(9999));serverSocketChannel.configureBlocking(false);while(true)&#123; SocketChannel socketChannel = serverSocketChannel.accept(); if(socketChannel != null)&#123; &#125;&#125;]]></content>
      <tags>
        <tag>java</tag>
        <tag>io</tag>
        <tag>nio</tag>
        <tag>aio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java集合之ArrayList原理详解]]></title>
    <url>%2F2020%2F03%2F23%2Fjava%E9%9B%86%E5%90%88%E4%B9%8BArrayList%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[数据结构ArrayList实现的是动态数组，我们都知道，数组是不能自由扩展的，但是ArrayList是可以动态扩展的，当需要添加新的元素时且空间不足就会重新分配一个原来1.5倍长度的新数组，然后把旧数组中的元素复制到新的数组。 特点ArrayList 特点是查询速度快，增加删除慢,线程不安全。 LinkedList 特点查询慢，增加删除快。 Vector 特点是查询速度快，增加删除慢,线程安全，而且Vector就是ArrayList的换皮，就是方法上多了些synchronized 继承体系 接口 Iterable&lt; T &gt; 实现这个接口允许使用增强for循环 Collection 所有的集合类都要实现这个根接口，他定义了集合的基本常用方法(比如CRUD方法，清空方法，获取集合元素个数方法等). List&lt; E &gt; 有序集合，这个接口可以精确控制列表中每个元素的插入位置，用户可以通过整数索引访问元素，并且这个列表允许重复元素 RandomAccess 标志接口（即该接口起到一个标志作用，没有任何抽象方法），实现这个接口支持快速随机访问 1234for (int i=0, n=list.size(); i &lt; n; i++) list.get(i); //比这个循环运行得更快： for (Iterator i=list.iterator(); i.hasNext(); ) i.next(); Cloneable 标志接口 表示对于该类的实例进行复制是合法的，在不实现Cloneable的接口调用对象的克隆方法会导致CloneNotSupportedException异常 Serializable 标志接口 表明该类的实例是可以被序列化和反序列化的 类和抽象类 AbstractCollection&lt; E &gt; 提供了Collection的骨架实现，用于减少实现Collection接口所需要的工作量 AbstractList&lt; E &gt; 提提供了List的骨架实现，用于减少实现List接口所需要的工作量 成员变量1234567891011private static final long serialVersionUID = 8683452581122892189L; private static final int DEFAULT_CAPACITY = 10;//默认容量大小 private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;//空容量数组 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;//默认空容量数组，下面有transient关键字的详细解释 transient Object[] elementData; // 实际存储对象的数组 private int size;//当前数组长度 transient关键字解释该关键字表示，如果该类被序列化，那么忽略transien标记的元素 1private transient Object[] elementData; 假如elementData的长度为10，而其中只有5个元素，那么在序列化的时候只需要存储5个元素，而数组中后面5个元素是不需要存储的。于是将elementData定义为transient，避免了Java自带的序列化机制，并定义了两个方法，实现了自己可控制的序列化操作。 12private void writeObject(java.io.ObjectOutputStream s)private void readObject(java.io.ObjectInputStream s) 构造方法123456789101112131415161718192021222324public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;//空长度数组&#125;public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA;//空长度数组 &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125;&#125;public ArrayList(Collection&lt;? extends E&gt; c) &#123;//使用了上限泛型 elementData = c.toArray();//调用父类AbstractCollection的方法转换成数组 if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class)//如果长度合法,就复制数组 elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123;//否则就为空数组 // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; 当我们创建ArrayList这个类的对象时候如果不传入参数，那么就会让elementData指向一个容量为0的数组 当我们创建ArrayList这个类的对象的时候可以传入一个默认长度，如果默认长度为0还是一个空数组，如果不为0但是非法，就抛出异常，否则就创建一个initialCapacity大小的数组 如果我们传入一个集合对象，那么他必须是E的子类，然后把传入集合转换为数组，之后复制到elementData元素中 核心扩容算法方法在介绍其他方法前，我们先介绍一下核心的扩容算法方法 12345678910private void grow(int minCapacity) &#123;//传入的大小容量为最小容量 int oldCapacity = elementData.length;//当前数组的长度称为旧容量 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);//新的容量=旧容量*1.5 if (newCapacity - minCapacity &lt; 0)//如果发现1.5倍新容量不能满足预期的最小容量 newCapacity = minCapacity;//就把最小容量作为扩容的容量 if (newCapacity - MAX_ARRAY_SIZE &gt; 0)//如果新的容量特别大(Integer.MAX_VALUE - 8) newCapacity = hugeCapacity(minCapacity);//就会选择使用int最大值或者最大值-8的容量 // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);//最后新建一个新的数组，长度是计算后的容量大小，然后将老数组复制进去&#125; 总结 每次扩容大小是之前的1.5倍 如果扩容1.5倍还不足以装下当前所有元素，那么就把扩容到传入的容量大小 如果最终扩容的大小大于Integer.Max-8，那么就会根据需要扩容到Integer的最大值或者最大值-8 添加方法(add)add(E)12345678910111213141516171819public boolean add(E e) &#123; ensureCapacityInternal(size + 1);//是否需要扩容，以及进行扩容，扩容的方法是否合法 elementData[size++] = e;//将e元素追加到数组末尾，并且增加size的值 return true;&#125;private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;//检查当前数组是否是空数组 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);//检查使用默认10容量还是最小容量 &#125; ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++;//记录操作次数（下面有详细解释） // overflow-conscious code if (minCapacity - elementData.length &gt; 0)//检查是否需要扩容 grow(minCapacity);//进行扩容&#125; modCount该字段表示list结构上被修改的次数。结构上的修改指的是那些改变了list的长度大小或者使得遍历过程中产生不正确的结果的其它方式。 该字段被Iterator以及ListIterator的实现类所使用，如果该值被意外更改，Iterator或者ListIterator 将抛出ConcurrentModificationException异常， 这是jdk在面对迭代遍历的时候为了避免不确定性而采取的快速失败原则。 add(int index ,E element)123456789101112131415161718192021222324 public void add(int index, E element) &#123;//把元素插入指定位置 rangeCheckForAdd(index);//检查插入的下标是否合法（index &gt; size || index &lt; 0） ensureCapacityInternal(size + 1); //是否需要扩容，以及进行扩容，扩容的方法是否合法 System.arraycopy(elementData, index, elementData, index + 1, size - index);//把指定下标及其以后的元素全部复制向后移动一位进行复制 elementData[index] = element;//覆盖指定下标的元素 size++; &#125;private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;//检查当前数组是否是空数组 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);//检查使用默认10容量还是最小容量 &#125; ensureExplicitCapacity(minCapacity); &#125; private void ensureExplicitCapacity(int minCapacity) &#123; modCount++;//记录操作次数（下面有详细解释） // overflow-conscious code if (minCapacity - elementData.length &gt; 0)//检查是否需要扩容 grow(minCapacity);//进行扩容 &#125; addAll(Collection&lt;? extends E&gt; c)12345678public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray();//转换成数组 int numNew = a.length;//带添加数组元素的个数 ensureCapacityInternal(size + numNew); //不说了，这个方法解释很多次了，就是检查扩容和扩容的 System.arraycopy(a, 0, elementData, size, numNew);//复制到末尾 size += numNew;//更新长度 return numNew != 0;&#125; addAll(int index, Collection&lt;? extends E&gt; c)12345678910111213141516public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index);//检查下标是否合法 Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); //扩容 int numMoved = size - index;//计算偏移量 if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew);//两次复制 size += numNew;//更新长度 return numNew != 0;&#125; 总结 添加元素都要检查是否需要扩容，也就是说如果我们需要频繁插入元素，那么推荐构造方法指定容量大小，可以大大减轻扩容的次数，带来性能上的提升。 修改1234567public E set(int index, E element) &#123; rangeCheck(index);//校验下标是否合法 E oldValue = elementData(index);//取出旧元素 elementData[index] = element;//更新index下标的元素 return oldValue;//返回更新前的元素&#125; 真是超级简单了，真的没有其他的可以解释 剩下的就都不说了。真是太简单了。 ConcurrentModificationException异常当方法检测到对象的并发修改，但不允许这种修改时，抛出此异常。 modCount就是修改次数，在具体的实现类中的Iterator中才会使用。在List集合中，ArrayList是List接口的实现类， modCount：表示list集合结构上被修改的次数。（在ArrayList所有涉及结构变化的方法中，都增加了modCount的值） list结构上别修改是指：改变了list的长度的大小或者是遍历结果中产生了不正确的结果的方式。add()和remove()方法会是modCount进行+1操作。modCount被修改后会产生ConcurrentModificationException异常， 这是jdk的快速失败原则。 单线程下产生这个异常 1234567891011public static void main(String[] args) throws InterruptedException &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); list.add(2); Iterator&lt;Integer&gt; iterator = list.iterator(); while(iterator.hasNext())&#123; Integer integer = iterator.next(); if(integer==2) list.remove(integer); &#125;&#125; 从异常信息可以发现，异常出现在checkForComodification()方法中。 我们不忙看checkForComodification()方法的具体实现，我们先根据程序的代码一步一步看ArrayList源码的实现： 首先看ArrayList的iterator()方法的具体实现，查看源码发现在ArrayList的源码中并没有iterator()这个方法，那么很显然这个方法应该是其父类或者实现的接口中的方法，我们在其父类AbstractList中找到了iterator()方法的具体实现，下面是其实现代码： 1public Iterator&lt;E&gt; iterator() &#123; return new Itr();&#125; 从这段代码可以看出返回的是一个指向Itr类型对象的引用，我们接着看Itr的具体实现，在AbstractList类中找到了Itr类的具体实现，它是AbstractList的一个成员内部类，下面这段代码是Itr类的所有实现： 12345678910111213141516171819202122232425262728293031323334353637private class Itr implements Iterator&lt;E&gt; &#123; int cursor = 0; int lastRet = -1; int expectedModCount = modCount; public boolean hasNext() &#123; return cursor != size(); &#125; public E next() &#123; checkForComodification(); try &#123; E next = get(cursor); lastRet = cursor++; return next; &#125; catch (IndexOutOfBoundsException e) &#123; checkForComodification(); throw new NoSuchElementException(); &#125; &#125; public void remove() &#123; if (lastRet == -1) throw new IllegalStateException(); checkForComodification(); try &#123; AbstractList.this.remove(lastRet); if (lastRet &lt; cursor) cursor--; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException e) &#123; throw new ConcurrentModificationException(); &#125; &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125;&#125; 首先我们看一下它的几个成员变量： cursor：表示下一个要访问的元素的索引，从next()方法的具体实现就可看出 lastRet：表示上一个访问的元素的索引 expectedModCount：表示对ArrayList修改次数的期望值，它的初始值为modCount。 modCount是AbstractList类中的一个成员变量 1protected transient int modCount = 0; 该值表示对List的修改次数，查看ArrayList的add()和remove()方法就可以发现，每次调用add()方法或者remove()方法就会对modCount进行加1操作。 好了，到这里我们再看看上面的程序： 当调用list.iterator()返回一个Iterator之后，通过Iterator的hashNext()方法判断是否还有元素未被访问，我们看一下hasNext()方法，hashNext()方法的实现很简单： 1public boolean hasNext() &#123; return cursor != size();&#125; 如果下一个访问的元素下标不等于ArrayList的大小，就表示有元素需要访问，这个很容易理解，如果下一个访问元素的下标等于ArrayList的大小，则肯定到达末尾了。 然后通过Iterator的next()方法获取到下标为0的元素，我们看一下next()方法的具体实现： 1234567891011public E next() &#123; checkForComodification(); try &#123; E next = get(cursor); lastRet = cursor++; return next; &#125; catch (IndexOutOfBoundsException e) &#123; checkForComodification(); throw new NoSuchElementException(); &#125;&#125; 这里是非常关键的地方：首先在next()方法中会调用checkForComodification()方法，然后根据cursor的值获取到元素，接着将cursor的值赋给lastRet，并对cursor的值进行加1操作。初始时，cursor为0，lastRet为-1，那么调用一次之后，cursor的值为1，lastRet的值为0。注意此时，modCount为0，expectedModCount也为0。 接着往下看，程序中判断当前元素的值是否为2，若为2，则调用list.remove()方法来删除该元素。 我们看一下在ArrayList中的remove()方法做了什么： 12345678910111213141516171819202122public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125;private void fastRemove(int index)&#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index,numMoved); elementData[--size] = null; // Let gc do its work&#125; 通过remove方法删除元素最终是调用的fastRemove()方法，在fastRemove()方法中，首先对modCount进行加1操作（因为对集合修改了一次），然后接下来就是删除元素的操作，最后将size进行减1操作，并将引用置为null以方便垃圾收集器进行回收工作。 那么注意此时各个变量的值：对于iterator，其expectedModCount为0，cursor的值为1，lastRet的值为0。 对于list，其modCount为1，size为0。 接着看程序代码，执行完删除操作后，继续while循环，调用hasNext方法()判断，由于此时cursor为1，而size为0，那么返回true，所以继续执行while循环，然后继续调用iterator的next()方法： 注意，此时要注意next()方法中的第一句：checkForComodification()。 在checkForComodification方法中进行的操作是： 1234final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException();&#125; 如果modCount不等于expectedModCount，则抛出ConcurrentModificationException异常。 很显然，此时modCount为1，而expectedModCount为0，因此程序就抛出了ConcurrentModificationException异常。 到这里，想必大家应该明白为何上述代码会抛出ConcurrentModificationException异常了。 关键点就在于：调用list.remove()方法导致modCount和expectedModCount的值不一致。 注意，像使用for-each进行迭代实际上也会出现这种问题。 关键点就在于：调用list.remove()方法导致modCount和expectedModCount的值不一致。 注意，像使用for-each进行迭代实际上也会出现这种问题。 如何实现线程同步方法一使用VectorVector中的方法都是同步方法， 所以是线程安全的 方法二使用Collections.synchronizedList();方法这个类就是使用了装饰者模式，几乎给所有的方法都加了synchronized关键字进行了同步处理。 方法三使用CopyOnWriteArrayList();这个类在写入的时候会先加一个可重入锁(ReentrantLock),然后复制一个新的数组，让后在新的数组中写入，这个时候如果有其他线程读，会在旧数组中读，并且读不加锁，这样就保证了并发安全，然后读操作完成后会让新数组的引用覆盖旧数组的引用，之后解锁，也就是说这个容器适合大量读的场景，但是不适合大量写。]]></content>
      <tags>
        <tag>集合</tag>
        <tag>原理</tag>
        <tag>list</tag>
        <tag>array</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String table详解]]></title>
    <url>%2F2020%2F03%2F21%2FString-table%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[String table又称为String pool，字符串常量池，其存在于堆中(jdk1.8及其以后改的)。最重要的一点，String table中存储的并不是String类型的对象，存储的而是指向String对象的索引，真实对象还是存储在堆中。 String字节码直接使用双引号声明出来的String对象会直接存储在常量池中一定要先记住这句话 在学习之前首先先学习一下String的字节码 案例一12345678910/** * @author yang * @date 2020/3/20 下午 1:49 */public class EnuTest&#123; public static void main(String[] args)&#123; String a="a"; String b="b"; &#125;&#125; 对应字节码 123450 ldc #2 &lt;a&gt;//把符号引用变为字符串对象引用,且加入到StringTable中去2 astore_1//把字符串对象引用存入局部变量表1位置3 ldc #3 &lt;b&gt;//把符号引用变为字符串对象引用,且加入到StringTable中去5 astore_2//把字符串对象引用存入局部变量表1位置6 return 案例二12345678public class EnuTest&#123; public static void main(String[] args)&#123; String a="a"; String b="b"; String d=a+b;//新加入代码 &#125;&#125; 对应字节码 123456789101112131415 0 ldc #2 &lt;a&gt; 2 astore_1 3 ldc #3 &lt;b&gt; 5 astore_2 9 new #5 &lt;java/lang/StringBuilder&gt;//创建StringBuilder对象12 dup13 invokespecial #6 &lt;java/lang/StringBuilder.&lt;init&gt;&gt;//调用无参数构造方法16 aload_117 invokevirtual #7 &lt;java/lang/StringBuilder.append&gt;//调用append方法追加20 aload_221 invokevirtual #7 &lt;java/lang/StringBuilder.append&gt;//调用append方法追加24 invokevirtual #8 &lt;java/lang/StringBuilder.toString&gt;//调用toString方法打印27 astore 429 return StringBuilder源码 12345@Overridepublic String toString() &#123; // Create a copy, don't share the array return new String(value, 0, count);//可以发现String d=a+b;new 了一个新对象，并且这个新对象并没有加入到StringTable（字符串常量池中）&#125; 可以发现String d=a+b;new 了一个新对象，并且这个新对象并没有加入到StringTable（字符串常量池中） 究竟什么时候会存入字符串常量池呢? 经过反复实验发现 直接使用双引号声明出来的String对象会直接存储在常量池中。 演示12345public class EnuTest&#123; public static void main(String[] args)&#123; String a=new String("abc")+new String("bcd");//[abc,bcd]存入了常量池 &#125;&#125; 对应字节码文件 12345678910111213141516 0 new #2 &lt;java/lang/StringBuilder&gt; 3 dup 4 invokespecial #3 &lt;java/lang/StringBuilder.&lt;init&gt;&gt; 7 new #4 &lt;java/lang/String&gt;10 dup11 ldc #5 &lt;abc&gt;//第一次13 invokespecial #6 &lt;java/lang/String.&lt;init&gt;&gt;16 invokevirtual #7 &lt;java/lang/StringBuilder.append&gt;19 new #4 &lt;java/lang/String&gt;22 dup23 ldc #8 &lt;bcd&gt;//第二次25 invokespecial #6 &lt;java/lang/String.&lt;init&gt;&gt;28 invokevirtual #7 &lt;java/lang/StringBuilder.append&gt;31 invokevirtual #9 &lt;java/lang/StringBuilder.toString&gt;34 astore_135 return 案例三12345678public class EnuTest&#123; public static void main(String[] args)&#123; String a="a"; String b="b"; String c="ab"; String d="a"+"b"; &#125;&#125; 对应字节码 123456789 0 ldc #2 &lt;a&gt; 2 astore_1 3 ldc #3 &lt;b&gt; 5 astore_2 6 ldc #4 &lt;ab&gt; 8 astore_3 9 ldc #4 &lt;ab&gt;11 astore 413 return 我们仔细阅读不难发现String c=”ab”和String d是相等的，因为他们指向的是同一个常量池。 接下来我们都明白了，我们就看一些题目吧 123456789101112public class EnuTest&#123; public static void main(String[] args)&#123; String a="a"; String b="b"; String c="ab"; String d="a"+"b"; String e=new String("a")+new String("b");//出现引号的只有a和b也就是说字符串常量池只有[a,b] System.out.println(c==d); System.out.println(c==e); &#125;&#125; 答案是 12truefalse 是不是现在就很清楚了。 还有一个很有意思的操作12345678public class Test02 &#123; public static void main(String[] args)&#123; String s1 =new String("123"); String s2=new String("123"); System.out.println(s2.intern()==s1.intern());//true说明常量池中的是同一个 System.out.println(s2==s1);//false说明对象的引用不是同一个 &#125;&#125; 要是不清楚还有终极大招12345678910public class EnuTest&#123; public static void main(String[] args)&#123; String abc=new String("abc"); System.out.println(abc.intern()==abc);//false原因是abc.intern虽然打算存入abc但是字符串常量池已经有了,所有返回了字符串常量池的引用,所以对象abc和常量池的引用一定不相等啊 System.out.println(abc.intern()=="abc");//true这个原因就不需要解释了吧 abc=abc.intern();//这次我们改变引，引用常量池中的 System.out.println(abc);//打印结果还是abc &#125;&#125; 是不是感觉明白点了，那么接下来我们在玩点骚气的 12345678910111213public class EnuTest&#123; public static void main(String[] args)&#123; String a="a"; String bc="bc"; String abc=new String("abc").intern();//此时常量池中只有[a,bc,abc] String bcd="abc";//他直接从常量池中取出了"abc"的引用 System.out.println(bcd==abc);//true &#125;&#125; intern解释3.String.intern() in JDK6 Jdk6中常量池位于PermGen（永久代）中，PermGen是一块主要用于存放已加载的类信息和字符串池的大小固定的区域。执行intern()方法时，若常量池中不存在等值的字符串，JVM就会在常量池中创建一个等值的字符串，然后返回该字符串的引用。除此以外，JVM 会自动在常量池中保存一份之前已使用过的字符串集合。Jdk6中使用intern()方法的主要问题就在于常量池被保存在PermGen中：首先，PermGen是一块大小固定的区域，一般不同的平台PermGen的默认大小也不相同，大致在32M到96M之间。所以不能对不受控制的运行时字符串（如用户输入信息等）使用intern()方法，否则很有可能会引发PermGen内存溢出；其次String对象保存在Java堆区，Java堆区与PermGen是物理隔离的，因此如果对多个不等值的字符串对象执行intern操作，则会导致内存中存在许多重复的字符串，会造成性能损失。 4.String.intern() in JDK7 Jdk7将常量池从PermGen区移到了Java堆区，执行intern操作时，如果常量池已经存在该字符串，则直接返回字符串引用，否则复制该字符串对象的引用到常量池中并返回。堆区的大小一般不受限，所以将常量池从PremGen区移到堆区使得常量池的使用不再受限于固定大小。除此之外，位于堆区的常量池中的对象可以被垃圾回收。当常量池中的字符串不再存在指向它的引用时，JVM就会回收该字符串。可以使用 -XX:StringTableSize 虚拟机参数设置字符串池的map大小。字符串池内部实现为一个HashMap，所以当能够确定程序中需要intern的字符串数目时，可以将该map的size设置为所需数目*2（减少hash冲突），这样就可以使得String.intern()每次都只需要常量时间和相当小的内存就能够将一个String存入字符串池中。 StringTable这个地方也是可以被垃圾回收的，当没有持有这个字符串常量池的引用时就会被垃圾回收掉 StringTable的底层实现是HashTable 调优方案一由于底层实现是HashTable，当字符串常量池特别大的时候可以使用参数-XX:StringTableSize=大小来增加桶容量 这样可以减少hash碰撞 方案二如果有一批字符串常量量也特别大，比如全国人民的地址信息，你会发现这些信息有好些是重复的，就可以利用这些重复信息来实现优化。 总结想把字符串加入常量池（StringTable）只有两种方法 常量池中没有的字符，通过intern加入 常量池没有字符是，双引号括起来的会被加入]]></content>
      <tags>
        <tag>字节码</tag>
        <tag>StringTable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[静态内部类何时被加载]]></title>
    <url>%2F2020%2F03%2F21%2F%E9%9D%99%E6%80%81%E5%86%85%E9%83%A8%E7%B1%BB%E4%BD%95%E6%97%B6%E8%A2%AB%E5%8A%A0%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[首先先看一段代码 1234567891011121314151617181920212223/** * @author yang * @date 2020/3/20 下午 1:49 */public class EnuTest&#123; public static void main(String[] args) &#123; Demo demo = new Demo(); &#125;&#125;class Demo &#123; static int a=0; static &#123; System.out.println("外部类被加载"); &#125; public static class Inner&#123; static &#123; System.out.println("内部类被加载"); &#125; public static void run()&#123; System.out.println("内部类方法被调用"); &#125; &#125;&#125; 1外部类被加载 也就说说初始化内部类的时候并没有初始化里面的静态内部类，也是被动调用 再来看第二段代码 1234567891011121314151617181920212223/** * @author yang * @date 2020/3/20 下午 1:49 */public class EnuTest&#123; public static void main(String[] args) &#123; Demo.Inner.run();//唯一改变的地方，直接调用静态内部类的静态方法 &#125;&#125;class Demo &#123; static int a=0; static &#123; System.out.println("外部类被加载"); &#125; public static class Inner&#123; static &#123; System.out.println("内部类被加载"); &#125; public static void run()&#123; System.out.println("内部类方法被调用"); &#125; &#125;&#125; 运行结果 12内部类被加载内部类方法被调用 也就说说这个静态内部类的初始化并不会触发外部类的初始化，即可以单独存在，也就是说这种调用方法是被动调用 接下来看第三段代码 1234567891011121314151617181920212223/** * @author yang * @date 2020/3/20 下午 1:49 */public class EnuTest&#123; public static void main(String[] args) &#123; Demo.Inner.run(); &#125;&#125;class Demo &#123; static int a=0;//因为内部类是静态的，内部要想访问除非静态，或者内部类创建外部对象 static &#123; System.out.println("外部类被加载"); &#125; public static class Inner&#123; static &#123; System.out.println("内部类被加载"); &#125; public static void run()&#123; System.out.println("内部类方法被调用"+a);//代码唯一改变的地方 &#125; &#125;&#125; 123内部类被加载外部类被加载内部类方法被调用0 也就是证实了内部类的存在并不依赖外部类的 结论外部类的初始化并不会触发内部类的初始化。 内部类的先初始化也不会导致外部类的初始化。 如果内部类的静态方法使用到了外部类，那么静态内部类会先初始化然后初始化外部类。 非静态内部类依赖外部类吗这个答案可想而知，我们无论如何，只要创建内部类，就一定要保证外部类的存在，答案是依赖]]></content>
      <tags>
        <tag>内部类</tag>
        <tag>被动调用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Integer陷阱]]></title>
    <url>%2F2020%2F03%2F20%2FInteger%E9%99%B7%E9%98%B1%2F</url>
    <content type="text"><![CDATA[首先对象使用==比较的是是否为同一个对象 12345678910111213141516public class EnuTest &#123; public static void main(String[] args) &#123; Integer integer1=110; Integer integer2=110; System.out.println(integer2==integer1); Integer integer3=150; Integer integer4=150; System.out.println(integer3==integer4); &#125;&#125;//输出结果为truefalse 为什么会这样呢，是不是发现和String很像，当然我们这篇文章并不讨论String。 原因分析jdk1.5引入了装箱和拆箱的机制。 当我们打开Integer的源码就会发现,java.lang.Integer类里面有个成员静态内部类IntegerCache 123456789101112131415161718192021222324252627282930313233private static class IntegerCache &#123; static final int low = -128; static final int high; static final Integer cache[]; static &#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty("java.lang.Integer.IntegerCache.high"); if (integerCacheHighPropValue != null) &#123; try &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; catch( NumberFormatException nfe) &#123; // If the property cannot be parsed into an int, ignore it. &#125; &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127; &#125; private IntegerCache() &#123;&#125;&#125; 我们仔细阅读这个源码不难发现他维护了一个缓存区，这个缓存区[-128, 127] 之间的数都会被缓存。是不是顿时感觉就明白了，别慌。 你仔细看看问题发生的代码 1234Integer integer5=new Integer(110);Integer integer6=new Integer(110);system.out.println(integer5==integer6);//结果是false 不是说凡是在[-128,127]之间的都会被缓存吗，(这里先不讨论new就是创建了一个新的对象) 我们打开Integer的构造函数 123456public Integer(int value) &#123; this.value = value;&#125;public Integer(String s) throws NumberFormatException &#123; this.value = parseInt(s, 10);&#125; 发现都没有和IntegerCache发生关系，所以不可能为true。 问题就来了，java是如何把[-128,127]存储到IntegerCache中的呢，似乎这个问题陷入了死角。 前面说过，在jdk1.5中引入了自动装箱和拆箱概念，问题就发生在这。 123456public static void run()&#123; int a=100; Integer integer=110;//自动装箱 integer=100;//自动装箱&#125; 接下来是反编译后的字节码 123456789101112 0 bipush 100//100入操作数栈 2 istore_0//100弹出操作数栈，并保存到局部变量表0位置上，0位置上就是a 3 bipush 110//100入操作数栈 5 invokestatic #2 &lt;java/lang/Integer.valueOf&gt;//调用valueOf方法 8 astore_1//栈顶保存到局部变量表1位置上，1位置上就是integer 9 bipush 10011 invokestatic #2 &lt;java/lang/Integer.valueOf&gt;//调用valueOf方法14 astore_1//栈顶保存到局部变量表1位置上，1位置上就是integer15 sipush 15018 invokestatic #2 &lt;java/lang/Integer.valueOf&gt;21 astore_2//栈顶保存到局部变量表1位置上，1位置上就是integer22 return 对比一下源代码我们发现 虚拟机居然调用了valueOf这个方法,而且我们发现基本数据类型是不会调用这个方法的,也就说说这个自动装箱和拆箱其实是编译器搞的，也就是当编译期发现了这个装箱就会增加一个调用方法valueOf(int i)这个方法。 那么我们就看一下valueOf的源代码吧 1234567891011public static Integer valueOf(int i) &#123;//编译期调用的正是这个方法 if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)//判断有没有超出缓冲区的范围 return IntegerCache.cache[i + (-IntegerCache.low)];//返回缓冲区中的结果 return new Integer(i);&#125;public static Integer valueOf(String s) throws NumberFormatException &#123; return Integer.valueOf(parseInt(s, 10));&#125;public static Integer valueOf(String s, int radix) throws NumberFormatException &#123; return Integer.valueOf(parseInt(s,radix));&#125; 我们发现只有valueOf(int i)这个确实是这样的。 仔细看一下8个包装类型发现并不是所有的类型都有这个缓冲区的, 有缓存区的有的有Byte,Short，Character，Integer,Long. 猜想IntegerCache的设计思路 首先这个类的作用是维护一个缓冲区，也就说说所有的Integer类型都要共用的一个类，并且Integer是非静态的类，也就说说这个类一定是静态的，因为如果不是静态的，那么所有的Integer将无法共享这个静态成员内部类。 然后这个类肯定只能Integer访问和使用，不能让其他类使用，所有这个类一定是私有的成员内部类，。 如果这个类是私有的那么Intger想要访问，必须通过里面的静态非私有属性或者静态非私有方法来访问。 以上是我的猜想，那么接下来咱们验证一下吧. 1234567891011121314151617181920212223242526272829private static class IntegerCache &#123;//确实是私有的且静态的 static final int low = -128; static final int high; static final Integer cache[];//外部可以通过这个非私属性拿到这个属性，并且是default（包）权限 static &#123; int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty("java.lang.Integer.IntegerCache.high"); if (integerCacheHighPropValue != null) &#123; try &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; catch( NumberFormatException nfe) &#123; &#125; &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); assert IntegerCache.high &gt;= 127; &#125; private IntegerCache() &#123;&#125; &#125;]]></content>
      <tags>
        <tag>源码</tag>
        <tag>Integer</tag>
        <tag>陷阱</tag>
        <tag>字节码</tag>
        <tag>猜想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.4操作系统进程同步和2.5经典进程的同步问题]]></title>
    <url>%2F2020%2F03%2F20%2F2.4%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%AD%A5%E5%92%8C2.5%E7%BB%8F%E5%85%B8%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[简介​ 进程同步是一个操作系统级别的概念,是在多道程序的环境下，存在着不同的制约关系，为了协调这种互相制约的关系，实现资源共享和进程协作，从而避免进程之间的冲突，引入了进程同步。 进程描述定义 进程是程序的一次执行。 进程是一个程序及其数据在处理机上顺序执行时所发生的活动。 进程是程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。 本教材定义进程为：进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。 临界资源​ 在操作系统中，进程是占有资源的最小单位（线程可以访问其所在进程内的所有资源，但线程本身并不占有资源或仅仅占有一点必须资源）。但对于某些资源来说，其在同一时间只能被一个进程所占用。这些一次只能被一个进程所占用的资源就是所谓的临界资源。典型的临界资源比如物理上的打印机，或是存在硬盘或内存中被多个进程所共享的一些变量和数据等(如果这类资源不被看成临界资源加以保护，那么很有可能造成丢数据的问题)。 ​ 对于临界资源的访问，必须是互诉进行。也就是当临界资源被占用时，另一个申请临界资源的进程会被阻塞，直到其所申请的临界资源被释放。而进程内访问临界资源的代码被成为临界区。 ​ 对于临界区的访问过程分为四个部分： 进入区:查看临界区是否可访问，如果可以访问，则转到步骤二，否则进程会被阻塞 临界区:在临界区做操作 退出区:清除临界区被占用的标志 剩余区：进程与临界区不相关部分的代码 临界资源使用规则：忙则等待、优先等待、空闲让进、让权等待（在临界区的进程，不能在临界区内长时间处于事件等待，必须在一定时间退出临界区）。 多个进程常常需要共同修改某些共享变量、表格、文件数据库等，协作完成一些功能。共享协作带来了进程的同步和互斥、死锁、饥饿等问题。 进程同步 ​ 进程同步也是进程之间直接的制约关系，是为完成某种任务而建立的两个或多个线程，这个线程需要在某些位置上协调他们的工作次序而等待、传递信息所产生的制约关系。进程间的直接制约关系来源于他们之间的合作。 ​ 比如说进程A需要从缓冲区读取进程B产生的信息，当缓冲区为空时，进程B因为读取不到信息而被阻塞。而当进程A产生信息放入缓冲区时，进程B才会被唤醒。 进程互斥 ​ 进程互斥是进程之间的间接制约关系。当一个进程进入临界区使用临界资源时，另一个进程必须等待。只有当使用临界资源的进程退出临界区后，这个进程才会解除阻塞状态。 ​ 比如进程B需要访问打印机，但此时进程A占有了打印机，进程B会被阻塞，直到进程A释放了打印机资源,进程B才可以继续执行。 实现临界区互斥的基本方法硬件实现方法 ​ 通过硬件实现临界区最简单的办法就是关CPU的中断。从计算机原理我们知道，CPU进行进程切换是需要通过中断来进行。如果屏蔽了中断那么就可以保证当前进程顺利的将临界区代码执行完，从而实现了互斥。这个办法的步骤就是:屏蔽中断–执行临界区–开中断。但这样做并不好，这大大限制了处理器交替执行任务的能力。并且将关中断的权限交给用户代码，那么如果用户代码屏蔽了中断后不再开，那系统岂不是跪了？ 信号量实现方式 ​ 这也是我们比较熟悉P V操作。通过设置一个表示资源个数的信号量S，通过对信号量S的P和V操作来实现进程的的互斥。 ​ P和V操作分别表示占有和释放。P V操作是操作系统的原语，意味着具有原子性。 ​ P操作首先减少信号量，表示有一个进程将占用或等待资源，然后检测S是否小于0,如果小于0则阻塞，如果大于0则占有资源进行执行。 ​ V操作是和P操作相反的操作，首先增加信号量，表示占用或等待资源的进程减少了1个。然后检测S是否小于0，如果小于0则唤醒等待使用S资源的其它进程。 ​ 前面我们C#模拟进程的同步和互斥其实算是信号量进行实现的。 经典进程的同步问题生产者–消费者问题 ​ 问题描述:生产者-消费者问题是一个经典的进程同步问题，该问题最早由Dijkstra提出，用以演示他提出的信号量机制。本作业要求设计在同一个进程地址空间内执行的两个线程。生产者线程生产物品，然后将物品放置在一个空缓冲区中供消费者线程消费。消费者线程从缓冲区中获得物品，然后释放缓冲区。当生产者线程生产物品时，如果没有空缓冲区可用，那么生产者线程必须等待消费者线程释放出一个空缓冲区。当消费者线程消费物品时，如果没有满的缓冲区，那么消费者线程将被阻塞，直到新的物品被生产出来 ​ 这里生产者和消费者是既同步又互斥的关系，首先只有生产者生产了，消费着才能消费，这里是同步的关系。但他们对于临界区的访问又是互斥的关系。因此需要三个信号量empty和full用于同步缓冲区，而mut变量用于在访问缓冲区时是互斥的。 读者–写者问题 问题描述:​ 一个数据文件或记录，统称数据对象，可被多个进程共享，其中有些进程只要求读称为”读者”，而另一些进程要求写或修改称为”写者”。 ​ 规定:允许多个读者同时读一个共享对象，但禁止读者、写者同时访问一个共享对象，也禁止多个写者访问一个共享对象，否则将违反Bernstein并发执行条件。 问题分析​ 通过描述可以分析，这里的读者和写者是互斥的，而写者和写者也是互斥的，但读者之间并不互斥。 ​ 由此我们可以设置3个变量，一个用来统计读者的数量，另外两个分别用于对读者数量读写的互斥，读者和读者写者和写者的互斥。 哲学家进餐问题 问题描述:​ 有五个哲学家，他们的生活方式是交替地进行思考和进餐。哲学家们公用一张圆桌，周围放有五把椅子，每人坐一把。在圆桌上有五个碗和五根筷子，当一个哲学家思考时，他不与其他人交谈，饥饿时便试图取用其左、右最靠近他的筷子，但他可能一根都拿不到。只有在他拿到两根筷子时，方能进餐，进餐完后，放下筷子又继续思考。 根据问题描述,五个哲学家分别可以看作是五个进程。五只筷子分别看作是五个资源。只有当哲学家分别拥有左右的资源时，才得以进餐。如果不指定规则，当每个哲学家手中只拿了一只筷子时会造成死锁，从而五个哲学家都因为吃不到饭而饿死。因此我们的策略是让哲学家同时拿起两只筷子。因此我们需要对每个资源设置一个信号量，此外，还需要使得哲学家同时拿起两只筷子而设置一个互斥信号量，]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java零碎小细节]]></title>
    <url>%2F2020%2F03%2F19%2Fjava%E9%9B%B6%E7%A2%8E%E5%B0%8F%E7%BB%86%E8%8A%82%2F</url>
    <content type="text"><![CDATA[boolean大小问题问题引入今天在看java编程思想的时候发现8个基本类型变量基本上都有明确的大小，但是boolean并没有大小。 解决来源是《Java虚拟机规范》一书中的描述：“虽然定义了boolean这种数据类型，但是只对它提供了非常有限的支持。在Java虚拟机中没有任何供boolean值专用的字节码指令，Java语言表达式所操作的boolean值，在编译之后都使用Java虚拟机中的int数据类型来代替，而boolean数组将会被编码成Java虚拟机的byte数组，每个元素boolean元素占8位”。这样我们可以得出boolean类型占了单独使用是4个字节，在数组中又是1个字节。 使用局部变量定义数组的时候数组会被初始化当使用局部变量的时候必须先初始化才能使用，但是使用局部变量定义数组的时候数组里面的所有元素都会被初始化为零值。 问题分析 成员变量的值存放于java堆中，在创建对象的时候JVM在分配内存时将整块区域置为零即完成了初始化，方便快捷。 而局部变量运行时被分配于虚拟机栈中，量大，生命周期短，如果由JVM完成初始化，将是一笔很大的性能开销。所以java规定局部变量手动必须初始化。 当一个对象使用关键字“new”创建时，会在堆上分配内存空间，然后返回对象的引用，这对数组来说也是一样的，因为数组也是一个对象,所以和成员变量一样在整块区域置为零即完成了初始化； JAVA何时加载静态语句块父类静态代码块 &gt; 子类静态代码块 Java虚拟机加载类时，就会执行该块代码。父类构造函数 &gt; 子类构造函数 （先有父亲，后有孩子）如果是多级继承关系的话，高层的父类首先执行，然后依次递减。总结：静态优先执行，父类优先于子类执行。 静态代码块是在JVM加载类的时候执行的，而且静态代码块执行且仅执行一次 静态代码块什么时候开始执行 静态代码块在初始化阶段才会被执行，也就说单纯的类加载是不会执行静态代码块的。 也就说有些情况是不会触发这个静态代码块的执行的。 主动加载和被动加载的区别在于，主动加载会触发类的初始化。 主动加载的情况 使用new关键字实例化对象的时候、读取或设置一个类的静态字段的时候，已经调用一个类的静态方法的时候。 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类没有被初始化就会先初始化它的父类。 当虚拟机启动的时候，用户需要指定一个要执行的主类（就是包含main()方法的那个类），虚拟机会先初始化这个类； 使用Jdk1.7动态语言支持的时候的一些情况。 当一个接口中定义了JDK8新加入的默认方法(被default关键字修饰的接口方法时，如果这个接口的实现类发生了初始化，那么该接口要在其之前被初始化) 类不被加载情况举例12345678910111213141516171819package jvm;public class ClassLoaderTest &#123; public static void main(String[] args) throws ClassNotFoundException &#123; //1. System.out.println(Demo.class);//不会执行初始化阶段 //2. Class.forName("jvm.Demo");//会执行初始化阶段也就说说会执行静态代码块 &#125;&#125;class Demo&#123; static &#123; System.out.println("被加载了"); hello(); &#125; public static void hello()&#123; System.out.println("hello方法被执行了!"); &#125;&#125; 当然不会触发静态代码块的方案还有很多. 非静态方法都隐藏一参数this非静态非方法都有一个隐藏参数this，也就说this只有非静态方法才能用 演示这是两个方法，一个静态方法，一个非静态方法 1234public static void f1()&#123;&#125;public void f2()&#123;&#125; 我们可以看到方法f1压根没有局部变量表，但是方法f2局部变量表有个this Java中创建子类实例时会创建父类实例？首先每个类的这些元数据，无论是在构建这个类的实例还是调用这个类某个对象的方法，都会访问方法区的这些元数据。构建一个对象时，JVM会在堆中给对象分配空间，这些空间用来存储当前对象实例属性以及其父类的实例属性（而这些属性信息都是从方法区获得） 注意，这里并不是仅仅为当前对象的实例属性分配空间，还需要给父类的实例属性分配。 总之，会为父类分配堆内存，但是这块内存属于子类的堆内存。 i++和++i的区别i++和++i都会变成四个字节码指令，其中不同的地方在2,3条指令，这两个指令是 iload 把局部变量表中的值加载到操作数栈中 iinc * by * 第一个占位符表示局部变量表的位置，第二个表示该位置自增的数，比如inc 1 by 1就表示 1位置自增1 注意只有这两条指令 区别i++是先iload后 inc，++i是先inc后iload 陷阱12345678public class EnuTest&#123; public static void main(String[] args)&#123; int a=0; for (int i = 0; i &lt; 10; i++) a=a++; System.out.println(a); &#125;&#125; 比如这行代码结果就是0，就是利用了这个坑，道理也很简单，每次a自增前都把当前值0加载到了操作数栈中，然后因为有个等于号对应指令就是把操作数栈中栈顶的值存入局部变量表中，也就是说a自增后又被重新覆盖为0了 Java中，如果对整数不指定类型，默认时int类型，对小数不指定类型，默认是double类型如果要指定长整型，最好写为long a = 100000000L,如果要指定为单精度最好写为float a= 12.34F Java程序的种类有：（a）内嵌于Web文件中，由浏览器来观看的_Applet （b）可独立运行的 Application （c）服务器端的 Servlets 多态调用过程12345678910111213141516171819202122232425262728293031323334353637383940414243package thread.demoone;/** * @author yang * @date 2020/4/15 下午 3:34 */class Test &#123; public static void main(String[] args) &#123; System.out.println(new B().getValue()); &#125; static class A &#123; protected int value; public A (int v) &#123; setValue(v); &#125; public void setValue(int value) &#123; this.value= value; &#125; public int getValue() &#123; try &#123; value ++; return value; &#125; finally &#123; this.setValue(value); System.out.println(value); &#125; &#125; &#125; static class B extends A &#123; public B () &#123; super(5); setValue(getValue()- 3); &#125; public void setValue(int value) &#123; super.setValue(2 * value); &#125; &#125;&#125;//结果为223417 java中只能子类重写父类能访问到的且非静态的方法，而且重写方法的时候修饰符可以扩大，也就是父类的方法访问修饰符号如果是default，那么子类重写的时候使用public也是被允许的静态方法不能够被重写，而且静态方法的调用只和引用有关 123456789101112131415161718192021222324252627282930313233343536public class Demo &#123; public static void main(String[] args) &#123; A a=new A(); A b=new B(); a.pubMethod(); a.staMethod(); b.pubMethod(); //虽然实例化的是B对象，但是调用的静态方法是a的 b.staMethod(); &#125;&#125;class A&#123; private void preMethod()&#123; System.out.println("A-&gt;私有非静态方法"); &#125; public void pubMethod()&#123; System.out.println("A-&gt;公有非静态方法"); &#125; public static void staMethod()&#123; System.out.println("A-&gt;公有静态方法"); &#125;&#125;class B extends A&#123; private void preMethod()&#123; System.out.println("B-&gt;私有非静态方法"); &#125; public void pubMethod()&#123; System.out.println("B-&gt;公有非静态方法"); &#125; public static void staMethod()&#123; System.out.println("B-&gt;公有静态方法"); &#125;&#125; java中switch的参数类型支持的数据类型有char,byte,short,int,enum,String以及他们对应的包装类型(如果有包装类型的话)，在JDK1.7之前不支持char和String类型 final变量 对于基本类型，final 使数值不变； 对于引用类型，final 使引用不变，也就不能引用其它对象，但是被引用的对象本身是可以修改的。 方法 声明方法不能被子类重写。 private 方法隐式地被指定为 final，如果在子类中定义的方法和基类中的一个 private 方法签名相同，此时子类的方法不是重写基类方法，而是在子类中定义了一个新的方法。 类 声明类不允许被继承。 静态方法不能是抽象方法，因为静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法。静态导包在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低 1import static com.xxx.ClassName.* 类的初始化顺序 父类（静态变量、静态语句块） 子类（静态变量、静态语句块） 父类（实例变量、普通语句块） 父类（构造函数） 子类（实例变量、普通语句块） 子类（构造函数） 泛型擦除泛型信息只存在于代码编译阶段，在进入 JVM 之前，与泛型相关的信息会被擦除掉，专业术语叫做类型擦除。 1234List&lt;String&gt; l1 = new ArrayList&lt;String&gt;();List&lt;Integer&gt; l2 = new ArrayList&lt;Integer&gt;(); System.out.println(l1.getClass() == l2.getClass());//结果为true 因为 List和 List在 jvm 中的 Class 都是 List.class所以结果为true]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[秒杀系统实现思路]]></title>
    <url>%2F2020%2F03%2F19%2F%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[并发系统实现思路第一版主要是使用mysql实现秒杀，利用CAS和自旋锁保证商品不超卖，也就是说第一版主要是为了后面的并发系统打下基础，而且在这个秒杀系统中我们使用SpringSecurity的方式实现JWT。 难点：使用mysql解决超卖问题1234567CREATE TABLE `commoditys` ( `uid` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) CHARACTER SET utf8 DEFAULT NULL, `number` int(11) DEFAULT NULL, `version` int(11) DEFAULT NULL, PRIMARY KEY (`uid`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4; 在数据库字段中我们新增了一个字段version，该字段表示操作的版本号，原理就是CAS(乐观锁)，注意mysql的存储引擎是InnoDB,在InnoDB引擎中使用update语句，如果where后面的字段是索引，那么多个会话操作同一条数据是一个行锁，我们可以利用这个特性实现自旋锁和乐观锁解决超卖问题。 实现CAS（乐观锁）和自旋锁的关键SQL语句1234-- 先获取商品信息SELECT * FROM commoditys WHERE uid=#&#123;commodityId&#125;-- 如果版本号没有变化就更新库存，并且版本号要加一UPDATE commoditys SET number=number-1,version=version+1 WHERE uid=#&#123;id&#125; AND version=#&#123;version&#125; 自旋锁的原理就是，先获取版本号，然后下一次修改商品库存的时候比对版本号是不是上次获取的版本号，如果是说明现在修改库存是安全的，然后在让版本号Version加一. 实现乐观锁和自旋锁的java代码1234567891011121314//该锁一直自旋，当然设置自旋的次数更好。public Integer scekill(Integer commodityId)&#123; //自旋减库存 while (true)&#123; Commodity commodit = scekillMapper.getCommoditById(commodityId); if(commodit.getNumber()&lt;=0)&#123;//如果没有库存，则秒杀失败 return 1; &#125; Integer integer = scekillMapper.setCommoditById(commodityId, commodit.getVersion()); if(integer==1)&#123;//秒杀成功 return 0; &#125; &#125; &#125; 难点：如何使用JWT防范中间人攻击简单点讲，所谓中间人攻击就是用户在提交请求的时候，被提交的请求并不是直接到达了服务器，而是通过了许多交换机和服务器，如果黑客在 提交的时候监听了你提交的数据，比如说传统基于cookie和session模式中，黑客拿到了你的cookie，然后通过手段向服务器发起请求，很容易就能伪造登陆。 我的解决方案就是，一个token只能使用一次，每次在给浏览器颁发token的时候在token存放一下当前请求的ip，每次服务器拿到token就要校验上次的ip和这一次是不是同一个ip。 最后吞吐率只有40/sec]]></content>
      <tags>
        <tag>秒杀系统</tag>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm学习第三天-类加载器]]></title>
    <url>%2F2020%2F03%2F19%2Fjvm%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%89%E5%A4%A9-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[类加载器 虚拟机设计团队把类加载阶段中的“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。实现这个动作的代码模块称为“类加载器”。 类与类加载器对于任何一个类，都需要由加载它的类加载器和这个类来确立其在JVM中的唯一性。也就是说，两个类来源于同一个Class文件，并且被同一个类加载器加载，这两个类才相等。 这段代码就演示了这种情况 123456789101112131415161718192021222324252627282930313233343536373839package jvm;import java.io.IOException;import java.io.InputStream;public class ClassLoaderTest &#123; public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException &#123; ClassLoader myLoader = new ClassLoader() &#123; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; String fileName = name.substring(name.lastIndexOf(".") + 1) + ".class"; InputStream inputStream = getClass().getResourceAsStream(fileName); if (inputStream == null) &#123; return super.loadClass(name); &#125; try &#123; byte[] b = new byte[inputStream.available()]; inputStream.read(b); return defineClass(name, b, 0, b.length); &#125; catch (IOException e) &#123; throw new ClassNotFoundException(); &#125; &#125; &#125;; Object obj = myLoader.loadClass("jvm.ClassLoaderTest").newInstance(); System.out.println(obj.getClass()); System.out.println(obj instanceof jvm.ClassLoaderTest); ClassLoaderTest classLoaderTest = new ClassLoaderTest(); System.out.println(classLoaderTest.getClass()); System.out.println(classLoaderTest instanceof jvm.ClassLoaderTest); &#125;&#125;//运行结果为class jvm.ClassLoaderTestfalseclass jvm.ClassLoaderTesttrue 双亲委派模型从虚拟机的角度来说，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），该类加载器使用C++语言实现，属于虚拟机自身的一部分。另外一种就是所有其它的类加载器，这些类加载器是由Java语言实现，独立于JVM外部，并且全部继承自抽象类java.lang.ClassLoader。 从Java开发人员的角度来看，大部分Java程序一般会使用到以下三种系统提供的类加载器： 启动类加载器（Bootstrap ClassLoader）：负责加载JAVA_HOME\lib目录中并且能被虚拟机识别的类库到JVM内存中，如果名称不符合的类库即使放在lib目录中也不会被加载。该类加载器无法被Java程序直接引用。 扩展类加载器（Extension ClassLoader）：该加载器主要是负责加载JAVA_HOME\lib\，该加载器可以被开发者直接使用。 应用程序类加载器（Application ClassLoader）：该类加载器也称为系统类加载器，它负责加载用户类路径（Classpath）上所指定的类库，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。我们的应用程序都是由这三类加载器互相配合进行加载的。另外还有自定义类加载器。自定义类加载器(必须继承 ClassLoader)。 这些类加载器之间的关系 如上图所示的类加载器之间的这种层次关系，就称为类加载器的双亲委派模型（Parent Delegation Model）。该模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。子类加载器和父类加载器不是以继承（Inheritance）的关系来实现，而是通过组合（Composition）关系来复用父加载器的代码。 双亲委派模型的工作过程为如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的加载器都是如此，因此所有的类加载请求都会传给顶层的启动类加载器，只有当父加载器反馈自己无法完成该加载请求（该加载器的搜索范围中没有找到对应的类）时，子加载器才会尝试自己去加载。 优点（重点） 保证了系统的安全性 保证了同一个类由各种类加载器加载都是同一个类 模型实现 123456789101112131415161718192021222324252627protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; &#123;//首先，检查请求的类是否已经被加载过了 Class c = findLoadedClass(name); if (c == null) &#123; try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123;//如果父类加载器抛出ClassNotFoundException//说明父类加载器无法完成加载请求 &#125; if (c == null) &#123;//在父类加载器无法加载的时候//再调用本身的findClass方法来进行类加载 c = findClass(name); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 获取加载器1234567public class ClassLoderTest2 &#123; public static void main(String[] args) &#123; ClassLoderTest2 classLoderTest2 = new ClassLoderTest2(); System.out.println(classLoderTest2.getClass().getClassLoader());//Applaction加载器 System.out.println(classLoderTest2.getClass().getClassLoader().getParent());//扩展类加载器 &#125;&#125;]]></content>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
        <tag>虚拟器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的zip安装方法]]></title>
    <url>%2F2020%2F03%2F18%2Fmysql%E7%9A%84zip%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[windows安装方法本文来自https://howwrite.github.io/ 下载文件先去清华大学镜像站下载文件 找到想要版本的mysql,进去下载对应的zip文件,我下载的是mysql8.0的64位版:mysql-8.0.11-winx64.zip 下载完成后解压到合适的位置,如：C:\mysql-8.0.11 配置 解压完后在根目录创建一个名为my.ini的文件,添加以下内容 1234567891011121314151617[mysqld]character-set-server=utf8port = 3306# 设置mysql的安装目录basedir=D:\\mysql-8.0.11# 设置mysql数据库的数据的存放目录datadir=D:\\mysql-8.0.11\\datadefault-storage-engine = INNODBcollation-server = utf8_general_ci[mysql]default-character-set=utf8[mysql.server]default-character-set=utf8[mysql_safe]default-character-set=utf8[client]default-character-set=utf8 basedir是解压目录,datadir是mysql存放数据的目录 然后打开电脑的环境变量 新建系统变量MYSQL_HOME=C:\mysql-8.0.11(解压路径) 在path中增加%MYSQL_HOME%\bin 在mysql的bin目录下运行初始化系统命令 1mysqld --initialize 初始化成功后，会在data文件夹下生成一些文件，其中xxx.err文件中说明了root账户的临时密码 如 1[Server] A temporary password is generated for root@localhost: JafC,2cE&lt;C# 那么JafC,2cE&lt;C#就是临时密码,一般在第二行就会看到 注册mysql服务 1mysqld -install MySQL 启动mysql服务 1net start MySQL 停止mysql服务 1net stop MySQL 先用root和临时密码登录数据库 ubuntu18安装mysql说明：此种方式完全参考官方提供的教程https://dev.mysql.com/doc/mysql-apt-repo-quick-guide/en/。 注意：通过APT方式安装的版本都是现在最新的版本，现在我安装的是5.7.18。通过这种方式安装好之后开机自启动都已经配置好，和命令行上的环境变量，无需手动配置。 (可省略)下载官方提供的mysql-apt-config.deb包进行APT源设置，下载地址：https://dev.mysql.com/downloads/repo/apt/ 下载了,然后运行sudo dpkg -i xxx.deb 运行这个安装包 第一个确定进去选择5.7,然后选ok 然后运行sudo apt-get update 然后运行sudo apt-get install mysql-server 中间会让你输入密码 如果依赖不足,输入sudo apt-get install -f 打开etc\mysql\mysql.conf.d\mysql.cnf在下面加上 1character-set-server=utf8default-storage-engine = INNODBcollation-server = utf8_general_ci[mysql]default-character-set=utf8[mysql.server]default-character-set=utf8[mysql_safe]default-character-set=utf8[client]default-character-set=utf8 服务管理 1#启动sudo service mysql start#停止sudo service mysql stop#服务状态sudo service mysql status 通用 执行更改新密码 1ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;new_password&apos;; 刷新 1flush privileges; 退出重启服务器用新密码登录即可 改密码 1update user set authentication_string = password(&quot;new_password&quot;) where user=&apos;root&apos;;]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm学习第二天-虚拟机执行子系统]]></title>
    <url>%2F2020%2F03%2F18%2Fjvm%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E5%A4%A9-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[字节码简介Java字节码指令由一个字节长度的，代表某种特定操作含义的数字（操作码）以及其后的零至多个代表此操作所需参数（操作数）。此外字节码指令是面向操作数栈的，这里操作数栈在功能上对应实体机的寄存器但是结构上有所区别。 字节码与数据类型在字节码指令集中，大多数指令都对应的其操作所对应的数据类型信息，比如iload表示从局部变量表中加载int型的数据到操作栈中，fload从局部变量表中加载float型的数据到操作栈中…但是由于Java字节码的操作码只有一个字节（即0~255），这意味着指令集的操作码总数不可能超过256条。所以如果要求Java运行时所有的数据类型都有对应的与数据类型相关的指令去支持的话，操作码的总数将超过256条。所以JAVA字节码指令集被设计为Not Orthogonal（非完全独立）,即并非每种数据类型和每种操作都有对应的指令，有一些指令可以在必要的时候将一些不被支持的数据类型转换为被支持的数据类型。我们可以以数据类型为列，操作指令为行制作一张表，其中为空的项即说明虚拟机不支持对这种数据类型进行这项操作。 加载和存储指令加载和存储指令用于将数据在帧栈中的局部变量表和操作数栈之间传输。 将一个局部变量表加载到操作数栈：iload、iload_、lload、lload_、fload、fload_、dload、dload_、aload、aload_。将一个数值从操作数栈储存到局部变量表：istore,istore_,lstore,lstore_,fstore,fstore_,dstore,dstore_,astore,astore_ 运算指令 运算指令用于对操作数栈上的值进行某种特定的运算。 加法运算：iadd,ladd,fadd,dadd。减法运算：isub,lsub,fsub,dsub。乘法运算：imul,lmul,fmul,dmul。除法运算：idiv,ldiv,fdiv,ddiv。求余指令：irem,lrem,frem,drem。取反指令：imeg,lmeg,fmeg,dmeg。位移指令：ishl,ishr,iushr,lshl,lshr,lushr。按位或指令：ior,lor。按位与指令：iand,land。按位异或指令：ixor,lxor。局部变量自增指令：iinc。比较指令：dcmpg,dcmpl,fcmpg,fcmpl,lcmp。注：只有在除法指令（idiv,ldiv)和求余指令（irem,lrem)当出现除数为零时会导致虚拟机抛出AirtmeticException异常，其余整形和浮点型运算场景都不会抛出异常 类型转换指令类型转换指令可以将两种不同数值类型进行相互转换。Java虚拟机天然支持基本数据类型的宽化类型转换，例如int到long、flost、double等。对于窄化数据类型转化则必须用显示的转换指令： i2b(int -&gt; boolean)i2c(int -&gt; char)i2s(int -&gt; short)l2i(long -&gt; int)f2i(float -&gt; int)f2l(float -&gt; long)d2i(double -&gt; int)d2l(double -&gt; long)d2f(double -&gt; float) 对象创建与访问指令创建类实例的指令：new创建数组的指令：newarray,anewarray,multianewarray访问类字段（static字段）和实例字段（非static字段）的指令：getfield,putfield,getstatic,putstatic将一个数组元素加载到操作数栈的指令:baload,caload,saload,iaload,faload,daload,aaload将一个操作数栈的值存储到数组元素中的指令：bastore,castore,iastore,sastore,fastore,fastore,dastore,aastore取数组长度的指令：arraylength检查类实例类型的指令：instanceof,checkcast 操作数栈管理指令将一个操作数栈的栈顶一个或两个元素出栈：pop、pop2。复制栈顶一个或两个数值并将复制值或双份的复制值重新压入栈顶：dup、dup2、dup_x1,dup2_x1,dup_x2,dup2_x2。将栈顶端的两个数值交换：swap。控制转移指令 控制转移指令可以让Java虚拟机有条件或者无条件的从指定的位置而不是控制转移指令的下一条指令继续执行程序。 条件分支：ifeq,ifit,ifle,ifgt,ifnull,ifnonnull,if_icmpeq,if_icmpne,if_icmplt,if_icmpgt,if_icmple,if_icmpge,if_acmpeq,if_acmpne。复合条件分支：tableswitch,lookupswitch。无条件分支：gosto,goto_w,jsr,jsr_w,ret。 方法调用和返回指令invokevirtual:用于调用对象的实例方法，根据对象的实际类型进行分派（虚方法分派）。invokeinterface:用于调用接口方法，它在运行时搜索一个实现了这个接口方法的对象，找出适合的方法进行调用。invokespecial:用于调用一些需要特殊处理的实例方法，包括实例的初始化方法，私有方法和父类方法。invokestatic:用于调用类方法（static方法）invokedynamic:用于运行时动态解析出调用点限定符所应用的方法，并执行该方法。（前面的分派逻辑都固化在虚拟机内部，而该指令的分派逻辑是由用户自定义）。方法返回指令：ireture(返回类型是int,short,byte,char,boolean时),lreturn,freturn,dreturn,areturn,另外还有一条return供void方法、实例/类/接口的初始化方法使用。 异常处理指令显式抛出异常指令：athrow 同步指令monitorenter,monitorexit 代码分析12345public void test()&#123; int a=10; int b=10; int c=a+b; &#125; 123456789 0 bipush 10//存入10到操作数栈 2 istore_1//弹出栈顶元素存入位置1的局部变量中,而且位置1对应的是a 3 bipush 10//存入10到操作数栈 5 istore_2//弹出栈顶元素存入位置2的局部变量中,而且位置2对应的是b 6 iload_1//取出局部变量表1位置的int型变量存放在栈顶 7 iload_2//取出局部变量表2位置的int型变量存放在栈顶 8 iadd//弹出操作数栈的两个元素求和并把结果存入操作数栈中 9 istore_3//弹出操作数栈顶元素存放在局部变量表3的位置，对应变量为c10 return 虚拟类的加载机制 类加载时机java语言中类型的加载连接以及初始化过程都是在程序运行期间完成的，这种策略虽然会使类加载时稍微增加一些性能开销，但是会为java应用程序提供高度的灵活性。java里天生就可以动态扩展语言特性就是依赖运行期间动态加载和动态连接这个特点实现的。比如，如果编写一个面向接口的程序，可以等到运行时再指定其具体实现类。（解析阶段则不一定:在某些情况下可以在初始化阶段之后开始，这是为了支持java语言的运行时绑定特性(也称为动态绑定或晚期绑定). 加载” 是 “类加载” 过程的一个阶段，切不可将二者混淆。 加载阶段由三个基本动作组成： 通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 主动加载和被动加载主动加载和被动加载的区别在于，主动加载会触发类的初始化。 类必须初始化的6种情况 使用new关键字实例化对象的时候、读取或设置一个类的静态字段的时候，已经调用一个类的静态方法的时候。 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类没有被初始化就会先初始化它的父类。 当虚拟机启动的时候，用户需要指定一个要执行的主类（就是包含main()方法的那个类），虚拟机会先初始化这个类； 使用Jdk1.7动态语言支持的时候的一些情况。 当一个接口中定义了JDK8新加入的默认方法(被default关键字修饰的接口方法时，如果这个接口的实现类发生了初始化，那么该接口要在其之前被初始化) 相对于类加载过程的其他阶段，一个非数组类的加载阶段（准确地说，是加载阶段中获取类的二进制字节流的动作）是开发人员可控性最强的，因为加载阶段既可以使用系统提供的引导类加载器来完成，也可以由用户自定义的类加载器去完成，开发人员可以通过定义自己的类加载器去控制字节流的获取方式（即重写一个类加载器的loadClass（）方法）。 也就是说我们在加载的时候可以从很多地方加载，例如从压缩包加载，从网络加载，运行时计算生成等。 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，方法区中的数据存储格式由虚拟机实现自行定义，虚拟机规范未规定此区域的具体数据结构。然后在内存中实例化一个java.lang.Class类的对象（并没有明确规定是在Java堆中，对于HotSpot虚拟机而言，Class对象比较特殊，它虽然是对象，但是存放在方法区里面），这个对象将作为程序访问方法区中的这些类型数据的外部接口。 加载数组数组类本身不通过类加载器创建，它时有java虚拟机直接在内存中动态构造出来的，但数组类与类加载器仍然有很密切的关系，因为数组的元素类型（数组去掉所有维度的类型）最终还是要靠类加载器来完成。 连接验证验证是链接阶段的第一步，这一步主要的目的是确保class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身安全。 因为仅仅依靠java代码层面一些无法做到的事情java代码也可以表示出来，例如数组越界，所以jvm的编译期在字节码上看见这种事情会直接拒绝编译 验证阶段主要包括四个检验过程：文件格式验证、元数据验证、字节码验证和符号引用验证。 文件格式验证验证class文件格式规范，例如： class文件是否已魔术0xCAFEBABE开头 ， 主、次版本号是否在当前虚拟机处理范围之内等 元数据验证这个阶段是对字节码描述的信息进行语义分析，以保证起描述的信息符合java语言规范要求。验证点可能包括：这个类是否有父类(除了java.lang.Object之外，所有的类都应当有父类)、这个类是否继承了不允许被继承的类(被final修饰的)、如果这个类的父类是抽象类，是否实现了起父类或接口中要求实现的所有方法。 字节码验证进行数据流和控制流分析，这个阶段对类的方法体进行校验分析，这个阶段的任务是保证被校验类的方法在运行时不会做出危害虚拟机安全的行为。如：保证访法体中的类型转换有效，例如可以把一个子类对象赋值给父类数据类型，这是安全的，但不能把一个父类对象赋值给子类数据类型、保证跳转命令不会跳转到方法体以外的字节码命令上。 符号引用验证准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区(方法区是一个逻辑上的区域，在JDK7之前，HoSpot使用永久代来实现方法区，这是符合这种逻辑概念的，但是在JDK8及其以后类变量会随着Class对象一起放在java堆中)中进行分配。这个阶段中有两个容易产生混淆的知识点，首先是这时候进行内存分配的仅包括类变量(static 修饰的变量),而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在java堆中。其次是这里所说的初始值“通常情况”下是数据类型的零值，假设一个类变量定义为:**public static int value = 12; 那么变量value在准备阶段过后的初始值为0而不是12，因为这时候尚未开始执行任何java方法，而把value赋值为123的putstatic指令是程序被编译后，存放于类构造器()方法之中，所以把value赋值为12的动作将在初始化阶段才会被执行。 上面所说的“通常情况”下初始值是零值，那相对于一些特殊的情况，如果类字段的字段属性表中存在ConstantValue属性，那在准备阶段变量value就会被初始化为ConstantValue属性所指定的值，建设上面类变量value定义为：public static final int value = 123; 编译时javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value设置为123 数据类型 零值 int 0 long 0L short (short)0 char ‘\u0000’ byte (byte)0 boolean false float 0.0f double 0.0d reference null 解析 解析阶段是虚拟机常量池内的符号引用替换为直接引用的过程。 符号引用：符号引用是一组符号来描述所引用的目标对象，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标对象并不一定已经加载到内存中。 直接引用：直接引用可以是直接指向目标对象的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是与虚拟机内存布局实现相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同，如果有了直接引用，那引用的目标必定已经在内存中存在。 虚拟机规范并没有规定解析阶段发生的具体时间，只要求了在执行anewarry、checkcast、getfield、instanceof、invokeinterface、invokespecial、invokestatic、invokevirtual、multianewarray、new、putfield和putstatic这13个用于操作符号引用的字节码指令之前，先对它们使用的符号引用进行解析，所以虚拟机实现会根据需要来判断，到底是在类被加载器加载时就对常量池中的符号引用进行解析，还是等到一个符号引用将要被使用前才去解析它。 解析的动作主要针对类或接口、字段、类方法、接口方法四类符号引用进行。分别对应编译后常量池内的CONSTANT_Class_Info、CONSTANT_Fieldref_Info、CONSTANT_Methodef_Info、CONSTANT_InterfaceMethoder_Info四种常量类型。 类、接口的解析 字段解析 类方法解析 接口方法解析 初始化类的初始化阶段是类加载过程的最后一步，在准备阶段，类变量已赋过一次系统要求的初始值，而在初始化阶段，则是根据程序员通过程序制定的主观计划去初始化类变量和其他资源，或者可以从另外一个角度来表达：初始化阶段是执行类构造器&lt; clinit &gt;()方法的过程。在以下四种情况下初始化过程会被触发执行： 遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需先触发其初始化。生成这4条指令的最常见的java代码场景是：使用new关键字实例化对象、读取或设置一个类的静态字段(被final修饰、已在编译器把结果放入常量池的静态字段除外)的时候，以及调用类的静态方法的时候。 使用java.lang.reflect包的方法对类进行反射调用的时候 当初始化一个类的时候，如果发现其父类还没有进行过初始化、则需要先出发其父类的初始化 jvm启动时，用户指定一个执行的主类(包含main方法的那个类)，虚拟机会先初始化这个类 在上面准备阶段 public static int value = 12; 在准备阶段完成后 value的值为0，而在初始化阶调用了类构造器&lt; clinit &gt;()方法，这个阶段完成后value的值为12。 类构造器&lt; clinit &gt;()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块(static块)中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句快可以赋值，但是不能访问。 类构造器&lt; clinit &gt;()方法与类的构造函数(实例构造函数&lt; init &gt;()方法)不同，它不需要显式调用父类构造，虚拟机会保证在子类&lt; clinit &gt;()方法执行之前，父类的&lt; clinit &gt;()方法已经执行完毕。因此在虚拟机中的第一个执行的&lt; clinit &gt;()方法的类肯定是java.lang.Object。 由于父类的&lt; clinit &gt;()方法先执行，也就意味着父类中定义的静态语句快要优先于子类的变量赋值操作。 &lt; clinit &gt;()方法对于类或接口来说并不是必须的，如果一个类中没有静态语句，也没有变量赋值的操作，那么编译器可以不为这个类生成&lt; clinit &gt;()方法。 接口中不能使用静态语句块，但接口与类不太能够的是，执行接口的&lt; clinit &gt;()方法不需要先执行父接口的&lt; clinit &gt;()方法。只有当父接口中定义的变量被使用时，父接口才会被初始化。另外，接口的实现类在初始化时也一样不会执行接口的&lt; clinit &gt;()方法。 虚拟机会保证一个类的&lt; clinit &gt;()方法在多线程环境中被正确加锁和同步，如果多个线程同时去初始化一个类，那么只会有一个线程执行这个类的&lt; clinit &gt;()方法，其他线程都需要阻塞等待，直到活动线程执行&lt; clinit &gt;()方法完毕。如果一个类的&lt; clinit &gt;()方法中有耗时很长的操作，那就可能造成多个进程阻塞。]]></content>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AQS详解]]></title>
    <url>%2F2020%2F03%2F16%2FAQS%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Lock接口锁是用来控制多个线程访问共享资源的方式，一般来说，一个锁能够防止多个线程同时访问共享资源（但是有些锁可以允许多个线程并发的访问共享资源，比如读写锁）。在Lock接口出现之前，Java程序是靠synchronized关键字实现锁功能的，而Java 5之后，并发包中新增了Lock接口（以及相关实现类）用来实现锁功能，它提供了与synchronized关键字类似的同步功能，只是在使用时需要显式地获取和释放锁。虽然它缺少了（通过synchronized块或者方法所提供的）隐式获取释放锁的便捷性，但是却拥有了锁获取与释放的可操作性、可中断的获取锁以及超时获取锁等多种synchronized关键字所不具备的同步特性。 12345678910111213141516class X&#123; //定义锁对象，其中构造方法如果传入true就是公平锁，否则是非公平锁 private final ReentrantLock lock=new ReentrantLock(); //定义需要保证线程安全的方法 public void m()&#123; //加锁 lock.lock(); try&#123; //...method body &#125; //使用finally块来保证释放锁 finally&#123; lock.unlock(); &#125; &#125;&#125; 使用Reentrantlock可以进行尝试锁定tryLock()，这样无法锁定，或者在指定时间内无法锁定，返回false； 使用ReentrantLock还可以调用lockInterruptibly()方法，可以对线程interrupt()方法做出响应，在一个线程等待锁的过程中，可以被打断，打断后会抛异常。 手动实现一个自旋锁方案一123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package thread;import java.util.concurrent.atomic.AtomicInteger;/** * @author yang * @date 2020/4/16 下午 4:44 * 实现一个自旋锁 */public class SpinLock &#123; static AtomicInteger atomicInteger=new AtomicInteger(0); static Integer count=0;//测试数据,来测试线程是否安全 //加锁,如果获取不到锁就进行忙等待获取自旋锁 public static void lock()&#123; //自旋获取锁 while (!atomicInteger.compareAndSet(0,1))&#123;//如果设置不成功则一直处于忙等状态 System.out.println(Thread.currentThread().getName()+"自旋获取锁失败!正在重新尝试"); &#125; System.out.println(Thread.currentThread().getName()+"获取到锁"); &#125; //解锁 public static void unlock()&#123; if(!atomicInteger.compareAndSet(1, 0))&#123; System.out.println("没有加锁无法解锁"); &#125;else &#123; System.out.println(Thread.currentThread().getName()+"解锁成功"); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Thread thread = new Thread(() -&gt; &#123;//假设线程一获取到了锁但是过了很久才释放锁. for (int i = 0; i &lt;10 ; i++) &#123; lock(); count++; try &#123; Thread.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; unlock(); &#125; &#125;); Thread thread1 = new Thread(() -&gt; &#123; for (int i = 0; i &lt;10 ; i++) &#123; lock(); count++; unlock(); &#125; &#125;); thread.start(); thread1.start(); thread.join(); thread1.join(); System.out.println(count);//打印最终结果 &#125;&#125; 打印输出一部分 1234567891011Thread-0获取到锁Thread-1自旋获取锁失败!正在重新尝试Thread-1自旋获取锁失败!正在重新尝试Thread-1自旋获取锁失败!正在重新尝试Thread-1自旋获取锁失败!正在重新尝试Thread-1自旋获取锁失败!正在重新尝试Thread-1自旋获取锁失败!正在重新尝试Thread-1自旋获取锁失败!正在重新尝试Thread-1自旋获取锁失败!正在重新尝试Thread-1自旋获取锁失败!正在重新尝试... 我们可以看到由于Thread-0拿到了锁并没有释放，结果导致Thread-1大量进行自旋操作，这种操作无疑是非常浪费性能的，所以 缺点：耗费CPU资源，没有竞争到锁的线程会一直占用CPU资源进行CAS操作。 方案二Java提供了一个较为底层的并发工具类：LockSupport，可以让线程停止下来(阻塞)，还可以唤醒线程。 1234// 阻塞线程LockSupport.park(Object blocker) // 唤醒线程LockSupport.unpark(Thread thread) 这两个方法均来自java最牛逼的类Unsafe 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * @author yang * @date 2020/5/6 23:29 */public class CASDemo &#123; public static void main(String[] args) &#123; MyLock myLock = new MyLock(); new Thread(()-&gt;&#123; myLock.lock(); try &#123; System.out.println(Thread.currentThread().getName()+"获取到锁"); TimeUnit.SECONDS.sleep(1); myLock.unlock(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+"释放锁"); &#125;).start(); new Thread(()-&gt;&#123; myLock.lock(); try &#123; System.out.println(Thread.currentThread().getName()+"获取到锁"); TimeUnit.SECONDS.sleep(1); myLock.unlock(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+"释放锁"); &#125;).start(); &#125;&#125;/** * 使用CAS自定义一个锁 */class MyLock&#123; private AtomicInteger state=new AtomicInteger(1); LinkedBlockingQueue&lt;Thread&gt; threads=new LinkedBlockingQueue&lt;Thread&gt;();//存放被park的线程,相当于自定义的AQS public void lock()&#123; while (!state.compareAndSet(1, 0))&#123;//自旋失败就park threads.add(Thread.currentThread()); LockSupport.park(); &#125;; &#125; public void unlock() throws InterruptedException &#123; while (!state.compareAndSet(0, 1))&#123;&#125;; if(threads.size()!=0)&#123; Thread take = threads.take(); LockSupport.unpark(take); &#125; &#125;&#125; 死锁的原因就是因为线程park的时候不会释放锁。 队列同步器AQS队列同步器AbstractQueuedSynchronizer（AQS）是用来构建锁或者其他同步组件的基础框架，它使用了一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作，并发包的作者（Doug Lea）期望它能够成为实现大部分同步需求的基础。 AQS的实现FIFO队列同步器依赖内部的同步队列（一个FIFO双向队列）来完成同步状态的管理，当前线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成为一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒，使其再次尝试获取同步状态。 AQS中的节点Node： 1234567891011121314static final class Node &#123; // 等待状态，若值为-1，表示后继节点处于等待状态 volatile int waitStatus; // 前一个节点 volatile Node prev; // 下一个节点 volatile Node next; // 节点绑定线程 volatile Thread thread; // 线程所处的等待锁的状态，初始化时，该值为0 volatile int waitStatus; static final int CANCELLED = 1; static final int SIGNAL = -1;&#125; AQS属性 12345678public abstract class AbstractQueuedSynchronizer &#123; // 等待队列头结点 private transient volatile Node head; // 等待队列尾结点 private transient volatile Node tail; // 状态 private volatile int state;&#125; 调用aquire(1)方法 123456public final void acquire(int arg) &#123; // 尝试获取同步器tryAcquire false--&gt; 入队addWaiter --&gt; park阻塞该线程acquireQueued if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 只执行上述方法便可完成整个的加锁逻辑。而该方法中又包含下列四个方法的调用： tryAcquire(arg) 该方法由继承AQS的子类实现，为获取锁的具体逻辑； addWaiter(Node.EXCLUSIVE) 该方法由AQS实现，负责在获取锁失败后调用，将当前请求锁的线程包装成Node并且放到等待队列中，并返回该Node。 acquireQueued(addWaiter(Node.EXCLUSIVE), arg) 该方法由AQS实现。针对上面加入到队列的Node不断尝试两种操作之一： 若前驱节点是head节点的时候，尝试获取锁； 调用park将当前线程挂起，线程阻塞。 selfInterrupt 该方法由AQS实现。恢复用户行为。 用户在外界调用t1.interrupt()进行中断。 线程在parkAndCheckInterrupt方法被唤醒之后。会调用Thread.interrupted();判断线程的中断标识，而该方法调用完毕会清除中断标识位。 而AQS为了不改变用户标识。再次调用selfInterrupt恢复用户行为。 公平锁的tryAcquire（子类重写）： 12345678910111213141516171819202122protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 如果没有后继节点，把stata CAS置1，把exclusiveOwnerThread置为当前线程 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 可重入锁 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); // 重入时 state + 1 setState(nextc); return true; &#125; return false; &#125; 判断是否有后续节点： 1234567public final boolean hasQueuedPredecessors() &#123; Node t = tail; Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); &#125; 实例化一个Node： 12345678910111213141516171819202122232425262728293031323334353637private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // 维护一个链表，prev和next节点 Node pred = tail; if (pred != null) &#123; // 把Node加入尾部 node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125;// 把Node加入队列，必要时初始化private Node enq(final Node node) &#123; // 自旋CAS // 当有大量的线程在同时入队的时候，同一时刻，只有一个线程能完整地完成这三步，而其他线程只能完成第一步，于是就出现了尾分叉. // 所有节点都会通过自旋不断的尝试入队，直到成功为止。 for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize // 实例化一个Thread为null的Node，并赋值给AQS的头 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; // 把当前线程Node入队 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 注：head指向的Node中的Thread永远为空，持有锁的线程不再在队列中。 acquireQueued 该方法是AQS的核心，addWaiter()将当前线程加入队列后，先自旋2次，使用acquireQueued()进行阻塞，中间可能被唤醒，但直到获取到资源后才返回，否则继续被park阻塞。 12345678910111213141516171819202122232425262728293031 final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); // 判断是否为第一个元素(队列中第二个Node) // 如果是第一个元素，自旋去获取锁，把当前节点置为head，把原head分离队列，方便GC if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; //阻塞当前线程park，获取不到的话自旋2次 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125;// 把当前节点置为head，Thread置为null private void setHead(Node node) &#123; head = node; node.thread = null; node.prev = null; &#125; 判断是否需要阻塞： 1234567891011121314151617181920private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) // 前一个线程节点的waitState=-1，可以阻塞了 return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // 将前一个节点waitState设置为-1，目的是多一次自旋 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 阻塞当前线程： 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 释放锁release(1)： 12345678910111213141516171819202122232425262728public void unlock() &#123; sync.release(1);&#125;public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) //唤醒第一个排队Node unparkSuccessor(h); return true; &#125; return false;&#125;protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // state = 0时把OwnerThread设为null if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 唤醒下一个节点： 123456789101112131415161718private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 从后向前找 // 因为一个节点要能入队，则它的prev属性一定是有值的，但是它的next属性可能暂时还没有值。 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; AQS的使用方法同步器的主要使用方式是继承，子类通过继承同步器并实现它的抽象方法来管理同步状态，在抽象方法的实现过程中免不了要对同步状态进行更改，这时就需要使用同步器提供的3个方法getState()、setState(int newState)和compareAndSetState(int expect,int update))来进行操作，因为它们能够保证状态的改变是安全的。子类推荐被定义为自定义同步组件的静态内部类，同步器自身没有实现任何同步接口，它仅仅是定义了若干同步状态获取和释放的方法来供自定义同步组件使用，同步器既可以支持独占式地获取同步状态，也可以支持共享式地获取同步状态，这样就可以方便实现不同类型的同步组件（ReentrantLock、ReentrantReadWriteLock和CountDownLatch等）。 例如在ReentrantLock中，Sync为继承于AQS的静态内部类： 1abstract static class Sync extends AbstractQueuedSynchronizer&#123;&#125; AQS的接口同步器的设计是基于模板方法模式的，也就是说，使用者需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法。 同步器有三种核心方法，同步器中使用int变量表示同步状态，重写同步器的指定方法，需要调用这三种核心方法来访问或更新同步状态： int getState():获取同步状态的当前值void setState(int newState):设置同步状态的值boolean compareAndSetState(int expect, int update):使用CAS原子性地设置同步状态的值，当同步状态的当前值为expect时，将其设置为给定值（update）。AQS同步器可重写的方法包括独占式的获取或释放同步状态、共享式的获取或释放同步状态、同步器是否在独占模式下被线程占用，重写这几个方法是实现一个锁的核心。 boolean tryAcquire(int arg):独占式的获取同步状态，实现该方法需要先获取并判断同步状态是否符合预期，再通过CAS设置同步状态。（即使用compareAndSetState(expect, update)方法）。可用于实现Lock接口中的tryLock()方法。 boolean tryRelease(int arg):独占式的释放同步状态，等待获取同步状态的线程将有机会获取同步状态; int tryAcquireShared(int arg):共享式的获取同步状态，返回大于等于0表示获取成功，否则获取失败; boolean tryReleaseShared(int arg)： 共享式的释放同步状态; boolean isHeldExclusively()： 用于获取同步器是否在独占模式下被线程占用，一般用来表示是否被当前线程所独占。 AQS提供的模板方法供锁来调用： 共享式同步状态获取与释放以自定义同步组件——TwinsLock展示如何实现共享式锁： ​ 123456789101112131415161718192021222324252627282930313233343536373839 public class TwinsLock implements Lock &#123; private final Sync sync = new Sync(2); private static final class Sync extends AbstractQueuedSynchronizer &#123; Sync(int count) &#123; if (count &lt;= 0) &#123; throw new IllegalArgumentException("count must large than zero."); &#125; setState(count); &#125; &#125; public int tryAcquireShared(int reduceCount) &#123; for (;;) &#123; int current = getState(); int newCount = current - reduceCount; if (newCount &lt; 0 || compareAndSetState(current,newCount)) &#123; return newCount; &#125; &#125; &#125; public boolean tryReleaseShared(int returnCount) &#123; for (;;) &#123; int current = getState(); int newCount = current + returnCount; if (compareAndSetState(current, newCount)) &#123; return true; &#125; &#125; &#125;&#125;public void lock() &#123; sync.acquireShared(1);&#125;public void unlock() &#123; sync.releaseShared(1);&#125;// 其他接口方法略 核心：调用AQS中的模板方法acquireShared()与releaseShared()，重写了tryAcquireShared与tryReleaseShared方法。 独占式超时获取同步状态通过调用同步器的doAcquireNanos(int arg, long nanosTimeout)方法可以超时获取同步状态，即在指定的时间段内获取同步状态，如果获取到同步状态则返回true，否则，返回false。 12345678910111213141516171819202122232425262728293031private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; // 计算还能等待多长时间 nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout);//最多让当前线程park这么久 if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; park()会让当前线程进入waiting状态。在此状态下，有两种途径可以唤醒该线程： 被unpark()； 被interrupt() 可打断的获取锁如果本线程是处于获取锁状态：调用线程的wait(),wait(long)或wait(long, int)会让它进入等待(阻塞)状态，或者调用线程的join(), join(long), join(long, int), sleep(long), sleep(long, int)也会让它进入阻塞状态。若线程在阻塞状态时，调用了它的interrupt()方法，那么它的中断状态会被清除并且会收到一个InterruptedException异常。需要注意的是，Thread.interrupted()会清除当前线程的中断标记位。 注意：synchronized和lock()在等待锁的时候无法被打断，而lockInterruptibly()可以被打断，抛出异常。 lockInterruptibly()的实现方法为： 12345678910111213141516171819202122232425262728293031323334public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1);&#125;public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg);&#125;private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 当park的时候被interrupt时，抛出异常 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 可以与tryAcquire()对比。 重入锁ReentrantLock可重入锁（也叫作递归锁），指的时同一线程外层函数获得锁之后，内层递归函数仍然能获取该锁的代码，在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁，也就是说，线程可以进入任何一个它已经拥有的锁所同步着的代码块。可重入锁最大的作用是避免死锁。 12345678910111213141516171819202122protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 如果没有后继节点，把stata CAS置1，把exclusiveOwnerThread置为当前线程 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 可重入锁 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); // 重入时 state + 1 setState(nextc); return true; &#125; return false; &#125; 可重入锁主要解决了两个问题： 线程再次获取锁。锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取。 锁的最终释放。线程重复n次获取了锁，随后在第n次释放该锁后，其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增，计数表示当前锁被重复获取的次数，而锁被释放时，计数自减，当计数等于0时表示锁已经成功释放。 公平与非公平锁ReentrantLock还可以实现非公平锁，其区别在于非公平锁在加锁时先进行了一次CAS获取锁的尝试，如果获取到锁，直接执行，不需要排队阻塞。 非公平锁： 123456final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; 公平锁： 123final void lock() &#123; acquire(1);&#125; 刚释放锁的线程再次获取同步状态的几率会非常大，使得其他线程只能在同步队列中等待。 公平性锁保证了锁的获取按照FIFO原则，而代价是进行大量的线程切换。非公平性锁虽然可能造成线程“饥饿”，但极少的线程切换，保证了其更大的吞吐量。 读写锁写锁是独占的，当写锁被获取到时，后续（非当前写操作线程）的读写操作都会被阻塞，写锁释放之后，所有操作继续执行。 读锁是共享的，多个线程可以共同读取数据。 一般情况下，读写锁的性能都会比排它锁好，因为大多数场景读是多于写的。在读多于写的情况下，读写锁能够提供比排它锁更好的并发性和吞吐量。Java并发包提供读写锁的实现是ReentrantReadWriteLock。 读写锁使用案例： 123456789101112131415161718192021222324252627282930313233343536public class Cache &#123; static Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); static Lock r = rwl.readLock(); static Lock w = rwl.writeLock(); // 获取一个key对应的value public static final Object get(String key) &#123; r.lock(); try &#123; return map.get(key); &#125; finally &#123; r.unlock(); &#125; &#125; // 设置key对应的value，并返回旧的value public static final Object put(String key, Object value) &#123; w.lock(); try &#123; return map.put(key, value); &#125; finally &#123; w.unlock(); &#125; &#125; // 清空所有的内容 public static final void clear() &#123; w.lock(); try &#123; map.clear(); &#125; finally &#123; w.unlock(); &#125; &#125;&#125; 读写锁的实现原理： 读写锁同样依赖自定义同步器来实现同步功能，而读写状态就是其同步器的同步状态。读写锁的自定义同步器需要在同步状态（一个整型变量）上维护多个读线程和一个写线程的状态。 如果在一个整型变量上维护多种状态，就一定需要按位切割使用这个变量，读写锁将变量切分成了两个部分，高16位表示读，低16位表示写，划分方式如图（当前同步状态表示一个线程已经获取了写锁，且重进入了两次，同时也连续获取了两次读锁）： 写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态。 1234567891011121314151617181920212223242526272829303132protected final boolean tryAcquire(int acquires) &#123; /* * Walkthrough: * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); int c = getState(); // 获取写锁状态值 int w = exclusiveCount(c); if (c != 0) &#123; // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error("Maximum lock count exceeded"); // Reentrant acquire setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true; &#125; 读锁是一个支持重进入的共享锁，它能够被多个线程同时获取，在没有其他写线程访问（或者写状态为0）时，读锁总会被成功地获取，而所做的也只是（线程安全的）增加读状态。 123456789101112131415161718192021222324252627282930313233343536373839404142protected final int tryAcquireShared(int unused) &#123; /* * Walkthrough: * 1. If write lock held by another thread, fail. * 2. Otherwise, this thread is eligible for * lock wrt state, so ask if it should block * because of queue policy. If not, try * to grant by CASing state and updating count. * Note that step does not check for reentrant * acquires, which is postponed to full version * to avoid having to check hold count in * the more typical non-reentrant case. * 3. If step 2 fails either because thread * apparently not eligible or CAS fails or count * saturated, chain to version with full retry loop. */ Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current); &#125; Condition接口任意一个Java对象，都拥有一组监视器方法（定义在java.lang.Object上），主要包括wait()、wait(long timeout)、notify()以及notifyAll()方法，这些方法与synchronized同步关键字配合，可以实现等待/通知模式。Condition接口也提供了类似Object的监视器方法，与Lock配合可以实现等待/通知模式。 使用方法： 1234567891011121314151617181920Lock lock = new ReentrantLock();Condition condition = lock.newCondition();public void conditionWait() throws InterruptedException &#123; lock.lock(); try &#123; condition.await(); &#125; finally &#123; lock.unlock(); &#125;&#125; public void conditionSignal() throws InterruptedException &#123; lock.lock(); try &#123; condition.signal(); // condition.signalAll(); &#125; finally &#123; lock.unlock(); &#125;&#125; 实现原理： ConditionObject是同步器AbstractQueuedSynchronizer的内部类，因为Condition的操作需要获取相关联的锁，所以作为同步器的内部类也较为合理。每个Condition对象都包含着一个队列（以下称为等待队列），该队列是Condition对象实现等待/通知功能的关键。 等待队列： 等待队列是一个FIFO的队列，在队列中的每个节点都包含了一个线程引用，该线程就是在Condition对象上等待的线程，如果一个线程调用了Condition.await()方法，那么该线程将会释放锁、构造成节点加入等待队列并进入等待状态。事实上，节点的定义复用了同步器中节点的定义，也就是说，同步队列和等待队列中节点类型都是同步器的静态内部类AbstractQueuedSynchronizer.Node。 在Object的监视器上，一个对象拥有一个同步队列和等待队列，而同步器拥有一个同步队列和多个等待队列。 等待await： 当前线程调用await()方法时，会使当前线程进入等待队列并释放锁，同时线程状态变为等待状态，相当于同步队列的首节点（获取了锁的节点）移动到Condition的等待队列中。 ConditionObject的await()方法： 123456789101112131415161718192021public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 当前线程加入等待队列 Node node = addConditionWaiter(); // 释放同步状态，也就是释放锁 int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125; 调用该方法的线程成功获取了锁的线程，也就是同步队列中的首节点，该方法会将当前线程构造成节点并加入等待队列中，然后释放同步状态，唤醒同步队列中的后继节点，然后当前线程会进入等待状态。 通知signal()： 调用Condition的signal()方法，将会唤醒在等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节点移到同步队列中。 1234567public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first);&#125; 通过调用同步器的enq(Node node)方法，等待队列中的头节点线程安全地移动到同步队列。当节点移动到同步队列后，当前线程再使用LockSupport唤醒该节点的线程。被唤醒后的线程，将从await()方法中的while循环中退出（isOnSyncQueue(Node node)方法返回true，节点已经在同步队列中），进而调用同步器的acquireQueued()方法加入到获取同步状态的竞争中。成功获取同步状态之后，被唤醒的线程将从先前调用的await()方法返回，此时该线程已经成功地获取了锁。 Condition的signalAll()方法，相当于对等待队列中的每个节点均执行一次signal()方法，效果就是将等待队列中所有节点全部移动到同步队列中，并唤醒每个节点的线程。]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>锁</tag>
        <tag>并发</tag>
        <tag>AQS</tag>
        <tag>自定义</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA反射详解]]></title>
    <url>%2F2020%2F03%2F15%2FJAVA%E5%8F%8D%E5%B0%84%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[概述定义JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性；这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制。 用途最重要的用途就是解耦，许多框架配合java反射技术以及工厂模式进行解耦，也就是说通过配置文件的方式创建对象 获取字节码的方式 Class.forName(“全限定类名”);将字节码加载进内存，返回Class对象.(多用于配置文件中，读取配置文件加载类) 类名.Class：通过类名属性获取Class 对象.getClass():通过对象的父类Object定义的getClass()方法获取字节码 反射机制的相关类与Java反射相关的类如下： 类名 用途 Class类 代表类的实体，在运行的Java应用程序中表示类和接口 Field类 代表类的成员变量（成员变量也称为类的属性） Method类 代表类的方法 Constructor类 代表类的构造方法 Class类Class代表类的实体，在运行的Java应用程序中表示类和接口。在这个类中提供了很多有用的方法，这里对他们简单的分类介绍。 获得类相关的方法 方法 用途 asSubclass(Class clazz) 把传递的类的对象转换成代表其子类的对象 Cast 把对象转换成代表类或是接口的对象 getClassLoader() 获得类的加载器 getClasses() 返回一个数组，数组中包含该类中所有公共类和接口类的对象 getDeclaredClasses() 返回一个数组，数组中包含该类中所有类和接口类的对象 forName(String className) 根据类名返回类的对象 getName() 获得类的完整路径名字 newInstance() 创建类的实例 getPackage() 获得类的包 getSimpleName() 获得类的名字 getSuperclass() 获得当前类继承的父类的名字 getInterfaces() 获得当前类实现的类或是接口 获得类中属性相关的方法 方法 用途 getField(String name) 获得某个公有的属性对象 getFields() 获得所有公有的属性对象 getDeclaredField(String name) 获得某个属性对象 getDeclaredFields() 获得所有属性对象 获得类中注解相关的方法 方法 用途 getAnnotation(Class annotationClass) 返回该类中与参数类型匹配的公有注解对象 getAnnotations() 返回该类所有的公有注解对象 getDeclaredAnnotation(Class annotationClass) 返回该类中与参数类型匹配的所有注解对象 getDeclaredAnnotations() 返回该类所有的注解对象 获得类中构造器相关的方法 方法 用途 getConstructor(Class…&lt;?&gt; parameterTypes) 获得该类中与参数类型匹配的公有构造方法 getConstructors() 获得该类的所有公有构造方法 getDeclaredConstructor(Class…&lt;?&gt; parameterTypes) 获得该类中与参数类型匹配的构造方法 getDeclaredConstructors() 获得该类所有构造方法 获得类中方法相关的方法 方法 用途 getMethod(String name, Class…&lt;?&gt; parameterTypes) 获得该类某个公有的方法 getMethods() 获得该类所有公有的方法 getDeclaredMethod(String name, Class…&lt;?&gt; parameterTypes) 获得该类某个方法 getDeclaredMethods() 获得该类所有方法 类中其他重要的方法 方法 用途 isAnnotation() 如果是注解类型则返回true isAnnotationPresent(Class&lt;? extends Annotation&gt; annotationClass) 如果是指定类型注解类型则返回true isAnonymousClass() 如果是匿名类则返回true isArray() 如果是一个数组类则返回true isEnum() 如果是枚举类则返回true isInstance(Object obj) 如果obj是该类的实例则返回true isInterface() 如果是接口类则返回true isLocalClass() 如果是局部类则返回true isMemberClass() 如果是内部类则返回true Field类Field代表类的成员变量（成员变量也称为类的属性）。 方法 用途 equals(Object obj) 属性与obj相等则返回true get(Object obj) 获得obj中对应的属性值 set(Object obj, Object value) 设置obj中对应属性值 Method类Method代表类的方法。 方法 用途 invoke(Object obj, Object… args) 传递object对象及参数调用该对象对应的方法 Constructor类Constructor代表类的构造方法。 方法 用途 newInstance(Object… initargs) 根据传递的参数创建类的对象 演示Person类 12345678public class Person &#123; private String name="默认值"; public int age; public String getName() &#123; return name; &#125;&#125; 获取Person的属性12345678910111213141516public static void main(String[] args) throws ClassNotFoundException &#123; Class personClass = Class.forName("Person");//这里要写全限定类名 //获取Person类的所有public属性 Field[] fields = personClass.getFields(); System.out.println("--------public属性--------"); for (Field field : fields) &#123; System.out.println(field.getName()); &#125; //获取Person类所有属性包括privice System.out.println("--------所有属性--------"); Field[] declaredFields = personClass.getDeclaredFields(); for (Field declaredField : declaredFields) &#123; System.out.println(declaredField.getName()); &#125;&#125; 结果为 12345--------public属性--------age--------所有属性--------nameage 修改Person属性的值（甚至可以修改他的私有属性）12345678910111213public static void main(String[] args) throws ClassNotFoundException, NoSuchFieldException, IllegalAccessException, InstantiationException &#123; Class personClass = Class.forName("Person");//加载到内存 Person person = (Person) personClass.newInstance();//实例化对象 Field age = personClass.getField("age");//获取Public属性 age.setInt(person,12);//修改其属性值 //强行设置私有属性的值 Field name = personClass.getDeclaredField("name"); name.setAccessible(true);//取消 Java 语言访问检查，否则会报错 name.set(person,"当你在控制台看见我的时候,我已经修改了private的值啦!!!"); System.out.println("Public设置的值"+person.age+"\nprivate设置的值"+person.getName());&#125; 读取配置文件创建指定的类并执行指定的方法bean.Properties配置文件 12classpath=Personmethod=getName 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import java.io.IOException;import java.io.InputStream;import java.lang.reflect.InvocationTargetException;import java.lang.reflect.Method;import java.util.Properties;public class JVMTest&#123; public static void main(String[] args) throws ClassNotFoundException, NoSuchFieldException, IllegalAccessException, InstantiationException, IOException, NoSuchMethodException, InvocationTargetException &#123; //读取配置文件类似spring框架里面的配置文件 Properties properties=readProperties(); //实例化配置文件里面指定的类 Object ob=beanFactory((String) properties.get("classpath")); //运行实例化类的配置文件指定的方法并且接收返回值 Object rel=runMethod((String) properties.get("method"),ob); System.out.println(rel); &#125; /** * 运行指定的方法 * @param methodName 方法名 * @param cls 类 */ public static Object runMethod(String methodName,Object cls) throws NoSuchMethodException, InvocationTargetException, IllegalAccessException &#123; Method method = cls.getClass().getMethod(methodName); return method.invoke(cls); &#125; /** * 根据传入的全类名创建对应的类 * @param classPath 全类名 * @return * @throws ClassNotFoundException * @throws IllegalAccessException * @throws InstantiationException */ public static Object beanFactory(String classPath) throws ClassNotFoundException, IllegalAccessException, InstantiationException &#123; return Class.forName(classPath).newInstance(); &#125; /** * 读取配置文件里面的信息并返回 * @return * @throws IOException */ public static Properties readProperties() throws IOException &#123; InputStream resourceAsStream = Object.class.getResourceAsStream("/bean.Properties"); Properties properties = new Properties(); properties.load(resourceAsStream); return properties; &#125;&#125; 运行结果 1默认值]]></content>
      <tags>
        <tag>JAVA</tag>
        <tag>反射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVMOOM溢出]]></title>
    <url>%2F2020%2F03%2F14%2FJVMOOM%E6%BA%A2%E5%87%BA%2F</url>
    <content type="text"><![CDATA[堆空间溢出12345678910111213141516171819202122232425/** * java堆内存溢出,首先在hospot虚拟机中堆内存是可以自动扩展的,但是我们可以调整他的上限 * -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=D:/发生OOM的时候自动保存内存快照 */public class OOMError &#123; public static void main(String[] args) &#123; ArrayList&lt;Object&gt; objects = new ArrayList&lt;&gt;(); while (true)&#123; objects.add(new Integer(1)); &#125; &#125;&#125;java.lang.OutOfMemoryError: Java heap spaceDumping heap to D:/\java_pid15796.hprof ...Heap dump file created [14831242 bytes in 0.071 secs]Exception in thread "main" java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3210) at java.util.Arrays.copyOf(Arrays.java:3181) at java.util.ArrayList.grow(ArrayList.java:261) at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:235) at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:227) at java.util.ArrayList.add(ArrayList.java:458) at oom.OOMError.main(OOMError.java:13)Process finished with exit code 1 如何定位哪里产生了大量对象导致了堆空间溢出了呢？我们使用工具Java VisualVm打开刚才保存的堆快照，中找到类视图，按照数量排序 我们可以看到确实是创建了大量的Integer对象可能导致了OOM 我们继续追踪，找到其中任意一个Integer发送持有他的对象的实例是一个ArrayList 我们找到这个ArrayList实例，我们发现他的大小足足有360145个对象 我们使用Jprofiler工具可以一键查看发送错误的位置 栈内存溢出123456789101112/** 由于Hospot虚拟机栈不可用动态扩展，所以无法产生oom错误，只会参数StackOverflowError*/public class StackOverflowError &#123; public static void main(String[] args) &#123; method(0); &#125; public static void method(int index)&#123; System.out.println(index); method(index+1); &#125;&#125; 方法区和运行时常量池溢出由于在JDK1.8中使用了元空间代替了永久代来实现，所以会动态扩展，要想产生溢出除了使用永久代实现了常量池，或者现在jvm的内存大小,当无法申请到新的内存的时候就会产生OOM 12345678910//-Xms10m -Xmx10mpublic class OOMError2 &#123; public static void main(String[] args) &#123; String str="a"; while (true)&#123; str=str+str; str.intern(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>OOM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中Native关键字]]></title>
    <url>%2F2020%2F03%2F13%2Fjava%E4%B8%ADNative%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[Native 今天在看java.lang.Object类的时候发现有个静态代码块由Native修饰，并且很疑惑。 native关键字说明被修饰的方法是一个原生态方法，并且方法的实现并不是由java来实现的，而是通过其他语言实现的，例如C++，也可以理解为这是一个java平台和本地c代码交互的API全称Java Native Interface，简称JNI。 为什么需要有这个关键字呢 与java环境外交互，这是本地方法存在的主要原因 有些需求的实现对于java来说非常困难，而且有性能问题的时候需要借助本地方法实现 来着百科对JNI的解释SUN公司发布的Java 本地接口(JNI)提供了将Java与C/C++、汇编等本地代码集成的方案，该规范使得在 Java 虚拟机内运行的 Java 代码能够与其它编程语言互相操作，包括创建本地方法、更新Java对象、调用Java方法，引用 Java类，捕捉和抛出异常等，也允许 Java代码调用 C/C++或汇编语言编写的程序和库。作为一个标准程序接口，它没有对底层 Java虚拟机的实现施加任何限制，并具有以下特点： 二进制兼容。本地方法库与同一平台上所有Java 虚拟机之间实现二进制兼容，即对于给定平台开发人员只需要维护一种版本的本地方法库。 效率高。为了实现实时系统，JNI 在效率与虚拟机无关性之间进行了优化，以保障高效运行。 功能强。JNI 提供了大量的函数及接口让本地方法与Java 虚拟机内核相互操作，增强两者的功能。 本地代码与 Java 虚拟机之间是通过 JNI 函数实现相互操作的。JNI 函数通过接口指针来获得，本地方法将 JNI 接口指针当作参数来接受。虚拟机保证在从相同的 Java 线程中对本地方法进行多次调用时，传递给本地方法的接口指针是相同的，本地方法被不同的 Java 线程调用时，它接受不同的 JNI接口指针。 示例代码123456789public class HelloWorld &#123; public native void displayHelloWorld();//所有native关键词修饰的都是对本地的声明 static &#123; System.loadLibrary("hello");//载入本地库 &#125; public static void main(String[] args) &#123; new HelloWorld().displayHelloWorld(); &#125;&#125;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JNI</tag>
        <tag>Java Native Interface</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM虚拟机入门]]></title>
    <url>%2F2020%2F03%2F12%2FJVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[JVM简介 JVM是JavaVirtualMachine（Java虚拟机）的缩写，JVM是一种用于计算设备的规范，它是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。Java语言的一个非常重要的特点就是与平台的无关性。而使用Java虚拟机是实现这一特点的关键。一般的高级语言如果要在不同的平台上运行，至少需要编译成不同的目标代码。而引入Java语言虚拟机后，Java语言在不同平台上运行时不需要重新编译。Java语言使用Java虚拟机屏蔽了与具体平台相关的信息，使得Java语言编译程序只需生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。Java虚拟机在执行字节码时，把字节码解释成具体平台上的机器指令执行。这就是Java的能够“一次编译，到处运行”的原因。 JRE/JDK/JVM是什么关系？ JRE(JavaRuntimeEnvironment，Java运行环境)，也就是Java平台。所有的Java 程序都要在JRE下才能运行。普通用户只需要运行已开发好的java程序，安装JRE即可。JDK(Java Development Kit)是程序开发者用来来编译、调试java程序用的开发工具包。JDK的工具也是Java程序，也需要JRE才能运行。为了保持JDK的独立性和完整性，在JDK的安装过程中，JRE也是 安装的一部分。所以，在JDK的安装目录下有一个名为jre的目录，用于存放JRE文件。 JVM(JavaVirtualMachine，Java虚拟机)是JRE的一部分。它是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。JVM有自己完善的硬件架构，如处理器、堆栈、寄存器等，还具有相应的指令系统。Java语言最重要的特点就是跨平台运行。使用JVM就是为了支持与操作系统无关，实现跨平台。 其他虚拟机通用平台的虚拟机Classic VMJDK1 与 JDK2 的官方默认虚拟机，世界第一种 java 虚拟机通过纯解释器执行 Java 代码，即时编译器只能通过外挂的形式存在，并且不能与解释器一起运行。（那个时候的 Java 很慢） Exact VMSun 公司为了解决 Classic VM 的效率问题而计划研发的，但只在 Solaris 系统上发布过，后来就被 HotSpot 取代了因其使用准确式内存管理而闻名。（知道内存中某一块区域存放的是哪一种数据结构，有利于垃圾收集） HotSpotJDK3 之后的官方默认虚拟机同样有准确式内存管理因其热点探测技术而闻名。（知道哪一段代码经常执行，将其编译成机器代码，提高运行效率） JRockitBEA 公司研发的，对服务端高度优化的虚拟机其垃圾收集机制和 MissionControl 服务套件，一直处于 Java 虚拟机的领先水平Oracle 在 2008 年收购 BEA 公司，在 2009 年收购 Sun 公司。Oracle 计划从 JDK8 开始将两种虚拟机融合成一种。（JDK8 的 HotSpot 已经放弃用永久代来实现方法区，转而使用元空间） J9IBM 公司研发，主要为了在自家研发的产品上跑 Java 程序 其他虚拟机Dalvik VMGoogle 为 Android 开发而研发的虚拟机，不是 java 虚拟机，但关系很密切Dalvik VM 基于寄存器运行，而 JVM 基于栈Dalvik 通过将 class 文件转化为 dex 文件来运行 Microsoft JVM微软曾经在其操作系统上开发了一款 win 专用的 JVM （Win 平台下最快的虚拟机），后和 Sun 打官司输掉，该项目停止。 Apache HarmonyApache 开发的 JDK，但一直没有得到 Sun 公司的授权，Apache 因此退出了 JCP后 Sun 公司开源了 OpenJDK，Apache Harmony 项目就变得不太热门64 位虚拟机因为指针膨胀和数据对齐补白等缘故，64 位虚拟机比 32 位虚拟机所需要消耗的内存更大 （约多 10% - 30% 的开销，性能相差 15%）现在大多数商用系统都是通过虚拟集群的方式来支持大于 4G 的内存。64 位的虚拟机还有一段路要走]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JWT入门]]></title>
    <url>%2F2020%2F03%2F12%2FJWT%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[基于token的鉴权机制基于token的鉴权机制类似于http协议也是无状态的，它不需要在服务端去保留用户的认证信息或者会话信息。这就意味着基于token认证机制的应用不需要去考虑用户在哪一台服务器登录了，这就为应用的扩展提供了便利。 流程上是这样的： 用户使用用户名密码来请求服务器 服务器进行验证用户的信息 服务器通过验证发送给用户一个token 客户端存储token，并在每次请求时附送上这个token值 服务端验证token值，并返回数据 这个token必须要在每次请求时传递给服务端，它应该保存在请求头里， 另外，服务端要支持CORS(跨来源资源共享)策略，一般我们在服务端这么做就可以了Access-Control-Allow-Origin: *。 JWT的构成第一部分我们称它为头部（header),第二部分我们称其为载荷（payload, 类似于飞机上承载的物品)，第三部分是签证（signature). headerjwt的头部承载两部分信息： 声明类型，这里是jwt 声明加密的算法 通常直接使用 HMAC SHA256 完整的头部就像下面这样的JSON： 1234&#123; 'typ': 'JWT', 'alg': 'HS256'&#125; 然后将头部进行base64加密（该加密是可以对称解密的),构成了第一部分. 1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9 playload载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分 标准中注册的声明 公共的声明 私有的声明 标准中注册的声明 (建议但不强制使用) ： iss: jwt签发者 sub: jwt所面向的用户 aud: 接收jwt的一方 exp: jwt的过期时间，这个过期时间必须要大于签发时间 nbf: 定义在什么时间之前，该jwt都是不可用的. iat: jwt的签发时间 jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。 公共的声明 ： 公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密. 私有的声明 ： 私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。 定义一个payload: 12345&#123; "sub": "1234567890", "name": "John Doe", "admin": true&#125; 然后将其进行base64加密，得到Jwt的第二部分。 1eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9 signaturejwt的第三部分是一个签证信息，这个签证信息由三部分组成： header (base64后的) payload (base64后的) secret 这个部分需要base64加密后的header和base64加密后的payload使用.连接组成的字符串，然后通过header中声明的加密方式进行加盐secret组合加密，然后就构成了jwt的第三部分。 1234// javascriptvar encodedString = base64UrlEncode(header) + '.' + base64UrlEncode(payload);var signature = HMACSHA256(encodedString, 'secret'); // TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ 将这三部分用.连接成一个完整的字符串,构成了最终的jwt: 1eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ 注意：secret是保存在服务器端的，jwt的签发生成也是在服务器端的，secret就是用来进行jwt的签发和jwt的验证，所以，它就是你服务端的私钥，在任何场景都不应该流露出去。一旦客户端得知这个secret, 那就意味着客户端是可以自我签发jwt了。 java演示首先导入maven坐标 12345&lt;dependency&gt; &lt;groupId&gt;com.auth0&lt;/groupId&gt; &lt;artifactId&gt;java-jwt&lt;/artifactId&gt; &lt;version&gt;3.10.3&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package jwt;import com.auth0.jwt.JWT;import com.auth0.jwt.JWTVerifier;import com.auth0.jwt.algorithms.Algorithm;import com.auth0.jwt.interfaces.DecodedJWT;import java.util.Date;import java.util.HashMap;import java.util.Map;import java.util.concurrent.TimeUnit;/** * @author yang * @date 2020/5/17 21:55 */public class JWTDemo &#123; public static void main(String[] args) throws InterruptedException &#123; String uid="135466"; for (int i = 0; i &lt; 10; i++) &#123; TimeUnit.SECONDS.sleep(1); String token = JWTUtil.getToken(Long.parseLong(uid)); System.out.println("第"+i+"次"+token+"解密结果"+JWTUtil.verify(token)); &#125; &#125;&#125;class JWTUtil&#123; private static final long expireTime = 16;//过期时间 private static final String tokenPassowrd = "mima";//私钥 public static String getToken(Long uid)&#123; Date date=new Date(System.currentTimeMillis()+expireTime); Algorithm algorithm = Algorithm.HMAC256(tokenPassowrd); // 设置头部信息 Map&lt;String,Object&gt; header=new HashMap&lt;&gt;(); header.put("Type", "jwt"); header.put("alg","hm265"); return JWT.create().withHeader(header). withClaim("userId",uid).//负载 withExpiresAt(date).//设置过期时间 sign(algorithm); &#125; public static long verify(String token)&#123; try &#123; Algorithm algorithm = Algorithm.HMAC256(tokenPassowrd); JWTVerifier build = JWT.require(algorithm).build(); DecodedJWT verify = build.verify(token); Date expiresAt = verify.getExpiresAt(); System.out.println(expiresAt.toString()); return verify.getClaim("userId").asLong(); &#125;catch (Exception e)&#123; return 0l; &#125; &#125;&#125; 非对称加密RSA介绍 如果使用私钥加密，持有私钥或者公钥才可以解密 如果使用公钥加密，持有私钥才能解密。 如果在分布式系统中，我们令牌生成服务器必须使用私钥加密，因为如果我们采用了公钥加密，也就是说其他服务器使用的是公钥解密，并且其他服务器使用私钥再次加密，也能通过token服务器的验证因为（私钥加密公钥也可以解密）]]></content>
      <tags>
        <tag>JWT</tag>
        <tag>token</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx入门]]></title>
    <url>%2F2020%2F03%2F11%2Fnginx%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[nginx入门简介 ginx (engine x) 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。Nginx是由伊戈尔·赛索耶夫为俄罗斯访问量第二的Rambler.ru站点（俄文：Рамблер）开发的，第一个公开版本0.1.0发布于2004年10月4日。 其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。 三大功能反向代理什么是代理，和什么是反向代理正向代理加假如 你需要访问谷歌，但是你不能直接访问，需要借助翻墙软件，那么这种行为就是正向代理，即用户—&gt;访问翻墙的服务器(代理服务器)—-&gt;谷歌. 需要明确的是，这种代理服务器带你你访问的方法是由用户主动发起的，对于谷歌来说，他并不能直接知道你，也就是说谷歌对于用户来说是透明的（这里有点不恰当，能大概理解意思即可），但是用户对于谷歌来说谷歌并不知道用户是否使用了代理服务器 反向代理反向代理和正向代理恰好相反，即代理由用户主动变成了谷歌主动。反向代理服务器位于用户与目标服务器之间，但是对于用户而言，反向代理服务器就相当于目标服务器，即用户直接访问反向代理服务器就可以获得目标服务器的资源。同时，用户不需要知道目标服务器的地址，也无须在用户端作任何设定。反向代理服务器通常可用来作为Web加速，即使用反向代理作为Web服务器的前置机来降低网络和服务器的负载，提高访问效率。 负载均衡负载均衡：多在高并发情况下需要使用。其原理就是将数据流量分摊到多个服务器执行，减轻每台服务器的压力，多台服务器(集群)共同完成工作任务，从而提高了数据的吞吐量。 Nginx可使用的负载均衡策略有：轮询（默认）、权重、ip_hash、url_hash(第三方)、fair(第三方)。 动静分离 常用于前后端分离，Nginx提供的动静分离是指把动态请求和静态请求分离开，合适的服务器处理相应的请求，使整个服务器系统的性能、效率更高。 Nginx可以根据配置对不同的请求做不同转发，这是动态分离的基础。静态请求对应的静态资源可以直接放在Nginx上做缓冲，更好的做法是放在相应的缓冲服务器上。动态请求由相应的后端服务器处理。 配置文件详解nginx 文件结构123456789101112131415161718192021222324252627... #全局块events &#123; #events块 ...&#125;http #http块&#123; ... #http全局块 server #server块 &#123; ... #server全局块 location [PATTERN] #location块 &#123; ... &#125; location [PATTERN] &#123; ... &#125; &#125; server &#123; ... &#125; ... #http全局块&#125; 1、全局块：配置影响nginx全局的指令。一般有运行nginx服务器的用户组，nginx进程pid存放路径，日志存放路径，配置文件引入，允许生成worker process数等。 2、events块：配置影响nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等。 3、http块：可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，连接超时时间，单连接请求数等。 4、server块：配置虚拟主机的相关参数，一个http中可以有多个server。 5、location块：配置请求的路由，以及各种页面的处理情况。 配置举例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330#定义Nginx运行的用户和用户组user www www;#nginx进程数，建议设置为等于CPU总核心数。worker_processes 8; #全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]error_log /usr/local/nginx/logs/error.log info;#进程pid文件pid /usr/local/nginx/logs/nginx.pid;#指定进程可以打开的最大描述符：数目#工作模式与连接数上限#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。#现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。worker_rlimit_nofile 65535;events&#123; #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型 #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。 #补充说明： #与apache相类，nginx针对不同的操作系统，有不同的事件模型 #A）标准事件模型 #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll #B）高效事件模型 #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。 #Epoll：使用于Linux内核2.6版本及以后的系统。 #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。 #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。 use epoll; #单个进程最大连接数（最大连接数=连接数*进程数） #根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cpu跑到100%就行。每个进程允许的最多连接数，理论上每台nginx服务器的最大连接数为。 worker_connections 65535; #keepalive超时时间。 keepalive_timeout 60; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。 #分页大小可以用命令getconf PAGESIZE 取得。 #[root@web001 ~]# getconf PAGESIZE #4096 #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。 client_header_buffer_size 4k; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。 open_file_cache max=65535 inactive=60s; #这个是指多长时间检查一次缓存的有效信息。 #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息. open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。 #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态. open_file_cache_min_uses 1; #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误. open_file_cache_errors on;&#125; #设定http服务器，利用它的反向代理功能提供负载均衡支持http&#123; #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #默认编码 #charset utf-8; #服务器名字的hash表大小 #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小. server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。 client_header_buffer_size 32k; #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。 large_client_header_buffers 4 64k; #设定通过nginx上传文件的大小 client_max_body_size 8m; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。 sendfile on; #开启目录列表访问，合适下载服务器，默认关闭。 autoindex on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nopush on; tcp_nodelay on; #长连接超时时间，单位是秒 keepalive_timeout 120; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩等级 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。 gzip_vary on; #开启限制IP连接数的时候需要使用 #limit_zone crawler $binary_remote_addr 10m; #负载均衡配置 upstream piao.jd.com &#123; #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 server 192.168.80.121:80 weight=3; server 192.168.80.122:80 weight=2; server 192.168.80.123:80 weight=3; #nginx的upstream目前支持4种方式的分配 #1、轮询（默认） #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 #2、weight #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 #例如： #upstream bakend &#123; # server 192.168.0.14 weight=10; # server 192.168.0.15 weight=10; #&#125; #2、ip_hash #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 #例如： #upstream bakend &#123; # ip_hash; # server 192.168.0.14:88; # server 192.168.0.15:80; #&#125; #3、fair（第三方） #按后端服务器的响应时间来分配请求，响应时间短的优先分配。 #upstream backend &#123; # server server1; # server server2; # fair; #&#125; #4、url_hash（第三方） #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法 #upstream backend &#123; # server squid1:3128; # server squid2:3128; # hash $request_uri; # hash_method crc32; #&#125; #tips: #upstream bakend&#123;#定义负载均衡设备的Ip及设备状态&#125;&#123; # ip_hash; # server 127.0.0.1:9090 down; # server 127.0.0.1:8080 weight=2; # server 127.0.0.1:6060; # server 127.0.0.1:7070 backup; #&#125; #在需要使用负载均衡的server中增加 proxy_pass http://bakend/; #每个设备的状态设置为: #1.down表示单前的server暂时不参与负载 #2.weight为weight越大，负载的权重就越大。 #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误 #4.fail_timeout:max_fails次失败后，暂停的时间。 #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。 #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug #client_body_temp_path设置记录文件的目录 可以设置最多3层目录 #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡 &#125; #虚拟主机的配置 server &#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name www.jd.com jd.com; index index.html index.htm index.php; root /data/www/jd; #对******进行负载均衡 location ~ .*.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; #图片缓存时间设置 location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; #JS和CSS缓存时间设置 location ~ .*.(js|css)?$ &#123; expires 1h; &#125; #日志格式设定 #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址； #$remote_user：用来记录客户端用户名称； #$time_local： 用来记录访问时间与时区； #$request： 用来记录请求的url与http协议； #$status： 用来记录请求状态；成功是200， #$body_bytes_sent ：记录发送给客户端文件主体内容大小； #$http_referer：用来记录从那个页面链接访问过来的； #$http_user_agent：记录客户浏览器的相关信息； #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。 #反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。 log_format access &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; $http_x_forwarded_for&apos;; #定义本虚拟主机的访问日志 access_log /usr/local/nginx/logs/host.access.log main; access_log /usr/local/nginx/logs/host.access.404.log log404; #对 &quot;/&quot; 启用反向代理 location / &#123; proxy_pass http://127.0.0.1:88; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。 proxy_set_header Host $host; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数， #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。 #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误 client_body_buffer_size 128k; #表示使nginx阻止HTTP应答代码为400或者更高的应答。 proxy_intercept_errors on; #后端服务器连接的超时时间_发起握手等候响应超时时间 #nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 90; #后端服务器数据回传时间(代理发送超时) #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据 proxy_send_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_read_timeout 90; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小 proxy_buffer_size 4k; #proxy_buffers缓冲区，网页平均在32k以下的设置 #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长 #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k; &#125; #设定查看Nginx状态的地址 location /NginxStatus &#123; stub_status on; access_log on; auth_basic &quot;NginxStatus&quot;; auth_basic_user_file confpasswd; #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。 &#125; #本地动静分离反向代理配置 #所有jsp的页面均交由tomcat或resin处理 location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; &#125; #所有静态文件由nginx直接读取不经过tomcat或resin location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt| pdf|xls|mp3|wma)$ &#123; expires 15d; &#125; location ~ .*.(js|css)?$ &#123; expires 1h; &#125; &#125;&#125;]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>数据库</tag>
        <tag>分页</tag>
        <tag>WEB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis入门]]></title>
    <url>%2F2020%2F03%2F11%2FRedis%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Redis简介 REmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。 Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Hash), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。 BSD协议 BSD开源协议是一个给于使用者很大自由的协议。可以自由的使用，修改源代码，也可以将修改后的代码作为开源或者专有软件再发布。当你发布使用了BSD协议的代码，或者以BSD协议代码为基础做二次开发自己的产品时，需要满足三个条件： 如果再发布的产品中包含源代码，则在源代码中必须带有原来代码中的BSD协议。 如果再发布的只是二进制类库/软件，则需要在类库/软件的文档和版权声明中包含原来代码中的BSD协议。 不可以用开源代码的作者/机构名字和原来产品的名字做市场推广。 BSD代码鼓励代码共享，但需要尊重代码作者的著作权。BSD由于允许使用者修改和重新发布代码，也允许使用或在BSD代码上开发商业软件发布和销 售，因此是对商业集成很友好的协议。 很多的公司企业在选用开源产品的时候都首选BSD协议，因为可以完全控制这些第三方的代码，在必要的时候可以修改或者 二次开发。 非关系型数据库什么是数据库？ 数据库是数据的仓库。 与普通的“数据仓库”不同的是，数据库依据“数据结构”来组织数据，因为“数据结构”，所以我们看到的数据是比较“条理化”的（比如不会跟以前的普通文件存储式存储成一个文件那么不条理化，我们的数据库分成一个个库，分成一个个表，分成一条条记录，这些记录是多么分明） 也因为其“数据结构”式，所以有极高的查找速率（比如B-Tree查找法），（由于专精，可以根据自己的结构特性来快速查找，所以对于数据库的查找会比较快捷；不像普通文件系统的“查找”那么通用） 如果与EXCEL来比的话，能明显的看出数据库的好处，我们能给一个个“字段”添加“约束”（比如约束一列的值不能为空） 数据库与普通的文件系统的主要区别（起因）：数据库能快速查找对应的数据 常说的XX数据库，其实实质上是XX数据库管理系统。数据库管理系统是一个软件，是数据库管理的程序实现。 什么是关系型数据库？ 关系型数据库是依据关系模型来创建的数据库。 所谓关系模型就是“一对一、一对多、多对多”等关系模型，关系模型就是指二维表格模型,因而一个关系型数据库就是由二维表及其之间的联系组成的一个数据组织。 关系型数据可以很好地存储一些关系模型的数据，比如一个老师对应多个学生的数据（“多对多”），一本书对应多个作者（“一对多”），一本书对应一个出版日期（“一对一”） 关系模型是我们生活中能经常遇见的模型，存储这类数据一般用关系型数据库 关系模型包括数据结构（数据存储的问题，二维表）、操作指令集合（SQL语句）、完整性约束(表内数据约束、表与表之间的约束)。 NOSQL的意思是not-only sql,不仅仅是sql 性能官方的bench-mark数据： 测试完成了50个并发执行100000个请求。 设置和获取的值是一个256字节字符串。 Linux box是运行Linux 2.6,这是X3320 Xeon 2.5 ghz。 文本执行使用loopback接口(127.0.0.1)。 结果:读的速度是110000次/s,写的速度是81000次/s 线程问题redis是单线程，线程安全 redis可以能够快速执行的原因： 绝大部分请求是纯粹的内存操作（非常快速） 采用单线程,避免了不必要的上下文切换和竞争条件 非阻塞IO - IO多路复用 redis的性能瓶颈不是CPU而是内存 IO多路复用中有三种方式：select,poll,epoll。需要注意的是，select,poll是线程不安全的，epoll是线程安全的 redis内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间 这3个条件不是相互独立的，特别是第一条，如果请求都是耗时的，采用单线程吞吐量及性能可想而知了。应该说redis为特殊的场景选择了合适的技术方案。 数据类型字符串、哈希、列表、集合、有序集合 类型 简介 特性 场景 String(字符串) 二进制安全 可以包含任何数据,比如jpg图片或者序列化的对象,一个键最大能存储512M — Hash(字典) 键值对集合,即编程语言中的Map类型 适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去) 存储、读取、修改用户属性 List(列表) 链表(双向链表) 增删快,提供了操作某一段元素的API 1,最新消息排行等功能(比如朋友圈的时间线) 2,消息队列 Set(集合) 哈希表实现,元素不重复 1、添加、删除,查找的复杂度都是O(1) 2、为集合提供了求交集、并集、差集等操作 1、共同好友 2、利用唯一性,统计访问网站的所有独立ip 3、好友推荐时,根据tag求交集,大于某个阈值就可以推荐 Sorted Set(有序集合) 将Set中的元素增加一个权重参数score,元素按score有序排列 数据插入集合时,已经进行天然排序 1、排行榜 2、带权重的消息队列 String（字符串）key-Stringstring 是 redis 最基本的类型，你可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value。 string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如jpg图片或者序列化的对象。 string 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB。 实例1234redis 127.0.0.1:6379&gt; SET runoob "Hello World!"OKredis 127.0.0.1:6379&gt; GET runoob"Hello World!" 在以上实例中我们使用了 Redis 的 SET 和 GET 命令。键为 runoob，对应的值为 菜鸟教程。 注意：一个键最大能存储 512MB。 Hash（哈希）key-mapRedis hash 是一个键值(key=&gt;value)对集合。 Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。 实例DEL runoob 用于删除前面测试用过的 key，不然会报错：(error) WRONGTYPE Operation against a key holding the wrong kind of value 1234567redis 127.0.0.1:6379&gt; DEL runoobredis 127.0.0.1:6379&gt; HMSET runoob field1 "Hello" field2 "World""OK"redis 127.0.0.1:6379&gt; HGET runoob field1"Hello"redis 127.0.0.1:6379&gt; HGET runoob field2"World" 实例中我们使用了 Redis HMSET, HGET 命令，HMSET 设置了两个 field=&gt;value 对, HGET 获取对应 field 对应的 value。 每个 hash 可以存储 232 List（列表）key-listRedis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。 实例123456789101112redis 127.0.0.1:6379&gt; DEL runoobredis 127.0.0.1:6379&gt; lpush runoob redis(integer) 1redis 127.0.0.1:6379&gt; lpush runoob mongodb(integer) 2redis 127.0.0.1:6379&gt; lpush runoob rabitmq(integer) 3redis 127.0.0.1:6379&gt; lrange runoob 0 101) "rabitmq"2) "mongodb"3) "redis"redis 127.0.0.1:6379&gt; 列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)。 Set（集合）key-setRedis 的 Set 是 string 类型的无序集合。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。 sadd 命令添加一个 string 元素到 key 对应的 set 集合中，成功返回 1，如果元素已经在集合中返回 0。 1sadd key member 实例1234567891011121314redis 127.0.0.1:6379&gt; DEL runoobredis 127.0.0.1:6379&gt; sadd runoob redis(integer) 1redis 127.0.0.1:6379&gt; sadd runoob mongodb(integer) 1redis 127.0.0.1:6379&gt; sadd runoob rabitmq(integer) 1redis 127.0.0.1:6379&gt; sadd runoob rabitmq(integer) 0redis 127.0.0.1:6379&gt; smembers runoob1) "redis"2) "rabitmq"3) "mongodb" 注意：以上实例中 rabitmq 添加了两次，但根据集合内元素的唯一性，第二次插入的元素将被忽略。 集合中最大的成员数为 232 - 1(4294967295, 每个集合可存储40多亿个成员)。 zset(sorted set：有序集合)Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。 zset的成员是唯一的,但分数(score)却可以重复。 zadd 命令添加元素到集合，元素在集合中存在则更新对应score 1zadd key score member 实例12345678910111213redis 127.0.0.1:6379&gt; DEL runoobredis 127.0.0.1:6379&gt; zadd runoob 0 redis(integer) 1redis 127.0.0.1:6379&gt; zadd runoob 0 mongodb(integer) 1redis 127.0.0.1:6379&gt; zadd runoob 0 rabitmq(integer) 1redis 127.0.0.1:6379&gt; zadd runoob 0 rabitmq(integer) 0redis 127.0.0.1:6379&gt; &gt; ZRANGEBYSCORE runoob 0 10001) "mongodb"2) "rabitmq"3) "redis" GEO地理位置支持（geospatial）3.2版本里面新增的一个功能就是对GEO(地理位置)的支持 有效的经度从-180度到180度。 有效的纬度从-85.05112878度到85.05112878度。 命令命令：GEOADD key longitude latitude member [longitude latitude member …] 命令描述：将指定的地理空间位置（经度、纬度度、名称）添加到指定的key中。 返回值：添加到sorted set元素的数目，但不包括已更新score的元素。 命令：GEODIST key member1 member2 [unit] 命令描述： 返回两个给定位置之间的距离。如果两个位置之间的其中一个不存在， 那么命令返回空值。指定单位的参数 unit 必须是以下单位的其中一个： m 表示单位为米。 km 表示单位为千米。 mi 表示单位为英里。 ft 表示单位为英尺。 命令：GEOPOS key member [member …] 命令描述：从key里返回所有给定位置元素的位置（经度和纬度）。 返回值：GEOPOS 命令返回一个数组， 数组中的每个项都由两个元素组成： 第一个元素为给定位置元素的经度， 而第二个元素则为给定位置元素的纬度。当给定的位置元素不存在时， 对应的数组项为空值。 命令：GEOHASH key member [member …] 命令描述：返回一个或多个位置元素的 Geohash 表示。通常使用表示位置的元素使用不同的技术，使用Geohash位置52点整数编码。由于编码和解码过程中所使用的初始最小和最大坐标不同，编码的编码也不同于标准。此命令返回一个标准的Geohash 返回值：一个数组， 数组的每个项都是一个 geohash 。 命令返回的 geohash 的位置与用户给定的位置元素的位置一一对应。 命令：GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] 命令描述： 以给定的经纬度为中心， 返回键包含的位置元素当中， 与中心的距离不超过给定最大距离的所有位置元素。 范围可以使用以下其中一个单位： m 表示单位为米。 km 表示单位为千米。 mi 表示单位为英里。 ft 表示单位为英尺。 在给定以下可选项时， 命令会返回额外的信息： WITHDIST: 在返回位置元素的同时， 将位置元素与中心之间的距离也一并返回。 距离的单位和用户给定的范围单位保持一致。 WITHCOORD: 将位置元素的经度和维度也一并返回。 WITHHASH: 以 52 位有符号整数的形式， 返回位置元素经过原始 geohash 编码的有序集合分值。 这个选项主要用于底层应用或者调试， 实际中的作用并不大。 命令默认返回未排序的位置元素。 通过以下两个参数， 用户可以指定被返回位置元素的排序方式： ASC: 根据中心的位置， 按照从近到远的方式返回位置元素。 DESC: 根据中心的位置， 按照从远到近的方式返回位置元素。 在默认情况下， GEORADIUS 命令会返回所有匹配的位置元素。 虽然用户可以使用 COUNT `` 选项去获取前 N 个匹配元素， 但是因为命令在内部可能会需要对所有被匹配的元素进行处理， 所以在对一个非常大的区域进行搜索时， 即使只使用 COUNT 选项去获取少量元素， 命令的执行速度也可能会非常慢。 但是从另一方面来说， 使用 COUNT 选项去减少需要返回的元素数量， 对于减少带宽来说仍然是非常有用的。 返回值： 在没有给定任何 WITH 选项的情况下， 命令只会返回一个像 [“New York”,”Milan”,”Paris”] 这样的线性（linear）列表。 在指定了 WITHCOORD 、 WITHDIST 、 WITHHASH 等选项的情况下， 命令返回一个二层嵌套数组， 内层的每个子数组就表示一个元素。 在返回嵌套数组时， 子数组的第一个元素总是位置元素的名字。 至于额外的信息， 则会作为子数组的后续元素， 按照以下顺序被返回： 以浮点数格式返回的中心与位置元素之间的距离， 单位与用户指定范围时的单位一致。 geohash 整数。 由两个元素组成的坐标，分别为经度和纬度。 命令：GEORADIUSBYMEMBER key member radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] 命令描述：这个命令和 GEORADIUS 命令一样， 都可以找出位于指定范围内的元素， 但是 GEORADIUSBYMEMBER 的中心点是由给定的位置元素决定的。 HyperLogLong使用场景统计网页访问量。 解决方案方案一如果使用set来统计访问量的话，假设通过set存储ip来确定访问量，一个ipv4占用4个字节，那么1000万访问量就占用了4*1000_0000字节=30.81mb左右，那么这还只是一篇文章的访问量统计，如果有100篇呢？，而且ipv4我们假设的是使用直接存储的方式，如果我们使用字符串来存储，那么一个Ipv4在ASCII下占用12个字节。 所以内存开销太大，不推荐使用 方案二redis 2.8.6 版本之后，新的命令功能，HyperLogLog。 Redis 提供了 HyperLogLog 数据结构就是用来解决这种统计问题的。HyperLogLog 提供不精确的去重计数方案，虽然不精确但是也不是非常不精确，标准误差是 0.81%，这样的精确度已经可以满足上面的 UV 统计需求了。 基本概念Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。 在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存(因为 Redis 对 HyperLogLog 的存储进行了优化，在计数比较小时，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩阵，才会占用 12k 的空间。)，就可以计算接近 2^64 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。 但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 基本命令PFADD key element [element …]，添加到HyperLogLog结构中时间复杂度：O(1) to add every element. 12345redis&gt; PFADD hll a b c d e f g(integer) 1redis&gt; PFCOUNT hll(integer) 7redis&gt; PFCOUNT key [key …]统计hyperLogLog中不重复元素的个数PFMERGE destkey sourcekey [sourcekey …]和并多个hyperLogLog123456789redis&gt; PFADD hll1 foo bar zap a(integer) 1redis&gt; PFADD hll2 a b c foo(integer) 1redis&gt; PFMERGE hll3 hll1 hll2OKredis&gt; PFCOUNT hll3(integer) 6redis&gt; bitmapBitMap是什么就是通过一个bit位来表示某个元素对应的值或者状态,其中的key就是对应元素本身。我们知道8个bit可以组成一个Byte，所以bitmap本身会极大的节省储存空间。 Redis中的BitMapRedis从2.2.0版本开始新增了setbit,getbit,bitcount等几个bitmap相关命令。虽然是新命令，但是并没有新增新的数据类型，因为setbit等命令只不过是在set上的扩展。 使用场景使用 bitmap 实现用户上线次数统计假设现在我们希望记录自己网站上的用户的上线频率，比如说，计算用户 A 上线了多少天，用户 B 上线了多少天，诸如此类，以此作为数据，从而决定让哪些用户参加 beta 测试等活动 —— 这个模式可以使用SETBIT和 BITCOUNT 来实现。 比如说，每当用户在某一天上线的时候，我们就使用 SETBIT ，以用户名作为 key ，将那天所代表的网站的上线日作为 offset 参数，并将这个 offset 上的为设置为 1 。 举个例子，如果今天是网站上线的第 100 天，而用户 peter 在今天阅览过网站，那么执行命令 SETBIT peter 100 1 ；如果明天 peter 也继续阅览网站，那么执行命令 SETBIT peter 101 1 ，以此类推。 当要计算 peter 总共以来的上线次数时，就使用 BITCOUNT 命令：执行 BITCOUNT peter ，得出的结果就是 peter 上线的总天数。 假设现在我们希望记录自己网站上的用户的上线频率，比如说，计算用户 A 上线了多少天，用户 B 上线了多少天，诸如此类，以此作为数据，从而决定让哪些用户参加 beta 测试等活动 —— 这个模式可以使用 SETBIT 和 BITCOUNT 来实现。 比如说，每当用户在某一天上线的时候，我们就使用 SETBIT ，以用户名作为 key ，将那天所代表的网站的上线日作为 offset 参数，并将这个 offset 上的为设置为 1 。 举个例子，如果今天是网站上线的第 100 天，而用户 peter 在今天阅览过网站，那么执行命令 SETBIT peter 100 1 ；如果明天 peter 也继续阅览网站，那么执行命令 SETBIT peter 101 1 ，以此类推。 当要计算 peter 总共以来的上线次数时，就使用 BITCOUNT 命令：执行 BITCOUNT peter ，得出的结果就是 peter 上线的总天数。 常用命令SETBIT key offset value时间复杂度：O(1) 设置或者清空key的value(字符串)在offset处的bit值。 1234567redis&gt; SETBIT mykey 7 1(integer) 0redis&gt; SETBIT mykey 7 0(integer) 1redis&gt; GET mykey"\x00"redis&gt; BITCOUNT key [start end]时间复杂度：O(N) 统计字符串被设置为1的bit数. 123456789redis&gt; SET mykey "foobar"OKredis&gt; BITCOUNT mykey(integer) 26redis&gt; BITCOUNT mykey 0 0(integer) 4redis&gt; BITCOUNT mykey 1 1(integer) 6redis&gt; GETBIT key offset时间复杂度：O(1) 返回key对应的string在offset处的bit值 当offset超出了字符串长度的时候，这个字符串就被假定为由0比特填充的连续空间。当key不存在的时候，它就认为是一个空字符串，所以offset总是超出范围，然后value也被认为是由0比特填充的连续空间。到内存分配。 123456789redis&gt; SETBIT mykey 7 1(integer) 0redis&gt; GETBIT mykey 0(integer) 0redis&gt; GETBIT mykey 7(integer) 1redis&gt; GETBIT mykey 100(integer) 0redis&gt;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>数据库</tag>
        <tag>Redis</tag>
        <tag>非关系型数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis常用命令]]></title>
    <url>%2F2020%2F03%2F09%2FRedis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Redis 常用命令登录 redis-cli -p 5566 -a password检查key是否存在 EXISTS key搜索某关键字 KSYS *4返回一个Key所影响的vsl的类型 TYPE key Stringset key value ：给数据库中名称为key的string赋予值value get key ：返回数据库中名称为key的string的value getset key value ：给名称为key的string赋予上一次的value mget key1 key2,… key N ：返回库中多个string的value setnx key value ：添加string，名称为key，值为value setex key time value ：向库中添加string，设定过期时间time mset key N value N ：批量设置多个string的值 msetnx key N value N ：如果所有名称为key i的string都不存在 incr key ：名称为key的string增1操作 incrby key integer ：名称为key的string增加integer decr key ：名称为key的string减1操作 decrby key integer ：名称为key的string减少integer append key value ：名称为key的string的值附加value substr key start end ：返回名称为key的string的value的子串 Hashhset key field value ：向名称为key的hash中添加元素field hget key field ：返回名称为key的hash中field对应的value hmget key fields ：返回名称为key的hash中field i对应的value hmset key fields ：向名称为key的hash中添加元素field hincrby key field integer ：将名称为key的hash中field的value增加integer hexists key field ：名称为key的hash中是否存在键为field的域 hdel key field ：删除名称为key的hash中键为field的域 hlen key ：返回名称为key的hash中元素个数 hkeys key ：返回名称为key的hash中所有键 hvals key ：返回名称为key的hash中所有键对应的value hgetall key ：返回名称为key的hash中所有的键（field）及其对应的value Listrpush key value ：在名称为key的list尾添加一个值为value的元素 lpush key value ：在名称为key的list头添加一个值为value的 元素和push命令一个作用 llen key ：返回名称为key的list的长度 lrange key start end ：返回名称为key的list中start至end之间的元素 ltrim key start end ：截取名称为key的list lindex key index ：返回名称为key的list中index位置的元素 lset key index value ：给名称为key的list中index位置的元素赋值 lrem key count value ：删除count个key的list中值为value的元素 lpop key ：返回并删除名称为key的list中的首元素 rpop key ：返回并删除名称为key的list中的尾元素 blpop key1 key2,… key N timeout ：lpop命令的block版本。 brpop key1 key2,… key N timeout ：rpop的block版本。 rpoplpush srckey dstkey ：返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部 setsadd key member ：向名称为key的set中添加元素member srem key member ：删除名称为key的set中的元素member spop key ：随机返回并删除名称为key的set中一个元素 smove srckey dstkey member ：移到集合元素 scard key ：返回名称为key的set的基数 sismember key member ：member是否是名称为key的set的元素 sinter key1 key2,…key N ：求交集 sinterstore dstkey keys ：求交集并将交集保存到dstkey的集合 sunion key1 keys ：求并集 sunionstore dstkey keys ：求并集并将并集保存到dstkey的集合 sdiff key1 keys ：求差集 sdiffstore dstkey keys ：求差集并将差集保存到dstkey的集合 smembers key ：返回名称为key的set的所有元素 srandmember key ：随机返回名称为key的set的一个元素 对value操作exists key ：确认一个key是否存在 del key ：删除一个key type key ：返回值的类型 keys pattern ：返回满足给定pattern的所有key randomkey：随机返回key空间的一个 keyrename oldname newname ：重命名key dbsize：返回当前数据库中key的数目 expire：设定一个key的活动时间（s） ttl：获得一个key的活动时间 select index ：按索引查询 move key dbindex ：移动当前数据库中的key到dbindex数据库 flushdb：删除当前选择数据库中的所有key flushall：删除所有数据库中的所有key]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>数据库</tag>
        <tag>Redis</tag>
        <tag>非关系型数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之组合模式]]></title>
    <url>%2F2020%2F03%2F09%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[组合模式 组合模式也叫合成模式，用来描述部分和整体的关系。组合模式，也是很多人没有听说过的，那就不妨了解一下。其实组合模式就是上级管理下级的关系模式，比如说经理可以管理几个员工，他是有增删改查功能，而经理也是被总经理管理。。。 类型 结构型 适用场景 维护和战士部分-整体的场景，如树形菜单、文件和文件夹管理。 从一个整体中能够独立出部分模块或功能场景。 优点 高层模块调用简单：一颗树形结构中所有节点都是Component，局部和整体对调用者来说没有任何区别，高层模块不必关心自己处理的是单个对象还是整个组合结构。 节点自由增加：容易扩展，想要增加节点只要找到它的父节点就行，符合开闭原则，对后续的维护非常有利。 缺点 使得设计更加复杂。客户端需要花更多时间理清类之间的层次关系。 例子 定义 允许将对象组合成树形结构来表现”整体/部分”层次结构。组合能让客户以一致的方式处理个别对象以及对象组合。 特点 组件接口同时具有叶子节点和父节点的属性，具有2种角色。组合模式以单一责任设计原则换取透明性。 ### 代码实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116import java.util.ArrayList;import java.util.List;/** * 菜单组件，同时具有菜单和菜的角色，菜单可以有子菜单 */abstract class MenuComponent &#123; /* 菜具有的方法 */ // 获取菜名 public String getName() &#123; throw new UnsupportedOperationException(); &#125; // 获取菜价格 public int getPrice() &#123; throw new UnsupportedOperationException(); &#125; /* 菜单具有的方法 */ // 向菜单中添加菜或子菜单 public void add(MenuComponent menuComponent) &#123; throw new UnsupportedOperationException(); &#125; /* 共有方法 */ public void print() &#123; throw new UnsupportedOperationException(); &#125;&#125;// 菜class MenuItem extends MenuComponent &#123; public String name; public int price; public MenuItem(String name, int price) &#123; this.name = name; this.price = price; &#125; @Override public String getName() &#123; return name; &#125; @Override public int getPrice() &#123; return price; &#125; @Override public void print() &#123; System.out.println("菜名: " + name + ": " + price); &#125;&#125;// 菜单class Menu extends MenuComponent &#123; // 用于存储菜名或子菜单 public List&lt;MenuComponent&gt; list = new ArrayList&lt;&gt;(); public String menuName; public Menu(String menuName) &#123; this.menuName = menuName; &#125; @Override public void add(MenuComponent menuComponent) &#123; list.add(menuComponent); &#125; @Override public String getName() &#123; return menuName; &#125; @Override public void print() &#123; System.out.println("菜单名: " + menuName); list.forEach(MenuComponent::print); &#125;&#125;// 客户端演示class Client &#123; public MenuComponent menuComponent; public void setMenuComponent(MenuComponent menuComponent) &#123; this.menuComponent = menuComponent; &#125; public void print() &#123; menuComponent.print(); &#125; public static void main(String[] args) &#123; Menu menu = new Menu("主菜单"); menu.add(new MenuItem("可乐", 3)); menu.add(new MenuItem("炸鸡", 15)); Menu subMenu = new Menu("子菜单"); subMenu.add(new MenuItem("汉堡", 20)); subMenu.add(new MenuItem("薯条", 10)); // 将子菜单加入主菜单 menu.add(subMenu); Client client = new Client(); client.setMenuComponent(menu); // 递归打印 client.print(); &#125;&#125; 总结这样我们就很方便的表示了整体和部分的关系]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>设计模式</tag>
        <tag>结构型</tag>
        <tag>组合模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之代理模式]]></title>
    <url>%2F2020%2F03%2F09%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[代理模式代理(Proxy)是一种设计模式,提供了间接对目标对象进行访问的方式;即通过代理对象访问目标对象.这样做的好处是:可以在目标对象实现的功能上,增加额外的功能补充,即扩展目标对象的功能. 这就符合了设计模式的开闭原则，即在对既有代码不改动的情况下进行功能的扩展。 举个例子来说明代理的作用:明星与经纪人之间就是被代理和代理的关系,明星出演活动的时候，明星就是一个目标对象,他只要负责活动中的节目,而其他琐碎的事情就交给他的代理人(经纪人) 来解决.这就是代理思想在现实中的一个例子。 静态代理在使用静态代理时,被代理对象与代理对象需要一起实现相同的接口或者是继承相同父类，因此要定义一个接口或抽象类. 12345678910111213141516171819202122232425262728293031323334353637383940414243// 接口 interface IStar &#123; void sing(); &#125; // 真实对象 class LDHStar implements IStar &#123; @Override public void sing() &#123; System.out.println("刘德华唱歌"); &#125; &#125; // 代理类需要有真实对象的控制权 (引用) class ProxyManger implements IStar &#123; // 真实对象的引用 private IStar star; public ProxyManger() &#123; super(); &#125; public ProxyManger(IStar star) &#123; super(); this.star = star; &#125; @Override public void sing() &#123; System.out.println("唱歌前准备"); star.sing(); System.out.println("善后工作"); &#125; &#125;class Test&#123;public static void main(String[] args) &#123; // 创建明星对象 IStar ldh = new LDHStar(); ProxyManger proxy = new ProxyManger(ldh); proxy.sing(); &#125;&#125; 静态代理总结:优点：可以做到在不修改目标对象的功能前提下,对目标功能扩展.缺点: 因为代理对象需要与目标对象实现一样的接口,所以会有很多代理类,类太多.同时,一旦接口增加方法,目标对象与代理对象都要维护. 而动态代理方式可以解决上面的问题 动态代理动态代理的主要特点就是能够在程序运行时JVM才为被代理对象生成代理对象。 常说的动态代理也叫做JDK代理也是一种接口代理，JDK中生成代理对象的代理类就是Proxy，所在包是java.lang.reflect 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//目标类接口interface IDog&#123; void run();&#125;//目标类class GunDog implements IDog&#123; @Override public void run() &#123; System.out.println("猎狗在跑"); &#125;&#125;class DogUtils&#123; public static void method1() &#123; System.out.println("增强方式一"); &#125; public static void method2() &#123; System.out.println("增强方式二"); &#125;&#125;class MyInvocationHandle implements InvocationHandler&#123; private Object target; public void setTarget(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; DogUtils.method1(); method.invoke(target, args); DogUtils.method2(); return null; &#125;&#125; //生产代理对象的工厂 class MyProxyFactory&#123; public static Object getProxy(Object target) &#123; MyInvocationHandle handle = new MyInvocationHandle(); handle.setTarget(target); Object proxy = Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), handle); return proxy; &#125; &#125;public class ProxyDemo &#123; public static void main(String[] args) &#123; IDog dog = new GunDog(); IDog proxy =(IDog) MyProxyFactory.getProxy(dog); proxy.run(); &#125;&#125; 总结：代理对象不需要实现接口,但是目标对象一定要实现接口,否则不能使用动态代理，因此这也算是这种方式的缺陷。 Cglib代理上面的静态代理和动态代理模式有个相同点就是都要求目标对象是实现一个接口的对象,然而并不是任何对象都会实现一个接口，也存在没有实现任何的接口的对象, 这时就可以使用继承目标类以目标对象子类的方式实现代理,这种方法就叫做:Cglib代理，也叫作子类代理,它是在内存中构建一个子类对象从而实现对目标对象功能的扩展. 使用JDK动态代理有一个限制,就是被代理的对象必须实现一个或多个接口,若想代理没有实现接口的类,就需要使用Cglib实现. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class CglibProxy &#123; public static void main(String[] args) &#123; int[] arr = new int[100000]; for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = (int) (Math.random() * 1000); &#125; //实例化一个增强器，也就是cglib中的一个class generator Enhancer enhancer = new Enhancer(); //设置目标类 enhancer.setSuperclass(ArraySort2.class); //设置拦截对象，这里直接使用匿名内部类写法 enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object object , Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; String sortName = method.getName(); switch (sortName) &#123; case "bubbleSort": sortName = "冒泡排序"; break; case "selectSort": sortName = "选择排序"; break; case "quickSort": sortName = "快速排序"; break; default: break; &#125; long start = System.currentTimeMillis(); //此处一定要使用proxy的invokeSuper方法来调用目标类的方法 proxy.invokeSuper(object, args); long end = System.currentTimeMillis(); System.out.println("本次" + sortName + "的执行时间为: " + (end -start) + "ms"); return null; &#125; &#125;); //生成代理类并返回一个实例 ArraySort2 arraySort = (ArraySort2) enhancer.create(); arraySort.bubbleSort(arr); arraySort.selectSort(arr); arraySort.quickSort(arr); &#125; &#125;class ArraySort2&#123; public void quickSort(int[] arr) &#123; Arrays.sort(arr); &#125; public void selectSort(int[] arr) &#123; for (int i = 0; i &lt; arr.length; i++) &#123; for (int j = i+1; j &lt; arr.length; j++) &#123; if (arr[i] &gt; arr[j]) &#123; int temp = 0; temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125; &#125; &#125; &#125; public void bubbleSort(int[] arr) &#123; for (int i = 0; i &lt; arr.length - 1; i++) &#123; for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123; if (arr[j] &gt; arr[j + 1]) &#123; int temp = 0; temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125; &#125; &#125; &#125;&#125; 总结： 在Spring的AOP编程中: 如果加入容器的目标对象有实现接口,用JDK代理 如果目标对象没有实现接口,用Cglib代理。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>设计模式</tag>
        <tag>代理模式</tag>
        <tag>结构型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之装饰者模式]]></title>
    <url>%2F2020%2F03%2F09%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[装饰者模式定义（动态扩展被装饰者类的功能） 在不改变原有对象的基础之上，将功能附加到对象上。提供了比继承更有弹性的替代方案（扩展原有对象功能） 类型 结构型 适用场景 扩展一个类的功能或者给一个类添加附加职责 给一个对象动态的添加功能，或动态撤销功能。 特点优点 可以动态扩展被装饰类的功能 继承的有力补充，比继承灵活，不改变原有对象的情况下给一个对象扩展功能。（继承在扩展功能是静态的，必须在编译时就确定好，而使用装饰者可以在运行时决定，装饰者也建立在继承的基础之上的） 通过使用不同装饰类以及这些类的排列组合，可以实现不同的效果。 符合开闭原则 缺点 这种比继承更加灵活机动的特性，也同时意味着更加多的复杂性。 装饰模式会导致设计中出现许多小类，如果过度使用，会使程序变得很复杂。 装饰模式是针对抽象组件（Component）类型编程。但是，如果你要针对具体组件编程时，就应该重新思考你的应用架构，以及装饰者是否合适。当然也可以改变Component接口，增加新的公开的行为，实现“半透明”的装饰者模式。在实际项目中要做出最佳选择。 装饰者相关的设计模式 装饰者和代理模式 装饰者模式关注的是对象的动态添加功能。代理模式关注的是对对象的控制访问，对它的用户隐藏对象的具体信息。 装饰者模式和适配器模式 装饰者模式和被装饰的类要实现同一个接口，或者装饰类是被装饰的类的子类。 适配器模式和被适配的类具有不同的接口。 面开始看代码，看代码之前首先假设一个应用场景吧假设我们现在在路边摊看到一个卖煎饼果子的，现在想买煎饼果子，煎饼果子一般的话都是可以加鸡蛋加香肠什么的，好那我们就来模拟一下加在煎饼果子上加东西的操作。 首先我们看一下使用继承的方式怎么实现。 创建一个煎饼果子类 123456789public class Battercake &#123; protected String getDesc()&#123; return "煎饼果子"; &#125; protected int cost()&#123; return 8; &#125;&#125; 加鸡蛋类，我们让加鸡蛋类继承煎饼果子类 1234567891011public class BattercakeWithEgg extends Battercake &#123; @Override public String getDesc() &#123; return super.getDesc()+" 加一个鸡蛋"; &#125; @Override public int cost() &#123; return super.cost()+1; &#125;&#125; 加香肠类，同样的继承煎饼果子类。 1234567891011public class BattercakeWithEggSausage extends BattercakeWithEgg &#123; @Override public String getDesc() &#123; return super.getDesc()+ " 加一根香肠"; &#125; @Override public int cost() &#123; return super.cost()+2; &#125;&#125; 测试类 123456789101112131415public class DecoratorV1Test &#123; public static void main(String[] args) &#123; Battercake battercake = new Battercake(); System.out.println(battercake.getDesc()+" 销售价格:"+battercake.cost()); Battercake battercakeWithEgg = new BattercakeWithEgg(); System.out.println(battercakeWithEgg.getDesc()+" 销售价格:"+battercakeWithEgg.cost()); Battercake battercakeWithEggSausage = new BattercakeWithEggSausage(); System.out.println(battercakeWithEggSausage.getDesc()+" 销售价格:"+battercakeWithEggSausage.cost()); &#125;&#125; 输出结果 123煎饼 销售价格:8煎饼 加一个鸡蛋 销售价格:9煎饼 加一个鸡蛋 加一根香肠 销售价格:11 这样做有个问题，什么问题呢？假设我们现在要加2个鸡蛋呢？糟糕我们没写加2个鸡蛋的类，如果还有3个4个什么的那是不是就要类爆炸了。下面我们使用装饰者模式实现一下。 首先我们定义一个抽象的煎饼果子 12345public abstract class ABattercake &#123; protected abstract String getDesc(); protected abstract int cost();&#125; 实体煎饼果子类，实体煎饼果子继承了抽象煎饼果子类。 1234567891011public class Battercake extends ABattercake &#123; @Override protected String getDesc() &#123; return "煎饼"; &#125; @Override protected int cost() &#123; return 8; &#125;&#125; 装饰父类，这里也是可以使用抽象类，等会儿我们再说什么时候使用抽象类什么时候使用实体类。注意构造器和这个里面的花费、描述方法的写法。这里注入一个抽象煎饼类的对象。我们的获取描述花费的操作都委托抽象煎饼类来执行，为什么要这么做可以去看看我之前的文章依赖倒置原则。 12345678910111213141516public class AbstractDecorator extends ABattercake &#123; private ABattercake aBattercake; public AbstractDecorator(ABattercake aBattercake) &#123; this.aBattercake = aBattercake; &#125; @Override protected String getDesc() &#123; return this.aBattercake.getDesc(); &#125; @Override protected int cost() &#123; return this.aBattercake.cost(); &#125;&#125; 鸡蛋的装饰类，这里注意他的构造器，参数是父类的对象抽象煎饼类对象，这里获取描述和花费方法都是调用了父类的方法。 123456789101112131415public class EggDecorator extends AbstractDecorator &#123; public EggDecorator(ABattercake aBattercake) &#123; super(aBattercake); &#125; @Override protected String getDesc() &#123; return super.getDesc()+" 加一个鸡蛋"; &#125; @Override protected int cost() &#123; return super.cost()+1; &#125;&#125; 香肠装饰类 123456789101112131415public class SausageDecorator extends AbstractDecorator&#123; public SausageDecorator(ABattercake aBattercake) &#123; super(aBattercake); &#125; @Override protected String getDesc() &#123; return super.getDesc()+" 加一根香肠"; &#125; @Override protected int cost() &#123; return super.cost()+2; &#125;&#125; 最后是测试类，创建一个实体煎饼果子类并赋值给抽象煎饼果子类，然后将这个父类对象注入装饰类，再把得到的对象赋值给创建的抽象对象。 123456789101112public class DecoratorV2Test &#123; public static void main(String[] args) &#123; ABattercake aBattercake; aBattercake = new Battercake(); aBattercake = new EggDecorator(aBattercake); aBattercake = new EggDecorator(aBattercake); aBattercake = new SausageDecorator(aBattercake); System.out.println(aBattercake.getDesc()+" 销售价格:"+aBattercake.cost()); &#125;&#125; 输入结果 1煎饼 加一个鸡蛋 加一个鸡蛋 加一根香肠 销售价格:12 最后我们来说说装饰父类什么时候使用抽象类。一般当我们需要在具体的类中都需涛执行一些特定的操作时。我们一般就会使用抽象类，并定义抽象方法。 12345678910111213141516171819public abstract class AbstractDecorator extends ABattercake &#123; private ABattercake aBattercake; public AbstractDecorator(ABattercake aBattercake) &#123; this.aBattercake = aBattercake; &#125;//定义每个抽象类的独特方法 protected abstract void doSomething(); @Override protected String getDesc() &#123; return this.aBattercake.getDesc(); &#125; @Override protected int cost() &#123; return this.aBattercake.cost(); &#125;&#125;]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>设计模式</tag>
        <tag>代理模式</tag>
        <tag>结构型</tag>
        <tag>装饰者模式</tag>
        <tag>适配器模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之适配器模式]]></title>
    <url>%2F2020%2F03%2F05%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[适配器模式 适配器模式(Adapter Pattern)：将一个接口转换成客户希望的另一个接口，使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。适配器模式既可以作为类结构型模式，也可以作为对象结构型模式。 在适配器模式中，我们通过增加一个新的适配器类来解决接口不兼容的问题，使得原本没有任何关系的类可以协同工作。 根据适配器类与适配者类的关系不同，适配器模式可分为对象适配器和类适配器两种，在对象适配器模式中，适配器与适配者之间是关联关系；在类适配器模式中，适配器与适配者之间是继承（或实现）关系。 角色Target（目标抽象类）：目标抽象类定义客户所需接口，可以是一个抽象类或接口，也可以是具体类。 Adapter（适配器类）：适配器可以调用另一个接口，作为一个转换器，对Adaptee和Target进行适配，适配器类是适配器模式的核心，在对象适配器中，它通过继承Target并关联一个Adaptee对象使二者产生联系。 Adaptee（适配者类）：适配者即被适配的角色，它定义了一个已经存在的接口，这个接口需要适配，适配者类一般是一个具体类，包含了客户希望使用的业务方法，在某些情况下可能没有适配者类的源代码。 类适配器假设要给一个手机充电，但是手机充电器只能是5v现在有一个220v的电源 被适配类，电源 12345678910111213package adapter;/** * 需要被使用的类 */public class Volt220 &#123; int v=220; public int volt()&#123; return v; &#125;&#125; 使用者,即充电器(只需要传入一个实现VoltInter接口的类传入即可充电) 1234567891011121314package adapter;/** * 手机充电器类 */public class PhoneCharger&#123; public void charger(VoltInter volt)&#123; if(volt.getVolt()!=5)&#123; System.out.println("电压不适配，无法充电"); &#125;else&#123; System.out.println("充电电压5V"); &#125; &#125;&#125; 接口 123456789101112package adapter;/** * 电压接口,要想给手机充电必须先实现这个接口 */public interface VoltInter &#123; /** * 获取电压 * @return */ public int getVolt();&#125; 适配器类(继承被适配类，实现使用者的接口或者抽象类) 123456789101112package adapter;/** * 适配器,基础被使用类，实现电源接口 */public class ChargerAdapter extends Volt220 implements VoltInter&#123; @Override public int getVolt() &#123; System.out.println("正在将"+super.volt()+"转换为5v"); return super.volt()/44; &#125;&#125; 这样一个类适配器就完成了，当然你肯定会有很多疑问，比如为什么要使用继承呢，不是继承违反了迪米特法则么，而不是把被适配者传入呢，别慌嘛，因为这是类适配器，底下肯定还要解决这个问题. 特点 违反了迪米特法则，增加了耦合度 因为继承了被适配类，所以可以根据需要重写被适配者，增加了灵活性 对象适配器只需要把上面的代码的适配器更改即可 12345678910111213141516171819package adapter;/** * 适配器,基础被使用类，实现电源接口 */public class ChargerAdapter implements VoltInter&#123; private Volt220 volt220; public ChargerAdapter(Volt220 volt220) &#123; this.volt220=volt220; &#125; @Override public int getVolt() &#123; System.out.println("正在将"+volt220.volt()+"转换为5v"); return volt220.volt()/44; &#125;&#125; 根据合成复用原则，这样通过传入参数的方式，当然也可以是接口，就解决了类适配器的问题。而且这种方式是一种较为常用的方式 特点 对象适配器和类适配器其实算是同一种思想，只是实现方式不同，根据合成复用原则，使用组合代替继承，所以他解决了继承被适配类的局限性问题，也不需要dist是接口 使用成本更低，更灵活 接口适配器模式当你想实现一个接口但又不想实现所有接口方法，只想去实现一部分方法时，就用中默认的适配器模式，他的方法是在接口和具体实现类中添加一个抽象类，而用抽象类去空实现目标接口的所有方法。而具体的实现类只需要覆盖其需要完成的方法即可。代码如下： 接口 1234567891011package adapter;/** * 有一个接口 */public interface Interface &#123; public void method1(); public void method2(); public void method3(); public void method4();&#125; 抽象类 123456789101112131415161718192021222324252627package adapter;/** *适配器 * 实现该接口所有的方法,但是都是空实现，方便使用这个抽象类的对象只需要关注其中一部分方法，无需全部实现 */public class Abstract implements Interface&#123; @Override public void method1() &#123; &#125; @Override public void method2() &#123; &#125; @Override public void method3() &#123; &#125; @Override public void method4() &#123; &#125;&#125; 客户端 123456789101112package adapter;public class Test &#123; public static void main(String[] args) &#123; //客户端使用只需要实现接口中的一部分即可，就无需实现该接口的所有实现类 new Abstract()&#123; @Override public void method1()&#123; &#125;; &#125;;&#125; 这种方法是不是很像gui编程里面事件监听呢，其实他们就是接口适配器模式。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>设计模式</tag>
        <tag>Spring</tag>
        <tag>框架</tag>
        <tag>接口</tag>
        <tag>适配器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单片机推挽输出和开漏输出和准双向IO以及上拉电阻]]></title>
    <url>%2F2020%2F03%2F05%2F%E5%8D%95%E7%89%87%E6%9C%BA%E6%8E%A8%E6%8C%BD%E8%BE%93%E5%87%BA%E5%92%8C%E5%BC%80%E6%BC%8F%E8%BE%93%E5%87%BA%E5%92%8C%E5%87%86%E5%8F%8C%E5%90%91IO%E4%BB%A5%E5%8F%8A%E4%B8%8A%E6%8B%89%E7%94%B5%E9%98%BB%2F</url>
    <content type="text"><![CDATA[推挽输出推挽输出既可以输出低电平，也可以输出高电平，可以直接驱动功耗不大的数字器件。 推挽电路是由两个三极管或MOSFET，以推挽方式存在于电路中，电路工作时，两只对称的开关管每次只有一个导通，所以导通损耗小、效率高、既提高电路的负载能力，又提高开关速度。其示意结构如下图所示： 当内部输出1电平时,上边的MOS管导通同时下边的MOS管截至,IO口输出高电平; 当内部输出0电平时,上边的MOS管截至同时下边的MOS管导通,IO口输出低电平; 开漏输出开漏输出只能输出低电平,如果要输出高电平必须通过上拉电阻才能实现。就类似于三级管的集电极输出,. 当io口为低电平的时候三极管不导通也就是输出低电平 当io口为高电平的时候三极管导通就输出高电平，也就是说让电路同时具备了高低电平的能力 准双向IO这个可以理解为吧开漏输出集成到了单片机的内部]]></content>
      <categories>
        <category>单片机</category>
      </categories>
      <tags>
        <tag>上拉电阻</tag>
        <tag>推挽</tag>
        <tag>开漏</tag>
        <tag>三极管</tag>
        <tag>准双向</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之原型模式]]></title>
    <url>%2F2020%2F03%2F05%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[原型模式 原型模式是一种创建型设计模式,它通过复制一个已经存在的实例来返回新的实例,而不是新建实例.被复制的实例就是我们所称的原型,这个原型是可定制的.原型模式多用于创建复杂的或者耗时的实例, 因为这种情况下,复制一个已经存在的实例可以使程序运行更高效,或者创建值相等,只是命名不一样的同类数据. 特点原型模式中的拷贝分为”浅拷贝”和”深拷贝”:浅拷贝: 对值类型的成员变量进行值的复制,对引用类型的成员变量只复制引用,不复制引用的对 深拷贝: 对值类型的成员变量进行值的复制,对引用类型的成员变量也进行引用对象的复制. 场景现在有一个问题假设我们需要创建一个对象一百次。你就想了，这很简单啊，直接for循环new它一百次就是ojbk了，其实有一个更好的办法，这个办法速度更快，就是java提供的复制 浅拷贝Person类,其中我们只要实现Cloneable接口里面的clone方法即可实现克隆 123456789101112131415161718192021222324252627282930313233343536373839404142434445package Protptype;public class Person implements Cloneable&#123; private String name; private int age; private Person friend; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public Person getFriend() &#123; return friend; &#125; public void setFriend(Person friend) &#123; this.friend = friend; &#125; @Override public Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125; @Override public String toString() &#123; return "Person&#123;" + "name='" + name + '\'' + ", age=" + age + ", friend=" + friend + '&#125;'; &#125;&#125; 但是我为什么标题说他是浅拷贝呢，请看接下来的例子 12345678910111213141516171819202122232425262728293031package Protptype;public class Test &#123; public static void main(String[] args) &#123; Person friend=new Person(); friend.setName("小明"); Person person=new Person(); person.setName("小红"); person.setAge(18); person.setFriend(friend); Person clone=null; try &#123; clone= (Person) person.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; System.out.println("改名前"); System.out.println(person); System.out.println(clone); friend.setName("王小明"); person.setName("王小红"); System.out.println("改名后"); System.out.println(person); System.out.println(clone); &#125;&#125; 123456改名前Person&#123;name=&apos;小红&apos;, age=18, friend=Person&#123;name=&apos;小明&apos;, age=0, friend=null&#125;&#125;Person&#123;name=&apos;小红&apos;, age=18, friend=Person&#123;name=&apos;小明&apos;, age=0, friend=null&#125;&#125;改名后Person&#123;name=&apos;小红&apos;, age=18, friend=Person&#123;name=&apos;王小明&apos;, age=0, friend=null&#125;&#125;Person&#123;name=&apos;小红的克隆人&apos;, age=18, friend=Person&#123;name=&apos;王小明&apos;, age=0, friend=null&#125;&#125; 从上面看出来，当小红的朋友改名字的时候克隆人的朋友也跟着改名字，这么说明他俩的朋友是同一个人，也就是说发生了值复制，也说明了浅复制对于普通变量来说是值复制，对于引用变量来说只是复制了引用，但是为什么改了名字，克隆人的名字和原来人的名字没有一起变化呢，难道string不是引用变量么，不不不，因为String特殊的原因，这里两人的String不是同一个对象，那么我们应该如何实现深复制呢 深复制(clone方法里面clone引用型变量)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package Protptype;public class Person implements Cloneable&#123; private String name; private int age; private Person friend; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public Person getFriend() &#123; return friend; &#125; public void setFriend(Person friend) &#123; this.friend = friend; &#125; @Override public Object clone() throws CloneNotSupportedException &#123;//在克隆方法中手动复制子类 Person person= (Person) super.clone(); person.setFriend(new Person()); return person; &#125; @Override public String toString() &#123; return "Person&#123;" + "name='" + name + '\'' + ", age=" + age + ", friend=" + friend + '&#125;'; &#125;&#125; 深复制(使用序列化和反序列化推荐使用)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package Protptype;import java.io.*;public class Person implements Cloneable,Serializable&#123; private String name; private int age; private Person friend; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public Person getFriend() &#123; return friend; &#125; public void setFriend(Person friend) &#123; this.friend = friend; &#125; @Override public Object clone() throws CloneNotSupportedException &#123;//在克隆方法中手动复制子类 return super.clone(); &#125; /** * 深克隆，使用序列化和反序列化进行克隆 * @return * @throws IOException * @throws ClassNotFoundException */ public Object deepClone() throws IOException, ClassNotFoundException &#123; /** * 写入当前对象的二进制流 */ ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject( this ); /** * 写出当前对象二进制流 */ ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray()); ObjectInputStream ois; ois = new ObjectInputStream(bis); return ois.readObject(); &#125; @Override public String toString() &#123; return "Person&#123;" + "name='" + name + '\'' + ", age=" + age + ", friend=" + friend + '&#125;'; &#125;&#125; 结果 123456改名前Person&#123;name=&apos;小红&apos;, age=18, friend=Person&#123;name=&apos;小明&apos;, age=0, friend=null&#125;&#125;Person&#123;name=&apos;小红&apos;, age=18, friend=Person&#123;name=&apos;小明&apos;, age=0, friend=null&#125;&#125;改名后Person&#123;name=&apos;小红&apos;, age=18, friend=Person&#123;name=&apos;王小明&apos;, age=0, friend=null&#125;&#125;Person&#123;name=&apos;小红的克隆人&apos;, age=18, friend=Person&#123;name=&apos;小明&apos;, age=0, friend=null&#125;&#125;]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>java</tag>
        <tag>设计模式</tag>
        <tag>原则</tag>
        <tag>原型模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之工厂模式]]></title>
    <url>%2F2020%2F03%2F03%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[工厂模式 厂模式又称为创建模式，它是建对象的一种最佳方式。工厂模式的本质就是用工厂方法代替new操作创建一种实例化对象的方式。一句话中总结就是方便创建 同种类型接口产品 的 复杂对象。 重要特征根据传入的参数不同，来获取大量的对象 适用场景 创建对象需要大量重复的代码。 创建对象需要访问某些信息，而这些信息不应该包含在复合类中。 创建对象的生命周期必须集中管理，以保证在整个程序中具有一致的行为。 简单工厂模式简单工厂模式最大的优点在于实现对象的创建和对象的使用分离，将对象的创建交给专门的工厂类负责，但是其最大的缺点在于工厂类不够灵活，增加新的具体产品需要修改工厂类的判断逻辑代码，而且产品较多时，工厂方法代码逻辑将会非常复杂。 直接看代码：定义一个抽象产品类形状类Shape 123abstract class Shape()&#123; public abstract void shape();&#125; 定义具体产品： 123456789101112131415class Circle extends Shape&#123; public void shape()&#123; System.out.println("圆形"); &#125;&#125;class Rectangle extends Shape&#123; public void shape()&#123; System.out.println("矩形"); &#125;&#125;class Triangle extends Shape&#123; public void shape()&#123; System.out.println("三角形"); &#125;&#125; 定义一个工厂生产具体产品 12345678910111213141516public class ShapeFactory&#123; public static Shape getshape(String sh)&#123; if(sh.equals("圆形"))&#123; return new Circle(); &#125;else if(sh.equals("矩形"))&#123; return new Rectangle(); &#125;else if(sh.equals("三角形"))&#123; return new Triangle(); &#125;else &#123; return null; &#125; &#125; public static void main(String args[])&#123;//根据需要获取指定对象，和new相比向当于交出了对象的创建 ShapeFactory.getshape("圆形").shape(); &#125;&#125; 从简单工厂中我们可以看出使用一个静态方法将实例化的创建和使用分离开。我们只需要调用方法传递参数就可以获得我们需要的对象。 缺点:我们不难看出如果我们想要增加一个形状类的产品不仅需要添加一个导出类而且我们必须要修改静态方法getshape，这样就违背了开闭原则（对于扩展是开放的，对于修改是封闭的） 工厂模式 假如说我们吧工厂也抽象出来，每次修改工厂产品的时候我们都可以写一个真正的工厂实现抽象工厂，那么我们是不是就解决了简单工厂没有遵守的开闭原则 抽象工厂：为具体工厂提供接口，也就是提供规范，只能有一个。 具体工厂：实现抽象工厂接口的类，可以有多个，根据需要生产的产品的变化可以使用其他的具体工厂 抽象产品：具体产品的父类。 具体产品：工厂模式中所有创建的对象都是具体产品的实例。 直接看代码：定义一个抽象产品类形状类Shape和一个工厂超类 123456abstract class Shape()&#123; public abstract void shape();&#125;abstract class Factory()&#123; public abstract void CreatShape();&#125; 定义具体产品： 123456789101112131415class Circle extends Shape&#123; public void shape()&#123; System.out.println("圆形"); &#125;&#125;class Rectangle extends Shape&#123; public void shape()&#123; System.out.println("矩形"); &#125;&#125;class Triangle extends Shape&#123; public void shape()&#123; System.out.println("三角形"); &#125;&#125; 定义多个个工厂生产具体产品 123456789101112131415161718public class CircleFactory extends Factory &#123; public static Shape CreatShape(String sh)&#123; if(sh.equals("圆形"))&#123; return new Circle(); &#125;else &#123; return null; &#125; &#125;&#125;public class RectangleFactory&#123; public static Shape CreatShape(String sh)&#123; if(sh.equals("矩形"))&#123; return new Rectangle(); &#125;else &#123; return null; &#125; &#125;&#125; 客户端 123456789public class Test&#123; public static void main(String args[])&#123; //根据需要获取指定对象，和new相比向当于交出了对象创建 getshape(new CircleFactory()); &#125; public static void getshape(Factory fac)&#123; fac.CreatShape().shape(); &#125;&#125; 如上所示：即使我们增加一个新的形状类，我们也只需要增加相应的工厂类，不需要修改代码的任何方法。当我们需要这个新产品的时候我们只需要getshap（new 新的工厂类），其他的我们不用去关心，不需要了解方法的实现，对象是如何创建的，我们只需要调用方法就行了——良好的封装性。优点： 良好的封装性：如上面所说。 可以是代码结构变得清晰，有效的封装变化，通常new一个具体类是很复杂多变的，通过工厂方法将new的过 程封装在具体工厂的方法中，调用者无须知道实例化的过程，只需要调用方法就可以得到自己想要的产品。 优点 添加新产品时，除了增加新产品类外，还要提供与之对应的具体工厂类，系统类的个数将成对增加，在一定程度上增加了系统的复杂度；同时，有更多的类需要编译和运行，会给系统带来一些额外的开销； 由于考虑到系统的可扩展性，需要引入抽象层，在客户端代码中均使用抽象层进行定义，增加了系统的抽象性和理解难度，且在实现时可能需要用到DOM、反射等技术，增加了系统的实现难度。 虽然保证了工厂方法内的对修改关闭，但对于使用工厂方法的类，如果要更换另外一种产品，仍然需要修改实例化的具体工厂类； 一个具体工厂只能创建一种具体产品 缺点 当一个类不知道它所需要的对象的类时 在工厂方法模式中，客户端不需要知道具体产品类的类名，只需要知道所对应的工厂即可； 当一个类希望通过其子类来指定创建对象时 在工厂方法模式中，对于抽象工厂类只需要提供一个创建产品的接口，而由其子类来确定具体要创建的对象，利用面向对象的多态性和里氏代换原则，在程序运行时，子类对象将覆盖父类对象，从而使得系统更容易扩展。 将创建对象的任务委托给多个工厂子类中的某一个，客户端在使用时可以无须关心是哪一个工厂子类创建产品子类，需要时再动态指定，可将具体工厂类的类名存储在配置文件或数据库中。 工厂模式举例java.lang.Calendar类就是一个单例模式+简单工厂模式]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>java</tag>
        <tag>设计模式</tag>
        <tag>原则</tag>
        <tag>工厂设计模式</tag>
        <tag>工厂模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之单例设计模式]]></title>
    <url>%2F2020%2F03%2F03%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例设计模式 单例模式，是一种常用的软件设计模式。在它的核心结构中只包含一个被称为单例的特殊类。通过单例模式可以保证系统中，应用该模式的类一个类只有一个实例。即一个类只有一个对象实例。 优点： 在内存中只有一个对象，节省内存空间； 避免频繁的创建销毁对象，可以提高性能； 避免对共享资源的多重占用，简化访问； 为整个系统提供一个全局访问点。 缺点： 不适用于变化频繁的对象； 滥用单例将带来一些负面问题，如为了节省资源将数据库连接池对象设计为的单例类，可能会导致共享连接池对象的程序过多而出现连接池溢出； 如果实例化的对象长时间不被利用，系统会认为该对象是垃圾而被回收，这可能会导致对象状态的丢失； 单例设计模式种类 恶汉式 懒汉式 双重检查 静态内部类 枚举 恶汉式(成员变量)1234567891011121314151617181920212223242526public class Singleton01 &#123; public static void main(String[] args) &#123; System.out.println("单例设计模式恶汉式~"); Singleton singleton1=Singleton.getInstance(); Singleton singleton2=Singleton.getInstance(); System.out.println(singleton1==singleton2); &#125;&#125;/** * 单例设计模式恶汉式~ * 01.私有化构造器，防止外部重复new对象 * 02.私有化静态成员变量防止外部修改对象引用 * 02.提供静态方法提供给外部获取该类 */class Singleton &#123; private Singleton()&#123;&#125;; //final可以优化 private static final Singleton singleton=new Singleton(); public static Singleton getInstance()&#123; return singleton; &#125;&#125; 特点 只要类加载就立刻创建对象 如果这个类永远没有被使用那么还是会创建这个对象并且浪费内存 由于在类装载的时候实例化这个对象，所以不会造成线程安全问题 恶汉式(静态代码块)123456789101112131415161718192021222324252627282930public class Singleton01 &#123; public static void main(String[] args) &#123; System.out.println("单例设计模式恶汉式~"); Singleton singleton1=Singleton.getInstance(); Singleton singleton2=Singleton.getInstance(); System.out.println(singleton1==singleton2); &#125;&#125;/** * 单例设计模式恶汉式~ * 01.私有化构造器，防止外部重复new对象 * 02.私有化静态成员变量防止外部修改对象引用 * 02.提供静态方法提供给外部获取该类 */class Singleton &#123; static &#123; singleton=new Singleton(); &#125; private Singleton()&#123;&#125;; private static Singleton singleton; public static Singleton getInstance()&#123; return singleton; &#125;&#125; 特点这个特点和上面一样 懒汉式(延迟加载，但线程不安全)12345678910111213141516171819202122232425262728293031public class Singleton01 &#123; public static void main(String[] args) &#123; System.out.println("单例设计模式懒汉式~线程不安全"); Singleton singleton1=Singleton.getInstance(); Singleton singleton2=Singleton.getInstance(); System.out.println(singleton1==singleton2); &#125;&#125;/** * 单例设计模式懒汉式~ * 01.私有化构造器，防止外部重复new对象 * 02.私有化静态成员变量防止外部修改对象引用 * 03.提供静态方法提供给外部获取该类 * 04.提供静态方法中判断是否已经创建对象 */class Singleton &#123; private Singleton()&#123;&#125;; private static Singleton singleton; public static Singleton getInstance()&#123; if(singleton==null)&#123; //有可能多个线程同时进入这个代码块，以至于单例模式并不单例 singleton=new Singleton(); &#125; return singleton; &#125;&#125; 特点 实现了懒加载，保证了不浪费内存，但是带来了新的问题 在多线程的情况下有可能创建多个Singleton对象 懒汉式(延迟加载，方法同步)12345678910111213141516171819202122232425262728293031public class Singleton01 &#123; public static void main(String[] args) &#123; System.out.println("单例设计模式懒汉式~线程不安全"); Singleton singleton1=Singleton.getInstance(); Singleton singleton2=Singleton.getInstance(); System.out.println(singleton1==singleton2); &#125;&#125;/** * 单例设计模式懒汉式~ * 01.私有化构造器，防止外部重复new对象 * 02.私有化静态成员变量防止外部修改对象引用 * 03.提供静态方法提供给外部获取该类 * 04.提供静态方法中判断是否已经创建对象 */class Singleton &#123; private Singleton()&#123;&#125;; private static Singleton singleton; //相比上面的添加了方法锁，来保证线程安全问题，但是多个线程创建对象的时候其他现在必须在外部等待 public static synchronized Singleton getInstance()&#123; if(singleton==null)&#123; singleton=new Singleton(); &#125; return singleton; &#125;&#125; 特点 实现了懒加载，也避免了线程安全问题。 但是由于同步方法颗粒度过大，导致创建的时候验证影响效率 懒汉式(延迟加载，双重检查)1234567891011121314151617181920212223242526272829303132333435public class Singleton01 &#123; public static void main(String[] args) &#123; System.out.println("单例设计模式懒汉式~线程不安全"); Singleton singleton1=Singleton.getInstance(); Singleton singleton2=Singleton.getInstance(); System.out.println(singleton1==singleton2); &#125;&#125;/** * 单例设计模式懒汉式~ * 01.私有化构造器，防止外部重复new对象 * 02.私有化静态成员变量防止外部修改对象引用 * 03.提供静态方法提供给外部获取该类 * 04.提供静态方法中判断是否已经创建对象 */class Singleton &#123; private Singleton()&#123;&#125;; private static volatile Singleton singleton; public static Singleton getInstance()&#123; if(singleton==null)&#123; synchronized (Singleton.class)&#123; //在创建单例设计模式的时候双重检查保证了多个线程中只有一个线程去创建静态对象，二其他线程无需等待 if(singleton==null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 关于volatile关键字的使用，在单线程的环境下是不存在指令重排的情况，涉及到多线程就会涉及到指令重排。比如创建对象大致为三个过程：1.开辟内存空间2.创建对象。3.对象指定内存空间。在创建对象的过程中，多线程环境中是不一定会按照指令的顺序来进行创建对象。比如说执行步骤是132，在执行完2的时候，导致其他线程认为对象已经创建完毕，然后内存指向了一片空白。所以需要添加volitile关键字，保证对象是创建完毕再继续使用。 特点 实现了该类的懒加载 解决了线程问题，并且也解决了性能问题,推荐使用 静态内部类1234567891011121314class Singleton1&#123; private static Singleton1 singleton; private Singleton1()&#123;&#125;; private static class LazyHolder &#123; //防止内部误操作，不小心对其使用了代理或者其他的情况，final修饰，不允许改变 private static final Singleton1 INSTANCE = new Singleton1(); &#125; public static Singleton1 getInstance()&#123; return LazyHolder.INSTANCE; &#125;&#125; 通过内部类来实现懒加载单例模式，该种实现方式也较为常用。关于内部类实现懒加载的解释：类信息只有在使用其Class相关的时候才会加载字节码相关的类信息。静态内部类同样如此，只有在用到静态内部类的时候才会去用到我们内部类的静态相关信息。所以称其为懒加载。 很多种单例的写法都有一个通病，就是无法防止反射机制的漏洞，从而无法保证对象的唯一性，如下举例： 利用如下的反正代码对上文构造的单例进行对象的创建。 但是上面代码也有缺陷，比如说可以使用反射机制破坏123456789101112131415161718192021222324public class Test002 &#123; public static void main(String[] args) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException &#123; Class&lt;Singleton1&gt; singleton1Class = Singleton1.class; Constructor&lt;Singleton1&gt; declaredConstructor = singleton1Class.getDeclaredConstructor(null); declaredConstructor.setAccessible(true); Singleton1 singleton1 = declaredConstructor.newInstance(null); System.out.println(singleton1==Singleton1.getInstance());//单例模式居然拿到的是两个对象 &#125;&#125;class Singleton1&#123; private static Singleton1 singleton; private Singleton1()&#123;&#125;; private static class LazyHolder &#123; private static final Singleton1 INSTANCE = new Singleton1(); &#125; public static Singleton1 getInstance()&#123; return LazyHolder.INSTANCE; &#125;&#125; 上述代码单例模式拿到的居然是两个对象，可想而知，如果你用java写了个软件，其中使用上面的单例模式的话，别人很容易就破解了。 枚举123456enum Singleton1 &#123; INSTANCE; public void sayOk()&#123; System.out.println("OK"); &#125;&#125; 嘿嘿嘿就是这么简单。 其实这就是 enum 的一块语法糖，JVM 会阻止反射获取枚举类的私有构造方法。 仍然使用上文的反射代码来进行测试，发现，报错。嘿嘿，完美解决反射的问题。 而且enum类型无法通过反射机制被创建。 缺点使用枚举的方法是起到了单例的作用，但是也有一个弊端， 那就是 无法进行懒加载。 单例模式举例java.lang.Runtime这个类就是个典型的懒汉模式单例设计模式]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>java</tag>
        <tag>设计模式</tag>
        <tag>原则</tag>
        <tag>单例设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之建造者模式]]></title>
    <url>%2F2020%2F03%2F01%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[建造者模式 当一个类的内部数据过于复杂的时候（通常是负责持有数据的类，比如Config、VO、PO、Entity…），要创建的话可能就需要了解这个类的内部结构，还有这些东西是怎么组织装配等一大坨乱七八糟的东西，这个时候就会增加学习成本而且会很混乱，这个时候就想啊想一种什么法子来管理一下这个类中的数据呢，怎么在创建的时候让它按部就班的来，并且代码可读性很好别让我看花了眼啊，我要的东西也能都很好设置进来，这就是Builder模式的应用场景，Builder模式可以将一个类的构建和表示进行分离。 建造者模式和工厂模式的区别工厂模式在创建对象的时候客户端不能自定义，而建造者模式可以在创建对象的时候，可以根据具体建造者的不同和指挥者不同进行DIY对象 主要作用 在用户不知道对象的建造过程和细节的情况下就可以直接创建复杂的对象。 用户只需要给出指定复杂对象的类型和内容； 建造者模式负责按顺序创建复杂对象（把内部的建造过程和细节隐藏起来) 适用场景 隔离复杂对象的创建和使用，相同的方法，不同执行顺序，产生不同事件结果 多个部件都可以装配到一个对象中，但产生的运行结果不相同 产品类非常复杂或者产品类因为调用顺序不同而产生不同作用 初始化一个对象时，参数过多，或者很多参数具有默认值 Builder模式不适合创建差异性很大的产品类 产品内部变化复杂，会导致需要定义很多具体建造者类实现变化，增加项目中类的数量，增加系统的理解难度和运行成本 需要生成的产品对象有复杂的内部结构，这些产品对象具备共性； builder.png 模式讲解： 指挥者（Director）直接和客户（Client）进行需求沟通； 沟通后指挥者将客户创建产品的需求划分为各个部件的建造请求（Builder）； 将各个部件的建造请求委派到具体的建造者（ConcreteBuilder）； 各个具体建造者负责进行产品部件的构建； 最终构建成具体产品（Product）。 分析使用场景当一个类的构造函数参数个数超过4个，而且这些参数有些是可选的参数，考虑使用构造者模式。 解决问题分析当一个类的构造函数参数超过4个，而且这些参数有些是可选的时，我们通常有两种办法来构建它的对象。 例如我们现在有如下一个类计算机类Computer，其中cpu与ram是必填参数，而其他3个是可选参数，那么我们如何构造这个类的实例呢,通常有两种常用的方式： 方式一折叠构造函数模式 12345678910111213141516171819public class Computer &#123; ... public Computer(String cpu, String ram) &#123; this(cpu, ram, 0); &#125; public Computer(String cpu, String ram, int usbCount) &#123; this(cpu, ram, usbCount, "罗技键盘"); &#125; public Computer(String cpu, String ram, int usbCount, String keyboard) &#123; this(cpu, ram, usbCount, keyboard, "三星显示器"); &#125; public Computer(String cpu, String ram, int usbCount, String keyboard, String display) &#123; this.cpu = cpu; this.ram = ram; this.usbCount = usbCount; this.keyboard = keyboard; this.display = display; &#125;&#125; 方式二使用javabean方式 1234567891011121314151617181920public class Computer &#123; ... public String getCpu() &#123; return cpu; &#125; public void setCpu(String cpu) &#123; this.cpu = cpu; &#125; public String getRam() &#123; return ram; &#125; public void setRam(String ram) &#123; this.ram = ram; &#125; public int getUsbCount() &#123; return usbCount; &#125;...&#125; 对比分析 第一种方式使用和阅读非常不方便，而且客户端在调用构造方式的时候需要决定到底使用拿一个，然后里面还要放置一大堆参数。 第二种方式很容易导致对象在运行的时候被客户端修改，于是乎导致这个类在使用的时候非常容易出错 方式三使用建造者模式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Computer &#123; private String cpu;//必须 private String ram;//必须 private int usbCount;//可选 private String keyboard;//可选 private String display;//可选 private Computer(Builder builder)&#123; this.cpu=builder.cpu; this.ram=builder.ram; this.usbCount=builder.usbCount; this.keyboard=builder.keyboard; this.display=builder.display; &#125; //静态内部类 public static class Builder&#123; private String cpu;//必须 private String ram;//必须 private int usbCount;//可选 private String keyboard;//可选 private String display;//可选 public Builder(String cup,String ram)&#123; this.cpu=cup; this.ram=ram; &#125; public Builder setUsbCount(int usbCount) &#123; this.usbCount = usbCount; return this; &#125; public Builder setKeyboard(String keyboard) &#123; this.keyboard = keyboard; return this; &#125; public Builder setDisplay(String display) &#123; this.display = display; return this; &#125; public Computer build()&#123; return new Computer(this); &#125; &#125; public static void main(String[] args) &#123; Computer builder = new Builder("英特尔", "三星").setDisplay("24寸").build(); &#125;&#125; 总结这种方式不仅解决了构造方法过对的问题，而且避免了javabean方式容易导致对象在运行的时候被修改，而且实现了面向调用链编程。 建造者模式扩展 Product: 最终要生成的对象，例如 Computer实例。 Builder： 构建者的抽象基类（有时会使用接口代替）。其定义了构建Product的抽象步骤，其实体类需要实现这些步骤。其会包含一个用来返回最终产品的方法Product getProduct()。 ConcreteBuilder: Builder的实现类。 Director: 决定如何构建最终产品的算法. 其会包含一个负责组装的方法void Construct(Builder builder)， 在这个方法中通过调用builder的方法，就可以设置builder，等设置完成后，就可以通过builder的 getProduct() 方法获得最终的产品。 Computer类 12345678910111213141516171819202122232425262728293031public class Computer &#123; private String cpu;//必须 private String ram;//必须 private int usbCount;//可选 private String keyboard;//可选 private String display;//可选 public Computer(String cpu, String ram) &#123; this.cpu = cpu; this.ram = ram; &#125; public void setUsbCount(int usbCount) &#123; this.usbCount = usbCount; &#125; public void setKeyboard(String keyboard) &#123; this.keyboard = keyboard; &#125; public void setDisplay(String display) &#123; this.display = display; &#125; @Override public String toString() &#123; return "Computer&#123;" + "cpu='" + cpu + '\'' + ", ram='" + ram + '\'' + ", usbCount=" + usbCount + ", keyboard='" + keyboard + '\'' + ", display='" + display + '\'' + '&#125;'; &#125;&#125; 抽象建造者 123456public abstract class ComputerBuilder &#123; public abstract void setUsbCount(); public abstract void setKeyboard(); public abstract void setDisplay(); public abstract Computer getComputer();&#125; 真实构建者 苹果电脑构建者类 12345678910111213141516171819202122public class MacComputerBuilder extends ComputerBuilder &#123; private Computer computer; public MacComputerBuilder(String cpu, String ram) &#123; computer = new Computer(cpu, ram); &#125; @Override public void setUsbCount() &#123; computer.setUsbCount(2); &#125; @Override public void setKeyboard() &#123; computer.setKeyboard("苹果键盘"); &#125; @Override public void setDisplay() &#123; computer.setDisplay("苹果显示器"); &#125; @Override public Computer getComputer() &#123; return computer; &#125;&#125; 联想电脑构建者类 12345678910111213141516171819202122public class LenovoComputerBuilder extends ComputerBuilder &#123; private Computer computer; public LenovoComputerBuilder(String cpu, String ram) &#123; computer=new Computer(cpu,ram); &#125; @Override public void setUsbCount() &#123; computer.setUsbCount(4); &#125; @Override public void setKeyboard() &#123; computer.setKeyboard("联想键盘"); &#125; @Override public void setDisplay() &#123; computer.setDisplay("联想显示器"); &#125; @Override public Computer getComputer() &#123; return computer; &#125;&#125; 指挥者 1234567public class ComputerDirector &#123; public void makeComputer(ComputerBuilder builder)&#123; builder.setUsbCount(); builder.setDisplay(); builder.setKeyboard(); &#125;&#125; 使用 123456789101112public static void main(String[] args) &#123; ComputerDirector director=new ComputerDirector();//1 ComputerBuilder builder=new MacComputerBuilder("I5处理器","三星125");//2 director.makeComputer(builder);//3 Computer macComputer=builder.getComputer();//4 System.out.println("mac computer:"+macComputer.toString()); ComputerBuilder lenovoBuilder=new LenovoComputerBuilder("I7处理器","海力士222"); director.makeComputer(lenovoBuilder); Computer lenovoComputer=lenovoBuilder.getComputer(); System.out.println("lenovo computer:"+lenovoComputer.toString());&#125;]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>java</tag>
        <tag>设计模式</tag>
        <tag>原则</tag>
        <tag>工厂设计模式</tag>
        <tag>工厂模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之七大原则]]></title>
    <url>%2F2020%2F02%2F23%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%B8%83%E5%A4%A7%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[设计模式什么是设计模式 设计模式最早是从建筑领域引入到软件工程领域的，软件开发者在平时开发软件的时候发现有些场景和需求在不同的软件开发中是很相似的，于是乎将这些解决方案抽象出来就形成了设计模式 设计模式的目的和作用(5大作用目的) 代码重用性 可读性 可扩展性 可靠性 使程序呈现高内聚，低耦合的特性 设计模式的七大原则 单一职责原则 接口隔离原则 依赖倒置(倒转)原则 里氏替换原则 迪米特法则 合成复用原则 开闭原则 单一职责原则介绍 对于一个类来说一个类应该只负责一项职责，如果一个类负责多个职责，则应该拆分这个类，（如果这个类功能特别单一则可以违反类单一职责原则，但是要遵循方法单一职责原则） 举例太简单了，太容易了就不举例了╮(╯▽╰)╭ 单一职责原则细节和注意事项 降低类的复杂度，一个类只负责一项职责 提高类的可读性，可维护性 降低变更引起的风险 通常情况下要遵守单一职责原则，只有逻辑足够简单，才可以违反类单一则责原则，但是要在方法层面上遵循单一职责原则 接口隔离原则介绍 一个类不应该依赖他不需要的接口，即一个类对另一个类的依赖应该建立在最小的接口上。 举例类A和类B都依赖一个接口interface,并且类A只需要这个接口的前几个方法，而类B只需要后几个方法，类A1和类B1都是对该接口的实现，不过类A1主要由类A调用实现，如果只有一个接口的话，那么类A1和类B1都要实现这个接口的所有方法。 错误示范1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859interface I &#123; public void method1(); public void method2(); public void method3(); public void method4(); public void method5();&#125;class A&#123; public void depend1(I i)&#123; i.method1(); &#125; public void depend2(I i)&#123; i.method2(); &#125; public void depend3(I i)&#123; i.method3(); &#125;&#125;class A1 implements I&#123; public void method1() &#123; System.out.println("类A1实现接口I的方法1"); &#125; public void method2() &#123; System.out.println("类A1实现接口I的方法2"); &#125; public void method3() &#123; System.out.println("类A1实现接口I的方法3"); &#125; //对于类A1来说，method4和method5不是必需的，但是由于接口A中有这两个方法， //所以在实现过程中即使这两个方法的方法体为空，也要将这两个没有作用的方法进行实现。 public void method4() &#123;&#125; public void method5() &#123;&#125;&#125;class B&#123; public void depend2(I i)&#123; i.method4(); &#125; public void depend3(I i)&#123; i.method5(); &#125;&#125;class B1 implements I&#123; public void method1() &#123;&#125; //对于类B1来说，method2和method3不是必需的，但是由于接口A中有这两个方法， //所以在实现过程中即使这两个方法的方法体为空，也要将这两个没有作用的方法进行实现。 public void method2() &#123;&#125; public void method3() &#123;&#125; public void method4() &#123; System.out.println("类B1实现接口I的方法4"); &#125; public void method5() &#123; System.out.println("类B1实现接口I的方法5"); &#125;&#125; 正确示范上述情况其实我们可以把I接口分解成两个接口，让A1实现接口一让B1实现接口2即可，这样就隔离开了这两个接口，并且这两个接口都是他们的最小接口，那这样就是接口隔离原则了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152interface I1 &#123; public void method1(); public void method2(); public void method3();&#125;interface I2 &#123; public void method4(); public void method5();&#125;class A&#123; public void depend1(I1 i)&#123; i.method1(); &#125; public void depend2(I1 i)&#123; i.method2(); &#125; public void depend3(I1 i)&#123; i.method3(); &#125;&#125;class A1 implements I1&#123;//那么就可以不实现4和5方法了 public void method1() &#123; System.out.println("类A1实现接口I1的方法1"); &#125; public void method2() &#123; System.out.println("类A1实现接口I1的方法2"); &#125; public void method3() &#123; System.out.println("类A1实现接口I1的方法3"); &#125;&#125;class B&#123; public void depend2(I2 i)&#123; i.method4(); &#125; public void depend3(I2 i)&#123; i.method5(); &#125;&#125;class B1 implements I2&#123; public void method4() &#123; System.out.println("类B1实现接口I2的方法4"); &#125; public void method5() &#123; System.out.println("类B1实现接口I2的方法5"); &#125;&#125; 接口隔离原则细节和注意事项 接口要高内聚。什么是高内聚？高内聚就是提高接口、类、模块的处理能力，减少对外的交互. 定制服务。一个系统或系统内的模块之间必然会有耦合，有耦合就要相互访问的接口（并不一定就是Java中定义的Interface，也可能是一个类或者是单纯的数据交换），我们设计时就需要给各个访问者（也就是客户端）定制服务，什么是定制服务？单独为一个个体提供优良优良的服务。我们在做系统设计时也需要考虑对系统之间或模块之间的定义要采用定制服务，采用定制服务就必然有一个要求就是：只提供访问者需要的方法，只暴露给调用的类它需要的方法，它不需要的方法则隐藏起来。只有专注地为一个模块提供定制服务，才能建立最小的依赖关系。 接口尽量小，但是要有限度。接口的设计粒度是越小系统越灵活，这是不争的事实，但是这就带来成接口数量过多，使设计结构的复杂化，开发难度增加，维护性降低，这不是一个项目或产品所期望看到的。所以一定要适度。 依赖倒置原则介绍 1、高层模块不应该依赖底层模块，二者都应该依赖抽象。 2、抽象不应该依赖细节，细节应该依赖抽象。 3、依赖倒置的中心思想是面向接口编程。 4、依赖倒置原则是基于这样的设计理念：相对于细节的多变性，抽象的东西要稳定的多。以抽象为基础搭建的架构比以细节为基础搭建的架构要稳定的多。 5、使用接口或抽象类的目的是指定好规范，而不涉及任何具体的操作，把展现细节的任务交给他们的实现类来完成。 举例错误示范假如我喜欢玩游戏，那么有两个类，一个类是我只有一个方法就是玩，然后还有一个游戏类 123456789101112131415class My&#123; public void play(Factorio i)&#123; System.out.println("我在玩"+i.getName()); &#125;&#125;class Factorio&#123; public String getName()&#123; return "异星工厂"; &#125;&#125;public class Test&#123; public static void main(String[]args)&#123; new My().play(new Factorio()); &#125;&#125; 假如说我玩的游戏不知一个，有多个游戏那么上面代码怎么办呢，是不是就需要写多个play方法重载之类进行解决呢。 正确示范1234567891011121314151617181920212223242526272829interface Play&#123; public void getName();&#125;class My&#123; public void play(Play i)&#123; System.out.println("我在玩"+i.getName()); &#125;&#125;class Factorio implements Play&#123; public String getName()&#123; return "异星工厂"; &#125;&#125;class BF4 implements Play&#123; public String getName()&#123; return "战地4"; &#125;&#125;public class Test&#123; public static void main(String[]args)&#123; new My().play(new Factorio()); new My().play(new BF4()); &#125;&#125; 这样每次新增功能的改动就非常小了 注意事项 低层模块尽量都要有抽象类或者接口，或者而知都有，这样程序稳定性更好 变量的生命类型尽量是抽象类或者接口，这样我们的变量引用和实际对象间就存在一个缓存层，利于程序的扩展和优化 继承时遵循里氏原则 抽象不应该依赖细节 细节应该依赖抽象 里氏替换原则介绍 里氏替换原则(LSP)指的是所有引用基类的地方都可以透明的使用其子类的对象 可以理解为:只要有父类出现的地方，都可以使用子类来替代。而且不会出现任何错误或者异常。但是反过来却不行。子类出现的地方,不能使用父类来替代。 如果不符合上述的规定的话，我们可以想象子类的实例化调用方法时候,调用的确实父类的方法。会出现意想不到的结果 代码就不放出来了,这个也没有啥好说的里氏替换原则细节和注意事项 子类必须实现父类的抽象方法，但不得重写父类的非抽象(已实现的)方法。 子类中可增加自己特有的方法。(可以随时扩展) 当子类覆盖或者实现父类的方法时,方法的前置条件(方法形参)要比父类输入参数更加宽松。否则会调用到父类的方法。 当子类的方法实现父类的抽象方法时，方法的后置条件（即方法的返回值）要比父类更严格。否则会调用到父类的方法。 开闭原则定义 一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。 举例现在有一个图形基础类还有两个继承图形基础类的子类三角形和正方形，还有一个工具类可以将传入的图形之类画出来 错误示范123456789101112131415161718192021222324252627282930313233343536class Graph&#123; Integer id;&#125;class Triangle extends Graph&#123; public Triangle()&#123; super.id=1; &#125; public void drawTriangle()&#123; System.out.println("画三角形"); &#125;&#125;class Square extends Graph&#123; public Triangle()&#123; super.id=2; &#125; public void drawSquare()&#123; System.out.println("画正方形"); &#125;&#125;class Painting&#123; void painting(Graph g)&#123; if(g.id==1)&#123; g.drawTriangle(); &#125;else if(g.id==2)&#123; g.drawSquare(); &#125; &#125;&#125;public class Test&#123; public static void main(String[] args)&#123; Painting p=new Painting(); p.painting(new drawTriangle()); &#125;&#125; 如果现在我们有一个新的需求需要添加一个新的图形，那么一定得修改工具类Painting里面的方法，而且还要添加新的类 正确示范12345678910111213141516171819202122232425262728293031323334class Graph&#123; Integer id; abstract void draw();&#125;class Triangle extends Graph&#123; public Triangle()&#123; super.id=1; &#125; public void draw()&#123; System.out.println("画三角形"); &#125;&#125;class Square extends Graph&#123; public Triangle()&#123; super.id=2; &#125; public void draw()&#123; System.out.println("画正方形"); &#125;&#125;class Painting&#123; void painting(Graph g)&#123; g.draw(); &#125;&#125;public class Test&#123; public static void main(String[] args)&#123; Painting p=new Painting(); p.painting(new drawTriangle()); &#125;&#125; 我们把基础图形类Graph的一个方法draw定义成抽象的，接下来他的所有子类都实现这个方法，那么我们新增一个新的图形类那么只需要继承这个基础图形类即可，无需在修改工具类Painting类里面的方法，这样就满足了开闭原则。 那么我们为什么要在基类Graph里面新添一个抽象方法而不让其他的子类的同一个名字来解决呢，因为painting这个方法的参数是基类的，如果只是单独修改子类的方法为draw那么就不满足多态的概念，仔细想想为什么吧。 开闭原则细节和注意事项 要是面向对象的编程，在开发过程中都会强调开闭原则 是最基础的设计原则，其他五个设计原则都是开闭原则的具体形态 可以提高代码的复用性 可以提高代码的可维护性 用抽象构建框架，用实现扩展细节 迪米特法则（最少知道原则）定义迪米特法则(Law of Demeter, LoD)是1987年秋天由lan holland在美国东北大学一个叫做迪米特的项目设计提出的，它要求一个对象应该对其他对象有最少的了解，所以迪米特法则又叫做最少知识原则（Least Knowledge Principle, LKP）。 举例举一个例子：有一个集团公司，下属单位有分公司和直属部门，现在要求打印出所有下属单位的员工ID。先来看一下违反迪米特法则的设计。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667//总公司员工class Employee&#123; private String id; public void setId(String id)&#123; this.id = id; &#125; public String getId()&#123; return id; &#125;&#125;//分公司员工class SubEmployee&#123; private String id; public void setId(String id)&#123; this.id = id; &#125; public String getId()&#123; return id; &#125;&#125;class SubCompanyManager&#123; public List&lt;SubEmployee&gt; getAllEmployee()&#123; List&lt;SubEmployee&gt; list = new ArrayList&lt;SubEmployee&gt;(); for(int i=0; i&lt;100; i++)&#123; SubEmployee emp = new SubEmployee(); //为分公司人员按顺序分配一个ID emp.setId("分公司"+i); list.add(emp); &#125; return list; &#125;&#125;class CompanyManager&#123; public List&lt;Employee&gt; getAllEmployee()&#123; List&lt;Employee&gt; list = new ArrayList&lt;Employee&gt;(); for(int i=0; i&lt;30; i++)&#123; Employee emp = new Employee(); //为总公司人员按顺序分配一个ID emp.setId("总公司"+i); list.add(emp); &#125; return list; &#125; public void printAllEmployee(SubCompanyManager sub)&#123; List&lt;SubEmployee&gt; list1 = sub.getAllEmployee(); for(SubEmployee e:list1)&#123; System.out.println(e.getId()); &#125; List&lt;Employee&gt; list2 = this.getAllEmployee(); for(Employee e:list2)&#123; System.out.println(e.getId()); &#125; &#125;&#125;//客户端public class Client&#123; public static void main(String[] args)&#123; CompanyManager e = new CompanyManager(); e.printAllEmployee(new SubCompanyManager()); &#125;&#125; 现在这个设计的主要问题出在CompanyManager中，根据迪米特法则，只与直接的朋友发生通信，而SubEmployee类并不是CompanyManager类的直接朋友（以局部变量出现的耦合不属于直接朋友），从逻辑上讲总公司只与他的分公司耦合就行了，与分公司的员工并没有任何联系，这样设计显然是增加了不必要的耦合。按照迪米特法则，应该避免类中出现这样非直接朋友关系的耦合。修改后的代码如下: 12345678910111213141516171819202122232425262728293031323334353637383940class SubCompanyManager&#123; public List&lt;SubEmployee&gt; getAllEmployee()&#123; List&lt;SubEmployee&gt; list = new ArrayList&lt;SubEmployee&gt;(); for(int i=0; i&lt;100; i++)&#123; SubEmployee emp = new SubEmployee(); //为分公司人员按顺序分配一个ID emp.setId("分公司"+i); list.add(emp); &#125; return list; &#125; public void printEmployee()&#123; List&lt;SubEmployee&gt; list = this.getAllEmployee(); for(SubEmployee e:list)&#123; System.out.println(e.getId()); &#125; &#125;&#125;class CompanyManager&#123; public List&lt;Employee&gt; getAllEmployee()&#123; List&lt;Employee&gt; list = new ArrayList&lt;Employee&gt;(); for(int i=0; i&lt;30; i++)&#123; Employee emp = new Employee(); //为总公司人员按顺序分配一个ID emp.setId("总公司"+i); list.add(emp); &#125; return list; &#125; public void printAllEmployee(SubCompanyManager sub)&#123; sub.printEmployee(); List&lt;Employee&gt; list2 = this.getAllEmployee(); for(Employee e:list2)&#123; System.out.println(e.getId()); &#125; &#125;&#125; 修改后，为分公司增加了打印人员ID的方法，总公司直接调用来打印，从而避免了与分公司的员工发生耦合。 迪米特法则的初衷是降低类之间的耦合，由于每个类都减少了不必要的依赖，因此的确可以降低耦合关系。但是凡事都有度，虽然可以避免与非直接的类通信，但是要通信，必然会通过一个“中介”来发生联系，例如本例中，总公司就是通过分公司这个“中介”来与分公司的员工发生联系的。过分的使用迪米特原则，会产生大量这样的中介和传递类，导致系统复杂度变大。所以在采用迪米特法则时要反复权衡，既做到结构清晰，又要高内聚低耦合。 合成复用原则 软件复用时，要尽量先使用组合或者聚合等关联关系来实现，其次才考虑使用继承关系来实现 问题由来：通常类的复用分为继承复用和合成复用两种，继承复用虽然有简单和易实现的优点，但它也存在以下缺点。 继承复用破坏了类的封装性。因为继承会将父类的实现细节暴露给子类，父类对子类是透明的，所以这种复用又称为“白箱”复用。子类与父类的耦合度高。父类的实现的任何改变都会导致子类的实现发生变化，这不利于类的扩展与维护。它限制了复用的灵活性。从父类继承而来的实现是静态的，在编译时已经定义，所以在运行时不可能发生变化。 解决方案：合成复用原则是通过将已有的对象纳入新对象中，作为新对象的成员对象来实现的，新对象可以调用已有对象的功能，从而达到复用]]></content>
      <categories>
        <category>学习</category>
        <category>算法</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>java</tag>
        <tag>设计模式</tag>
        <tag>原则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC详解]]></title>
    <url>%2F2020%2F02%2F23%2FJUC%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[什么是JUC juc就是java5.0提供的并发包 线程和进程进程：一个程序，QQ.exe Music.exe 程序的集合；一个进程往往可以包含多个线程，至少包含一个！Java默认有几个线程？ 2 个 mian、GC线程：开了一个进程 Typora，写字，自动保存（线程负责的）对于Java而言：Thread、Runnable、CallableJava 真的可以开启线程吗？ 开不了 123456789101112131415161718192021222324252627282930313233public synchronized void start() &#123; /** * This method is not invoked for the main method thread or "system" * group threads created/set up by the VM. Any new functionality added * to this method in the future may have to also be added to the VM. * * A zero status value corresponds to state "NEW". */ if (threadStatus != 0) throw new IllegalThreadStateException(); /* Notify the group that this thread is about to be started * so that it can be added to the group's list of threads * and the group's unstarted count can be decremented. */ group.add(this); boolean started = false; try &#123; start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ &#125; &#125; &#125; private native void start0(); 我们可以看到，真正开启线程的是start0这个方法，而且start0是一个native方法 并发编程的本质：充分利用CPU的资源 线程的状态在java中线程有6个状态 12345678910111213141516171819public enum State &#123; //新生 NEW, //运行 RUNNABLE, //阻塞 BLOCKED, //等待 WAITING, //超时等待 TIMED_WAITING, //终止 TERMINATED; &#125; LockLock接口的实现类 其中ReentrantLock通过构造方法的参数不同可以分为公平锁和非公平锁两种 公平锁：先来先执行 非公平锁：可以插队 synchronized和Lock的区别 Synchronized 内置的Java关键字， Lock 是一个Java类 Synchronized 无法判断获取锁的状态，Lock 可以判断是否获取到了锁 Synchronized 会自动释放锁，lock 必须要手动释放锁！如果不释放锁，死锁 Synchronized 线程 1（获得锁，阻塞）、线程2（等待，傻傻的等）；Lock锁就不一定会等待下 去； Synchronized 可重入锁，不可以中断的，非公平；Lock ，可重入锁，可以 判断锁，非公平（可以 自己设置）； Synchronized 适合锁少量的代码同步问题，Lock 适合锁大量的同步代码！ 生产者和消费者问题synchronized（存在虚假唤醒问题）下面的代码如果只有一个消费者和生产者没有问题，但是如果有多个则会产生虚假唤醒问题 当一个条件满足时，很多线程都被唤醒了，但是只有其中部分是有用的唤醒，其它的唤醒都是无用功，这就是虚假唤醒，解决方案就是把等待的判断条件缓存while，让他自旋 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * @author yang * @date 2020/4/23 下午 4:22 * 虚假唤醒 */public class Thread09 &#123; public static void main(String[] args) &#123; Tick tick = new Tick(); new Thread(()-&gt;&#123; try &#123; for (int i = 0; i &lt; 10; i++) &#123; tick.add(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;,"A").start(); new Thread(()-&gt;&#123; try &#123; for (int i = 0; i &lt; 10; i++) &#123; tick.sub(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;,"b").start(); &#125;&#125;class Tick&#123; private int num=0; public synchronized void add()throws Exception&#123; if(num!=0)&#123; this.wait(); &#125; System.out.println(Thread.currentThread().getName()+"---&gt;"+(++num)); this.notifyAll(); &#125; public synchronized void sub()throws Exception&#123; if(num&lt;=0)&#123; this.wait(); &#125; System.out.println(Thread.currentThread().getName()+"---&gt;"+(--num)); this.notifyAll(); &#125;&#125; JUC版本生产者和消费者模型在synchronized中我们使用的是wait()方法和notify()方法，在JUC中我们需要借助Condition类的await和signal方法实现相同的功能。 Condition就是一个监视器类,他和wait方法一致，需要绑定到一个锁上才能使用，并且Condition最重要的作用就是可以精确的通知和唤醒线程。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * @author yang * @date 2020/4/23 下午 4:59 * 生产者消费者使用JUC按照顺序执行 * A--&gt;B--&gt;C */public class Thread10 &#123; public static void main(String[] args) &#123; Tack tack = new Tack(); new Thread(()-&gt;&#123; for (int i = 0; i &lt; 10; i++) &#123; tack.printA(); &#125; &#125;).start(); new Thread(()-&gt;&#123; for (int i = 0; i &lt; 10; i++) &#123; tack.printB(); &#125; &#125;).start(); new Thread(()-&gt;&#123; for (int i = 0; i &lt; 10; i++) &#123; tack.printC(); &#125; &#125;).start(); &#125;&#125;//资源类class Tack&#123; private int num=1;//资源 private Lock lock=new ReentrantLock(); private Condition conditiona=lock.newCondition(); private Condition conditionb=lock.newCondition(); private Condition conditionc=lock.newCondition(); public void printA()&#123; lock.lock(); try &#123; while (num !=1)&#123; conditiona.await(); &#125; System.out.println(Thread.currentThread().getName()+"A"); num=2; conditionb.signal(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void printB()&#123; lock.lock(); try &#123; while (num !=2)&#123; conditionb.await(); &#125; System.out.println(Thread.currentThread().getName()+"B"); num=3; conditionc.signal(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void printC()&#123; lock.lock(); try &#123; while (num !=3)&#123; conditionc.await(); &#125; System.out.println(Thread.currentThread().getName()+"C"); num=1; conditiona.signal(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 我们使用Lock和Condition就可以实现非常复杂的解锁方式。 集合类不安全List不安全如果多个线程同时对List操作就会抛出并发修改异常ConcurrentModificationException 解决方案 使用list的替代Vector来实现 使用Collections.synchronizedList类的方法包装List 使用JUC提供的线程安全容器CopyOnWriteArrayList Set不安全如果多个线程同时对set操作就会抛出并发修改异常ConcurrentModificationException 解决方案 使用set的替代hashTable来实现 使用Collections.synchronizedSet类的方法包装set 使用JUC提供的线程安全容器ConcurrentHashMap 常用辅助类CountDownLatch(减法计数器) 123456789101112131415public class Thread11 &#123; // 计数器 public static void main(String[] args) throws InterruptedException &#123; // 总数是6，必须要执行任务的时候，再使用！ CountDownLatch countDownLatch = new CountDownLatch(6); for (int i = 1; i &lt;=6 ; i++) &#123; new Thread(()-&gt;&#123; System.out.println(Thread.currentThread().getName()+" Go out"); countDownLatch.countDown(); // 数量-1 &#125;,String.valueOf(i)).start(); &#125; countDownLatch.await(); // 等待计数器归零，然后再向下执行 System.out.println("Close Door"); &#125;&#125; 原理countDownLatch.countDown();//数量-1 countDownLatch.await();//计数器为零才执行 CyclicBarrier加法计数器1234567891011121314151617181920212223242526public class Thread11 &#123; // 计数器 public static void main(String[] args) throws InterruptedException &#123; /** * 集齐7颗龙珠召唤神龙 */ // 召唤龙珠的线程 CyclicBarrier cyclicBarrier = new CyclicBarrier(7, () -&gt; &#123; System.out.println("召唤神龙成功！"); &#125;); for (int i = 1; i &lt;= 7; i++) &#123; final int temp = i;// lambda能不能操作到i,需要借助final来控制 new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + "收集" + temp + "个龙珠"); try &#123; cyclicBarrier.await(); // 等待 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125; &#125;&#125; Semaphore信号量 可以用来限流 12345678910111213141516171819202122public class Thread11 &#123; // 计数器 public static void main(String[] args) throws InterruptedException &#123; // 线程数量：停车位! 限流！ Semaphore semaphore = new Semaphore(3); for (int i = 1; i &lt;=6 ; i++) &#123; new Thread(()-&gt;&#123; // acquire() 得到 try &#123; semaphore.acquire(); System.out.println(Thread.currentThread().getName()+"抢到车 位"); TimeUnit.SECONDS.sleep(2); System.out.println(Thread.currentThread().getName()+"离开车 位"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; semaphore.release(); // release() 释放 &#125; &#125;,String.valueOf(i)).start(); &#125; &#125;&#125; 原理：semaphore.acquire() 获得，假设如果已经满了，等待，等待被释放为止！ semaphore.release(); 释放，会将当前的信号量释放 + 1，然后唤醒等待的线程！作用： 多个共享资源互斥的使用！并发限流，控制最大的线程数！ 读写锁读写锁在读取的时候是共享锁，在写的时候是排它锁，可能有疑问，在写的时候加锁，读的时候不加锁不是也能实现类似读写锁的功能吗？其实读写锁还有个特点是共享锁和排它锁要互斥，否则会出现脏读或者幻读的问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990package thread;import java.util.HashMap;import java.util.Map;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReadWriteLock;import java.util.concurrent.locks.ReentrantLock;import java.util.concurrent.locks.ReentrantReadWriteLock;/** * @author yang * @date 2020/4/25 下午 6:35 * * 独占锁（写锁） 一次只能被一个线程占有 * 共享锁（读锁） 多个线程可以同时占有 * ReadWriteLock * 读-读 可以共存！ * 读-写 不能共存！ * 写-写 不能共存！ * */public class Thread11 &#123; public static void main(String[] args) throws InterruptedException &#123; MyCache myCache = new MyCache(); for (int i = 1; i &lt;= 5 ; i++) &#123; final int temp = i; new Thread(()-&gt;&#123; myCache.put(temp+"",temp+""); &#125;,String.valueOf(i)).start(); &#125; // 读取 for (int i = 1; i &lt;= 5 ; i++) &#123; final int temp = i; new Thread(()-&gt;&#123; myCache.get(temp+""); &#125;,String.valueOf(i)).start(); &#125; &#125;&#125;// 加锁的class MyCacheLock&#123; private volatile Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); // 读写锁： 更加细粒度的控制 private ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); private Lock lock = new ReentrantLock(); // 存，写入的时候，只希望同时只有一个线程写 public void put(String key,Object value)&#123; readWriteLock.writeLock().lock(); try &#123; System.out.println(Thread.currentThread().getName()+"写入"+key); map.put(key,value); System.out.println(Thread.currentThread().getName()+"写入OK"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; readWriteLock.writeLock().unlock(); &#125; &#125; // 取，读，所有人都可以读！ public void get(String key)&#123; readWriteLock.readLock().lock(); try &#123; System.out.println(Thread.currentThread().getName()+"读取"+key); Object o = map.get(key); System.out.println(Thread.currentThread().getName()+"读取OK"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; readWriteLock.readLock().unlock(); &#125; &#125;&#125;/*** 自定义缓存*/class MyCache&#123; private volatile Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); // 存，写 public void put(String key,Object value)&#123; System.out.println(Thread.currentThread().getName()+"写入"+key); map.put(key,value); System.out.println(Thread.currentThread().getName()+"写入OK"); &#125; // 取，读 public void get(String key)&#123; System.out.println(Thread.currentThread().getName()+"读取"+key); Object o = map.get(key); System.out.println(Thread.currentThread().getName()+"读取OK"); &#125;&#125; 队列 四组API 操作 抛出异常 有返回值，不抛出异常 阻塞等待 超时等待 添加 add offer put offer(,,) 移除 remove poll() take poll(,,) 检测队首元素 element peek - - 123456789101112131415161718/*** 抛出异常*/public static void test1()&#123; // 队列的大小 ArrayBlockingQueue blockingQueue = new ArrayBlockingQueue&lt;&gt;(3); System.out.println(blockingQueue.add("a")); System.out.println(blockingQueue.add("b")); System.out.println(blockingQueue.add("c")); // IllegalStateException: Queue full 抛出异常！ // System.out.println(blockingQueue.add("d")); System.out.println("=-==========="); System.out.println(blockingQueue.remove()); System.out.println(blockingQueue.remove()); System.out.println(blockingQueue.remove()); // java.util.NoSuchElementException 抛出异常！ // System.out.println(blockingQueue.remove());&#125; 1234567891011121314151617/*** 有返回值，没有异常*/public static void test2()&#123; // 队列的大小 ArrayBlockingQueue blockingQueue = new ArrayBlockingQueue&lt;&gt;(3); System.out.println(blockingQueue.offer("a")); System.out.println(blockingQueue.offer("b")); System.out.println(blockingQueue.offer("c")); // System.out.println(blockingQueue.offer("d")); // false 不抛出异常！ System.out.println("============================"); System.out.println(blockingQueue.poll()); System.out.println(blockingQueue.poll()); System.out.println(blockingQueue.poll()); System.out.println(blockingQueue.poll()); // null 不抛出异常！&#125; 1234567891011121314151617/*** 等待，阻塞（一直阻塞）*/public static void test3() throws InterruptedException &#123; // 队列的大小 ArrayBlockingQueue blockingQueue = new ArrayBlockingQueue&lt;&gt;(3); // 一直阻塞 blockingQueue.put("a"); blockingQueue.put("b"); blockingQueue.put("c"); // blockingQueue.put("d"); // 队列没有位置了，一直阻塞 System.out.println(blockingQueue.take()); System.out.println(blockingQueue.take()); System.out.println(blockingQueue.take()); System.out.println(blockingQueue.take()); // 没有这个元素，一直阻塞&#125; 1234567891011121314151617/*** 等待，阻塞（等待超时）*/public static void test4() throws InterruptedException &#123; // 队列的大小 ArrayBlockingQueue blockingQueue = new ArrayBlockingQueue&lt;&gt;(3); blockingQueue.offer("a"); blockingQueue.offer("b"); blockingQueue.offer("c"); // blockingQueue.offer("d",2,TimeUnit.SECONDS); // 等待超过2秒就退出 System.out.println("==============="); System.out.println(blockingQueue.poll()); System.out.println(blockingQueue.poll()); System.out.println(blockingQueue.poll()); blockingQueue.poll(2,TimeUnit.SECONDS); // 等待超过2秒就退出&#125; 使用同步队列实现生产者和消费者1234567891011121314151617181920212223242526272829303132333435import java.util.concurrent.ArrayBlockingQueue;/** * @author yang * @date 2020/5/3 16:30 */public class Test05 &#123; static ArrayBlockingQueue&lt;String&gt; queue= new ArrayBlockingQueue(1); public static void main(String[] args) &#123; //生产者 new Thread(()-&gt;&#123; for (int i = 0; i &lt; 10; i++) &#123; try &#123; queue.put(Integer.toString(i)); System.out.println("生产了"+i+"物品"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); //消费者 new Thread(()-&gt;&#123; for (int i = 0; i &lt; 10; i++) &#123; try &#123; String take = queue.take(); System.out.println("消费了"+take+"物品"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125;&#125; SynchronousQueue 同步队列1234567891011121314151617181920212223242526272829303132333435/*** 同步队列* 和其他的BlockingQueue 不一样， SynchronousQueue 不存储元素* put了一个元素，必须从里面先take取出来，否则不能在put进去值！*/public class SynchronousQueueDemo &#123;public static void main(String[] args) &#123;BlockingQueue&lt;String&gt; blockingQueue = new SynchronousQueue&lt;&gt;(); // 同步队列 new Thread(()-&gt;&#123; try &#123; System.out.println(Thread.currentThread().getName()+" put 1"); blockingQueue.put("1"); System.out.println(Thread.currentThread().getName()+" put 2"); blockingQueue.put("2"); System.out.println(Thread.currentThread().getName()+" put 3"); blockingQueue.put("3"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;,"T1").start(); new Thread(()-&gt;&#123; try &#123; TimeUnit.SECONDS.sleep(3); System.out.println(Thread.currentThread().getName()+"=&gt;"+blockingQueue.take()); TimeUnit.SECONDS.sleep(3); System.out.println(Thread.currentThread().getName()+"=&gt;"+blockingQueue.take()); TimeUnit.SECONDS.sleep(3); System.out.println(Thread.currentThread().getName()+"=&gt;"+blockingQueue.take()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;,"T2").start(); &#125;&#125; 线程池三大方法 12345678910111213141516171819202122// Executors 工具类、3大方法public class Demo01 &#123; public static void main(String[] args) &#123; ExecutorService threadPool = Executors.newSingleThreadExecutor();// 单个线程 //ExecutorService threadPool = Executors.newFixedThreadPool(5); // 创建一个固定的线程池的大小 // ExecutorService threadPool = Executors.newCachedThreadPool(); // 可伸缩 的，遇强则强，遇弱则弱 try &#123; for (int i = 0; i &lt; 100; i++) &#123; // 使用了线程池之后，使用线程池来创建线程 threadPool.execute(()-&gt;&#123; System.out.println(Thread.currentThread().getName()+" ok"); &#125;); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 线程池用完，程序结束，关闭线程池 threadPool.shutdown(); &#125; &#125;&#125; 7大参数123456789public ThreadPoolExecutor( int corePoolSize, // 核心线程池大小 int maximumPoolSize, // 最大核心线程池大小 long keepAliveTime, // 超时了没有人调用就会释放 TimeUnit unit, // 超时单位 BlockingQueue&lt;Runnable&gt; workQueue, // 阻塞队列 ThreadFactory threadFactory, // 线程工厂：创建线程的，一般不用动 RejectedExecutionHandler handle // 拒绝策略) 4种拒绝策略 123456/*** new ThreadPoolExecutor.AbortPolicy() // 满了，还有人进来，不处理这个人的，抛出异常 *new ThreadPoolExecutor.CallerRunsPolicy() // 哪来的去哪里！* new ThreadPoolExecutor.DiscardPolicy() //队列满了，丢掉任务，不会抛出异常！* new ThreadPoolExecutor.DiscardOldestPolicy() //队列满了，尝试去和最早的竞争，也不会抛出常！*/ 线程池的大小如何设置IO密集型 线程数大于CPU核心数即可，最佳是2倍 CPU密集型 线程数和CPU数相同即可]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>JUC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA泛型详解]]></title>
    <url>%2F2020%2F02%2F22%2FJAVA%E6%B3%9B%E5%9E%8B%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[JAVA泛型详解泛型只存在于编译期。 泛型的定义以及存在意义泛型，即“参数化类型”。这是JDK1.5引入的新特性,就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。**而且还可以像参数那样限定传入的类型。** 顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。 泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。 当我们不指定泛型的时候呢1234567891011121314public class EnuTest&#123; private static int a=0; public static void main(String[] args) throws Exception&#123; Father stringFather = new Father(); System.out.println(stringFather.get(new Object()).getClass());//Object类型 System.out.println(stringFather.getClass());//stringFather的类型并不受T的影响 &#125;&#125;class Father &lt;T&gt;&#123; public T get(T e)&#123; return e; &#125;&#125; 为什么泛型里面数据类型不能是基本类型呢？ 因为虚拟机在编译时会把带泛型的转换成Object类型，而基本类型不属于Object类型，所以泛型里面数据类型不能是基本类型。 为什么要使用泛型呢？ Java语言引入泛型的好处是安全简单。泛型的好处是在编译的时候检查类型安全，并且所有的强制转换都是自动和隐式的，提高代码的重用率。 例如：GenericClass{} 一些常用的泛型类型变量： E：元素（Element），多用于java集合框架 K：关键字（Key） N：数字（Number） T：类型（Type） V：值（Value） 如果要实现不同类型的加法，每种类型都需要重载一个add方法 1234567891011121314151617181920212223242526272829303132public class NeedGeneric &#123; private static int add(int a, int b) &#123; System.out.println(a + "+" + b + "=" + (a + b)); return a + b; &#125; private static float add(float a, float b) &#123; System.out.println(a + "+" + b + "=" + (a + b)); return a + b; &#125; private static double add(double a, double b) &#123; System.out.println(a + "+" + b + "=" + (a + b)); return a + b; &#125; private static &lt;T extends Number&gt; double add(T a, T b) &#123; System.out.println(a + "+" + b + "=" + (a.doubleValue() + b.doubleValue())); return a.doubleValue() + b.doubleValue(); &#125; public static void main(String[] args) &#123; NeedGeneric1.add(1, 2); NeedGeneric1.add(1f, 2f); NeedGeneric1.add(1d, 2d); NeedGeneric1.add(Integer.valueOf(1), Integer.valueOf(2)); NeedGeneric1.add(Float.valueOf(1), Float.valueOf(2)); NeedGeneric1.add(Double.valueOf(1), Double.valueOf(2)); &#125;&#125; 取出集合元素时需要人为的强制类型转化到具体的目标类型，且很容易现“java.lang. ClassCastException”异常。 1234567891011121314151617181920212223import java.util.ArrayList;import java.util.List;public class NeedGeneric2 &#123; static class C&#123; &#125; public static void main(String[] args) &#123; List list=new ArrayList(); list.add("A"); list.add("B"); list.add(new C()); list.add(100); //1.当我们将一个对象放入集合中，集合不会记住此对象的类型，当再次从集合中取出此对象时，改对象的编译类型变成了Object类型，但其运行时类型任然为其本身类型。 //2.因此，//1处取出集合元素时需要人为的强制类型转化到具体的目标类型，且很容易出现“java.lang.ClassCastException”异常。 for (int i = 0; i &lt; list.size(); i++) &#123;// System.out.println(list.get(i)); String value= (String) list.get(i); System.out.println(value); &#125; &#125;&#125; 所以使用泛型的意义在于1,适用于多种数据类型执行相同的代码（代码复用） 2, 泛型中的类型在使用时指定，不需要强制类型转换（类型安全，编译器会检查类型） 泛型类1234567891011class MyString &lt;T&gt;&#123;//泛型语法&lt;T,T,T&gt; T str; public T getStr() &#123; return str; &#125; public void setStr(T str) &#123; this.str = str; &#125;&#125; 这个就是泛型类的使用，但要注意的是，这个类是泛型类，方法却不是泛型方法，并且这些普通方便不能是静态的 一个类继承泛型类泛型类继承泛型类1234class Father &lt;T&gt;&#123;&#125;class Son&lt;E&gt; extends Father&lt;E&gt;&#123;//要是E,子类和父类必须都是E,要是T,必须都是T&#125; 子类泛型必须要有父类泛型的标识符 如果子类泛型想有新的泛型，只需要新增即可 1234class Father &lt;T&gt;&#123;&#125;class Son&lt;E,T&gt; extends Father&lt;E&gt;&#123;//虽然新加入了一个T，但是子类和父类的泛型标识要一致&#125; 为什么必须这样呢其实原因也很容易想到 假如java允许子类使用泛型的时候不声名父类类型，那么如果子类继承了父类的一些具有父类泛型类型的属性,那么父类的那些泛型应该是什么泛型呢？这样是不是就导致了父类泛型没有了意义。 证明1234class Father &lt;T&gt;&#123;&#125;class Son&lt;E&gt; extends Father&lt;String&gt;&#123;//这样子类就可以不用事先声明父类的泛型类型了,原因是已经知道了父类泛型类型&#125; 事实上这样都是为了保证父类泛型可知 普通类继承泛型类1234class Father &lt;T&gt;&#123;&#125;class Son extends Father&lt;String&gt;&#123;//必须指定父类泛型的类型&#125; 子类继承的时候要标识出来父类的类型 为什么会这样呢其实原因和上面一样，就怕子类不说明父类类型，那么父类类型也就没有意义了 泛型接口普通类实现泛型接口1234interface InterfaceFather &lt;T&gt;&#123;&#125;class Son implements InterfaceFather&lt;String&gt;&#123;&#125; 用法和泛型类一模一样 泛型类实现泛型接口1234interface InterfaceFather &lt;T&gt;&#123;&#125;class Son&lt;E&gt; implements InterfaceFather&lt;E&gt;&#123;&#125; 方法泛型只有在方法的返回值和方法的访问权限修饰符中间声明的泛型的参数才算泛型方法. 123456class Father &lt;T&gt;&#123; public &lt;E,T&gt; E getValue(T para)&#123; E rel=null; return rel; &#125;&#125; 值得注意的是，泛型方法可以声明为静态的，前提是不能使用到类的非静态方法和非静态变量。 12345class Father &lt;T&gt;&#123; public static &lt;V&gt; void getValue()&#123; &#125;&#125; 还有一点如果方法声明的泛型的标识和类泛型的标识一致，那么方法的泛型标识在这个方法的标识作用域中会覆盖类泛型的标识。 换句话说，如果类泛型标识和方法标识相同那么类标识对这个方法来说是失效的 泛型的通配符在使用”？“只能接收，不能修改。 问题描述java里面类和类之间是有继承关系 的，比如Cat extends Animals,那么Cat就是Animal的子类，但是集合是没有继承这个概念的，比如List&lt;Cat&gt; catList和List&lt;Animals&gt; animalList你不能说 animalList是catList的父类，所以很难看出来这两个类之间的联系，但是我们现在只想让list里面只加入Animals的子类怎么办呢？ 一种是Animals有多少个子类就定义多少个list，这种方法虽然也可以实现但是Animals如果有一百个，一千个，一万个子类呢你这种方法是不是就太耗时了呢。 第二种就是用通配符来实现。比如：List animals 这个时候animals就只能添加Animals的子类了，一个list搞定。 1234567891011121314151617181920public class Test &#123; public static void main(String []args)&#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(1); list.add(2); list.add(3); list.add(4); List&lt;String&gt; stringList = new ArrayList&lt;&gt;(); stringList.add("h"); stringList.add("e"); stringList.add("l"); stringList.add("l"); stringList.add("o"); getList(stringList); getList(list); &#125; //无论传入什么List都会被接收 public static List getList(List&lt;?&gt; list)&#123; return list; &#125; 用List声明的List 不能使用add方法，因为你不知道的类型是什么，但是list.add(null)就可以，因为null是所有类型都有的。举个例子 123456public static List getList(List&lt;?&gt; list)&#123; // list.add(1);//会报参数不匹配的错误,编译期报错 // list.add("hello");//会报参数不匹配的错误,编译期报错 list.add(null);//添加成功 return list;&#125; 用get方法也只能用Object来接收，因为你不知道你的类型是什么。 123456public static List getList(List&lt;?&gt; list)&#123; int i = list.get(0); //编译期报错 String j = list.get(1); //编译期报错 Object o = list.get(3); //运行正确 return list;&#125; 但是这样又带来了新的问题，因为他可以传递任意类型List集合的泛型，所有有可能他瞎传，既然泛型就是参数化类型，那么能不能像参数那样限定类型呢。（当然这些限定不是非要使用集合才能使用这些限定的） 上边界通配符号(也叫泛型的上限)可以接收E以及E的子类型的泛型，这里面的E不止是类哦，也可以是接口，看个例子。 12345678910111213141516171819202122232425262728293031323334//这个是继承了类的用法 public class Test &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(1); getList(list); List&lt;String&gt; strings = new ArrayList&lt;&gt;(); strings.add("hello"); getList(strings);//编译期报错 &#125; public static List getList(List&lt;? extends Number&gt; list) &#123; return list; &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(1); getList(list);// 编译期报错 List&lt;Test2&gt; test2s = new ArrayList&lt;&gt;(); getList(test2s); &#125; //上边界为接口的实现，只要是实现了此接口的类都可以被当做泛型传进来 public static List getList(List&lt;? extends Test1&gt; list) &#123; return list; &#125;&#125;interface Test1&#123;&#125;class Test2 implements Test1&#123;&#125; 以上可知上边界就是你传入的类型必须得是E的子类，或者是实现接口的类。 下边界通配符（泛型的下限） 就是传入的类型必须得是E以及E的父类，举个例子 123456789101112131415161718public class Test &#123; public static void main(String[] args) &#123; List&lt;Animals&gt; animals = new ArrayList&lt;&gt;(); getList(animals); List&lt;Cat&gt; cats = new ArrayList&lt;&gt;(); getList(cats); List&lt;Dog&gt; dogs = new ArrayList&lt;&gt;(); getList(dogs);//编译出错，因为Dog不是Cat的父类 &#125; public static List getList(List&lt;? super Cat&gt; list) &#123; return list; &#125;&#125;class Animals&#123;&#125;class Cat extends Animals&#123;&#125;class Dog extends Animals&#123;&#125; 上下边界通配符的副作用上边界通配符会导致修改失效，但是获取有效 下边界通配符会导致获取有效，但是修改失效 PECS原则 频繁往外读取内容的，适合用上界Extends。 经常往里插入的，适合用下界Super。 泛型上下限的理解假设A的子类有B和C两个 B的子类有B1 C的子类有C1 泛型的上限理解那么List&lt; ? extends A &gt; list1就表示泛型的上限。 那么下面的赋值都是正确的 List&lt; ? extends A &gt; list1=List&lt; B &gt;(); List&lt; ? extends A &gt; list1=List&lt; B1 &gt;(); List&lt; ? extends A &gt; list1=List&lt; C &gt;(); List&lt; ? extends A &gt; list1=List&lt; C1 &gt;(); 如果list1是可以被添加的话，那么这就会出现问题， 假设此时List&lt; ? extends A &gt; list1=List&lt; B &gt;();此时如果add一个B1类那么是一点问题都没有的，如果此时add的是一个C1对象呢？这就会出现问题，因为C1对象不是B的子类呀！List&lt; ? extends A &gt;指的是所有对象是A的子类即可，但是具体是拿一个子类在编译期还是一个未知数。 如果list1可以获取呢？ 显然没有任何问题，因为他们都是一个类的子类。 泛型的下限理解上限我个人认为泛型的上限多用于消费者场景，泛型的本质就是保证类型安全，假设有如下需求，我们作为开发者需要实现一个工具，该工具有个方法，可以传入一个集合类型，并且实现该集合类型中的所有包装类型相加。 方案一使用重载,实现多个方法 1234567public static void sum(List&lt;Integer&gt; list)&#123; ...&#125;public static void sum(List&lt;Double&gt; list)&#123; ...&#125;... 显然这样是不可取的 方案二使用泛型通配符?因为Integer是Number类的子类，但是List&lt; integer &gt;并不是List&lt; Number &gt;的子类，所有需要泛型通配符来表示这个关系 123public static void sum(List&lt;?&gt; list)&#123; ...&#125; 但是这样又有一个弊端 12345678910111213141516171819202122public class AddUtil &#123; public static void main(String[] args) &#123; List&lt;Number&gt; list=new ArrayList&lt;&gt;(); list.add(new Integer(3)); list.add(new Double(3.2)); list.add(new Long(3)); sum(list); //上面的代码没有问题可以正常工作，但是下面的代码就不能保证这个工具类的正常使用,因为你没有限制传入的类型 List&lt;String&gt; list1=new ArrayList&lt;&gt;(); list1.add(new String("123")); sum(list1); &#125; public static void sum(List&lt;?&gt; list)&#123; double sum=0; for (Object number : list) &#123; sum+=Double.parseDouble(number.toString()); &#125; System.out.println(sum); &#125;&#125; 方式三使用泛型的上限12345678910111213141516171819202122232425public class AddUtil &#123; public static void main(String[] args) &#123; List&lt;Number&gt; list=new ArrayList&lt;&gt;(); list.add(new Integer(3)); list.add(new Double(3.2)); list.add(new Long(3)); sum(list); List&lt;String&gt; list1=new ArrayList&lt;&gt;(); sum(list1); &#125; /** * 一个求和工具类,可以将传入的list集合中的所有包装类型求和 * @param list 包装类型的集合 * @return */ public static double sum(List&lt;? extends Number&gt; list)&#123; double sum=0; for (Number number : list) &#123; sum+=number.doubleValue(); &#125; return sum; &#125;&#125; 到此完美收工，泛型的上限就可以用来做类的时候限制传入的参数类型，即泛型的本质“类型化参数”。 泛型的下限这个目前还没有想清楚，以后想清楚了会继续更新。]]></content>
      <tags>
        <tag>JAVA</tag>
        <tag>泛型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[电路基础]]></title>
    <url>%2F2020%2F02%2F16%2F%E7%94%B5%E8%B7%AF%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[前言 最近在学习51单片机，但是无奈初中电路知识忘了，结果难以理解现在的一些东西，比如上拉电阻，于是乎我打算学习一下电路的基本知识. 欧姆定律在同一电路中，通过某一导体的电流跟这段导体两端的电压成正比，跟这段导体的电阻成反比,这就是欧姆定律. U=I*R I=U/R 分压定律和分流定律在串联电路中，各电阻上的电流相等，各电阻两端的电压之和等于电路总电压。可知每个电阻上的电压小于电路总电压，故串联电阻分压。 在并联电路中，各电阻两端的电压相等，各电阻上的电流之和等于总电流（干路电流）。可知每个电阻上的电流小于总电流（干路电流），故并联电阻分流。 电阻的串并联就好像水流，串联只有一条道路，电阻越大，流的越慢，并联的支路越多，电流越大。 那么问题来了怎么计算并联电路的支路上的电流呢 例子分流假设有一个并联电路，其中有两个路，我们假设这两条支路个有一个电阻。 分路1电流=干路电流*分路2电阻/（分路电阻1+分路电阻2） 分压假设有一个串联电路，其中有两个电阻 电阻1电压=总电压*(电阻1大小)/(电阻1+电阻2) 其实能把这些电路知识想象成水流就能明白很多了，例如电流的大小就是水流的大小，电阻就是河道对水流的阻碍，电压大小就是水流速度，那么久很容易啦(^o^)/~]]></content>
      <categories>
        <category>单片机</category>
      </categories>
      <tags>
        <tag>电路</tag>
        <tag>单片机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot缓存详解]]></title>
    <url>%2F2020%2F02%2F14%2FSpringboot%E7%BC%93%E5%AD%98%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[缓存的作用 缓存就是用于数据交换的缓冲区，一半特点就是速度快。 1.热点数据放入缓存以减少对数据库的访问次数2.临时数据放入缓存中减少数据库的压力，例如短信验证码3分钟有效就可以放入缓存中，超过3分钟就从缓存中去掉。不同缓存的作用操作系统磁盘缓存 ——&gt; 减少磁盘机械操作。数据库缓存——&gt;减少文件系统IO。应用程序缓存——&gt;减少对数据库的查询。Web服务器缓存——&gt;减少应用服务器请求。客户端浏览器缓存——&gt;减少对网站的访问。 缓存的策略1.基于访问时间 2.基于频率 3.基于访问模式 JSR107jsr107定义了5个核心接口 CachingProvider缓存提供者，定义了创建、配置、获取、管理多个CachingManager,并且一个java应用可以在运行期有多个CachingProviderCachingManage缓存管理器，定义了创建、配置、获取、管理多个唯一命名的Cache,这些Cache存在CacheManage的上下文中，并且CacheManage只能被一个CachingProvider拥有Cache是一个类似Map的数据结构并临时存储以Key为索引的值。一个Cache仅被一个CacheManager所拥有。Entry是一个存储在Cache中的key-value对。Expiry每一个存储在Cache中的条目有一个定义的有效期。一旦超过这个时间，条目为过期的状态。一旦过期，条目将不可访问、更新和删除。缓存有效期可以通过ExpiryPolicy设置。springboot缓存抽象Spring从3.1开始定义了org.springframework.cache.Cache和org.springframework.cache.CacheManager接口来统一不同的缓存技术；并支持使用JCache（JSR-107）注解简化我们开发； Cache接口为缓存的组件规范定义，包含缓存的各种操作集合； Cache接口下Spring提供了各种xxxCache的实现；如RedisCache，EhCacheCache , ConcurrentMapCache等； 每次调用需要缓存功能的方法时，Spring会检查检查指定参数的指定的目标方法是否已经被调用过；如果有就直接从缓存中获取方法调用后的结果，如果没有就调用方法并缓存结果后返回给用户。下次调用直接从缓存中获取。 使用Spring缓存抽象时我们需要关注以下两点； 确定方法需要被缓存以及他们的缓存策略 从缓存中读取之前缓存存储的数据 三、 几个重要概念和缓存注解 Cache 缓存接口，定义缓存操作。实现有： RedisCache、 EhCacheCache、 ConcurrentMapCache等 CacheManager 缓存管理器，管理各种缓存（Cache）组件 @Cacheable 主要针对方法配置，能够根据方法的请求参数对其结果进行缓存 @CacheEvict 清空缓存 @CachePut 保证方法被调用，又希望结果被缓存。 @EnableCaching 开启基于注解的缓存 keyGenerator 缓存数据时key生成策略 serialize 缓存数据时value序列化策略 简要说明： @Cacheable注解加载方法中，那么该方法第一次会查询数据库，然后就会吧数据放在缓存中，使用Cache 进行数据的读取等操作。 @CacheEvict删除缓存，例如根据id删除用户，那么也要删除缓存中的用户信息 @CachePut更新缓存，例如更新用户信息后，同时也要更新缓存中的用户信息 Cache SpEL available metadata 名字 位置 描述 示例 methodName root object 当前被调用的方法名 #root.methodName method root object 当前被调用的方法 #root.method.name target root object 当前被调用的目标对象 #root.target targetClass root object 当前被调用的目标对象类 #root.targetClass args root object 当前被调用的方法的参数列表 #root.args[0] caches root object 当前方法调用使用的缓存列表（如@Cacheable(value={“cache1”, “cache2”})）， 则有两个cache #root.caches[0].name argument name evaluation context 方法参数的名字. 可以直接 #参数名 ，也可以使用 #p0或#a0 的 形式， 0代表参数的索引； #iban 、 #a0 、 #p0 result evaluation context 方法执行后的返回值（仅当方法执行之后的判断有效，如 ‘unless’ ， ’cache put’的表达式 ’cache evict’的表达式 beforeInvocation=false） #result 四、缓存使用 1、引入spring-boot-starter-cache模块 2、 @EnableCaching开启缓存 3、使用缓存注解 4、切换为其他缓存* SpELSpring Cache提供了一些供我们使用的SpEL上下文数据，下表直接摘自Spring官方文档： 名称 位置 描述 示例 methodName root对象 当前被调用的方法名 #root.methodname method root对象 当前被调用的方法 #root.method.name target root对象 当前被调用的目标对象实例 #root.target targetClass root对象 当前被调用的目标对象的类 #root.targetClass args root对象 当前被调用的方法的参数列表 #root.args[0] caches root对象 当前方法调用使用的缓存列表 #root.caches[0].name Argument Name 执行上下文 当前被调用的方法的参数，如findArtisan(Artisan artisan),可以通过#artsian.id获得参数 #artsian.id result 执行上下文 方法执行后的返回值（仅当方法执行后的判断有效，如 unless cacheEvict的beforeInvocation=false） #result 注意： 1.当我们要使用root对象的属性作为key时我们也可以将“#root”省略，因为Spring默认使用的就是root对象的属性。 如 1@Cacheable(key = &quot;targetClass + methodName +#p0&quot;) 2.使用方法参数时我们可以直接使用“#参数名”或者“#p参数index”。 如： 12@Cacheable(value=&quot;users&quot;, key=&quot;#id&quot;)@Cacheable(value=&quot;users&quot;, key=&quot;#p0&quot;) SpEL提供了多种运算符 类型 运算符 关系 &lt;，&gt;，&lt;=，&gt;=，==，!=，lt，gt，le，ge，eq，ne 算术 +，- ，* ，/，%，^ 逻辑 &amp;&amp;，||，!，and，or，not，between，instanceof 条件 ?: (ternary)，?: (elvis) 正则表达式 matches 其他类型 ?.，?[…]，![…]，^[…]，$[…] 演示1.开始使用前需要导入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;&lt;/dependency&gt; 2.然后在启动类注解@EnableCaching开启缓存123456789@SpringBootApplication@EnableCaching //开启缓存public class DemoApplication&#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 3.缓存@Cacheable``@Cacheable注解会先查询是否已经有缓存，有会使用缓存，没有则会执行方法并缓存。 1234@Cacheable(value = &quot;emp&quot; ,key = &quot;targetClass + methodName +#p0&quot;)public List&lt;NewJob&gt; queryAll(User uid) &#123; return newJobDao.findAllByUid(uid);&#125; 此处的value是必需的，它指定了你的缓存存放在哪块命名空间。 此处的key是使用的spEL表达式，参考上章。这里有一个小坑，如果你把methodName换成method运行会报错，观察它们的返回类型，原因在于methodName是String而methoh是Method。 此处的User实体类一定要实现序列化public class User implements Serializable，否则会报java.io.NotSerializableException异常。 到这里，你已经可以运行程序检验缓存功能是否实现。 深入源码，查看它的其它属性 我们打开@Cacheable注解的源码，可以看到该注解提供的其他属性，如： 1234567String[] cacheNames() default &#123;&#125;; //和value注解差不多，二选一String keyGenerator() default &quot;&quot;; //key的生成器。key/keyGenerator二选一使用String cacheManager() default &quot;&quot;; //指定缓存管理器String cacheResolver() default &quot;&quot;; //或者指定获取解析器String condition() default &quot;&quot;; //条件符合则缓存String unless() default &quot;&quot;; //条件符合则不缓存boolean sync() default false; //是否使用异步模式 4.配置@CacheConfig当我们需要缓存的地方越来越多，你可以使用@CacheConfig(cacheNames = {&quot;myCache&quot;})注解来统一指定value的值，这时可省略value，如果你在你的方法依旧写上了value，那么依然以方法的value值为准。 使用方法如下： 123456789@CacheConfig(cacheNames = &#123;"myCache"&#125;)public class BotRelationServiceImpl implements BotRelationService &#123; @Override @Cacheable(key = "targetClass + methodName +#p0")//此处没写value public List&lt;BotRelation&gt; findAllLimit(int num) &#123; return botRelationRepository.findAllLimit(num); &#125;&#125; 查看它的其它属性 123String keyGenerator() default ""; //key的生成器。key/keyGenerator二选一使用String cacheManager() default ""; //指定缓存管理器String cacheResolver() default ""; //或者指定获取解析器 5.更新@CachePut@CachePut注解的作用 主要针对方法配置，能够根据方法的请求参数对其结果进行缓存，和 @Cacheable 不同的是，它每次都会触发真实方法的调用 。简单来说就是用户更新缓存数据。但需要注意的是该注解的value 和 key 必须与要更新的缓存相同，也就是与@Cacheable 相同。示例： 123456789101112@CachePut(value = "emp", key = "targetClass + #p0")public NewJob updata(NewJob job) &#123; NewJob newJob = newJobDao.findAllById(job.getId()); newJob.updata(job); return job;&#125;@Cacheable(value = "emp", key = "targetClass +#p0")//清空缓存public NewJob save(NewJob job) &#123; newJobDao.save(job); return job;&#125; 查看它的其它属性 123456String[] cacheNames() default &#123;&#125;; //与value二选一String keyGenerator() default ""; //key的生成器。key/keyGenerator二选一使用String cacheManager() default ""; //指定缓存管理器String cacheResolver() default ""; //或者指定获取解析器String condition() default ""; //条件符合则缓存String unless() default ""; //条件符合则不缓存 6.清除@CacheEvict@CachEvict 的作用 主要针对方法配置，能够根据一定的条件对缓存进行清空 。 属性 解释 示例 allEntries 是否清空所有缓存内容，缺省为 false，如果指定为 true，则方法调用后将立即清空所有缓存 @CachEvict(value=”testcache”,allEntries=true) beforeInvocation 是否在方法执行前就清空，缺省为 false，如果指定为 true，则在方法还没有执行的时候就清空缓存，缺省情况下，如果方法执行抛出异常，则不会清空缓存 @CachEvict(value=”testcache”，beforeInvocation=true) 示例： 1234567891011121314151617181920212223@Cacheable(value = "emp",key = "#p0.id")public NewJob save(NewJob job) &#123; newJobDao.save(job); return job;&#125;//清除一条缓存，key为要清空的数据@CacheEvict(value="emp",key="#id")public void delect(int id) &#123; newJobDao.deleteAllById(id);&#125;//方法调用后清空所有缓存@CacheEvict(value="accountCache",allEntries=true)public void delectAll() &#123; newJobDao.deleteAll();&#125;//方法调用前清空所有缓存@CacheEvict(value="accountCache",beforeInvocation=true)public void delectAll() &#123; newJobDao.deleteAll();&#125; 其他属性 12345String[] cacheNames() default &#123;&#125;; //与value二选一String keyGenerator() default &quot;&quot;; //key的生成器。key/keyGenerator二选一使用String cacheManager() default &quot;&quot;; //指定缓存管理器String cacheResolver() default &quot;&quot;; //或者指定获取解析器String condition() default &quot;&quot;; //条件符合则清空 7.组合@Caching有时候我们可能组合多个Cache注解使用，此时就需要@Caching组合多个注解标签了。 1234567891011121314@Caching(cacheable = &#123; @Cacheable(value = "emp",key = "#p0"), ...&#125;,put = &#123; @CachePut(value = "emp",key = "#p0"), ...&#125;,evict = &#123; @CacheEvict(value = "emp",key = "#p0"), ....&#125;)public User save(User user) &#123; ....&#125; 下面讲到的整合第三方缓存组件都是基于上面的已经完成的步骤，所以一个应用要先做好你的缓存逻辑，再来整合其他cache组件。 五：整合EHCACHEEhcache是一种广泛使用的开源Java分布式缓存。主要面向通用缓存,Java EE和轻量级容器。它具有内存和磁盘存储，缓存加载器,缓存扩展,缓存异常处理程序,一个gzip缓存servlet过滤器,支持REST和SOAP api等特点。 1.导入依赖整合ehcache必须要导入它的依赖。 123456789&lt;dependency&gt; &lt;groupId&gt;net.sf.ehcache&lt;/groupId&gt; &lt;artifactId&gt;ehcache&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;&lt;/dependency&gt; 2.yml配置需要说明的是config: classpath:/ehcache.xml可以不用写，因为默认就是这个路径。但ehcache.xml必须有。 12345spring: cache: type: ehcache ehcache: config: classpath:/ehcache.xml 3.ehcache.xml在resources目录下新建ehcache.xml，注释啥的应该可以说相当详细了 123456789101112131415161718192021222324252627282930313233&lt;ehcache&gt; &lt;!-- 磁盘存储:将缓存中暂时不使用的对象,转移到硬盘,类似于Windows系统的虚拟内存 path:指定在硬盘上存储对象的路径 path可以配置的目录有： user.home（用户的家目录） user.dir（用户当前的工作目录） java.io.tmpdir（默认的临时目录） ehcache.disk.store.dir（ehcache的配置目录） 绝对路径（如：d:\\ehcache） 查看路径方法：String tmpDir = System.getProperty("java.io.tmpdir"); --&gt; &lt;diskStore path="java.io.tmpdir" /&gt; &lt;!-- defaultCache:默认的缓存配置信息,如果不加特殊说明,则所有对象按照此配置项处理 maxElementsInMemory:设置了缓存的上限,最多存储多少个记录对象 eternal:代表对象是否永不过期 (指定true则下面两项配置需为0无限期) timeToIdleSeconds:最大的发呆时间 /秒 timeToLiveSeconds:最大的存活时间 /秒 overflowToDisk:是否允许对象被写入到磁盘 说明：下列配置自缓存建立起600秒(10分钟)有效 。 在有效的600秒(10分钟)内，如果连续120秒(2分钟)未访问缓存，则缓存失效。 就算有访问，也只会存活600秒。 --&gt; &lt;defaultCache maxElementsInMemory="10000" eternal="false" timeToIdleSeconds="600" timeToLiveSeconds="600" overflowToDisk="true" /&gt; &lt;cache name="myCache" maxElementsInMemory="10000" eternal="false" timeToIdleSeconds="120" timeToLiveSeconds="600" overflowToDisk="true" /&gt;&lt;/ehcache&gt; 4.使用缓存@CacheConfig(cacheNames = {“myCache”})设置ehcache的名称，这个名称必须在ehcache.xml已配置 。 123456789@CacheConfig(cacheNames = &#123;"myCache"&#125;)public class BotRelationServiceImpl implements BotRelationService &#123; @Cacheable(key = "targetClass + methodName +#p0") public List&lt;BotRelation&gt; findAllLimit(int num) &#123; return botRelationRepository.findAllLimit(num); &#125;&#125; 整合完毕！ 别忘了在启动类开启缓存！]]></content>
      <categories>
        <category>框架</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>Spring</tag>
        <tag>框架</tag>
        <tag>SSM</tag>
        <tag>Mybatis</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringSecurity入门]]></title>
    <url>%2F2020%2F02%2F14%2FSpringSecurity%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[spring security简介springsecurity的核心主要是： 认证（那你是谁） 授权 （能干什么） 防范csrf工具（跨域伪造身份攻击） Spring Security主要是从两个方面解决安全性问题：web请求级别：使用Servlet规范中的过滤器（Filter）保护Web请求并限制URL级别的访问。 方法调用级别：使用Spring AOP保护方法调用，确保具有适当权限的用户才能访问安全保护的方法。 spring security的本质是一组过滤器链。采用的是责任链的设计模式，它有一条很长的过滤器链。 WebAsyncManagerIntegrationFilter：将 Security 上下文与 Spring Web 中用于处理异步请求映射的 WebAsyncManager 进行集成。 SecurityContextPersistenceFilter：在每次请求处理之前将该请求相关的安全上下文信息加载到 SecurityContextHolder 中，然后在该次请求处理完成之后，将 SecurityContextHolder 中关于这次请求的信息存储到一个“仓储”中，然后将 SecurityContextHolder 中的信息清除，例如在Session中维护一个用户的安全信息就是这个过滤器处理的。 HeaderWriterFilter：用于将头信息加入响应中。 CsrfFilter：用于处理跨站请求伪造。 LogoutFilter：用于处理退出登录。 UsernamePasswordAuthenticationFilter：用于处理基于表单的登录请求，从表单中获取用户名和密码。默认情况下处理来自 /login 的请求。从表单中获取用户名和密码时，默认使用的表单 name 值为 username 和 password，这两个值可以通过设置这个过滤器的usernameParameter 和 passwordParameter 两个参数的值进行修改。 DefaultLoginPageGeneratingFilter：如果没有配置登录页面，那系统初始化时就会配置这个过滤器，并且用于在需要进行登录时生成一个登录表单页面。 BasicAuthenticationFilter：检测和处理 http basic 认证。 RequestCacheAwareFilter：用来处理请求的缓存。 SecurityContextHolderAwareRequestFilter：主要是包装请求对象request。 AnonymousAuthenticationFilter：检测 SecurityContextHolder 中是否存在 Authentication 对象，如果不存在为其提供一个匿名 Authentication。 SessionManagementFilter：管理 session 的过滤器 ExceptionTranslationFilter：处理 AccessDeniedException 和 AuthenticationException 异常。 FilterSecurityInterceptor：可以看做过滤器链的出口。 RememberMeAuthenticationFilter：当用户没有登录而直接访问资源时, 从 cookie 里找出用户的信息, 如果 Spring Security 能够识别出用户提供的remember me cookie, 用户将不必填写用户名和密码, 而是直接登录进入系统，该过滤器默认不开启。 责任链执行流程 流程说明 客户端发起一个请求，进入 Security 过滤器链。 当到 LogoutFilter 的时候判断是否是登出路径，如果是登出路径则到 logoutHandler ，如果登出成功则到 logoutSuccessHandler 登出成功处理，如果登出失败则由 ExceptionTranslationFilter ；如果不是登出路径则直接进入下一个过滤器。 当到 UsernamePasswordAuthenticationFilter 的时候判断是否为登录路径，如果是，则进入该过滤器进行登录操作，如果登录失败则到 AuthenticationFailureHandler 登录失败处理器处理，如果登录成功则到 AuthenticationSuccessHandler 登录成功处理器处理，如果不是登录请求则不进入该过滤器。 当到 FilterSecurityInterceptor 的时候会拿到 uri ，根据 uri 去找对应的鉴权管理器，鉴权管理器做鉴权工作，鉴权成功则到 Controller 层否则到 AccessDeniedHandler 鉴权失败处理器处理。 springboot整合SpringSecurity导入maven坐标(本文使用的springboot版本是2.2.7，因为不同版本的security有出入)1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 方式一使用配置文件使用SpringSecurity在application.yml文件中添加 1234security: user: name: admin password: 123456 就可以使用直接使用了，并且有一个默认的login页面，该页面由springsecurity提供。 如果不写user后面的默认密码，该页面账号默认为user.密码在控制台上。但是我们上述的yaml文件配置了默认的账号和密码，所有我们采用admin，123456登陆。 方式二使用配置类的方式使用SpringSecurity我们需要在springboot能扫描到的包下面创建一个类，类名可以随意，但是该类必须继承WebSecurityConfigurerAdapter，并且添加@EnableWebSecurity注解，该注解内部已经注解了@Configuration注解，所有我们无需添加其他注解。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package conm.qs304.scekillsytem.scekillsytem.config;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;/** * @author yang * @date 2020/5/16 17:38 *///@Configuration@EnableWebSecuritypublic class SercurityConfiguration extends WebSecurityConfigurerAdapter &#123; //认证用户来源 @Override //如果配置了,那么配置文件中的用户会失效 protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; //密码不能直接写123,因为springSercurity认为是不安全的,因为代码可以被反编译从而获取到密码,所以需要对密码进行加密获取使用&#123;noop&#125;告诉框架这是一个原文 //在配置类中角色不能添加前对ROLE_USER,应该写成USER auth.inMemoryAuthentication().withUser("user").password("&#123;noop&#125;123").roles("USER"); &#125; @Override public void configure(HttpSecurity http) throws Exception &#123;// //1.释放静态资源// //必须以authorizeRequests开始// http.authorizeRequests().// //释放静态资源比如login.html不能拦截// antMatchers("/login","/login","/index","/index.html","/css/**").permitAll().// antMatchers("/**").hasAnyRole("USER","ADMIN").// //其他资源必须认证通过才能访问// anyRequest().authenticated().// //新的开始// and().// //自定义登陆页// formLogin().// loginPage("/login.html").// loginProcessingUrl("/login").// successForwardUrl("/index").// failureForwardUrl("/login.html").// permitAll().// and().// logout().// logoutUrl("/logout").// logoutSuccessUrl("/login.html").// invalidateHttpSession(true).permitAll().// //测试方便释放csrf// and().csrf().disable(); http.authorizeRequests(). antMatchers("/vip/**").hasRole("USER"). antMatchers("/**").permitAll();//如果下面的规则和上面的规则重复则上面的规则优先 http.formLogin().loginPage("/login").usernameParameter("username").passwordParameter("pwd").failureForwardUrl("/login").loginProcessingUrl("/toLogin").defaultSuccessUrl("/vip/vip"); http.csrf().disable(); &#125;&#125; 如果下面的规则和上面的规则重复，那么上面的规则优先。 如果有多个配置文件可以通过在类上添加注解@Order(int)参数来指定优先级，其中数值越小优先级越高 configure该方法有多个重载，而且该方法提供的参数对象都可以链式编程 123protected void configure(AuthenticationManagerBuilder auth)//自定义身份认证public void configure(WebSecurity web)//自定义SpringSecurity的Filter链protected void configure(HttpSecurity http)//自定义拦截器保护请求 protected void configure(AuthenticationManagerBuilder auth)代码解析12345678//inMemoryAuthentication表示从内存进行身份验证，当然还可以从数据库中auth.jdbcAuthentication() auth.inMemoryAuthentication().//必须将账号密码还有角色都填写，否则会抛出IllegalArgumentException: Cannot pass a null GrantedAuthority collection，异常//并且roles不能以ROLE_USER开头，否则会抛出IllegalArgumentException: ROLE_USER cannot start with ROLE_ (it is automatically added)//并且密码不能直接写到代码中，因为可以反编译java程序获取密码，这种方式极为不安全，当然也可以使用&#123;noop&#125;告诉SpringSecurity就是一个原文，当然这样不安全。withUser("user").password("&#123;noop&#125;123").roles("USER");//auth.inMemoryAuthentication().withUser("user").password(new BCryptPasswordEncoder().encode("123456")).roles("ROLE_USER");也可以这样提前加密 public void configure(HttpSecurity http) throws Exception每新添加一个规则都可以使用.and()方法连接，也可以多次使用http的方法连接 格式为 拦截规则.授予权限或角色 123456789//必须以他开头 http.authorizeRequests(). ///vip/**目录下规则声响，必须是USER角色才能访问 antMatchers("/vip/**").hasRole("USER"). //因为/**和上面的规则重复，所以会先使用上面的权限，permitAll表示谁都可以访问 antMatchers("/**").permitAll();//如果下面的规则和上面的规则重复则上面的规则优先 //配置登陆，登陆页面为/login，其中username绑定的参数是username，password绑定的参数是pwd，失败跳转/loing页面，表单提交到toLogin页面，成功跳转/iip/vip页面。http.formLogin().loginPage("/login").usernameParameter("username").passwordParameter("pwd").failureForwardUrl("/login").loginProcessingUrl("/toLogin").successForwardUrl("/vip/vip"); http.csrf().disable(); 如果出现403错误，大概率是因为csrf的问题 如果出现405错误，可以将successForwardUrl方法换成defaultSuccessUrl方法。 在SpringSecurity中默认的提交表单的url是/login，而且必须是post请求 在源代码中可知，只有GET”, “HEAD”, “TRACE”, “OPTIONS请求才会被csrf拦截，所有使用get请求是不安全的 123private static final class DefaultRequiresCsrfMatcher implements RequestMatcher &#123; private final HashSet&lt;String&gt; allowedMethods = new HashSet&lt;&gt;( Arrays.asList("GET", "HEAD", "TRACE", "OPTIONS")); 基于数据库的认证首先需要创建一个Service接口，该接口继承UserDetailsService接口，然后搞一个实现类实现Service这个接口,并且重新里面的loadUserByUsername(String username)方法, 该方法的参数username是前端传入的username 1234567891011121314151617181920@Servicepublic class LoginServiceImpl implements LoginService &#123; //该username就是前端传入的username,return null直接就表示认证失败 @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; if (username!=null&amp;&amp;!username.equals(""))&#123; if(username.equals("root"))&#123;//比较前端传入的root和数据库中的root是否相同，这里采用模拟数据库的方式 List&lt;SimpleGrantedAuthority&gt; list=new ArrayList&lt;&gt;();//赋予该角色N种权限 list.add(new SimpleGrantedAuthority("ROLE_USER")); UserDetails userDetails=new User("root","&#123;noop&#125;123",list);//传入数据库密码，和权限。 return userDetails; &#125; &#125;else &#123; return null;//认证失败 &#125; return null; &#125;&#125; 然后在配置类中写 123456789@AutowiredLoginServiceImpl loginService;//认证用户来源@Overrideprotected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; //使用数据库认证 auth.userDetailsService(loginService);&#125; 到此我们就实现了数据库的认证]]></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>JWT</tag>
        <tag>spring</tag>
        <tag>springSecurity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ForkJoin入门]]></title>
    <url>%2F2020%2F02%2F11%2FForkJoin%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[ForkJoin 分而治之框架ForkJoin在jdk1.7中，他可以并行执行任务，也就是说，我们可以把一个任务分成很多个小任务，然后使用ForkJoin并行处理任务，之后在把所有的任务结果合并起来。 特点:工作窃取每个线程都维护了一个双端队列，每个队列中都装了很多个任务，如果有一个线程执行完成了他队列里面的所有任务，那么他就会偷别人线程中的任务。 演示自定义一个区间求和类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package java8;import java.util.concurrent.ExecutionException;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.RecursiveTask;/** * @author yang * @date 2020/5/11 17:39 */public class forkJoinDemo &#123; /** * 使用forkjoin框架进行分而治之计算 * @param args */ public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ForkJoinPool forkJoinPool = new ForkJoinPool(); Sum sum = new Sum(1L, 100L); forkJoinPool.submit(sum); System.out.println(sum.get()); &#125;&#125;class Sum extends RecursiveTask&lt;Long&gt;&#123; private Long star; private Long end; private Long temp=10L;//临界值 public Sum(Long star, Long end) &#123; this.star = star; this.end = end; &#125; @Override protected Long compute() &#123; if(this.end-this.star&lt;temp)&#123;//可以开始计算了 Long sum=0L; for (Long i=star;i&lt;=end;i++)&#123; sum+=i; &#125; return sum; &#125;else &#123;//forkjoin递归调用 Long middle=(star+end)/2; Sum sum1 = new Sum(star, middle); Sum sum2 = new Sum(middle + 1, end); sum1.fork(); sum2.fork(); return sum1.join()+sum2.join(); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>JUC</tag>
        <tag>ForkJoin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门]]></title>
    <url>%2F2020%2F01%2F30%2FDocker%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Docker入门前言 docker是一种容器,其产生的目的只要是解决了开发环境和运维环境不同的一个解决方案，解决了运行环境和配置环境的问题，但是它又和虚拟化技术不同，docker比虚拟化技术占用资源更少，启动更快，甚至启动是毫秒级的 Docker的重要部分镜像 将软件环境打包好的模板，用来创建容器的，一个镜像可以创建多个容器。 容器 Docker的运行组件，启动一个镜像就是一个容器，容器与容器之间相互隔离，并且互不影响。 仓库仓库就是镜像的仓库，分为私有仓库和公共仓库，其中私有仓库是自己的镜像仓库，公共仓库是docker提供的仓库 docker常用命令1、Docker容器信息123456##查看docker容器版本docker version##查看docker容器信息docker info##查看docker容器帮助docker --help 2、镜像操作提示：对于镜像的操作可使用镜像名、镜像长ID和短ID。 2.1、镜像查看1234##列出本地imagesdocker images##含中间映像层docker images -a 1234##只显示镜像IDdocker images -q##含中间映像层docker images -qa 1234##显示镜像摘要信息(DIGEST列)docker images --digests##显示镜像完整信息docker images --no-trunc 12##显示指定镜像的历史创建；参数：-H 镜像大小和日期，默认为true；--no-trunc 显示完整的提交记录；-q 仅列出提交记录IDdocker history -H redis 2.2、镜像搜索12345678##搜索仓库MySQL镜像docker search mysql## --filter=stars=600：只显示 starts&gt;=600 的镜像docker search --filter=stars=600 mysql## --no-trunc 显示镜像完整 DESCRIPTION 描述docker search --no-trunc mysql## --automated ：只列出 AUTOMATED=OK 的镜像docker search --automated mysql 2.3、镜像下载123456##下载Redis官方最新镜像，相当于：docker pull redis:latestdocker pull redis##下载仓库所有Redis镜像docker pull -a redis##下载私人仓库镜像docker pull bitnami/redis 2.4、镜像删除12345678##单个镜像删除，相当于：docker rmi redis:latestdocker rmi redis##强制删除(针对基于镜像有运行的容器进程)docker rmi -f redis##多个镜像删除，不同镜像间以空格间隔docker rmi -f redis tomcat nginx##删除本地全部镜像docker rmi -f $(docker images -q) 2.5、镜像构建12345##（1）编写dockerfilecd /docker/dockerfilevim mycentos##（2）构建docker镜像docker build -f /docker/dockerfile/mycentos -t mycentos:1.1 3、容器操作提示：对于容器的操作可使用CONTAINER ID 或 NAMES。 3.1、容器启动1234##新建并启动容器，参数：-i 以交互模式运行容器；-t 为容器重新分配一个伪输入终端；--name 为容器指定一个名称docker run -i -t --name mycentos##后台启动容器，参数：-d 已守护方式启动容器docker run -d mycentos 注意：此时使用”docker ps -a”会发现容器已经退出。这是docker的机制：要使Docker容器后台运行，就必须有一个前台进程。解决方案：将你要运行的程序以前台进程的形式运行。 1234##启动一个或多个已经被停止的容器docker start redis##重启容器docker restart redis 3.2、容器进程12345##top支持 ps 命令参数，格式：docker top [OPTIONS] CONTAINER [ps OPTIONS]##列出redis容器中运行进程docker top redis##查看所有运行容器的进程信息for i in `docker ps |grep Up|awk &apos;&#123;print $1&#125;&apos;`;do echo \ &amp;&amp;docker top $i; done 3.3、容器日志123456##查看redis容器日志，默认参数docker logs rabbitmq##查看redis容器日志，参数：-f 跟踪日志输出；-t 显示时间戳；--tail 仅列出最新N条容器日志；docker logs -f -t --tail=20 redis##查看容器redis从2019年05月21日后的最新10条日志。docker logs --since=&quot;2019-05-21&quot; --tail=10 redis 3.4、容器的进入与退出1234567891011121314##使用run方式在创建时进入docker run -it centos /bin/bash##关闭容器并退出exit##仅退出容器，不关闭快捷键：Ctrl + P + Q##直接进入centos 容器启动命令的终端，不会启动新进程，多个attach连接共享容器屏幕，参数：--sig-proxy=false 确保CTRL-D或CTRL-C不会关闭容器docker attach --sig-proxy=false centos ##在 centos 容器中打开新的交互模式终端，可以启动新进程，参数：-i 即使没有附加也保持STDIN 打开；-t 分配一个伪终端docker exec -i -t centos /bin/bash##以交互模式在容器中执行命令，结果返回到当前终端屏幕docker exec -i -t centos ls -l /tmp##以分离模式在容器中执行命令，程序后台运行，结果不会反馈到当前终端docker exec -d centos touch cache.txt 3.5、查看容器12345678##查看正在运行的容器docker ps##查看正在运行的容器的IDdocker ps -q##查看正在运行+历史运行过的容器docker ps -a##显示运行容器总文件大小docker ps -s 123456##显示最近创建容器docker ps -l##显示最近创建的3个容器docker ps -n 3##不截断输出docker ps --no-trunc 1234##获取镜像redis的元信息docker inspect redis##获取正在运行的容器redis的 IPdocker inspect --format=&apos;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&apos; redis 3.6、容器的停止与删除123456789101112131415##停止一个运行中的容器docker stop redis##杀掉一个运行中的容器docker kill redis##删除一个已停止的容器docker rm redis##删除一个运行中的容器docker rm -f redis##删除多个容器docker rm -f $(docker ps -a -q)docker ps -a -q | xargs docker rm## -l 移除容器间的网络连接，连接名为 dbdocker rm -l db ## -v 删除容器，并删除容器挂载的数据卷docker rm -v redis 3.7、生成镜像12##基于当前redis容器创建一个新的镜像；参数：-a 提交的镜像作者；-c 使用Dockerfile指令来创建镜像；-m :提交时的说明文字；-p :在commit时，将容器暂停docker commit -a=&quot;DeepInThought&quot; -m=&quot;my redis&quot; [redis容器ID] myredis:v1.1 3.8、容器与主机间的数据拷贝123456##将rabbitmq容器中的文件copy至本地路径docker cp rabbitmq:/[container_path] [local_path]##将主机文件copy至rabbitmq容器docker cp [local_path] rabbitmq:/[container_path]/##将主机文件copy至rabbitmq容器，目录重命名为[container_path]（注意与非重命名copy的区别）docker cp [local_path] rabbitmq:/[container_path]]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSO单点登录入门]]></title>
    <url>%2F2020%2F01%2F12%2FSSO%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[什么是单点登录？ 单点登录就是我们只需要登录一个系统，就可以无缝衔接登录其他系统。 比如，只要我们登录了淘宝，那么进入天猫的时候就无需登录了，这就是单点登录，注意他和第三方登陆不同。 单点登录实现方案Session跨域Session跨域就是我们不使用系统（Tomcat）提供的Session，而是我们自定义一套Session，通过设置cookie的domain实现cookie跨入，然后自定义的Session的session_id存入cookie中并作为key，然后session作为value，将session存入数据库中(比如redis中，类似分布式session).这样可以用实现单点登录。 什么是跨域 当前页面url 被请求页面url 是否跨域 原因 http://www.test.com/ http://www.test.com/index.html 否 同源（协议、域名、端口号相同） http://www.test.com/ https://www.test.com/index.html 跨域 协议不同（http/https） http://www.test.com/ http://www.baidu.com/ 跨域 主域名不同（test/baidu） http://www.test.com/ http://blog.test.com/ 跨域 子域名不同（www/blog） http://www.test.com:8080/ http://www.test.com:7001/ 跨域 端口号不同（8080/7001） 使用JWT方式（JSON WEB TOKEN） JWT认证就是，用户认证通过之后，我们使用某种算法生成一个令牌，每次用户请求的时候只需要使用该令牌就行，服务器只需要校验令牌的合法性即可，也就是说这种方法令牌的安全性非常重要。]]></content>
      <tags>
        <tag>SSO</tag>
        <tag>单点登录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis配置文件详解]]></title>
    <url>%2F2019%2F12%2F30%2Fredis%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406################################### NETWORK ################################### # 指定 redis 只接收来自于该IP地址的请求，如果不进行设置，那么将处理所有请求bind 127.0.0.1 #是否开启保护模式，默认开启。要是配置里没有指定bind和密码。开启该参数后，redis只会本地进行访问，拒绝外部访问。要是开启了密码和bind，可以开启。否则最好关闭，设置为noprotected-mode yes #redis监听的端口号port 6379 #此参数确定了TCP连接中已完成队列(完成三次握手之后)的长度， 当然此值必须不大于Linux系统定义的/proc/sys/net/core/somaxconn值，默认是511，而Linux的默认参数值是128。当系统并发量大并且客户端速度缓慢的时候，可以将这二个参数一起参考设定。该内核参数默认值一般是128，对于负载很大的服务程序来说大大的不够。一般会将它修改为2048或者更大。在/etc/sysctl.conf中添加:net.core.somaxconn = 2048，然后在终端中执行sysctl -ptcp-backlog 511 #此参数为设置客户端空闲超过timeout，服务端会断开连接，为0则服务端不会主动断开连接，不能小于0timeout 0 #tcp keepalive参数。如果设置不为0，就使用配置tcp的SO_KEEPALIVE值，使用keepalive有两个好处:检测挂掉的对端。降低中间设备出问题而导致网络看似连接却已经与对端端口的问题。在Linux内核中，设置了keepalive，redis会定时给对端发送ack。检测到对端关闭需要两倍的设置值tcp-keepalive 300 #是否在后台执行，yes：后台运行；no：不是后台运行daemonize yes #redis的进程文件pidfile /var/run/redis/redis.pid #指定了服务端日志的级别。级别包括：debug（很多信息，方便开发、测试），verbose（许多有用的信息，但是没有debug级别信息多），notice（适当的日志级别，适合生产环境），warn（只有非常重要的信息）loglevel notice #指定了记录日志的文件。空字符串的话，日志会打印到标准输出设备。后台运行的redis标准输出是/dev/nulllogfile /usr/local/redis/var/redis.log #是否打开记录syslog功能# syslog-enabled no #syslog的标识符。# syslog-ident redis #日志的来源、设备# syslog-facility local0 #数据库的数量，默认使用的数据库是0。可以通过”SELECT 【数据库序号】“命令选择一个数据库，序号从0开始databases 16################################### SNAPSHOTTING ################################### #RDB核心规则配置 save &lt;指定时间间隔&gt; &lt;执行指定次数更新操作&gt;，满足条件就将内存中的数据同步到硬盘中。官方出厂配置默认是 900秒内有1个更改，300秒内有10个更改以及60秒内有10000个更改，则将内存中的数据快照写入磁盘。若不想用RDB方案，可以把 save &quot;&quot; 的注释打开，下面三个注释# save &quot;&quot;save 900 1save 300 10save 60 10000 #当RDB持久化出现错误后，是否依然进行继续进行工作，yes：不能进行工作，no：可以继续进行工作，可以通过info中的rdb_last_bgsave_status了解RDB持久化是否有错误stop-writes-on-bgsave-error yes #配置存储至本地数据库时是否压缩数据，默认为yes。Redis采用LZF压缩方式，但占用了一点CPU的时间。若关闭该选项，但会导致数据库文件变的巨大。建议开启。rdbcompression yes #是否校验rdb文件;从rdb格式的第五个版本开始，在rdb文件的末尾会带上CRC64的校验和。这跟有利于文件的容错性，但是在保存rdb文件的时候，会有大概10%的性能损耗，所以如果你追求高性能，可以关闭该配置rdbchecksum yes #指定本地数据库文件名，一般采用默认的 dump.rdbdbfilename dump.rdb #数据目录，数据库的写入会在这个目录。rdb、aof文件也会写在这个目录dir /usr/local/redis/var################################# REPLICATION ################################# # 复制选项，slave复制对应的master。# replicaof &lt;masterip&gt; &lt;masterport&gt; #如果master设置了requirepass，那么slave要连上master，需要有master的密码才行。masterauth就是用来配置master的密码，这样可以在连上master后进行认证。# masterauth &lt;master-password&gt; #当从库同主机失去连接或者复制正在进行，从机库有两种运行方式：1) 如果slave-serve-stale-data设置为yes(默认设置)，从库会继续响应客户端的请求。2) 如果slave-serve-stale-data设置为no，INFO,replicaOF, AUTH, PING, SHUTDOWN, REPLCONF, ROLE, CONFIG,SUBSCRIBE, UNSUBSCRIBE,PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB,COMMAND, POST, HOST: and LATENCY命令之外的任何请求都会返回一个错误”SYNC with master in progress”。replica-serve-stale-data yes #作为从服务器，默认情况下是只读的（yes），可以修改成NO，用于写（不建议）#replica-read-only yes # 是否使用socket方式复制数据。目前redis复制提供两种方式，disk和socket。如果新的slave连上来或者重连的slave无法部分同步，就会执行全量同步，master会生成rdb文件。有2种方式：disk方式是master创建一个新的进程把rdb文件保存到磁盘，再把磁盘上的rdb文件传递给slave。socket是master创建一个新的进程，直接把rdb文件以socket的方式发给slave。disk方式的时候，当一个rdb保存的过程中，多个slave都能共享这个rdb文件。socket的方式就的一个个slave顺序复制。在磁盘速度缓慢，网速快的情况下推荐用socket方式。repl-diskless-sync no #diskless复制的延迟时间，防止设置为0。一旦复制开始，节点不会再接收新slave的复制请求直到下一个rdb传输。所以最好等待一段时间，等更多的slave连上来repl-diskless-sync-delay 5 #slave根据指定的时间间隔向服务器发送ping请求。时间间隔可以通过 repl_ping_slave_period 来设置，默认10秒。# repl-ping-slave-period 10 # 复制连接超时时间。master和slave都有超时时间的设置。master检测到slave上次发送的时间超过repl-timeout，即认为slave离线，清除该slave信息。slave检测到上次和master交互的时间超过repl-timeout，则认为master离线。需要注意的是repl-timeout需要设置一个比repl-ping-slave-period更大的值，不然会经常检测到超时# repl-timeout 60 #是否禁止复制tcp链接的tcp nodelay参数，可传递yes或者no。默认是no，即使用tcp nodelay。如果master设置了yes来禁止tcp nodelay设置，在把数据复制给slave的时候，会减少包的数量和更小的网络带宽。但是这也可能带来数据的延迟。默认我们推荐更小的延迟，但是在数据量传输很大的场景下，建议选择yesrepl-disable-tcp-nodelay no #复制缓冲区大小，这是一个环形复制缓冲区，用来保存最新复制的命令。这样在slave离线的时候，不需要完全复制master的数据，如果可以执行部分同步，只需要把缓冲区的部分数据复制给slave，就能恢复正常复制状态。缓冲区的大小越大，slave离线的时间可以更长，复制缓冲区只有在有slave连接的时候才分配内存。没有slave的一段时间，内存会被释放出来，默认1m# repl-backlog-size 1mb # master没有slave一段时间会释放复制缓冲区的内存，repl-backlog-ttl用来设置该时间长度。单位为秒。# repl-backlog-ttl 3600 # 当master不可用，Sentinel会根据slave的优先级选举一个master。最低的优先级的slave，当选master。而配置成0，永远不会被选举replica-priority 100 #redis提供了可以让master停止写入的方式，如果配置了min-replicas-to-write，健康的slave的个数小于N，mater就禁止写入。master最少得有多少个健康的slave存活才能执行写命令。这个配置虽然不能保证N个slave都一定能接收到master的写操作，但是能避免没有足够健康的slave的时候，master不能写入来避免数据丢失。设置为0是关闭该功能# min-replicas-to-write 3 # 延迟小于min-replicas-max-lag秒的slave才认为是健康的slave# min-replicas-max-lag 10 # 设置1或另一个设置为0禁用这个特性。# Setting one or the other to 0 disables the feature.# By default min-replicas-to-write is set to 0 (feature disabled) and# min-replicas-max-lag is set to 10.#requirepass配置可以让用户使用AUTH命令来认证密码，才能使用其他命令。这让redis可以使用在不受信任的网络中。为了保持向后的兼容性，可以注释该命令，因为大部分用户也不需要认证。使用requirepass的时候需要注意，因为redis太快了，每秒可以认证15w次密码，简单的密码很容易被攻破，所以最好使用一个更复杂的密码# requirepass foobared #把危险的命令给修改成其他名称。比如CONFIG命令可以重命名为一个很难被猜到的命令，这样用户不能使用，而内部工具还能接着使用# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 #设置成一个空的值，可以禁止一个命令# rename-command CONFIG &quot;&quot;# 设置能连上redis的最大客户端连接数量。默认是10000个客户端连接。由于redis不区分连接是客户端连接还是内部打开文件或者和slave连接等，所以maxclients最小建议设置到32。如果超过了maxclients，redis会给新的连接发送’max number of clients reached’，并关闭连接# maxclients 10000redis配置的最大内存容量。当内存满了，需要配合maxmemory-policy策略进行处理。注意slave的输出缓冲区是不计算在maxmemory内的。所以为了防止主机内存使用完，建议设置的maxmemory需要更小一些maxmemory 122000000 #内存容量超过maxmemory后的处理策略。#volatile-lru：利用LRU算法移除设置过过期时间的key。#volatile-random：随机移除设置过过期时间的key。#volatile-ttl：移除即将过期的key，根据最近过期时间来删除（辅以TTL）#allkeys-lru：利用LRU算法移除任何key。#allkeys-random：随机移除任何key。#noeviction：不移除任何key，只是返回一个写错误。#上面的这些驱逐策略，如果redis没有合适的key驱逐，对于写命令，还是会返回错误。redis将不再接收写请求，只接收get请求。写命令包括：set setnx setex append incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby getset mset msetnx exec sort。# maxmemory-policy noeviction # lru检测的样本数。使用lru或者ttl淘汰算法，从需要淘汰的列表中随机选择sample个key，选出闲置时间最长的key移除# maxmemory-samples 5 # 是否开启salve的最大内存# replica-ignore-maxmemory yes#以非阻塞方式释放内存#使用以下配置指令调用了lazyfree-lazy-eviction nolazyfree-lazy-expire nolazyfree-lazy-server-del noreplica-lazy-flush no#Redis 默认不开启。它的出现是为了弥补RDB的不足（数据的不一致性），所以它采用日志的形式来记录每个写操作，并追加到文件中。Redis 重启的会根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。但是redis如果中途宕机，会导致可能有几分钟的数据丢失，根据save来策略进行持久化，Append Only File是另一种持久化方式，可以提供更好的持久化特性。Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。若开启rdb则将no改为yesappendonly no 指定本地数据库文件名，默认值为 appendonly.aofappendfilename &quot;appendonly.aof&quot; #aof持久化策略的配置#no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快#always表示每次写入都执行fsync，以保证数据同步到磁盘#everysec表示每秒执行一次fsync，可能会导致丢失这1s数据# appendfsync alwaysappendfsync everysec# appendfsync no # 在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说，执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no。如果对延迟要求很高的应用，这个字段可以设置为yes，否则还是设置为no，这样对持久化特性来说这是更安全的选择。设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yes。Linux的默认fsync策略是30秒。可能丢失30秒数据no-appendfsync-on-rewrite no #aof自动重写配置。当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写。当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程auto-aof-rewrite-percentage 100 #设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写auto-aof-rewrite-min-size 64mb #aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存。重启可能发生在redis所在的主机操作系统宕机后，尤其在ext4文件系统没有加上data=ordered选项（redis宕机或者异常终止不会造成尾部不完整现象。）出现这种现象，可以选择让redis退出，或者导入尽可能多的数据。如果选择的是yes，当截断的aof文件被导入的时候，会自动发布一个log给客户端然后load。如果是no，用户必须手动redis-check-aof修复AOF文件才可以aof-load-truncated yes #加载redis时，可以识别AOF文件以“redis”开头。#字符串并加载带前缀的RDB文件，然后继续加载AOF尾巴aof-use-rdb-preamble yes# 如果达到最大时间限制（毫秒），redis会记个log，然后返回error。当一个脚本超过了最大时限。只有SCRIPT KILL和SHUTDOWN NOSAVE可以用。第一个可以杀没有调write命令的东西。要是已经调用了write，只能用第二个命令杀lua-time-limit 5000# 集群开关，默认是不开启集群模式# cluster-enabled yes #集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。这个文件并不需要手动配置，这个配置文件有Redis生成并更新，每个Redis集群节点需要一个单独的配置文件，请确保与实例运行的系统中配置文件名称不冲突# cluster-config-file nodes-6379.conf #节点互连超时的阀值。集群节点超时毫秒数# cluster-node-timeout 15000 #在进行故障转移的时候，全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了，导致数据过于陈旧，这样的slave不应该被提升为master。该参数就是用来判断slave节点与master断线的时间是否过长。判断方法是：#比较slave断开连接的时间和(node-timeout * slave-validity-factor) + repl-ping-slave-period#如果节点超时时间为三十秒, 并且slave-validity-factor为10,假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移# cluster-replica-validity-factor 10 # master的slave数量大于该值，slave才能迁移到其他孤立master上，如这个参数若被设为2，那么只有当一个主节点拥有2 个可工作的从节点时，它的一个从节点会尝试迁移# cluster-migration-barrier 1 #默认情况下，集群全部的slot有节点负责，集群状态才为ok，才能提供服务。设置为no，可以在slot没有全部分配的时候提供服务。不建议打开该配置，这样会造成分区的时候，小分区的master一直在接受写请求，而造成很长时间数据不一致# cluster-require-full-coverage yes#*群集公告IP#*群集公告端口#*群集公告总线端口# Example:## cluster-announce-ip 10.1.1.5# cluster-announce-port 6379# cluster-announce-bus-port 6380# slog log是用来记录redis运行中执行比较慢的命令耗时。当命令的执行超过了指定时间，就记录在slow log中，slog log保存在内存中，所以没有IO操作。#执行时间比slowlog-log-slower-than大的请求记录到slowlog里面，单位是微秒，所以1000000就是1秒。注意，负数时间会禁用慢查询日志，而0则会强制记录所有命令。slowlog-log-slower-than 10000 #慢查询日志长度。当一个新的命令被写进日志的时候，最老的那个记录会被删掉。这个长度没有限制。只要有足够的内存就行。你可以通过 SLOWLOG RESET 来释放内存slowlog-max-len 128#延迟监控功能是用来监控redis中执行比较缓慢的一些操作，用LATENCY打印redis实例在跑命令时的耗时图表。只记录大于等于下边设置的值的操作。0的话，就是关闭监视。默认延迟监控功能是关闭的，如果你需要打开，也可以通过CONFIG SET命令动态设置latency-monitor-threshold 0#键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了 Redis 数据集的事件。因为开启键空间通知功能需要消耗一些 CPU ，所以在默认配置下，该功能处于关闭状态。#notify-keyspace-events 的参数可以是以下字符的任意组合，它指定了服务器该发送哪些类型的通知：##K 键空间通知，所有通知以 __keyspace@__ 为前缀##E 键事件通知，所有通知以 __keyevent@__ 为前缀##g DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知##$ 字符串命令的通知##l 列表命令的通知##s 集合命令的通知##h 哈希命令的通知##z 有序集合命令的通知##x 过期事件：每当有过期键被删除时发送##e 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送##A 参数 g$lshzxe 的别名#输入的参数中至少要有一个 K 或者 E，否则的话，不管其余的参数是什么，都不会有任何 通知被分发。详细使用可以参考http://redis.io/topics/notifications notify-keyspace-events &quot;&quot;# 数据量小于等于hash-max-ziplist-entries的用ziplist，大于hash-max-ziplist-entries用hashhash-max-ziplist-entries 512 # value大小小于等于hash-max-ziplist-value的用ziplist，大于hash-max-ziplist-value用hashhash-max-ziplist-value 64 #-5:最大大小：64 KB&lt;--不建议用于正常工作负载#-4:最大大小：32 KB&lt;--不推荐#-3:最大大小：16 KB&lt;--可能不推荐#-2:最大大小：8kb&lt;--良好#-1:最大大小：4kb&lt;--良好list-max-ziplist-size -2 #0:禁用所有列表压缩#1：深度1表示“在列表中的1个节点之后才开始压缩，#从头部或尾部#所以：【head】-&gt;node-&gt;node-&gt;…-&gt;node-&gt;【tail】#[头部]，[尾部]将始终未压缩；内部节点将压缩。#2:[头部]-&gt;[下一步]-&gt;节点-&gt;节点-&gt;…-&gt;节点-&gt;[上一步]-&gt;[尾部]#2这里的意思是：不要压缩头部或头部-&gt;下一个或尾部-&gt;上一个或尾部，#但是压缩它们之间的所有节点。#3:[头部]-&gt;[下一步]-&gt;[下一步]-&gt;节点-&gt;节点-&gt;…-&gt;节点-&gt;[上一步]-&gt;[上一步]-&gt;[尾部]list-compress-depth 0 # 数据量小于等于set-max-intset-entries用iniset，大于set-max-intset-entries用setset-max-intset-entries 512 #数据量小于等于zset-max-ziplist-entries用ziplist，大于zset-max-ziplist-entries用zsetzset-max-ziplist-entries 128 #value大小小于等于zset-max-ziplist-value用ziplist，大于zset-max-ziplist-value用zsetzset-max-ziplist-value 64 #value大小小于等于hll-sparse-max-bytes使用稀疏数据结构（sparse），大于hll-sparse-max-bytes使用稠密的数据结构（dense）。一个比16000大的value是几乎没用的，建议的value大概为3000。如果对CPU要求不高，对空间要求较高的，建议设置到10000左右hll-sparse-max-bytes 3000 #宏观节点的最大流/项目的大小。在流数据结构是一个基数#树节点编码在这项大的多。利用这个配置它是如何可能#大节点配置是单字节和#最大项目数，这可能包含了在切换到新节点的时候# appending新的流条目。如果任何以下设置来设置# ignored极限是零，例如，操作系统，它有可能只是一集通过设置限制最大#纪录到最大字节0和最大输入到所需的值stream-node-max-bytes 4096stream-node-max-entries 100 #Redis将在每100毫秒时使用1毫秒的CPU时间来对redis的hash表进行重新hash，可以降低内存的使用。当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no。如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存activerehashing yes ##对客户端输出缓冲进行限制可以强迫那些不从服务器读取数据的客户端断开连接，用来强制关闭传输缓慢的客户端。#对于normal client，第一个0表示取消hard limit，第二个0和第三个0表示取消soft limit，normal client默认取消限制，因为如果没有寻问，他们是不会接收数据的client-output-buffer-limit normal 0 0 0 #对于slave client和MONITER client，如果client-output-buffer一旦超过256mb，又或者超过64mb持续60秒，那么服务器就会立即断开客户端连接client-output-buffer-limit replica 256mb 64mb 60 #对于pubsub client，如果client-output-buffer一旦超过32mb，又或者超过8mb持续60秒，那么服务器就会立即断开客户端连接client-output-buffer-limit pubsub 32mb 8mb 60 # 这是客户端查询的缓存极限值大小# client-query-buffer-limit 1gb #在redis协议中，批量请求，即表示单个字符串，通常限制为512 MB。但是您可以更改此限制。# proto-max-bulk-len 512mb #redis执行任务的频率为1s除以hzhz 10 #当启用动态赫兹时，实际配置的赫兹将用作作为基线，但实际配置的赫兹值的倍数#在连接更多客户端后根据需要使用。这样一个闲置的实例将占用很少的CPU时间，而繁忙的实例将反应更灵敏dynamic-hz yes #在aof重写的时候，如果打开了aof-rewrite-incremental-fsync开关，系统会每32MB执行一次fsync。这对于把文件写入磁盘是有帮助的，可以避免过大的延迟峰值aof-rewrite-incremental-fsync yes #在rdb保存的时候，如果打开了rdb-save-incremental-fsync开关，系统会每32MB执行一次fsync。这对于把文件写入磁盘是有帮助的，可以避免过大的延迟峰值rdb-save-incremental-fsync yes# 已启用活动碎片整理# activedefrag yes # 启动活动碎片整理的最小碎片浪费量# active-defrag-ignore-bytes 100mb # 启动活动碎片整理的最小碎片百分比# active-defrag-threshold-lower 10 # 我们使用最大努力的最大碎片百分比# active-defrag-threshold-upper 100 # 以CPU百分比表示的碎片整理的最小工作量# active-defrag-cycle-min 5 # 在CPU的百分比最大的努力和碎片整理# active-defrag-cycle-max 75 #将从中处理的set/hash/zset/list字段的最大数目#主词典扫描# active-defrag-max-scan-fields 1000]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>配置</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[uni-app入门]]></title>
    <url>%2F2019%2F12%2F25%2Funi-app%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[uni-app入门 有个老师想让我们做一款评分上传文件的软件，但是要求最好是安卓端，我也不会安卓，因为我是搞后台的，但是也搞过一点前端，于是乎我就学一点这个吧，也方便以后使用。 首先目录结构123456789101112131415┌─components uni-app组件目录│ └─comp-a.vue 可复用的a组件├─hybrid 存放本地网页的目录，详见├─platforms 存放各平台专用页面的目录，详见├─pages 业务页面文件存放的目录│ ├─index│ │ └─index.vue index页面│ └─list│ └─list.vue list页面├─static 存放应用引用静态资源（如图片、视频等）的目录，注意：静态资源只能存放于此├─wxcomponents 存放小程序组件的目录├─main.js Vue初始化入口文件├─App.vue 应用配置，用来配置App全局样式以及监听 应用生命周期├─manifest.json 配置应用名称、appid、logo、版本等打包信息└─pages.json 配置页面路由、导航条、选项卡等页面类信息 页面样式与布局uni-app 支持的通用 css 单位包括 px、rpx（也就说你全当小程序宽度就是750px,因为底层已经做好了适配） px 即屏幕像素 rpx 即响应式px，一种根据屏幕宽度自适应的动态单位。以750宽的屏幕为基准，750rpx恰好为屏幕宽度。屏幕变宽，rpx 实际显示效果会等比放大。 vue页面支持普通H5单位，但在nvue里不支持： rem 默认根字体大小为 屏幕宽度/20（微信小程序、头条小程序、App、H5） vh viewpoint height，视窗高度，1vh等于视窗高度的1% vw viewpoint width，视窗宽度，1vw等于视窗宽度的1% nvue还不支持百分比单位。（nvue标准就可以让小程序拥有更高的性能） App端，在 pages.json 里的 titleNView 或页面里写的 plus api 中涉及的单位，只支持 px。注意此时不支持 rpx Vue文件解析.vue 文件是一个自定义的文件类型，用类 HTML 语法描述一个 Vue 组件。每个 .vue 文件包含三种类型的顶级语言块 &lt;template&gt;、&lt;script&gt; 和 &lt;style&gt;，还允许添加可选的自定义块： 1234567891011121314151617181920212223&lt;template&gt; &lt;div class=&quot;example&quot;&gt;&#123;&#123; msg &#125;&#125;&lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; data () &#123; return &#123; msg: &apos;Hello world!&apos; &#125; &#125;&#125;&lt;/script&gt;&lt;style&gt;.example &#123; color: red;&#125;&lt;/style&gt;&lt;custom1&gt; This could be e.g. documentation for the component.&lt;/custom1&gt; vue-loader 会解析文件，提取每个语言块，如有必要会通过其它 loader 处理，最后将他们组装成一个 ES Module，它的默认导出是一个 Vue.js 组件选项的对象。 vue-loader 支持使用非默认语言，比如 CSS 预处理器，预编译的 HTML 模版语言，通过设置语言块的 lang 属性。例如，你可以像下面这样使用 Sass 语法编写样式： 123&lt;style lang=&quot;sass&quot;&gt; /* write Sass! */&lt;/style&gt; 更多细节可以在使用预处理器中找到。 语言块模板 每个 .vue 文件最多包含一个 &lt;template&gt; 块。 内容将被提取并传递给 vue-template-compiler 为字符串，预处理为 JavaScript 渲染函数，并最终注入到从 &lt;script&gt; 导出的组件中。 脚本 每个 .vue 文件最多包含一个 &lt;script&gt; 块。 这个脚本会作为一个 ES Module 来执行。 它的默认导出应该是一个 Vue.js 的组件选项对象。也可以导出由 Vue.extend() 创建的扩展对象，但是普通对象是更好的选择。 任何匹配 .js 文件 (或通过它的 lang 特性指定的扩展名) 的 webpack 规则都将会运用到这个 &lt;script&gt; 块的内容中。 样式 默认匹配：/\.css$/。 一个 .vue 文件可以包含多个 &lt;style&gt; 标签。 标签可以有 scoped 或者 module 属性 (查看 scoped CSS和 CSS Modules) 以帮助你将样式封装到当前组件。具有不同封装模式的多个 标签可以在同一个组件中混合使用。 任何匹配 .css 文件 (或通过它的 lang 特性指定的扩展名) 的 webpack 规则都将会运用到这个 &lt;style&gt; 块的内容中。 自定义块可以在 .vue 文件中添加额外的自定义块来实现项目的特定需求，例如 &lt;docs&gt; 块。vue-loader 将会使用标签名来查找对应的 webpack loader 来应用在对应的块上。webpack loader 需要在 vue-loader 的选项 loaders 中指定。 更多细节，查看自定义块。 Src 导入如果喜欢把 .vue 文件分隔到多个文件中，你可以通过 src 属性导入外部文件： 123&lt;template src=&quot;./template.html&quot;&gt;&lt;/template&gt;&lt;style src=&quot;./style.css&quot;&gt;&lt;/style&gt;&lt;script src=&quot;./script.js&quot;&gt;&lt;/script&gt; 需要注意的是 src 导入遵循和 webpack 模块请求相同的路径解析规则，这意味着： 相对路径需要以 ./ 开始 你可以从 NPM 依赖中导入资源： 12&lt;!-- import a file from the installed &quot;todomvc-app-css&quot; npm package --&gt;&lt;style src=&quot;todomvc-app-css/index.css&quot;&gt; 在自定义块上同样支持 src 导入，例如： 12&lt;unit-test src=&quot;./unit-test.js&quot;&gt;&lt;/unit-test&gt; 注释在语言块中使用该语言块对应的注释语法 (HTML、CSS、JavaScript、Jade 等)。顶层注释使用 HTML 注释语法：&lt;!-- comment contents here --&gt;。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>前端</tag>
        <tag>习惯</tag>
        <tag>app</tag>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卡特兰数详解]]></title>
    <url>%2F2019%2F12%2F19%2F%E5%8D%A1%E7%89%B9%E5%85%B0%E6%95%B0%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[卡特兰数1,1,2,5,14,42,132常见公式 问题一由 个“(”和 个“)”组成的字符串，要求左括号和右括号是匹配的，问一共有多少种合法的括号组合方式?解析:​ 加上现在有三对括号，我们吧这三对括号所有的情况排列下来 ​ $\color{red}()$()() 红色括号内没有括号 ​ $\color{red}()$(()) ​ $\color{red}($() $\color{red}{)}$() 红色括号内有一对括号 ​ $\color{red}($()()$\color{red}{)}$ 红色括号内有两对括号 ​ $\color{red}($(())$\color{red}{)}$ markdown染色太累了（╮(╯▽╰)╭） 到目前为止是不是发现有些规律呢？ 当n=3的时候假设f(n)就表示括号有三对的所有情况 ​ f(3)=f(0) * f(2)+f(1) * f(1)+f(2)*f(0) 上面这个公式和规律又有啥关系呢？我们可以这么想，第一个括号一定是左括号，那么第一个对括号一定是会出现，那么第一对括号之间可能出现一对括号或者到n-1对括号，为啥是n-1对呢，因为第一对括号已经确定了，所有里面最多只能有n-1对，所以说n对括号应该是: f(n)=f(0) * f(n-1)+…+f(n-1)*f(0)当然也有特殊情况，当n=0的时候答案应该是1,想一想为什么所有根据上面的公式我们写出代码 123456789101112131415161718192021222324252627282930313233343536373839#include&lt;iostream&gt;using namespace std;int sum[20];//存放卡特兰数结果等价于f(n)int f(int num)//计算num项的卡特兰数&#123; if(sum[num]!=-1) return sum[num]; else if(num==1) return 1; else if(num==0) return 1; else &#123; int sum1=0; for(int i=0;i&lt;num;i++) &#123; sum1+=f(i)*f(num-i-1); &#125; return sum[num]=sum1; &#125; &#125;int main(void)&#123; sum[0]=1; sum[1]=1; for(int i=0;i&lt;10;i++) sum[i]=-1; for(int i=1;i&lt;10;i++) &#123; cout&lt;&lt;f(i)&lt;&lt;endl; &#125; return 0;&#125; 上面的代码固然能够计算卡特兰数，当然不能忘了文章开头写的几个公式来一个线性复杂度的卡特兰数 123456789101112131415161718#include&lt;iostream&gt; using namespace std;long long catalan[20];int main(void)&#123; int n; cin&gt;&gt;n; catalan[0]=1; for(int i=1;i&lt;=n;i++)//公式3求解 catalan[i]=(catalan[i-1]*(4*i-2))/(i+1); cout&lt;&lt;catalan[n]; &#125; 其实上面这个代码的缺点也很明显，虽然速度很快，但是大多的卡特兰数体型的值都是比较大的，并且需要取模运算的，例如题型洛谷 P3200 栈所以接下来一个更通用的卡特兰数解法 123456789101112131415161718192021222324#include&lt;iostream&gt; using namespace std;int catalan[1000010];//注意卡特兰数数组的初始化结果为0 int main(void)&#123; int n,p;//n为计算第几项卡特兰数，p是取模 cin&gt;&gt;n&gt;&gt;p; //初始化前两项 catalan[0] =1; catalan[1] =1; for(int i=2;i&lt;=n;i++) for(int j=0;j&lt;n;j++) catalan[i]=(catalan[j]*catalan[i-j-1]%p+catalan[i])%p; cout&lt;&lt;catalan[n]; return 0;&#125; 其他类似题型问题一有2n个人排成一行进入剧场。入场费 5 元。其中只有 个人有一张 5 元钞票，另外n人只有 10 元钞票，剧院无其它钞票，问有多少中方法使得只要有 10 元的人买票，售票处就有 5 元的钞票找零？ 问题分析首先这个问题也是2n类型的问题，然后就是一个5元的和一个10元的结合在一起就能满足类似括号问题，5元就是左括号，10元就是右括号，那么问题就转换成了求解卡特兰数问题。 问题二 n个不同的数依次进栈，求不同的出栈结果的种数 问题分析首先这个问题也是满足2n个问题的，因为题目进栈和出栈的次数是一样的所有也满足2n问题，同时也转换成了括号问题，也就变成了求解卡特兰数。 问题三 n个结点可够造多少个不同的二叉树？ 问题分析f(n)就表示n个节点二叉树构造的不同二叉树，那么当n=3的时候f(n)=f(0) * f(2)+f(1) * f(1)+f(2) * f(0),为什么会是这样呢，一个二叉树的所有情况应该是根节点左子树的所有情况乘以右子数的所有情况，并且左子数所有节点加右节点等于n-1，如果左子树有0个节点那么右子树就有2个节点，依次类推会发现就是括号问题。]]></content>
      <categories>
        <category>算法</category>
        <category>C语言</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式session]]></title>
    <url>%2F2019%2F12%2F14%2F%E5%88%86%E5%B8%83%E5%BC%8Fsession%2F</url>
    <content type="text"><![CDATA[分布式session入门前言 我院大佬要安排一个项目，有一块要有人负责session这一块，于是乎没人想学，我就接下这个活了，希望自己能理解的不错吧。 session介绍session简介session是一次浏览器和服务器的交互会话，那会话又是什么呢，牛津词典的解释是进行某个活动连续的一段时间。 session作用session复制原理：任何一个服务器上的session发生改变（增删改），该节点会把这个 session的所有内容序列化，然后广播给所有其它节点，不管其他服务器需不需要session，以此来保证Session同步。 优点：如果其中一个服务器挂掉不会影响这个服务器集群。 缺点：如果用户访问量非常庞大，那么个个服务器之间进行session同步的次数会非常的多，以至于占用大量内网带宽 演示:1.复制多分tomcat 2.设置每个tomcat的server.xml来开启tomcat集群功能 3.在web.xml中添加信息：通知应用当前在集群环境中。 粘性session原理：粘性Session是指将用户锁定到某一个服务器上，比如上面说的例子，用户第一次请求时，负载均衡器将用户的请求转发到了A服务器上，如果负载均衡器设置了粘性Session的话，那么用户以后的每次请求都会转发到A服务器上，相当于把用户和A服务器粘到了一块，这就是粘性Session机制。 优点：简单，不需要对session做任何处理。 缺点：缺乏容错性，如果当前访问的服务器发生故障，用户被转移到第二个服务器上时，他的session信息都将失效。 适用场景：发生故障对客户产生的影响较小；服务器发生故障是低概率事件。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>分布式</tag>
        <tag>Spring</tag>
        <tag>SSM</tag>
        <tag>Mybatis</tag>
        <tag>习惯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis持久化详解]]></title>
    <url>%2F2019%2F12%2F10%2Fredis%E6%8C%81%E4%B9%85%E5%8C%96%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[redis持久化的两张方式RDB（快照）持久化：保存某个时间点的全量数据快照RDB就像是一台给Redis内存数据存储拍照的照相机，生成快照保存到磁盘的过程。触发RDB持久化分为手动触发和自动触发。Redis重启读取RDB速度快，但是无法做到实时持久化，因此一般用于数据冷备和复制传输。 手动触发 SAVE：阻塞Redis的服务器进程，知道RDB文件被创建完毕 BGSAVE：Fork出一个子进程来创建RDB文件，不阻塞服务器进程 lastsave 指令可以查看最近的备份时间 自动触发 根据redis.conf配置里的save m n定时触发（用的是BGSAVE） 主从复制时，主节点自动触发 执行Debug Relaod 执行Shutdown且没有开启AOF持久化 123456789# 在几秒内改动了多少数据就触发持久化# 想禁用的话不设置save 或者save ""save 900 1save 300 10save 60 10000# 备份进程出错主进程停止写入操作stop-writes-on-bgsave-error yes# 是否压缩rdb文件 推荐no 相对于硬盘成本cpu更值钱rdbcompression yes RDB模式原理 RDB模式在持久化的时候会fork()创建子线程，在后台进程存储。只有fork阶段会阻塞当前Redis服务器，不必到整个RDB过程结束，一般时间很短。因此Redis内部涉及到RDB都采用bgsave命令。这里注意一点，无论RDB还是AOF，由于使用了写时复制，fork出来的子进程不需要拷贝父进程的物理内存空间，但是会复制父进程的空间内存页表。 AOF模式（写命令才追加）RDB方式不能提供强一致性，如果Redis进程崩溃（主机断电），那么两次RDB之间的数据也随之消失。那么AOF的出现很好的解决了数据持久化的实时性，AOF以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中的命令来恢复数据。AOF会先把命令追加在AOF缓冲区，然后根据对应策略写入硬盘（appendfsync） 所有的写入命令追加到aof缓冲区 AOF缓冲区根据对应appendfsync配置向硬盘做同步操作 定期对AOF文件进行重写 Redis重启时，可以加载AOF文件进行数据恢复 AOF（Append-Only-File）持久化：保存写状态 记录除了查询以外的所有变更数据库状态的指令 以append的形式追加保存到AOF文件中（增量） 日志重写解决AOF文件不断增大的问题，原理如下 调用fork，创建一个子进程 子进程把新的AOF写到一个临时文件里，不依赖原来的AOF文件 主进程持续将新的变动同时写到内存和原来的AOF里 主进程获取子进程重写AOF完成信号，往新AOF同步增量变动 使用新的AOF文件替换掉旧的AOF文件 配置文件123456789101112131415# 默认关闭若要开启将no改为yesappendonly no# append文件的名字appendfilename "appendonly.aof"# AOF文件的写入方式# always一旦缓存区内容发生变化就写入AOF文件中appendfsync always# everysec 每个一秒将缓存区内容写入文件 默认开启的写入方式appendfsync everysec# 将写入文件的操作交由操作系统决定appendfsync no# 当AOF文件大小的增长率大于该配置项时自动开启重写（这里指超过原大小的100%）。auto-aof-rewrite-percentage 100# 当AOF文件大小大于该配置项时自动开启重写auto-aof-rewrite-min-size 64mb 总结RDB和AOF的优缺点RDB优点：全量数据快照，文件小，恢复快 RDB缺点：无法保存最近一次快照之后的数据，数据量大会由于I/O严重影响性能 AOF优点：可读性高，适合保存增量数据，数据不一丢失 AOF缺点：文件体积大，恢复时间长 必要的情况下可以使用RDB-AOF混合持久化]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>持久化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot整合redis]]></title>
    <url>%2F2019%2F11%2F29%2Fspringboot%E6%95%B4%E5%90%88redis%2F</url>
    <content type="text"><![CDATA[在springboot1.5.x版本中，springboot默认是使用jedis来操作redis的，但是在springboot2.x版本，默认是使用lettuce来操作数据库，所以配置有些差别。 因为在lettuce框架中使用的是netty框架来实现，而且netty框架使用的是NIO,所以lettuce比jedis的并发性更好 在我接下来的演示中都是使用的springboot2.2 导入启动器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.0.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.springbootRedisDemo&lt;/groupId&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 第二步配置redis的连接信息1234567spring.redis.host=127.0.0.1spring.redis.port=6379#由于Springboot2.X版本使用的不是jedis而是lettuce，所以之前关于jedis的配置都不会生效#会生效spring.redis.lettuce.pool.max-active=2#不会生效spring.redis.jedis.pool.max-active=2 redis能配置的所有信息都在RedisProperties这个类中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375/* * Copyright 2012-2019 the original author or authors. * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * https://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.springframework.boot.autoconfigure.data.redis;import java.time.Duration;import java.util.List;import org.springframework.boot.context.properties.ConfigurationProperties;/** * Configuration properties for Redis. * * @author Dave Syer * @author Christoph Strobl * @author Eddú Meléndez * @author Marco Aust * @author Mark Paluch * @author Stephane Nicoll * @since 1.0.0 */@ConfigurationProperties(prefix = "spring.redis")public class RedisProperties &#123; /** * Database index used by the connection factory. */ private int database = 0; /** * Connection URL. Overrides host, port, and password. User is ignored. Example: * redis://user:password@example.com:6379 */ private String url; /** * Redis server host. */ private String host = "localhost"; /** * Login password of the redis server. */ private String password; /** * Redis server port. */ private int port = 6379; /** * Whether to enable SSL support. */ private boolean ssl; /** * Connection timeout. */ private Duration timeout; /** * Client name to be set on connections with CLIENT SETNAME. */ private String clientName; private Sentinel sentinel; private Cluster cluster; private final Jedis jedis = new Jedis(); private final Lettuce lettuce = new Lettuce(); public int getDatabase() &#123; return this.database; &#125; public void setDatabase(int database) &#123; this.database = database; &#125; public String getUrl() &#123; return this.url; &#125; public void setUrl(String url) &#123; this.url = url; &#125; public String getHost() &#123; return this.host; &#125; public void setHost(String host) &#123; this.host = host; &#125; public String getPassword() &#123; return this.password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public int getPort() &#123; return this.port; &#125; public void setPort(int port) &#123; this.port = port; &#125; public boolean isSsl() &#123; return this.ssl; &#125; public void setSsl(boolean ssl) &#123; this.ssl = ssl; &#125; public void setTimeout(Duration timeout) &#123; this.timeout = timeout; &#125; public Duration getTimeout() &#123; return this.timeout; &#125; public String getClientName() &#123; return this.clientName; &#125; public void setClientName(String clientName) &#123; this.clientName = clientName; &#125; public Sentinel getSentinel() &#123; return this.sentinel; &#125; public void setSentinel(Sentinel sentinel) &#123; this.sentinel = sentinel; &#125; public Cluster getCluster() &#123; return this.cluster; &#125; public void setCluster(Cluster cluster) &#123; this.cluster = cluster; &#125; public Jedis getJedis() &#123; return this.jedis; &#125; public Lettuce getLettuce() &#123; return this.lettuce; &#125; /** * Pool properties. */ public static class Pool &#123; /** * Maximum number of "idle" connections in the pool. Use a negative value to * indicate an unlimited number of idle connections. */ private int maxIdle = 8; /** * Target for the minimum number of idle connections to maintain in the pool. This * setting only has an effect if both it and time between eviction runs are * positive. */ private int minIdle = 0; /** * Maximum number of connections that can be allocated by the pool at a given * time. Use a negative value for no limit. */ private int maxActive = 8; /** * Maximum amount of time a connection allocation should block before throwing an * exception when the pool is exhausted. Use a negative value to block * indefinitely. */ private Duration maxWait = Duration.ofMillis(-1); /** * Time between runs of the idle object evictor thread. When positive, the idle * object evictor thread starts, otherwise no idle object eviction is performed. */ private Duration timeBetweenEvictionRuns; public int getMaxIdle() &#123; return this.maxIdle; &#125; public void setMaxIdle(int maxIdle) &#123; this.maxIdle = maxIdle; &#125; public int getMinIdle() &#123; return this.minIdle; &#125; public void setMinIdle(int minIdle) &#123; this.minIdle = minIdle; &#125; public int getMaxActive() &#123; return this.maxActive; &#125; public void setMaxActive(int maxActive) &#123; this.maxActive = maxActive; &#125; public Duration getMaxWait() &#123; return this.maxWait; &#125; public void setMaxWait(Duration maxWait) &#123; this.maxWait = maxWait; &#125; public Duration getTimeBetweenEvictionRuns() &#123; return this.timeBetweenEvictionRuns; &#125; public void setTimeBetweenEvictionRuns(Duration timeBetweenEvictionRuns) &#123; this.timeBetweenEvictionRuns = timeBetweenEvictionRuns; &#125; &#125; /** * Cluster properties. */ public static class Cluster &#123; /** * Comma-separated list of "host:port" pairs to bootstrap from. This represents an * "initial" list of cluster nodes and is required to have at least one entry. */ private List&lt;String&gt; nodes; /** * Maximum number of redirects to follow when executing commands across the * cluster. */ private Integer maxRedirects; public List&lt;String&gt; getNodes() &#123; return this.nodes; &#125; public void setNodes(List&lt;String&gt; nodes) &#123; this.nodes = nodes; &#125; public Integer getMaxRedirects() &#123; return this.maxRedirects; &#125; public void setMaxRedirects(Integer maxRedirects) &#123; this.maxRedirects = maxRedirects; &#125; &#125; /** * Redis sentinel properties. */ public static class Sentinel &#123; /** * Name of the Redis server. */ private String master; /** * Comma-separated list of "host:port" pairs. */ private List&lt;String&gt; nodes; public String getMaster() &#123; return this.master; &#125; public void setMaster(String master) &#123; this.master = master; &#125; public List&lt;String&gt; getNodes() &#123; return this.nodes; &#125; public void setNodes(List&lt;String&gt; nodes) &#123; this.nodes = nodes; &#125; &#125; /** * Jedis client properties. */ public static class Jedis &#123; /** * Jedis pool configuration. */ private Pool pool; public Pool getPool() &#123; return this.pool; &#125; public void setPool(Pool pool) &#123; this.pool = pool; &#125; &#125; /** * Lettuce client properties. */ public static class Lettuce &#123; /** * Shutdown timeout. */ private Duration shutdownTimeout = Duration.ofMillis(100); /** * Lettuce pool configuration. */ private Pool pool; public Duration getShutdownTimeout() &#123; return this.shutdownTimeout; &#125; public void setShutdownTimeout(Duration shutdownTimeout) &#123; this.shutdownTimeout = shutdownTimeout; &#125; public Pool getPool() &#123; return this.pool; &#125; public void setPool(Pool pool) &#123; this.pool = pool; &#125; &#125;&#125; 第三步拿到RedisTemplate12345678910111213141516171819package com.springbootredisdemo.demo;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.RedisTemplate;@SpringBootTestclass DemoApplicationTests &#123; @Autowired RedisTemplate redisTemplate; @Test void contextLoads() &#123; redisTemplate.opsForValue().set("key","hahah"); System.out.println(redisTemplate.opsForValue().get("key")); redisTemplate.getConnectionFactory().getConnection().close(); &#125;&#125; API详解 操作String类型的都在redisTemplate.opsForValue() 操作Set类型的都在redisTemplate.opsForSet(); 操作Geo类型在在redisTemplate.opsForGeo() 操作Hash类型的都在redisTemplate.opsForHash() 自定义RedisTemplate为什么需要重写RedisTemplate假设我们有如下pojo类 1234567@Data@AllArgsConstructor@NoArgsConstructorpublic class User &#123; private String name; private int age;&#125; 如果我们自己存入redis，那么就会出现没有序列化的异常 1234567@Test void contextLoads() &#123; User user = new User("哈哈",2); redisTemplate.opsForValue().set("user",2); System.out.println(redisTemplate.opsForValue().get("key")); redisTemplate.getConnectionFactory().getConnection().close(); &#125; 解决方法方法一1234public class User implements Serializable &#123; private String name; private int age;&#125; 实现Serialzable接口，但是我们实际开发中并不会自己使用这种方式 方法二手动序列化JSON对象,这种方式是我们开发中比较常用的方式 12345678910111213141516171819@SpringBootTestclass DemoApplicationTests &#123; @Autowired RedisTemplate redisTemplate; @Test void contextLoads() &#123; User user = new User("哈哈",2); String json = null; try &#123; json= new ObjectMapper().writeValueAsString(user); &#125; catch (JsonProcessingException e) &#123; e.printStackTrace(); &#125; redisTemplate.opsForValue().set("user",json); System.out.println(redisTemplate.opsForValue().get("user")); &#125;&#125; 方法三上面的方法都太麻烦了，每次都需要手动序列化，虽然第一种也比较简单，但是第一种方式不通用，因为序列化为json，所有语言都能够读取，但是我们查看RedisTempation的源码发现他使用的是jdk的序列化方式 所有的序列化方式 12345678910111213141516171819202122232425@Configurationpublic class RedisConfig &#123; //编写我们自己的RedisTemplate @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate(); template.setConnectionFactory(factory); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); // key采用String的序列化方式 template.setKeySerializer(stringRedisSerializer); // hash的key也采用String的序列化方式 template.setHashKeySerializer(stringRedisSerializer); // value序列化方式采用jackson template.setValueSerializer(jackson2JsonRedisSerializer); // hash的value序列化方式采用jackson template.setHashValueSerializer(jackson2JsonRedisSerializer); template.afterPropertiesSet(); return template; &#125;&#125;]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安阳师院软件学院报名系统使用流程]]></title>
    <url>%2F2019%2F11%2F27%2F%E5%AE%89%E9%98%B3%E5%B8%88%E9%99%A2%E8%BD%AF%E4%BB%B6%E5%AD%A6%E9%99%A2%E6%8A%A5%E5%90%8D%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[安阳师院软件学院报名系统使用流程团队赛报名流程请大家使用谷歌浏览器或者国内的浏览器切换到极速模式在来打开本网站报名系统 前言 首先团队赛比赛有多个人参赛，该系统针对这类比赛提供团队比赛账号的注册，也就是说报名这类比赛必须先注册好个人账号，然后由团队账号邀请您加入该团队，之后进行报名。 第一步：注册属于您的个人账号1.进入登陆页面后点击创建账号,随后就能创建个人账号 学号和姓名必须要真实有效，否则影响您的获奖证书 电子邮箱可以用来找回密码 然后点击注册即可 第二步：如果您的队伍有团队账号请跳过这一步1.注册一个团队账号，在注册页面的上面有个团队账号点击即可 电子邮箱可以用来找回密码 第三步：登陆您团队账号1.登陆进去以后在导航栏找到管理我的团队 在邀请一栏中输入您队友的学号点击发送邀请即可，此时，该用户就会收到一个邀请信息，如果对方同意，那么在下面这一栏就会出现他的个人信息。 3.2个人账号同意加入队伍第一步登陆您的个人账号，点击导航栏的信封 第二步同意团队邀请 接下来在我加入的团队里面就能看见您当前加入的团队 第四步：报名比赛 团队比赛只能由团队账号报名 接下来点击导航栏的所有比赛找到您想参加的比赛点击报名即可如果没有邀请码可以直接确认跳过邀请码 如果没有邀请码点击确认即可 恭喜您成功报名个人赛报名流程第一步：您登陆您的个人账号 第二步：找到您要报名的比赛点击报名即可。]]></content>
      <categories>
        <category>软件学院</category>
      </categories>
      <tags>
        <tag>日常学习</tag>
        <tag>报名系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot入门环境搭建]]></title>
    <url>%2F2019%2F11%2F05%2FSpringBoot%E5%85%A5%E9%97%A8%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[SpringBoot入门环境搭建技术栈Springboot,mybatis,logback 开始第一步，idea新建SpringBoot工程 第二部配置开发环境 application.yml 12345678logging: file: path: loggerspring: profiles: active: devmybatis: mapper-locations: classpath:mapping/*.xml application-dev-yml 123456789101112131415161718spring: #注意下面的username和password的写法，这两个是大坑 datasource: url: jdbc:mysql://localhost:3306/dirver username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver http: encoding: force: true charset: utf-8 enabled: trueserver: port: 8081 tomcat: uri-encoding: UTF-8 第三步，使用mybatis-Generator生成mapper和mapping 第四步，配置logback]]></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>框架</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Thymeleaf入门教程]]></title>
    <url>%2F2019%2F11%2F01%2FThymeleaf%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Thymeleaf入门教程前言 最近在学习SpringBoot框架，以前在写web项目的时候一直使用的是JSP页面模板语言，但是在SpringBoot中已经不推荐使用了。所有要使用新的模板语言了，整合SpringBoot推荐这个Thymeleaf模板语言，所有就学习这个模板引擎吧 SpringBoot支持的模板语言 Thymeleaf(SpringBoot框架推荐) FreeMarker Velocity Groovy JSP … 1.快速开始首先要想使用Thymeleaf要添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; SpringBoot默认的存放模板页面的路径是src/main/resource/tempates或者src/main/view/templates 然后创建一个Controller对象，在其中进行参数传递 123456789@Controllerpublic class ThymeleafController &#123; @RequestMapping(value = "show", method = RequestMethod.GET) public String show(Model model)&#123; model.addAttribute("uid","123456789"); model.addAttribute("name","Jerry"); return "show"; &#125;&#125; 在SpringBoot默认页面下创建html文件(注意第二行的Thymeleaf的约束) 1234567891011&lt;!DOCTYPE HTML&gt;&lt;html xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;title&gt;SpringBoot模版渲染&lt;/title&gt; &lt;meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/&gt;&lt;/head&gt;&lt;body&gt; &lt;p th:text="'用户ID：' + $&#123;uid&#125;"/&gt; &lt;p th:text="'用户名称：' + $&#123;name&#125;"/&gt;&lt;/body&gt;&lt;/html&gt; 这样就会生成这样的html文件 1234567891011&lt;!DOCTYPE HTML&gt;&lt;html xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;title&gt;SpringBoot模版渲染&lt;/title&gt; &lt;meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/&gt;&lt;/head&gt;&lt;body&gt; &lt;p&gt;用户ID：123456789&lt;/p&gt; &lt;p&gt;用户名称：Jerry&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 标准表达式 ${...} : 变量表达式。 *{...} : 选择表达式。 #{...} : 消息 (i18n) 表达式。 @{...} : 链接 (URL) 表达式。 ~{...} : 片段表达式。 变量表达式变量表达式是OGNL表达式 - 如果将Thymeleaf 与Spring - 集成在上下文变量上(也称为Spring术语中的模型属性)，则为Spring EL。 它们看起来像这样: 1$&#123;person.name&#125; 选择表达式选择表达式就像变量表达式一样，它们不是整个上下文变量映射上执行，而是在先前选择的对象。 它们看起来像这样: 1*&#123;customer.name&#125; 它们所作用的对象由th:object属性指定: 12345&lt;div th:object="$&#123;book&#125;"&gt; ... &lt;span th:text="*&#123;title&#125;"&gt;...&lt;/span&gt; ...&lt;/div&gt; 所以这相当于: 123456&#123; // th:object="$&#123;book&#125;" final Book selection = (Book) context.getVariable("book"); // th:text="*&#123;title&#125;" output(selection.getTitle());&#125; 消息(i18n)表达式消息表达式(通常称为文本外部化，国际化或i18n)允许从外部源(如:.properties)文件中检索特定于语言环境的消息，通过键来引用这引用消息。 在Spring应用程序中，它将自动与Spring的MessageSource机制集成。如下 - 12#&#123;main.title&#125;#&#123;message.entrycreated($&#123;entryId&#125;)&#125; 以下是在模板中使用它们的方式: 123456&lt;table&gt; ... &lt;th th:text="#&#123;header.address.city&#125;"&gt;...&lt;/th&gt; &lt;th th:text="#&#123;header.address.country&#125;"&gt;...&lt;/th&gt; ...&lt;/table&gt; 请注意，如果希望消息键由上下文变量的值确定，或者希望将变量指定为参数，则可以在消息表达式中使用变量表达式: 1#&#123;$&#123;config.adminWelcomeKey&#125;($&#123;session.user.name&#125;)&#125;]]></content>
      <tags>
        <tag>模板</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch入门]]></title>
    <url>%2F2019%2F10%2F26%2Felasticsearch%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Elasticsearch elasticsearch是基于Lucene的一个分布式的使用REST接口的搜索引擎 特点 异步写入 单文档级操作具有原子性，一致性，隔离性和持久性 基本概念Cluster集群的意思，整个Elasticsearch是由一个或多个节点组成的集群。 Node一个Elasticsearch实例，一个Cluster由一个或多个Node组成。 Documentlasticsearch是面向文档的，这意味着您索引或搜索的最小数据单元是文档。文档在Elasticsearch中有一些重要的属性： 它是独立的。文档包含字段（名称）及其值。 它可以是分层的。可以将其视为文档中的文档。字段的值可以很简单，就像位置字段的值可以是字符串一样。它还可以包含其他字段和值。例如，位置字段可能包含城市和街道地址。 结构灵活。您的文档不依赖于预定义的架构。例如，并非所有事件都需要描述值，因此可以完全省略该字段。但它可能需要新的字段，例如位置的纬度和经度。 比如一段json在Elasticsearch中就以文档的形式保存 type文档的逻辑容器，从Elasticsearch6.0以后一个index只能有一个type 比如_doc就表示文档 index在Elasticsearch中index索引就是文档的集合，一个索引由一个或多个document组成 Elasticsearch的CRUDElasticsearch是遵循RESTful接口实现的也就是说正删改查都可以遵循REST接口规范 1234GET 获取一个资源 POST 添加一个资源 PUT 修改一个资源 DELETE 删除一个资源 简单的获取指定文档1GET / 当然如果你添加了数据比如执行了如下代码 12345PUT yang/_doc/1&#123; "user": "yang", "age": 22&#125; 然后使用 1GET yang/_doc/1 也可以获取 创建一个索引及文档12345PUT yang/_doc/1&#123; &quot;user&quot;: &quot;yang&quot;, &quot;age&quot;: 22&#125; 执行结果 1234567891011121314&#123; "_index" : "yang", "_type" : "_doc", "_id" : "1", "_version" : 1, "result" : "updated", "_shards" : &#123; "total" : 2, "successful" : 1, "failed" : 0 &#125;, "_seq_no" : 38, "_primary_term" : 1&#125; 其中put表示修改，yang是索引名称，_doc是type类型,1是主键 值得注意的是，执行上面的方法后，马上进行搜索可能结果是不可见的，因为在Elasticesearch中有一个叫做refresh的操作，通常有一个refresh timer来定时完成这个操作。这个周期为1秒。如果我们想让搜索结果立刻可见，可以使用如下参数 12345PUT yang/_doc/1?refresh=true&#123; &quot;user&quot;: &quot;yang&quot;, &quot;age&quot;: 22&#125; 但是这样做是有代价的，频繁的进行上述的refresh操作会导致Elasticsearch变的特别慢。 另一种方式使用refresh=wait_for，这样相当于一个同步操作，等待refresh周期完成后才返回。 version每次我们修改了同一个document，他的版本号就会加1，如果不存在则版本号为1 在次执行之前的代码，会发现返回值中的version字段变为了2 我们每次执行那个POST或者PUT接口时，如果文档已经存在，那么相应的版本就会自动加1 12345PUT yang/_doc/1&#123; &quot;user&quot;: &quot;yang&quot;, &quot;age&quot;: 22&#125; 1234567891011121314&#123; "_index" : "yang", "_type" : "_doc", "_id" : "1", "_version" : 2, "result" : "updated", "_shards" : &#123; "total" : 2, "successful" : 1, "failed" : 0 &#125;, "_seq_no" : 38, "_primary_term" : 1&#125; 如果不想让每次put和post接口的时候都加一，我们可以使用_create来实现， 12345PUT yang/_doc/1&#123; "user": "yang", "age": 22&#125; 报错信息 12345678910111213141516171819&#123; "error" : &#123; "root_cause" : [ &#123; "type" : "version_conflict_engine_exception", "reason" : "[1]: version conflict, document already exists (current version [7])", "index_uuid" : "K8He8JkrTRyRYmzRDzDWuw", "shard" : "0", "index" : "yang" &#125; ], "type" : "version_conflict_engine_exception", "reason" : "[1]: version conflict, document already exists (current version [7])", "index_uuid" : "K8He8JkrTRyRYmzRDzDWuw", "shard" : "0", "index" : "yang" &#125;, "status" : 409&#125; _create顾名思义，存在就报错 我们使用如下命令也一样 12345PUT yang/_doc/1?op_type=create&#123; "user": "yang", "age": 22&#125; 在请求中op_type可以有两种值index和create自动生成ID12345PUT yang/_doc/1&#123; "user": "yang", "age": 22&#125; 在上面的代码中我们添加必须指定id 其实在实际的应用中，这个并不必要。相反，当我们分配一个ID时，在数据导入的时候会检查这个ID的文档是否存在，如果是已经存在，那么就更新器版本。如果不存在，就创建一个新的文档。如果我们不指定文档的ID，转而让Elasticsearch自动帮我们生成一个ID，这样的速度更快。在这种情况下，我们必须使用POST，而不是PUT。 123456POST yang/_doc&#123; "user": "yang", "age": "22", "sex": "男"&#125; 返回指定的数据在之前GET返回值中我们获取了一大堆没有用的信息，如果我只想得到source的信息可以执行 1GET yang/_doc/1/_source 当然也可以只获取指定字段 1GET yang/_doc/1/?_source=user,age 注意_source前面有个?号，没有?号就报错 修改一个文档在上面我们看到了可以使用POST的命令来修改改一个文档。通常我们使用POST来创建一个新的文档。在使用POST的时候，我们甚至不用去指定特定的id，系统会帮我们自动生成。但是我们修改一个文档时，我们通常会使用PUT来进行操作，并且，我们需要指定一个特定的id来进行修改： 12345PUT yang/_doc/1&#123; "user": "yang", "age": 22&#125; 在put完成后，我们再次put 1234PUT yang/_doc/1&#123; "user": "yang",&#125; 然后在 1GET yang/_doc/1 会发现只有一个字段了，也就是说put进行了覆盖 如果我们不想每次想新增字段的时候都需要携带全部字段，我们可以使用 123456POST yang/_update/2&#123; "doc": &#123; "user": "yang" &#125;&#125; 在painless语言中，不能直接输入中文1234PUT yang/_doc/1&#123; "名字": "yang",&#125; 1234PUT yang/_doc/1&#123; "user": "名字",&#125; 第一个是不合法的，但是第二个是合法的 删除一个index1DELETE yang 这样在yang索引下的所有document(文档)都会被删除]]></content>
      <tags>
        <tag>elasticsearch</tag>
        <tag>搜索</tag>
        <tag>Lucene</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot入门]]></title>
    <url>%2F2019%2F10%2F20%2Fspringboot%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[springboot入门概述: 什么是springboot 它使用 “习惯优于配置” （项目中存在大量的配置，此外还内置一个习惯性的配置，让你无须）的理念让你的项目快速运行起来。 它并不是什么新的框架，而是默认配置了很多框架的使用方式，就像 Maven 整合了所有的 jar 包一样，Spring Boot 整合了所有框架 使用springboot有什么好处回顾我们之前的 SSM 项目，搭建过程还是比较繁琐的，需要： 1）配置 web.xml，加载 spring 和 spring mvc 2）配置数据库连接、配置日志文件 3）配置家在配置文件的读取，开启注解 4）配置mapper文件 ….. 而使用 Spring Boot 来开发项目则只需要非常少的几个配置就可以搭建起来一个 Web 项目，并且利用 IDEA 可以自动生成生成，这简直是太爽了… 划重点：简单、快速、方便地搭建项目；对主流开发框架的无配置集成；极大提高了开发、部署效率。 快速入门 1.导入maven坐标12345678910111213141516171819202122232425&gt; &lt;properties&gt;&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;&gt; &lt;/properties&gt;&gt; &lt;parent&gt;&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&gt; &lt;/parent&gt;&gt; &gt; &gt; &lt;dependencies&gt;&gt; &lt;dependency&gt;&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&gt; &lt;/dependency&gt;&gt; &lt;dependency&gt;&gt; &lt;groupId&gt;junit&lt;/groupId&gt;&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt;&gt; &lt;version&gt;4.11&lt;/version&gt;&gt; &lt;scope&gt;test&lt;/scope&gt;&gt; &lt;/dependency&gt;&gt; &lt;/dependencies&gt;&gt; 2.新建springboot入口（其他包必须与此类在同级目录或者子包下 ）123456789101112&gt; package com.qs304;&gt; &gt; import org.springframework.boot.SpringApplication;&gt; import org.springframework.boot.autoconfigure.SpringBootApplication;&gt; &gt; @SpringBootApplication&gt; public class SpringbootRunMain &#123;&gt; public static void main(String[] args) &#123;&gt; SpringApplication.run(SpringbootRunMain.class,args);&gt; &#125;&gt; &#125;&gt; 3.编写controller123456789101112131415&gt; package com.qs304.controller;&gt; &gt; import org.springframework.stereotype.Controller;&gt; import org.springframework.web.bind.annotation.RequestMapping;&gt; import org.springframework.web.bind.annotation.ResponseBody;&gt; &gt; @Controller&gt; public class HellpController &#123;&gt; @RequestMapping("/hello")&gt; @ResponseBody&gt; public String helloWorld()&#123;&gt; return "HelloWorld";&gt; &#125;&gt; &#125;&gt; 然后浏览器输入ip+项目名称就能访问了 默认生成的Spring Boot项目 主程序已经生成好了，我们只需要完成我们自己的逻辑 resources 文件夹中目录结构 static：保存所有的静态资源； js、css、images； templates：保存所有的模板页面；（Spring Boot默认jar包使用嵌入式的Tomcat，默认不支持JSP页面）；可以使用模板引擎（freemarker、thymeleaf）； application.properties：Spring Boot应用的配置文件；可以修改一些默认设置； Springboot研究 1.POM文件1.父项目（一般作为依赖管理）123456&gt; &lt;parent&gt;&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&gt; &lt;/parent&gt;&gt; 这个starter父项目还依赖了一个叫spring-boot-dependencies的父项目spring-boot-starter-parent(定义了每一个依赖的版本,管理springboot版本仲裁中心，定义了所有的依赖版本)1234567891011121314151617181920212223&gt; &lt;properties&gt;&gt; &lt;!-- Dependency versions --&gt;&gt; &lt;activemq.version&gt;5.14.5&lt;/activemq.version&gt;&gt; &lt;antlr2.version&gt;2.7.7&lt;/antlr2.version&gt;&gt; &lt;appengine-sdk.version&gt;1.9.59&lt;/appengine-sdk.version&gt;&gt; &lt;artemis.version&gt;1.5.5&lt;/artemis.version&gt;&gt; &lt;aspectj.version&gt;1.8.13&lt;/aspectj.version&gt;&gt; &lt;assertj.version&gt;2.6.0&lt;/assertj.version&gt;&gt; &lt;atomikos.version&gt;3.9.3&lt;/atomikos.version&gt;&gt; &lt;bitronix.version&gt;2.1.4&lt;/bitronix.version&gt;&gt; &lt;caffeine.version&gt;2.3.5&lt;/caffeine.version&gt;&gt; &lt;cassandra-driver.version&gt;3.1.4&lt;/cassandra-driver.version&gt;&gt; &lt;classmate.version&gt;1.3.4&lt;/classmate.version&gt;&gt; &lt;commons-beanutils.version&gt;1.9.3&lt;/commons-beanutils.version&gt;&gt; &lt;commons-collections.version&gt;3.2.2&lt;/commons-collections.version&gt;&gt; &lt;commons-codec.version&gt;1.10&lt;/commons-codec.version&gt;&gt; &lt;commons-dbcp.version&gt;1.4&lt;/commons-dbcp.version&gt;&gt; &lt;commons-dbcp2.version&gt;2.1.1&lt;/commons-dbcp2.version&gt;&gt; &lt;commons-digester.version&gt;2.1&lt;/commons-digester.version&gt;&gt; &lt;commons-pool.version&gt;1.6&lt;/commons-pool.version&gt;&gt; ...&gt; &lt;/properties&gt;&gt; 没有被定义的依赖还是需要我们手动进行版本的定义的 2.依赖&lt;dependency&gt;12345&gt; &lt;dependency&gt;&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&gt; &lt;/dependency&gt;&gt; spring-boot-starter-web：​ spring-boot-starter:是springboot的场景启动器，帮我们导入了web模块相关的依赖 也就是所还有很多其他的场景 springbot将所有的功能抽取出来，做成了一个个的starters（启动器）,只需要在项目里面引入这些相关场景，就能把需要的功能导入进来。 @SpringBootApplication: Spring Boot 应用标注在某个类上说明这个类似SpringBoot的主配置类,springBoot就是运行这个类的main方法来启动SpringBoot应用:@SpringBootApplication里面的注解 1234567891011121314151617&gt; @Target(&#123;ElementType.TYPE&#125;)&gt; @Retention(RetentionPolicy.RUNTIME)&gt; @Documented&gt; @Inherited&gt; @SpringBootConfiguration&gt; @EnableAutoConfiguration&gt; @ComponentScan(&gt; excludeFilters = &#123;@Filter(&gt; type = FilterType.CUSTOM,&gt; classes = &#123;TypeExcludeFilter.class&#125;&gt; ), @Filter(&gt; type = FilterType.CUSTOM,&gt; classes = &#123;AutoConfigurationExcludeFilter.class&#125;&gt; )&#125;&gt; )&gt; @ConfigurationPropertiesScan&gt; @SpringBootConfiguration:Spring Boot配置类标注在某个类上，表示这是一个SpringBoot的配置类: @SpringBootConfiguration:Spring里面的注解有 123456@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Configuration( proxyBeanMethods = false) Configuration：使用这个注解表示这个类是一个配置类（配置类也是一个组件）EnableAutoConfiguration：开启自动配置(以前手写SSM框架整合的时候需要我们手写配置，现在SpringBoot通过这个注解开启自动配置，这样自动配置才能生效)@EnableAutoConfiguration这个注解里面的注解有: 123456@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(&#123;AutoConfigurationImportSelector.class&#125;) @AutoConfigurationPackage：自动配置包@AutoConfigurationPackage里面的注解 12345@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(&#123;Registrar.class&#125;) ​ @import：给容器导入组件 最后，由SpringBootApplication标注的类，的所在包和下面的子包里面所有组件扫描到Spring容器中; 配置文件SpringBoot默认会使用两个全局配置文件 application.properties application.yml或者application.yaml yaml和properties配置文件同时存在，properties配置文件的内容会覆盖yaml配置文件的内容 yml简介 YAML (YAML Aint Markup Language)是一种标记语言，通常以.yml为后缀的文件，是一种直观的能够被电脑识别的数据序列化格式，并且容易被人类阅读，容易和脚本语言交互的，可以被支持YAML库的不同的编程语言程序导入，一种专门用来写配置文件的语言。可用于如： Java，C/C++, Ruby, Python, Perl, C#, PHP等。 yml的优点 YAML易于人们阅读。 YAML数据在编程语言之间是可移植的。 YAML匹配敏捷语言的本机数据结构。 YAML具有一致的模型来支持通用工具。 YAML支持单程处理。 YAML具有表现力和可扩展性。 YAML易于实现和使用。 yml的语法1.约定 k: v表示键值对关系，（注意冒号后面必须有一个空格) 使用空格的缩进表示层级关系，空格数目不重要，只要是左对齐的一列数据，都是一个层级的 大小写敏感 使用缩进时不允许使用tab键，只能使用空格 松散的表示，java中对于驼峰命名法，可以用原名或者使用-代替驼峰（bean的lastName属性，可以使用lastName或者last-name） 在yml语法中，空值可以使用null表示 键值对关系 字符串默认不用加单引号或者双引号 “”双引号；会转义字符串里面的特殊字符， ‘’单引号不会转义里面的字符 list数组类型行内写法使用[]，展开使用- map类型行内写法使用{}，展开使用k: v 日期使用 2019/01/01 文档块使用—-隔开，可以把不同的配置文件写入一个yml配置文件中 字面量：普通的值（数字，字符串，布尔 1k: v 字符串默认不用加上单引号或者双引号； &quot;&quot;：双引号；会转义字符串里面的特殊字符；特殊字符会作为本身想表示的意思 eg： name: “zhangsan \n lisi”：输出；zhangsan 换行 lisi &#39;&#39;：单引号；不会转义特殊字符，特殊字符最终只是一个普通的字符串数据 eg： name: ‘zhangsan \n lisi’：输出；zhangsan \n lisi 对象、Map（属性和值） k: v在下一行来写对象的属性和值的关系；注意缩进 1234person: name: 张三 gender: 男 age: 22Copy to clipboardErrorCopied 行内写法 1person: &#123;name: 张三,gender: 男,age: 22&#125;Copy to clipboardErrorCopied 数组（List、Set） 1234fruits: - 苹果 - 桃子 - 香蕉Copy to clipboardErrorCopied 行内写法 1fruits: [苹果,桃子,香蕉]Copy to clipboardErrorCopied 配置文件值注入123456&lt;!--导入配置文件处理器，配置文件进行绑定就会有提示--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;Copy to clipboardErrorCopied **配置文件：** 123456789101112131415person: name: 张三 gender: 男 age: 36 boss: true birth: 1982/10/1 maps: &#123;k1: v1,k2: v2&#125; lists: - apple - peach - banana pet: name: 小狗 age: 12 Copy to clipboardErrorCopied **测试** 1234567891011121314151617181920package cn.clboy.helloworldquickstart; import cn.clboy.helloworldquickstart.model.Person; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; @SpringBootTest class HelloworldquickstartApplicationTests &#123; @Autowired private Person person; @Test void contextLoads() &#123; System.out.println(person); &#125; &#125; Copy to clipboardErrorCopied ## properties 上面yaml对应的properties配置文件写法 12345678910person.name=李四 person.age=34 person.birth=1986/09/12 person.boss=true person.gender=女 person.lists=cat,dog,pig person.maps.k1=v1 person.maps.k2=v2 person.pet.name=&quot;小黑&quot; person.pet.age=10演示123456789101112ren: #普通的int类型 id: 10 #String类型 name: 100 #list类型，里面是String类型 list: ["我是双引号我换行码？\n换行",'我是单引号我换行码?\n不换行'] #string类型,使用null string: null #运行结果: #Person&#123;id=10, name='100', list=[我是双引号我换行码？ #换行, 我是单引号我换行码?\n不换行], string=''&#125; @Value和@ConfigurationProperties注解的区别 @ConfigurationProperties @Value 功能 批量注入文件中的属性 一个一个指定 松散绑定（松散语法） 支持 不支持 spel 不支持 支持 JSR303数据校验 支持 不支持 复杂类型封装 支持 不支持 总结 @Value只能获取基本数据类型 @ConfigurationProperties可以获取map,list等封装类型的值 配置文件yaml和properties都可以获取到值 如果只是需要在业务逻辑中获取一下配置文件中的某个值，使用@Value 如果要是把javabean和配置文件进行11映射，使用@ConfigurationProperties @ConfigurationProperties默认是从全局配置文件中获取值的 @PropertySource @PropertySource注解的作用是加载指定的配置文件，值可以是数组，也就是可以加载多个配置文件 springboot默认加载的配置文件名是`application`，如果配置文件名不是这个是不会被容器加载的. @ImportResource 如果要想加载xml等配置文件需要使用该注解 注意！这个注解是放在主入口函数的类上. @PropertySource与@ImportResource的区别@PropertySource 用于引入*.Properties或者 .yml (yml不能直接支持)用于给javabean注入值@ImportResource 用于引入.xml 类型的配置文件 在spring boot中已经被配置类替代@PropertySource 一般用在javabean的类名上@ImportResource一般用于启动类上 PropertySource自定义配置文件，多用于配置文件与实体属性映射 在从配置文件里面获取值，与javaBean做映射时存在一个问题，我们从主配置文件（application.yml）里面读取会导致主配置文件特别臃肿，为了按照不同模块自定义不同的配置文件引入了@PropertySource 演示： 12345678910person.propertiesperson.lastName=李四person.age=25person.birth=2017/12/15person.boss=trueperson.maps.key1=value1person.maps.key2=value2person.lists=a,b,cperson.dog.name=dogperson.dog.age=2 javabean 12345678@PropertySource(value = &#123;"classpath:person.properties"&#125;)//通过类路径修改默认配置文件@ConfigurationProperties(prefix = "person")//加载配置文件@Componentpublic class Person &#123; private String lastName; private Integer age; private boolean isBoss; private Date birth; @ImplementResources 一般情况下我们自定义的xml配置文件默认情况下这个bean是不会加载到Spring容器中来的，于是乎我们需要@ImportResoure注解将这个配置文件加载进来 123456&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="helloService" class="com.chentongwei.springboot.service.HelloService"&gt;&lt;/bean&gt;&lt;/beans&gt; 总结： @PropertySource 用于引入.Properties或者 *.yml 用于给javabean注入值 @ImportResource 用于引入.xml 类型的配置文件 在spring boot中已经被配置类替代 @PropertySource 一般用在javabean的类名上 @ImportResource一般用于启动类上 SpringBoot配置文件占位符前言: 在springboot的配置文件中，我们可以使用springboot提供的一些随机数或者使用我们在配置文件中定义的值 随机数12345678910person.propertiesperson.lastName=$&#123;person.properties&#125;person.age=25person.birth=2017/12/15person.boss=trueperson.maps.key1=$&#123;random.int[1024,65536]&#125;person.maps.key2=value2person.lists=a,b,cperson.dog.name=dogperson.dog.age=2 ${random.value} - 类似uuid的随机数，没有”-“连接 ${random.int} - 随机取整型范围内的一个值 ${random.long} - 随机取长整型范围内的一个值 ${random.long(100,200)} - 随机生成长整型100-200范围内的一个值 ${random.uuid} - 生成一个uuid，有短杠连接 ${random.int(10)} - 随机生成一个10以内的数 ${random.int(100,200)} - 随机生成一个100-200 范围以内的数 占位符12person.propertiesperson.lastName=$&#123;person.properties&#125;#引用person.properties的值 SpringBoot配置Profile多环境支持1.多Profile文件​ 我们在主配置文件编写的时候，文件名可以是 application-{profile}.yml或者application-{profile}.properties ,都行，以下用yml为主。以下主配置文件表示 application.yml 编写一个名为 application-dev.yml文件： 12server: port: 8081 123#编写一个名为application-prod.yml文件：server: port: 8082 先启动springboot项目，发现启动的端口为 81(application.yml中指定的端口为 81) ，也就是说默认启动的是application.yml的环境。 2.yml多文档块支持配置文件中也支持使用多文档块的方式创建多环境，是用 — (三个-)表示一个文档块 ，如果不指定启动别的文档块，默认启动第一个文档块，可以通过 spring.profiles.actice=dev 来指定启动别的文档块。 12345678910111213141516server: port: 8081spring: profiles: #指定启动的环境 active: dev---server: port: 8083spring: profiles: dev---server: port: 8084spring: profiles: prod 这样启动的时候就会使用dev这个环境 3.使用命令指定环境在idea里面有一个run configurations中指定参数 –spring.profiles.active=dev也可以指定环境 SpringBoot静态资源目录1、classpath 类目录 (src/mian/resource)classpath 即 WEB-INF 下面的 classes 目录 ，在 SpringBoot 项目中是 src/main/resource 目录。 2、ServletContext 根目录下( src/main/webapp )一、SpringBoot 访问web中的静态资源SpringBoot默认指定了一些固定的目录结构，静态资源放到这些目录中的某一个，系统运行后浏览器就可以访问到 1、SpringBoot 默认指定的可以存放静态资源的目录有哪些？ classpath:/META-INF/resources/ 需创建/META-INF/resources/ 目录 classpath:/resources/ 需创建/resources/目录 classpath:/static/ 工具自动生成的static目录，也是用的最多的目录 classpath:/public/ 需创建/public/ 目录 src/main/webapp/ 需创建/webapp/ 目录 这些目录下的文件可以直接访问不需要在url上面添加文件名 3、SpringBoot 默认的首页是放在任一个静态资源目录下的index.html 4、SpringBoot 默认的web页面图标是放在任一静态资源目录下的favicon.ico 配置文件加载顺序 外部配置加载顺序SpringBoot也可以从以下位置加载配置； 优先级从高到低；高优先级的配置覆盖低优先级的配置，所有的配置会形成互补配置 命令行参数 所有的配置都可以在命令行上进行指定 1java -jar xxx.jar --server.port=8087 --server.context-path=/abcCopy to clipboardErrorCopied 多个配置用空格分开； –配置项=值 来自java:comp/env的JNDI属性 Java系统属性（System.getProperties()） 操作系统环境变量 RandomValuePropertySource配置的random.*属性值 由jar包外向jar包内进行寻找； 再来加载不带profile jar包外部的application.properties或application.yml(不带spring.profile)配置文件 **jar包内部的application.properties或application.yml(不带spring.profile)配置文件 优先加载带profile **jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件 ⤴️ **jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件 @Configuration注解类上的@PropertySource 通过SpringApplication.setDefaultProperties指定的默认属性 自动配置原理SpringBoot启动的时候加载主配置类，开启了自动配置功能 12@SpringBootApplication @EnableAutoConfiguration @EnableAutoConfiguration 利用EnableAutoConfigurationImportSelector给容器中导入一些组件 getAutoConfigurationEntry方法中 12//获取候选的配置List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata,attributes) getCandidateConfigurations方法中，SpringFactoriesLoader.loadFactoryNames()，扫描所有jar包类路径下 META-INF/spring.factories，把扫描到的这些文件的内容包装成properties对象，从properties中获取到EnableAutoConfiguration.class（类名）对应的值，然后把它们添加在容器中 每一个这样的 xxxAutoConfiguration类都是容器中的一个组件，都加入到容器中；用他们来做自动配置； 每一个自动配置类进行自动配置功能； 演示自动配置以HttpEncodingAutoConfiguration为例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package org.springframework.boot.autoconfigure.web.servlet;......//表示这是一个配置类，以前编写的配置文件一样，也可以给容器中添加组件@Configuration( proxyBeanMethods = false)/** * 启动指定类的ConfigurationProperties功能； * 将配置文件中对应的值和HttpProperties绑定起来； * 并把HttpProperties加入到ioc容器中 */@EnableConfigurationProperties(&#123;HttpProperties.class&#125;)/** * Spring底层@Conditional注解 * 根据不同的条件，如果满足指定的条件，整个配置类里面的配置就会生效； * 判断当前应用是否是web应用，如果是，当前配置类生效 */@ConditionalOnWebApplication( type = Type.SERVLET)//判断当前项目有没有这个类@ConditionalOnClass(&#123;CharacterEncodingFilter.class&#125;)/** * 判断配置文件中是否存在某个配置 spring.http.encoding.enabled；如果不存在，判断也是成立的 * 即使我们配置文件中不配置pring.http.encoding.enabled=true，也是默认生效的； */@ConditionalOnProperty( prefix = "spring.http.encoding", value = &#123;"enabled"&#125;, matchIfMissing = true)public class HttpEncodingAutoConfiguration &#123; //它已经和SpringBoot的配置文件映射了 private final Encoding properties; //只有一个有参构造器的情况下，参数的值就会从容器中拿 public HttpEncodingAutoConfiguration(HttpProperties properties) &#123; this.properties = properties.getEncoding(); &#125; @Bean //给容器中添加一个组件，这个组件的某些值需要从properties中获取 @ConditionalOnMissingBean //判断容器有没有这个组件？（容器中没有才会添加这个组件） public CharacterEncodingFilter characterEncodingFilter() &#123; CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(org.springframework.boot.autoconfigure.http.HttpProperties.Encoding.Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce(org.springframework.boot.autoconfigure.http.HttpProperties.Encoding.Type.RESPONSE)); return filter; &#125; ...... 总结 SpringBoot启动会加载大量的自动配置类 我们看我们需要的功能有没有SpringBoot默认写好的自动配置类 再来看这个自动配置类中到底配置了哪些组件；（只要我们要用的组件有，我们就不需要再来配置了） 给容器中自动配置类添加组件的时候，会从properties类中获取某些属性。我们就可以在配置文件中指定这些属性的值 xxxxAutoConfigurartion：自动配置类； xxxxProperties:封装配置文件中相关属性； @Conditional派生注解作用：必须是@Conditional指定的条件成立，才给容器中添加组件，配置配里面的所有内容才生效； @Conditional扩展注解 作用（判断是否满足当前指定条件） @ConditionalOnJava 系统的java版本是否符合要求 @ConditionalOnBean 容器中存在指定Bean； @ConditionalOnMissingBean 容器中不存在指定Bean； @ConditionalOnExpression 满足SpEL表达式指定 @ConditionalOnClass 系统中有指定的类 @ConditionalOnMissingClass 系统中没有指定的类 @ConditionalOnSingleCandidate 容器中只有一个指定的Bean，或者这个Bean是首选Bean @ConditionalOnProperty 系统中指定的属性是否有指定的值 @ConditionalOnResource 类路径下是否存在指定资源文件 @ConditionalOnWebApplication 当前是web环境 @ConditionalOnNotWebApplication 当前不是web环境 @ConditionalOnJndi JNDI存在指定项 如何查看哪些配置类生效了自动配置类必须在一定的条件下才能生效； 我们怎么知道哪些自动配置类生效了； 我们可以通过配置文件启用 debug=true属性；来让控制台打印自动配置报告，这样我们就可以很方便的知道哪些自动配置类生效； Positive matches ：（自动配置类启用的） Negative matches：（没有启动，没有匹配成功的自动配置类）]]></content>
  </entry>
  <entry>
    <title><![CDATA[pageHelper入门]]></title>
    <url>%2F2019%2F10%2F20%2FpageHelper%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[pageHelper入门前言 之前写web网页的时候使用的是SQL语句中的limit进行分页，无意间发现这种分页写法特别傻屌（╮(╯▽╰)╭），假如你每页有100条数据，你要查询第100页的数据，那么这个SQL语句做的事情就是获取前100100大概这个范围的数据，然后把前100000条数据丢弃，这样是非常浪费性能的，所有我就学习了pageHelper这个分页插件 快速入门步骤 1.使用maven导入依赖 123456&gt; &lt;dependency&gt;&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt;&gt; &lt;version&gt;5.1.2&lt;/version&gt;&gt; &lt;/dependency&gt;&gt; 2.在配置文件中配置拦截器插件 第一种：使用spring的属性配置 12345678910111213141516&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt;&gt; &lt;!-- 注意其他配置 --&gt;&gt; &lt;property name="plugins"&gt;&gt; &lt;array&gt;&gt; &lt;bean class="com.github.pagehelper.PageInterceptor"&gt;&gt; &lt;property name="properties"&gt;&gt; &lt;!--使用下面的方式配置参数，一行配置一个 --&gt;&gt; &lt;value&gt;&gt; params=value1&gt; &lt;/value&gt;&gt; &lt;/property&gt;&gt; &lt;/bean&gt;&gt; &lt;/array&gt;&gt; &lt;/property&gt;&gt; &lt;/bean&gt;&gt; 第二种使用mybatis配置 12345678910111213141516&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt;&gt; &lt;!-- 注意其他配置 --&gt;&gt; &lt;property name="plugins"&gt;&gt; &lt;array&gt;&gt; &lt;bean class="com.github.pagehelper.PageInterceptor"&gt;&gt; &lt;property name="properties"&gt;&gt; &lt;!--使用下面的方式配置参数，一行配置一个 --&gt;&gt; &lt;value&gt;&gt; params=value1&gt; &lt;/value&gt;&gt; &lt;/property&gt;&gt; &lt;/bean&gt;&gt; &lt;/array&gt;&gt; &lt;/property&gt;&gt; &lt;/bean&gt;&gt; 3.编写需要分页的controller 1234567891011121314151617181920&gt; //获取第1页，10条内容，默认查询总数count&gt; PageHelper.startPage(1, 10);&gt; List&lt;Country&gt; list = countryMapper.selectAll();&gt; //用PageInfo对结果进行包装&gt; PageInfo page = new PageInfo(list);&gt; //测试PageInfo全部属性&gt; //PageInfo包含了非常全面的分页属性&gt; assertEquals(1, page.getPageNum());&gt; assertEquals(10, page.getPageSize());&gt; assertEquals(1, page.getStartRow());&gt; assertEquals(10, page.getEndRow());&gt; assertEquals(183, page.getTotal());&gt; assertEquals(19, page.getPages());&gt; assertEquals(1, page.getFirstPage());&gt; assertEquals(8, page.getLastPage());&gt; assertEquals(true, page.isFirstPage());&gt; assertEquals(false, page.isLastPage());&gt; assertEquals(false, page.isHasPreviousPage());&gt; assertEquals(true, page.isHasNextPage());&gt; 导航栏演示 12345678910111213141516171819202122232425262728293031323334&gt; &lt;div class="row"&gt;&gt; &lt;div class="col-md-6"&gt;当前是第$&#123;pageInfo.pageNum&#125;,页一共有$&#123;pageInfo.pages&#125;页,共有$&#123;pageInfo.total&#125;条数据&lt;/div&gt;&gt; &lt;div class="col-md-6"&gt;&gt; &lt;nav aria-label="Page navigation"&gt;&gt; &lt;ul class="pagination"&gt;&gt; &gt; &lt;c:if test="$&#123;pageInfo.pageNum!=1&#125;"&gt;&gt; &lt;li&gt;&gt; &lt;a href="$&#123;pageContext.request.contextPath&#125;/?pn=$&#123;pageInfo.prePage&#125;" aria-label="Previous"&gt;&gt; &lt;span aria-hidden="true"&gt;&amp;laquo;&lt;/span&gt;&gt; &lt;/a&gt;&gt; &lt;/li&gt;&gt; &lt;/c:if&gt;&gt; &gt; &lt;li class="$&#123;pageInfo.pageNum==1?"disabled":""&#125;"&gt;&lt;a href="$&#123;pageContext.request.contextPath&#125;/?pn=$&#123;pageInfo.firstPage&#125;"&gt;首页&lt;/a&gt;&lt;/li&gt;&gt; &gt; &lt;c:forEach items="$&#123;pageInfo.navigatepageNums&#125;" var="pageNum"&gt;&gt; &lt;li class="$&#123;pageInfo.pageNum==pageNum?"disabled":""&#125;"&gt;&lt;a href="$&#123;pageContext.request.contextPath&#125;/?pn=$&#123;pageNum&#125;"&gt;$&#123;pageNum&#125;&lt;/a&gt;&lt;/li&gt;&gt; &lt;/c:forEach&gt;&gt; &gt; &lt;li class="$&#123;pageInfo.pageNum==pageInfo.pages?"disabled":""&#125;"&gt;&lt;a href="$&#123;pageContext.request.contextPath&#125;/?pn=$&#123;pageInfo.lastPage&#125;"&gt;末页&lt;/a&gt;&lt;/li&gt;&gt; &gt; &lt;c:if test="$&#123;pageInfo.pageNum!=pageInfo.navigateLastPage&#125;"&gt;&gt; &lt;li&gt;&gt; &lt;a href="$&#123;pageContext.request.contextPath&#125;/?pn=$&#123;pageInfo.nextPage&#125;#" aria-label="Next"&gt;&gt; &lt;span aria-hidden="true"&gt;&amp;raquo;&lt;/span&gt;&gt; &lt;/a&gt;&gt; &lt;/li&gt;&gt; &lt;/c:if&gt;&gt; &lt;/ul&gt;&gt; &lt;/nav&gt;&gt; &lt;/div&gt;&gt; &lt;/div&gt;&gt; 参数介绍 3. 分页插件参数介绍分页插件提供了多个可选参数，这些参数使用时，按照上面两种配置方式中的示例配置即可。 分页插件可选参数如下： dialect：默认情况下会使用 PageHelper 方式进行分页，如果想要实现自己的分页逻辑，可以实现 Dialect(com.github.pagehelper.Dialect) 接口，然后配置该属性为实现类的全限定名称。 下面几个参数都是针对默认 dialect 情况下的参数。使用自定义 dialect 实现时，下面的参数没有任何作用。 helperDialect：分页插件会自动检测当前的数据库链接，自动选择合适的分页方式。 你可以配置helperDialect属性来指定分页插件使用哪种方言。配置时，可以使用下面的缩写值：oracle,mysql,mariadb,sqlite,hsqldb,postgresql,db2,sqlserver,informix,h2,sqlserver2012,derby特别注意：使用 SqlServer2012 数据库时，需要手动指定为 sqlserver2012，否则会使用 SqlServer2005 的方式进行分页。你也可以实现 AbstractHelperDialect，然后配置该属性为实现类的全限定名称即可使用自定义的实现方法。 offsetAsPageNum：默认值为 false，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置为 true 时，会将 RowBounds 中的 offset 参数当成 pageNum 使用，可以用页码和页面大小两个参数进行分页。 rowBoundsWithCount：默认值为false，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置为true时，使用 RowBounds 分页会进行 count 查询。 pageSizeZero：默认值为 false，当该参数设置为 true 时，如果 pageSize=0 或者 RowBounds.limit = 0 就会查询出全部的结果（相当于没有执行分页查询，但是返回结果仍然是 Page 类型）。 reasonable：分页合理化参数，默认值为false。当该参数设置为 true 时，pageNum&lt;=0 时会查询第一页， pageNum&gt;pages（超过总数时），会查询最后一页。默认false 时，直接根据参数进行查询。 params：为了支持startPage(Object params)方法，增加了该参数来配置参数映射，用于从对象中根据属性名取值， 可以配置 pageNum,pageSize,count,pageSizeZero,reasonable，不配置映射的用默认值， 默认值为pageNum=pageNum;pageSize=pageSize;count=countSql;reasonable=reasonable;pageSizeZero=pageSizeZero。 supportMethodsArguments：支持通过 Mapper 接口参数来传递分页参数，默认值false，分页插件会从查询方法的参数值中，自动根据上面 params 配置的字段中取值，查找到合适的值时就会自动分页。 使用方法可以参考测试代码中的 com.github.pagehelper.test.basic 包下的 ArgumentsMapTest 和 ArgumentsObjTest。 autoRuntimeDialect：默认值为 false。设置为 true 时，允许在运行时根据多数据源自动识别对应方言的分页 （不支持自动选择sqlserver2012，只能使用sqlserver），用法和注意事项参考下面的场景五。 closeConn：默认值为 true。当使用运行时动态数据源或没有设置 helperDialect 属性自动获取数据库类型时，会自动获取一个数据库连接， 通过该属性来设置是否关闭获取的这个连接，默认true关闭，设置为 false 后，不会关闭获取的连接，这个参数的设置要根据自己选择的数据源来决定。 重要提示： 当 offsetAsPageNum=false 的时候，由于 PageNum 问题，RowBounds查询的时候 reasonable 会强制为 false。使用 PageHelper.startPage 方法不受影响。 pageHelper属性1234567891011121314151617181920212223242526272829303132333435363738//当前页private int pageNum;//每页的数量private int pageSize;//当前页的数量private int size;//由于startRow 和endRow 不常用，这里说个具体的用法//可以在页面中"显示startRow 到endRow 共size 条数据"//当前页面第一个元素在数据库中的行号private int startRow;//当前页面最后一个元素在数据库中的行号private int endRow;//总记录数private long total;//总页数private int pages;//结果集private List&lt;T&gt; list;//前一页private int prePage;//下一页private int nextPage;//是否为第一页private boolean isFirstPage = false;//是否为最后一页private boolean isLastPage = false;//是否有前一页private boolean hasPreviousPage = false;//是否有下一页private boolean hasNextPage = false;//导航页码数private int navigatePages;//所有导航页号private int[] navigatepageNums;//导航条上的第一页private int navigateFirstPage;//导航条上的最后一页private int navigateLastPage;]]></content>
      <categories>
        <category>插件</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>数据库</tag>
        <tag>分页</tag>
        <tag>WEB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jQuery入门教程]]></title>
    <url>%2F2019%2F10%2F17%2FjQuery%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[jQuery入门教程 jQuery就是一个js库，它极大地简化了js的编程，因此jQuery也很容易学习和使用。 入门演示这个隐藏了body标签下div这个长200px和宽200px粉色的盒子，并且打印一行话 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;script src="jquery.min.js"&gt;&lt;/script&gt; &lt;style&gt; div&#123; height: 200px; width: 200px; background-color: red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="css"&gt;&lt;/div&gt; &lt;script&gt; $(function()&#123; $("div").hide(); alert("asfda"); &#125;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; jQuery顶级对象$ $是jQuery的一个别称，在代码中可以使用$符号代替jQuery，通常目的都是为了简化操作。 $是jQuery的顶级对象，相当于原生javaScript中的window 演示1234567891011121314151617181920212223242526272829&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;script src="jquery.min.js"&gt;&lt;/script&gt; &lt;style&gt; div&#123; height: 200px; width: 200px; background-color: red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="css"&gt;&lt;/div&gt; &lt;script&gt; $(function()&#123; $("div").hide(); alert("asfda"); &#125;); //下面的和上面的效果完全一致 jQuery(function()&#123; jQuery("div").hide(); alert("asfda"); &#125;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; jQuery对象和DOM对象 使用原生js获取的对象就是DOM对象 使用JQuery中的$获取的对象就是jQuery对象 他们之间可以相互转化，但是不相互转化之前不能使用对方的属性和方法 演示123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;script src="jquery.min.js"&gt;&lt;/script&gt; &lt;style&gt; div&#123; height: 200px; width: 200px; background-color: red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="css"&gt;&lt;/div&gt; &lt;script&gt; $(function()&#123; //获取原生的DOM对象 console.dir(document.querySelector('div')); //获取jQuery对象 console.dir($('div')); &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; jQuery和DOM对象相互转化DOM对象转化为JQuery对象 1$(&lt;DOM对象&gt;) jQuery对象转化DOM对象 12$(&lt;jQuer对象&gt;)[&lt;index&gt;]//下标访问的方式$(&lt;jQuer对象&gt;).get(&lt;index&gt;) 演示1234567891011121314151617181920212223242526272829303132&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;script src="jquery.min.js"&gt;&lt;/script&gt; &lt;style&gt; div&#123; height: 200px; width: 200px; background-color: red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="css"&gt;&lt;/div&gt; &lt;script&gt; $(function()&#123; //1.获取原生的DOM对象 var DOMClass=document.querySelector('div'); //转化jQuery对象 var parseJquery=$(DOMClass); //2.获取jQuery对象 var jQueryClass=$('div'); //转化为DOM对象,因为这个代码里面只有一个div所有通过下标访问0下标就可以得到 var parseDOM=jQueryClass[0]; &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; jQuery选择器1.基础选择器 名称 用法 描述 ID选择器 $(“#id”) 获取指定的ID元素 全选选择器 $(“*”) 获取所有元素 类选择器 $(“.class”) 获取同一类class的元素 标签选择器 $(“div”) 获取同一标签的所有元素 并集选择器 $(“div,p,li”) 获取多个元素 交集选择器 $(“li,current”) 交集选择器 演示123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;script src="jquery.min.js"&gt;&lt;/script&gt; &lt;style&gt; div&#123; height: 200px; width: 200px; background-color: red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="css"&gt;&lt;/div&gt; &lt;script&gt; $(function()&#123; //通过类选择器获取类为css的div盒子 console.dir($(".css")); &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; jQuery隐式迭代 在jQuery中会对jQuery对象进行隐式迭代 也就是说jQuery会对获取到的所有对象迭代执行相同的操作，这样可以极大的简化我们编写的代码 演示12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;script src="jquery.min.js"&gt;&lt;/script&gt; &lt;style&gt; div&#123; height: 200px; width: 200px; border: 1px solid red; background-color: red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="css"&gt;1&lt;/div&gt; &lt;div class="css"&gt;2&lt;/div&gt; &lt;div class="css"&gt;3&lt;/div&gt; &lt;div class="css"&gt;4&lt;/div&gt; &lt;script&gt; $(function()&#123; //利用jQuery的隐式迭代修改全部div的背景颜色 $('div').css("background-color","blue"); &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; jQuery筛选选择器 可以在获取的jQuery对象伪数组中筛选 语法 用法 描述 :first $(“li:first”) 获取li后面第一个li元素 :last $(“li:last”) 获取li伪数组中的最后一个元素 :eq(&lt; index &gt;) $(“li:eq(2)”) 获取li伪数组中的2下标元素 :odd $(“li:odd”) 获取到li元素中,选择索引号为奇数的元素 :even $(“li:even”) 获取到li元素中,选择索引号为偶数的元素 演示修改指定位置div的颜色 12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;script src="jquery.min.js"&gt;&lt;/script&gt; &lt;style&gt; div&#123; height: 200px; width: 200px; border: 1px solid red; background-color: red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="css"&gt;1&lt;/div&gt; &lt;div class="css"&gt;2&lt;/div&gt; &lt;div class="css"&gt;3&lt;/div&gt; &lt;div class="css"&gt;4&lt;/div&gt; &lt;script&gt; $(function()&#123; //利用jQuery的隐式迭代修改全部div的背景颜色 $('div:eq(2)').css("background-color","blue"); &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; jQuery筛选方法 语法 用法 说明 parent() $(“li”).parent() 查找li的父亲节点 children(selector) $(“ul”).children(“li”) 相当于$(“ul&gt;li”)，最近一级的（亲儿子） find(selector) $(“ul”).find(“li”) 相当于$(“ul li”)，后代选择器 siblings(selector) $(“.first”).siblings(‘li’) 查找兄弟节点不包括本身 nextAll([expr]) $(“.first”).nextAll() 查找当前元素之后所有同辈元素 prevtAll([expr]) $(“.last”).prevAll() 查找当前元素之前所有的同辈元素 hasClass(class) $(‘div’).hasClass（”protected”) 检查当前的元素是否有包含特定的类，如果有返回true eq(index) $(“li”).eq(2) 相当于$(“li:eq(2)”) 演示让2下标的div盒子后面的div盒子变色 12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;script src="jquery.min.js"&gt;&lt;/script&gt; &lt;style&gt; div&#123; height: 200px; width: 200px; border: 1px solid red; background-color: red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="css"&gt;1&lt;/div&gt; &lt;div class="css"&gt;2&lt;/div&gt; &lt;div class="css"&gt;3&lt;/div&gt; &lt;div class="css"&gt;4&lt;/div&gt; &lt;script&gt; $(function()&#123; //利用jQuery的隐式迭代修改全部div的背景颜色 $('div:eq(2)').nextAll().css("background-color","blue"); &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; jQuery排他思想 所谓排他是想也就是实现多选一的效果，设置当前元素的样式，清除兄弟元素的样式 核心函数就是$(“button”).siblings(“button”); 演示点击按钮变色，其余按钮清除原来颜色 1234567891011121314151617181920212223242526272829303132333435363738&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;script src="jquery.min.js"&gt;&lt;/script&gt; &lt;style&gt; div&#123; height: 200px; width: 200px; border: 1px solid red; background-color: red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;script&gt; $(function()&#123; //隐式迭代 $("button").click(function(event) &#123; //当前元素添加效果 $(this).css("background","blue"); //清除兄弟节点的效果 $(this).siblings('button').css("background",""); &#125;); &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; jQuery链式编程 实际上链式操作仅仅是通过对象上的方法最后 return this 把对象再返回回来，对象当然可以继续调用方法啦，所以就可以链式操作了 演示将上面那个按钮排他变色案例改编 123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;script src="jquery.min.js"&gt;&lt;/script&gt; &lt;style&gt; div&#123; height: 200px; width: 200px; border: 1px solid red; background-color: red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;button&gt;哈哈哈&lt;/button&gt; &lt;script&gt; $(function()&#123; //隐式迭代 $("button").click(function(event) &#123; //链式编程 $(this).css("background","blue").siblings('button').css("background",""); &#125;); &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>日常学习</tag>
        <tag>jQuery</tag>
        <tag>前端</tag>
        <tag>js</tag>
        <tag>javaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis逆向工程--MybatisGenerator]]></title>
    <url>%2F2019%2F10%2F14%2FMybatis%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B-MybatisGenerator%2F</url>
    <content type="text"><![CDATA[Mybatis逆向工程 mybatis需要手动编写mapper和接口，以及pojo对象，这对于一个大型工程来说特别消耗时间，所有也就有了自动生成的工具就是MybatisGenerator 使用步骤1.导入maven坐标 12345 &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt;&lt;/dependency&gt; 2.配置Generator配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN" "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;&lt;generatorConfiguration&gt; &lt;!-- 配置数据库连接--&gt; &lt;context id="DB2Tables" targetRuntime="MyBatis3"&gt; &lt;commentGenerator&gt; &lt;property name="suppressDate" value="true"/&gt; &lt;property name="suppressAllComments" value="true"/&gt; &lt;/commentGenerator&gt; &lt;jdbcConnection driverClass="com.mysql.jdbc.Driver" connectionURL="jdbc:mysql://localhost:3306/dirver" userId="root" password="123456"&gt; &lt;/jdbcConnection&gt; &lt;!-- java类型解析不需要动--&gt; &lt;javaTypeResolver &gt; &lt;property name="forceBigDecimals" value="false" /&gt; &lt;/javaTypeResolver&gt; &lt;!-- 指定javabean生成位置--&gt; &lt;javaModelGenerator targetPackage="com.qs304.skydrive.entity" targetProject=".\src\main\java"&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;property name="trimStrings" value="true" /&gt; &lt;/javaModelGenerator&gt; &lt;!-- 映射文件生成位置--&gt; &lt;sqlMapGenerator targetPackage="mapper" targetProject=".\src\main\resources"&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 指定dao接口生成位置--&gt; &lt;javaClientGenerator type="XMLMAPPER" targetPackage="com.qs304.skydrive.mapper" targetProject=".\src\main\java"&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;/javaClientGenerator&gt; &lt;!-- 指定每个表的生成策略--&gt; &lt;table tableName="user" domainObjectName="User"/&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 3.然后新建一个java文件读取配置文件开始自动生成pojo对象和接口文件和mybatis配置文件 123456789101112131415161718192021222324252627import org.junit.Test;import org.mybatis.generator.api.MyBatisGenerator;import org.mybatis.generator.config.Configuration;import org.mybatis.generator.config.xml.ConfigurationParser;import org.mybatis.generator.exception.InvalidConfigurationException;import org.mybatis.generator.exception.XMLParserException;import org.mybatis.generator.internal.DefaultShellCallback;import java.io.File;import java.io.IOException;import java.sql.SQLException;import java.util.ArrayList;import java.util.List;public class Generator &#123; @Test public void mybatisGenerator() throws InterruptedException, SQLException, IOException, XMLParserException, InvalidConfigurationException &#123; List&lt;String&gt; warnings = new ArrayList&lt;String&gt;(); boolean overwrite = true; File configFile = new File("D:\\code\\SSMCRUD\\src\\test\\mybatisGenerator.xml"); ConfigurationParser cp = new ConfigurationParser(warnings); Configuration config = cp.parseConfiguration(configFile); DefaultShellCallback callback = new DefaultShellCallback(overwrite); MyBatisGenerator myBatisGenerator = new MyBatisGenerator(config, callback, warnings); myBatisGenerator.generate(null); &#125;&#125;]]></content>
      <categories>
        <category>数据库</category>
        <category>框架</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
        <tag>配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速搭建java项目配置文件模板]]></title>
    <url>%2F2019%2F10%2F10%2F%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAjava%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%A8%A1%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[web.xml(包含Spring和SpringMVC)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xmlns:web="http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" id="WebApp_ID" version="2.5"&gt; &lt;!-- 中文乱码处理 --&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;filter&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- Spring配置文件信息 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:config/spring/applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- ContextLoaderListener监听器 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 日志配置 --&gt; &lt;context-param&gt; &lt;param-name&gt;log4jConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:config/log4j.properties&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.Log4jConfigListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 配置前端控制器 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;DispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:config/springmvc/springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;DispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;error-page&gt; &lt;error-code&gt;404&lt;/error-code&gt; &lt;location&gt;/WEB-INF/errors/404.jsp&lt;/location&gt; &lt;/error-page&gt; &lt;error-page&gt; &lt;error-code&gt;500&lt;/error-code&gt; &lt;location&gt;/WEB-INF/errors/500.jsp&lt;/location&gt; &lt;/error-page&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;/web-app&gt; applicationContext.xml(含C3P0配置和mybatis配置文件整合)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt;&lt;!-- 配置扫描范围--&gt; &lt;context:component-scan base-package="com.qs304"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Service"/&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Component"/&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Repository"/&gt; &lt;/context:component-scan&gt;&lt;!--加载数据源配置文件--&gt; &lt;context:property-placeholder location="classpath:config/db.properties"/&gt;&lt;!-- 配置C3P0数据源--&gt; &lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource" destroy-method="close" &gt; &lt;property name="driverClass" value="$&#123;jdbc.driver"&gt;&lt;/property&gt; &lt;property name="jdbcUrl" value="$&#123;jdbc.url"&gt;&lt;/property&gt; &lt;property name="user" value="$&#123;jdbc.username"&gt;&lt;/property&gt; &lt;property name="password" value="$&#123;jdbc.password"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt; &lt;!-- 扫描 po 包，使用别名 --&gt; &lt;property name="typeAliases" value="com.qs304.entity"&gt;&lt;/property&gt; &lt;!-- 扫描映射文件 --&gt; &lt;property name="mapperLocations" value="classpath:config/mapper/*.xml"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置扫描 dao 包，动态实现 dao 接口，注入到 spring 容器中 --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.ischoolbar.programmer.dao" /&gt; &lt;/bean&gt; &lt;!-- 事务管理器 （JDBC） --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;aop:config&gt;&lt;!-- 切入点表达式--&gt; &lt;aop:pointcut id="txPointcut" expression="execution(* com.qs304.servlet..*(..))"/&gt;&lt;!-- 配置事务增强--&gt; &lt;aop:advisor advice-ref="txAdvice" pointcut-ref="txPointcut"/&gt; &lt;/aop:config&gt;&lt;!-- 配置事务增强事务如何切入--&gt; &lt;tx:advice id="txAdvice"&gt; &lt;tx:attributes&gt;&lt;!-- 所有的方法都是事务方法--&gt; &lt;tx:method name="*"/&gt;&lt;!-- get开头的方法认为是查询进行调优--&gt; &lt;tx:method name="get*" read-only="true"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 启动声明式事务驱动 --&gt; &lt;tx:annotation-driven transaction-manager="transactionManager" /&gt;&lt;/beans&gt; springmvc.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:task="http://www.springframework.org/schema/task" xsi:schemaLocation="http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.2.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-3.2.xsd"&gt; &lt;!-- 只需要扫描包中的 Controller 注解 --&gt; &lt;context:component-scan base-package="com.ischoolbar.programmer.controller"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller" /&gt; &lt;/context:component-scan&gt; &lt;!-- 启动 mvc 注解驱动 --&gt; &lt;mvc:annotation-driven&gt;&lt;/mvc:annotation-driven&gt; &lt;!-- 启动定时任务 --&gt; &lt;task:annotation-driven/&gt; &lt;!-- 静态资源处理 --&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!-- 配置视图解析器 --&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/WEB-INF/views/"&gt;&lt;/property&gt; &lt;property name="suffix" value=".jsp"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 文件上传 --&gt; &lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;!-- 上传文件大小限制 --&gt; &lt;property name="maxUploadSize"&gt; &lt;value&gt;10485760&lt;/value&gt; &lt;/property&gt; &lt;!-- 请求的编码格式, 和 jsp 页面一致 --&gt; &lt;property name="defaultEncoding"&gt; &lt;value&gt;UTF-8&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 后台访问拦截器 --&gt; &lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/**"/&gt; &lt;!--&lt;mvc:mapping path="/grade/*"/&gt;--&gt; &lt;mvc:exclude-mapping path="/system/login"/&gt; &lt;mvc:exclude-mapping path="/system/get_cpacha"/&gt; &lt;mvc:exclude-mapping path="/h-ui/**"/&gt; &lt;mvc:exclude-mapping path="/easyui/**"/&gt; &lt;mvc:exclude-mapping path="/home-resources/**"/&gt; &lt;mvc:exclude-mapping path="/home/**"/&gt; &lt;bean class="com.ischoolbar.programmer.interceptor.LoginInterceptor"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; &lt;/beans&gt;]]></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>java</tag>
        <tag>Spring</tag>
        <tag>SSM</tag>
        <tag>SpringMVC</tag>
        <tag>Mybatis</tag>
        <tag>习惯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自定义简单的PRC框架]]></title>
    <url>%2F2019%2F10%2F10%2F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%AE%80%E5%8D%95%E7%9A%84PRC%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[SSM整合教程和步骤]]></title>
    <url>%2F2019%2F10%2F02%2FSSM%E6%95%B4%E5%90%88%E6%95%99%E7%A8%8B%E5%92%8C%E6%AD%A5%E9%AA%A4%2F</url>
    <content type="text"><![CDATA[SSM整合教程和步骤步骤1.配置spring和springmvc以及mybatis配置文件 2.配置web.xml文件先整合spring与springmvc 3.测试spring与springmvc整合情况 4.整合spring与springmvc与mybatis 教程1.配置spring和springmvc以及mybatis配置文件spring.xml 12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;!--开启注解扫描但是不扫描Controller注解包含的类--&gt; &lt;context:component-scan base-package="com.qs304"&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;/context:component-scan&gt;&lt;/beans&gt; springmvc.xml 123456789101112131415161718192021&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:context="http://www.springframework.org/schema/context" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;!--开启注解扫描但是只扫描Controller注解包含的类--&gt; &lt;context:component-scan base-package="com.qs304.controller"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;/context:component-scan&gt; &lt;!--因为一会要使用注解，所有开启注解扫描,注解只扫描Controller--&gt; &lt;!--配置视图解析器--&gt; &lt;bean id="internalResourceViewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/WEB-INF/pages/"&gt;&lt;/property&gt; &lt;property name="suffix" value=".jsp"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 2.配置web.xml文件先整合spring与springmvc web.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;!DOCTYPE web-app PUBLIC "-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN" "http://java.sun.com/dtd/web-app_2_3.dtd" &gt;&lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;!--配置前端控制器--&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;!--配置监听器加载spring框架--&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!--配置springxml文档路径--&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring.xml&lt;/param-value&gt; &lt;/context-param&gt;&lt;!-- 解决中文乱码--&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 前端控制器映射拦截说有路径下 &lt;url-pattern&gt;/&lt;url-pattern/&gt;匹配类似于/xxxx的URL，不会匹配到/xxx.xxx类型的URL&lt;url-pattern&gt;/*&lt;url-pattern/&gt;会匹配所有类型、所有后缀的URL，包括：/xxx、/xxx.xxx --&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 3.测试springmvc与spring整合情况4.整合spring与springmvc与mybatis首先单独写mybatis配置文件，例如名字叫做mybatis.xml mybatis.xml 然后测试mybatis能运行 之后吧mybatis配置文件整合到spring.xml配置文件中 spring.xml 1234567891011121314151617181920212223242526272829303132&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;context:component-scan base-package="com.qs304"&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;/context:component-scan&gt;&lt;!-- Spring整合mybatis框架--&gt;&lt;!-- 配置连接池--&gt; &lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt; &lt;property name="driverClass" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="jdbcUrl" value="jdbc:mysql://localhost:3306/demo"/&gt; &lt;property name="user" value="root"/&gt; &lt;property name="password" value="111"/&gt; &lt;/bean&gt;&lt;!-- 工厂注入来配置sqlsession--&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;/bean&gt;&lt;!-- 配置接口所在的包--&gt; &lt;bean id="mapperScannerConfigurer" class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.qs304.dao"/&gt; &lt;/bean&gt;&lt;/beans&gt; 之后就运行成功啦，完结散花、]]></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>Spring</tag>
        <tag>框架</tag>
        <tag>SSM</tag>
        <tag>SpringMVC</tag>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis深入理解XML配置文件]]></title>
    <url>%2F2019%2F09%2F28%2FMybatis%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3XML%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Mybatis体系结构SqlSessionFactory​ SqlSessionFactory是mybatis的关键对象，它是单个数据库映射关系经过编译后的内存镜像，SqlSessionFactor对象通过SqlSessionFactorBuilder对象创建获得。 SqlSessionFactorBuilder​ SqlSessionFactorBuilder可以从XML配置文件或者一个预先定制的Configguration的实例为核心构建，它是线程安全的。 SqlSession​ SqlSession也是mybatis的关键对象，它是执行持久化操作的对象，类似JDBC中的Connection对象，它是应用程序与持久化层之间执行交互操作的一个单线程对象， 每个线程都应该有他自己的SqlSession实例，SqlSession的实例不能共享，也是线程不安全的，所有绝对不能将SqlSession实例的引用放在一个类的静态字段中，也绝对不能放在任何类型的管理范围中，比如Serlvet中的HTTPSession对象中。 Mybatis的配置文件结构 configuration配置 propertes 属性 typeAliases 类型命名（别名） typeHandlers 类型处理器 objectFactory 对象工厂 plugins 插件 environments 环境 environment 环境变量 transationManager 事务管理器 dataSource 数据源 databaseIDProvider 数据库厂商标识 mapping 映射器 propertes 这些属性都是外部配置然后可以动态替换的演示:​ 在类路径下新建一个db.properties的java配置文件 1234driver=com.mysql.jdbc.Driverurl=jdbc:mysql://localhost:3306/mybatisusername=adminpassword=123456 然后在Mybatis主配置文件中添加元素 1&lt;properties resource="db.properties"/&gt; 之后就可以使用EL表达式获取对应的值 123456&lt;dataSoure type="POOLED"&gt; &lt;property name="driver" value="$&#123;dirver&#125;" /&gt; &lt;property name="url" value="$&#123;url&#125;" /&gt; &lt;property name="username" value="$&#123;username&#125;" /&gt; &lt;property name="password" value="$&#123;password&#125;" /&gt;&lt;/dataSoure&gt; settings设置这是Mybatis中非常重要的调整设置，他会改变Mybatis的运行时行为 配置参考 1234567891011121314151617&lt;settings&gt; &lt;setting name="cacheEnabled" value="true"/&gt; &lt;setting name="lazyLoadingEnabled" value="true"/&gt; &lt;setting name="multipleResultSetsEnabled" value="true"/&gt; &lt;setting name="useColumnLabel" value="true"/&gt; &lt;setting name="useGeneratedKeys" value="false"/&gt; &lt;setting name="autoMappingBehavior" value="PARTIAL"/&gt; &lt;setting name="autoMappingUnknownColumnBehavior" value="WARNING"/&gt; &lt;setting name="defaultExecutorType" value="SIMPLE"/&gt; &lt;setting name="defaultStatementTimeout" value="30"/&gt; &lt;setting name="defaultFetchSize" value="200"/&gt; &lt;setting name="safeRowBoundsEnabled" value="false"/&gt; &lt;setting name="mapUnderscoreToCamelCase" value="false"/&gt; &lt;setting name="localCacheScope" value="SESSION"/&gt; &lt;setting name="jdbcTypeForNull" value="OTHER"/&gt; &lt;setting name="lazyLoadTriggerMethods" value="equals,clone,hashCode,toString"/&gt;&lt;/settings&gt; typeAliases类型命名​ 类型别名时为java类型设置的一个短名字，存在的意义在于减少冗余的全限定类名 方法一1234&lt;!--这样配置后任何使用到com.qs304.beans.User的地方都能使用user代替--&gt;&lt;typeAliases&gt; &lt;typeAlias alias="user" type="com.qs304.beans.User"&gt;&lt;/typeAlias&gt;&lt;/typeAliases&gt; 方法二1234&lt;!--别名默认为类名首字母小写，指定这个包名后，mybatis会在下面的包中搜索--&gt;&lt;typeAliases&gt; &lt;pakage name="com.qs304.bean"/&gt;&lt;/typeAliases&gt; 若使用了注解这别名为注解的值，没有使用就是类名首字母小写 Mybatis已经为许多常见的java类型内建了相应的类型别名他们都是大小写不敏感的 参考：https://blog.csdn.net/lyf_ldh/article/details/77949004 mapper映射器Mybatis需要开发者告诉它去哪寻找映射文件这也就有了mapper 12345678910&lt;mappers&gt; &lt;!--使用类路径查找资源文件--&gt; &lt;mapper resource="com/qs304/dao/IStudent.xml"/&gt; &lt;!--使用绝对路径查找--&gt; &lt;mapper url="file:///C:/IStudent.xml"/&gt; &lt;!--使用接口查找--&gt; &lt;mapper class="com.qs304.dao.IStudent"/&gt; &lt;!--使用包名查找--&gt; &lt;package name="com.qs304.dao"/&gt;&lt;/mappers&gt; 深入理解Mapper XML映射文件SQL映射文件常用的元素 select 映射查询语句 insert 映射插入语句 update 映射删除语句 sql 可被其他语句引用的可重用语句块 cahe 给定命名空间的缓存配置 cache-ref 给其他命名空间缓存配置引用 resultMap 最复杂也是最强大的元素，用来描述如何从数据库结果集中加载对象 &lt;select&gt;12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;select &lt;!-- 1. id（必须配置） id是命名空间中的唯一标识符，可被用来代表这条语句 一个命名空间（namespace）对应一个dao接口 这个id也应该对应dao里面的某个方法（sql相当于方法的实现），因此id应该与方法名一致 --&gt; id="selectUser" &lt;!-- 2. parapeterType（可选配置，默认由mybatis自动选择处理） 将要传入语句的参数的完全限定名或别名，如果不配置，mybatis会通过ParamterHandler根据参数类型默认选择合适的typeHandler进行处理 paramterType 主要指定参数类型，可以是int, short, long, string等类型，也可以是复杂类型（如对象） --&gt; parapeterType="int" &lt;!-- 3. resultType（resultType 与 resultMap 二选一配置） 用来指定返回类型，指定的类型可以是基本类型，也可以是java容器，也可以是javabean --&gt; resultType="hashmap" &lt;!-- 4. resultMap（resultType 与 resultMap 二选一配置） 用于引用我们通过 resultMap 标签定义的映射类型，这也是mybatis组件高级复杂映射的关键 --&gt; resultMap="USER_RESULT_MAP" &lt;!-- 5. flushCache（可选配置） 将其设置为true，任何时候语句被调用，都会导致本地缓存和二级缓存被清空，默认值：false --&gt; flushCache="false" &lt;!-- 6. useCache（可选配置） 将其设置为true，会导致本条语句的结果被二级缓存，默认值：对select元素为true --&gt; useCache="true" &lt;!-- 7. timeout（可选配置） 这个设置是在抛出异常之前，驱动程序等待数据库返回请求结果的秒数，默认值为：unset（依赖驱动） --&gt; timeout="10000" &lt;!-- 8. fetchSize（可选配置） 这是尝试影响驱动程序每次批量返回的结果行数和这个设置值相等。默认值为：unset（依赖驱动） --&gt; fetchSize="256" &lt;!-- 9. statementType（可选配置） STATEMENT, PREPARED或CALLABLE的一种，这会让MyBatis使用选择Statement, PrearedStatement或CallableStatement，默认值：PREPARED --&gt; statementType="PREPARED" &lt;!-- 10. resultSetType（可选配置） FORWARD_ONLY，SCROLL_SENSITIVE 或 SCROLL_INSENSITIVE 中的一个，默认值为：unset（依赖驱动） --&gt; resultSetType="FORWORD_ONLY"&gt;&lt;/select&gt;]]></content>
      <categories>
        <category>数据库</category>
        <category>框架</category>
      </categories>
      <tags>
        <tag>语言</tag>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>数据库</tag>
        <tag>XML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis一对多和多对一以及多对多]]></title>
    <url>%2F2019%2F09%2F28%2FMybatis%E4%B8%80%E5%AF%B9%E5%A4%9A%E5%92%8C%E5%A4%9A%E5%AF%B9%E4%B8%80%E4%BB%A5%E5%8F%8A%E5%A4%9A%E5%AF%B9%E5%A4%9A%2F</url>
    <content type="text"><![CDATA[ORM和MybatisORM​ ORM 全称为:object/relation mapping（对象\关系数据库映射），简单来说就是一种规范，它的出现就是为了解决面向对象编程语言与关系数据库发展不均衡的产物，允许开发者利用面向对象语言的简单易用性又能利用关系数据库的技术优势，于是把关系数据库包装成面向对象模型，这个工具就是ORM。 基本映射方式数据表映射类​ 持久化类被映射到一个数据表，即一个表对应一个Model类 数据表的行映射（即实例）​ 数据表的每行映射一个对象 数据库表列（字段）映射对象的属性​ 数据库表的每列映射一个对象 一对多和多对一查询一个班有多个学生，一个学生一个班 班级表12345CREATE TABLE `class` ( `id` int(11) NOT NULL AUTO_INCREMENT, `class_name` varchar(255) NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8mb4; 学生表12345678CREATE TABLE `student` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) NOT NULL, `class_id` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `class_id` (`class_id`), CONSTRAINT `class_id` FOREIGN KEY (`class_id`) REFERENCES `class` (`id`) ON DELETE CASCADE ON UPDATE CASCADE) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8mb4; 首先导入pom.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.qs304&lt;/groupId&gt; &lt;artifactId&gt;MybatisQuery&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; pojo对象班级12345678910111213141516171819202122232425262728293031323334353637383940414243package com.qs304.beans;import java.io.Serializable;import java.util.List;public class Clazz implements Serializable &#123; private Integer id; private String className; private List&lt;Student&gt; students; @Override public String toString() &#123; return "Clazz&#123;" + "id=" + id + ", className='" + className + '\'' + ", students=" + students + '&#125;'; &#125; public List&lt;Student&gt; getStudents() &#123; return students; &#125; public void setStudents(List&lt;Student&gt; students) &#123; this.students = students; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getClassName() &#123; return className; &#125; public void setClassName(String className) &#123; this.className = className; &#125;&#125; 学生123456789101112131415161718192021222324252627282930313233343536373839404142package com.qs304.beans;import java.io.Serializable;public class Student implements Serializable &#123; private Integer id; private String name; private Clazz clazz; public Clazz getClazz() &#123; return clazz; &#125; public void setClazz(Clazz clazz) &#123; this.clazz = clazz; &#125; @Override public String toString() &#123; return "Student&#123;" + "id=" + id + ", name='" + name + '\'' + ", clazz=" + clazz + '&#125;'; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125;&#125; utils包123456789101112131415package com.qs304.utils;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import java.io.IOException;import java.io.InputStream;public class SqlFactory &#123; public static SqlSessionFactory getSqlFactory() throws IOException &#123; InputStream in=Resources.getResourceAsStream("mybatisConfig.xml"); return new SqlSessionFactoryBuilder().build(in); &#125;&#125; dao包123456789101112131415161718192021222324package com.qs304.dao;import com.qs304.beans.Clazz;import com.qs304.beans.Student;import java.util.List;public interface ImplDao &#123; /** * 一对多查询 * 根据班级id获取班级所有的学生以及班级信息 * @param id 班级id * @return Clazz 班级对象 */ public Clazz findClazzById(int id); /** * 多对一查询 * 根据学生id获取对应学生所在班级以及个人信息 * @param id 学生id * @return Student 学生对象 */ public Student findStudentById(int id);&#125; dao包xml文件123456789101112131415161718192021222324252627282930313233343536&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.qs304.dao.ImplDao"&gt; &lt;!--一对多映射配置--&gt; &lt;resultMap id="clazzStudentMap" type="com.qs304.beans.Clazz"&gt; &lt;id property="id" column="id"&gt;&lt;/id&gt; &lt;result property="className" column="class_name"&gt;&lt;/result&gt; &lt;collection property="students" ofType="student" &gt; &lt;id property="id" column="sid"&gt;&lt;/id&gt; &lt;result property="name" column="name"&gt;&lt;/result&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;resultMap id="studentClazzMap" type="com.qs304.beans.Student"&gt; &lt;id property="id" column="id"&gt;&lt;/id&gt; &lt;result property="name" column="name"&gt;&lt;/result&gt; &lt;association property="clazz" column="class_id"&gt; &lt;id property="id" column="sid"&gt;&lt;/id&gt; &lt;result property="className" column="class_name"&gt;&lt;/result&gt; &lt;/association&gt; &lt;/resultMap&gt; &lt;select id="findClazzById" parameterType="int" resultMap="clazzStudentMap"&gt; select class.*, student.id as sid,student.name from class left outer join student on class.id=student.class_id where class.id=#&#123;id&#125;; &lt;/select&gt; &lt;select id="findStudentById" parameterType="int" resultMap="studentClazzMap"&gt; select student.*,class.id as sid,class.class_name from student,class where class.id=student.class_id and student.id=#&#123;id&#125;; &lt;/select&gt;&lt;/mapper&gt; resourcesdb.properties1234driver=com.mysql.jdbc.Driverurl=jdbc:mysql://localhost:3306/testusername=rootpassword=111 mybatisConfig.xml文件1234567891011121314151617181920212223242526&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;properties resource="db.properties"/&gt; &lt;typeAliases&gt; &lt;package name="com.qs304.beans"/&gt; &lt;/typeAliases&gt; &lt;environments default="mysql"&gt; &lt;environment id="mysql"&gt; &lt;transactionManager type="JDBC"&gt;&lt;/transactionManager&gt; &lt;dataSource type="POOLED"&gt; &lt;property name="driver" value="$&#123;driver&#125;"/&gt; &lt;property name="url" value="$&#123;url&#125;"/&gt; &lt;property name="username" value="$&#123;username&#125;"/&gt; &lt;property name="password" value="$&#123;password&#125;"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;package name="com.qs304.dao"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; lof4j配置文件log4j.properties 1234567891011121314log4j.rootLogger = WARN,stdoutlog4j.appender.stdout = org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.Target = System.outlog4j.appender.stdout.layout = org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern = [%p][%d&#123;yyyy-MM-dd HH:mm:ss&#125; %l] %m%nlog4j.appender.D = org.apache.log4j.RollingFileAppenderlog4j.appender.D.File = log/Wifi_sy/Wifi_sy_warn.loglog4j.appender.D.Append = truelog4j.appender.D.Threshold = WARN log4j.appender.D.MaxFileSize = 10240KBlog4j.appender.D.MaxBackupIndex = 3 log4j.appender.D.layout = org.apache.log4j.PatternLayoutlog4j.appender.D.layout.ConversionPattern = %d&#123;yyyy-MM-dd HH:mm:ss&#125; [%c:%L:[%p]] %m%n 测试类123456789101112131415161718192021222324252627282930313233343536373839404142import com.qs304.beans.Clazz;import com.qs304.beans.Student;import com.qs304.dao.ImplDao;import com.qs304.utils.SqlFactory;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.junit.After;import org.junit.Before;import org.junit.Test;import java.io.IOException;import java.util.logging.Logger;public class test &#123; SqlSession sqlSession=null; SqlSessionFactory sqlSessionFactory=null; @Before public void befor() throws IOException &#123; sqlSessionFactory= SqlFactory.getSqlFactory(); sqlSession=sqlSessionFactory.openSession(); &#125; @Test public void test()&#123; ImplDao dao=sqlSession.getMapper(ImplDao.class); Clazz clazz=dao.findClazzById(1); System.out.printf(clazz.toString()); &#125; @Test public void test1()&#123; ImplDao dao=sqlSession.getMapper(ImplDao.class); Student student=dao.findStudentById(1); System.out.printf(student.toString()); &#125; @After public void after()&#123; sqlSession.commit(); sqlSession.close(); &#125;&#125;]]></content>
      <categories>
        <category>数据库</category>
        <category>框架</category>
      </categories>
      <tags>
        <tag>语言</tag>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>数据库</tag>
        <tag>ORM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis第二天（连接池，动态SQL语句）]]></title>
    <url>%2F2019%2F09%2F16%2Fmybatis%E7%AC%AC%E4%BA%8C%E5%A4%A9%EF%BC%88%E8%BF%9E%E6%8E%A5%E6%B1%A0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[mybatis连接池连接池数据源分类 UNPOOLED 不使用连接池的数据源 POOLED 使用传统的javax.sql.DataSource连接池的数据源 JNDI 使用JNDI实现的数据源 mybatis动态SQL语句作用：为了解决手动拼接SQL的麻烦元素:（注意由于markedown语法问题标签有空格） 标签名 说明 &lt; if &gt; 判断语句，用于但条件分支判断 &lt; choose &gt;(&lt; when &gt;,&lt; otherwise &gt;) 相当于switch语句，用于多条件分支判断 &lt; where &gt;,&lt; trim &gt;,&lt; set &gt; 辅助元素，用于处理一些SQL拼接，特殊字符问题 &lt; bind &gt; 从OGNL表达式中创建一个变量，并将其绑定到上下文，常用于模糊查询的Sql语句 代码演示：​ 假设有下面这个类 123456public class Person&#123; private Integer id; private String name; private Integer age; ...//以下的get和set方法以及toString方法省略&#125; &lt;if&gt;标签123456789101112131415161718192021&lt;select id="findPersonByidAndname" parameterType="com.qs304.domain.Person" resultType="com.qs304.domain.Person"&gt; select * from persons where 1=1 &lt;if test="id != null"&gt; and id = #&#123;id&#125; &lt;/if&gt; &lt;if test="name"&gt; and name = #&#123;name&#125; &lt;/if&gt;&lt;/select&gt;&lt;!--如果使用了where标签就可以不写where 1=1和and之类的--&gt;&lt;select id="findPersonByidAndname" parameterType="com.qs304.domain.Person" resultType="com.qs304.domain.Person"&gt; select * from persons &lt;where&gt; &lt;if test="id != null"&gt; id = #&#123;id&#125; &lt;/if&gt; &lt;if test="name"&gt; name = #&#123;name&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; &lt;foreach&gt; 元素1234567891011121314&lt;!-- 判断id是否在这个集合里面 select * from pesrsons where id in(1,2,3,4); 类似这样--&gt;&lt;select id="findPersonByIds" parameterType="List" resultType="com.qs304.domain.Person"&gt; select * from pesrsons where id in &lt;!-- 判断为空可以用 list.size&gt;0--&gt; &lt;foreach item="id" index="index" collection="list" open="(" separator="," close=")"&gt; #&#123;id&#125; &lt;/foreach&gt; &lt;/select&gt; item：配置的是循环中当前的元素。 index：配置的是当前元素在集合的位置下标。 collection：配置的list是传递过来的参数类型（首字母小写），它可以是一个array、list（或collection）、Map集合的键、POJO包装类中数组或集合类型的属性名等。 open和close：配置的是以什么符号将这些集合元素包装起来。 separator：配置的是各个元素的间隔符。]]></content>
      <categories>
        <category>数据库</category>
        <category>框架</category>
      </categories>
      <tags>
        <tag>语言</tag>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper入门]]></title>
    <url>%2F2019%2F09%2F14%2Fzookeeper%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[简介 ZooKeeper是一个分布式的，开放源码的分布式应用程序分布式应用程序协调服务，是Google的Chubby一个开源开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 通俗来讲 顾名思义 zookeeper 就是动物园管理员，他是用来管 hadoop（大象）、Hive(蜜蜂)、pig(小 猪)的管理员， Apache Hbase 和 Apache Solr 的分布式集群都用到了 zookeeper；Zookeeper: 是一个分布式的、开源的程序协调服务，是 hadoop 项目下的一个子项目。他提供的主要功 能包括：配置管理、名字服务、分布式锁、集群管理。 zookeeper提供了什么简单的说，zookeeper=文件系统+通知机制。 什么是强一致性和最终一致性 强一致性：在任何时刻所有的用户或者进程查询到的都是最近一次成功更新的数据。强一致性是程度最高一致性要求，也是最难实现的。关系型数据库更新操作就是这个案例。 最终一致性：和强一致性相对，在某一时刻用户或者进程查询到的数据可能都不同，但是最终成功更新的数据都会被所有用户或者进程查询到。当前主流的nosql数据库都是采用这种一致性策略。 CAP原则CAP原则又称CAP定理，指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。 CAP原则是NOSQL数据库的基石。 分布式系统的CAP理论：理论首先把分布式系统中的三个特性进行了如下归纳： 一致性（C）：一致性是指强一致性 可用性（A）：系统提供的服务一直处于可用状态，用户的操作请求在指定的响应时间内响应请求，超出时间范围，认为系统不可用 分区容忍性（P）：分布式系统在遇到任何忘了分区故障的时候，仍需要能保证对外提供一致性和可用性服务，除非是整个网络都发生故障。 总结 其中一致性指的是强一致性，并且在实现中只能同时满足cap中的两个特性，比如CA,和CP 一致性协议事务需要跨多个分布式节点时，为了保证事务的ACID特性，需要选举出一个协调者来协调分布式各个节点的调度，基于这个思想衍生了很多一致性协议： ZAB协议(原子广播协议)zookeeper的数据结构zookeeper数据模型的结构和文件系统很类似，整体上可以看做是一棵树，每个节点称作一个Znode,每个ZNode都可以通过唯一路径标识 Zonde 每一个znode默认能够存储1MB的数据 Znode节点分类持久化节点持久化节点创建这个节点的客户端在与zookeeper服务的连接断开后，这个节点也不会被删除（除非您使用API强制删除）。 持久化顺序编号节点当客户端请求创建这个节点A后，zookeeper会根据parent-znode的zxid状态，为这个A节点编写一个全目录唯一的编号（这个编号只会一直增长）。当客户端与zookeeper服务的连接断开后，这个节点也不会被删除。 临时节点临时目录节点创建这个节点的客户端在与zookeeper服务的连接断开后，这个节点（还有涉及到的子节点）就会被删除。 临时顺序编号目录节点当客户端请求创建这个节点A后，zookeeper会根据parent-znode的zxid状态，为这个A节点编写一个全目录唯一的编号（这个编号只会一直增长）。当创建这个节点的客户端与zookeeper服务的连接断开后，这个节点被删除。 zookeeper三种角色领导者(Leader)负责集群的写请求，并发起投票，只有超过半数的节点同意后才会提交该写请求。 跟随者(Follower)处理读请求，响应结果。转发写请求到Leader,在选举过程中参加投票 观察者(Observer)可以理解为没有投票权的Follower，主要职责是协助follower处理读请求，那么当整个zk集群写请求负载很高时，为什么不增加follower节点呢？原因是增加follower节点会让leader在提出写请求提案时，需要半数以上的follower投票节点同意，这样会增加leader和follower的通信压力，降低写操作的效率 zookeeper两种模式恢复模式当启动或领导(Leader)节点崩溃后，zk进入恢复状态，选举leader,当leader选出后，将完成leader和其他机器的数据同步，当大多数server完成和leader的同步后，恢复模式解结束. 广播模式一旦Leader已经和多数的Follower进入了状态同步后，进入广播模式。进入广播模式后，如果有新加入的服务器，会自动冲leader中同步数据.leader在接收客户端请求后，将会成事务提案广播给其他机器，如果有超过半数以上的Follower同意该提交后，在提交事务。 zxid事务id， 为了保证事务的顺序一致性，zookeeper 采用了递增的事 务 id 号（zxid）来标识事务。所有的提议（proposal）都 在被提出的时候加上了 zxid。实现中 zxid 是一个 64 位的 数字，它高32位是epoch（ZAB协议通过epoch编号来 区分 Leader 周期变化的策略）用来标识 leader 关系是否 改变，每次一个 leader 被选出来，它都会有一个新的 epoch=（原来的epoch+1），标识当前属于那个leader的 统治时期。低32位用于递增计数 epoch ：可以理解为当前集群所处的年代或者周期，每个 leader 就像皇帝，都有自己的年号，所以每次改朝换代， leader 变更之后，都会在前一个年代的基础上加 1 。这样 就算旧的 leader 崩 溃 恢 复 之 后 ，也 没 有 人 听 他 的 了 ，因 为 follower 只听从当前年代的 leader 的命令 zookeeper选举算法zk节点状态角色zk几区单节点状态（每个节点有且只有一个状态），zk的定位一定需要一个leader节点处于lading状态中 looking：寻找leader状态，当前集群没有leader，进入leader选举流程。 following：跟随者状态，接受leading节点同步和指挥。 leading：领导者状态。 observing：观察者状态，表名当前服务器是observer。 zookeeper消息广播算法zookeeper常用命令help 可以获取命令行帮助 ls path [watch] 查看指定路径下的所有节点 ls2 path [watch] 查看指定路径节点的状态 get path [watch] 获取指定节点保存的信息 set path data [watch]修改指定路径下节点的信息 create [-s] [-e] path data acl 创建指定路径下节点 delete path [version] 删除指定节点，如果该路径下还有子节点那么不能删除，必须使用rmr递归删除 stat [-w] path 查看节点状态 节点信息 cZxid：znode创建时的事务id（16进制）。 ctime：znode创建的时间。 mZxid：znode最后一次修改的事务id。 mtime：最后一次修改的时间。 pZxid：数据节点的子节点列表，最后一次被修改的事务id即在一个znode下创建一个子znode，可以看到子znode的cZxid，mZxid，pZxid都等于这个值，其中cZxid不会改变，另外mZxid，pZxid进行相应的操作会发生变更。 cversion：子节点的版本号。 dataVersion：数据节点的版本号，变更一次加1。 aclVersion：数据的ACL（权限控制列表）版本号，变更一次加1。 ephemeralOwner：如果是临时节点，则表示该节点创建的会话id，否则为 0x0（ephemeralOwner = 0x169843156830000）。 dataLength：数据长度（中文1个字表示3个字节长度）。 numChildren：子节点的数据长度。 watch简单使用在一些命令上有watch参数，比如说ls和get，这就是监听器，但是监听器只能监听一次。 ls2 的监听只对ls的子节点变化有效，对该节点和其子节点的内容改变无效 get 的监听只针对被监听节点的内容改变有效，对子节点的变化无效 zookeeperAPI使用首先导入maven坐标 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.13&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223242526272829303132333435363738package zookeeper;import org.apache.zookeeper.KeeperException;import org.apache.zookeeper.ZooDefs.Ids;import org.apache.zookeeper.ZooKeeper;import org.apache.zookeeper.data.Stat;import java.io.IOException;import static org.apache.zookeeper.CreateMode.PERSISTENT;/** * @author yang * @date 2020/5/9 18:07 */public class ZkAPIDemo &#123; public static void main(String[] args) throws IOException, KeeperException, InterruptedException &#123; //连接zookeeper ZooKeeper zooKeeper = new ZooKeeper("127.0.0.1:2181", 2000, (event) -&gt; System.out.println("触发了" + event.getType() + "的事件")); //创建节点 String s = zooKeeper.create("/testZookeeper/hello", "你好Zookeeper!".getBytes(), Ids.OPEN_ACL_UNSAFE, PERSISTENT); String s1 = zooKeeper.create("/testZookeeper", "哈哈!!!".getBytes(), Ids.OPEN_ACL_UNSAFE, PERSISTENT); System.out.println(s); //获取所有节点的值 zooKeeper.getChildren("/",false).forEach(System.out::println); //获取节点的值 byte[] data = zooKeeper.getData("/testZookeeper", false, null); System.out.println(new String(data)); //修改节点的值 Stat stat = zooKeeper.setData("/testZookeeper", "被修改了".getBytes(), -1); System.out.println(zooKeeper.getData("/testZookeeper",false,null)); //删除节点 zooKeeper.delete("/testZookeeper/hello",-1); &#125;&#125; zookeeper引用场景配置中心负载均衡命名服务分布式锁实现数据库实现分布式锁首先创建一个数据库表，里面要有两个字段 12345CREATE TABLE `lock` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`),UNIQUE (name)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 一定要注意name字段是唯一性约束，否则不能实现分布式锁。 一个线程在获取锁的时候插入一条数据，这个时候如果有其他线程获取锁则因为name是唯一的，所以会插入失败，解锁的时候删除该数据，这就实现了分布式锁。 我的坐标123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.qs304&lt;/groupId&gt; &lt;artifactId&gt;JVMTest&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.openjdk.jcstress/jcstress-core --&gt; &lt;dependency&gt; &lt;groupId&gt;org.openjdk.jcstress&lt;/groupId&gt; &lt;artifactId&gt;jcstress-core&lt;/artifactId&gt; &lt;version&gt;0.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.13&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.21&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.2.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;properties&gt; &lt;/properties&gt;&lt;/project&gt; 配置spring和mybatisapplication.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.3.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.3.xsd"&gt; &lt;context:component-scan base-package="distributedLock"&gt;&lt;/context:component-scan&gt; &lt;!--数据库连接池--&gt; &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/test"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="123456"/&gt; &lt;/bean&gt; &lt;!-- 配置SqlSessionFactory对象 --&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;!-- 注入数据库连接池 --&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;property name="configLocation" value="mybatis.xml"/&gt; &lt;/bean&gt; &lt;!--&lt;bean id="sqlsessionTemplate" class="org.mybatis.spring.SqlSessionTemplate"&gt;--&gt; &lt;!--&lt;constructor-arg index="0" ref="sqlSessionFactory" /&gt;--&gt; &lt;!--&lt;/bean&gt;--&gt; &lt;!-- 配置接口所在的包--&gt; &lt;bean id="mapperScannerConfigurer" class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="distributedLock.dao"/&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.JedisPool" id="jedisPool"&gt; &lt;constructor-arg name="host" value="127.0.0.1"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="poolConfig" ref="jedisPoolConfig"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="port" value="6379"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="timeout" value="10"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.JedisPoolConfig" id="jedisPoolConfig"&gt; &lt;property name="maxIdle" value="20" /&gt; &lt;property name="maxTotal" value="10" /&gt; &lt;property name="maxWaitMillis" value="5" /&gt; &lt;/bean&gt;&lt;/beans&gt; mybatis.xml 12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;typeAliases&gt; &lt;typeAlias alias="LockMsg" type="distributedLock.bean.LockMsg"/&gt; &lt;/typeAliases&gt; &lt;mappers&gt; &lt;mapper resource="distributedLock.dao.xml"&gt;&lt;/mapper&gt; &lt;/mappers&gt;&lt;/configuration&gt; mapper 1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="distributedLock.dao.LockMapper"&gt; &lt;select id="tryLock" resultType="java.lang.Integer"&gt; select * from `lock` where name=#&#123;name&#125;; &lt;/select&gt; &lt;insert id="lock" parameterType="LockMsg"&gt; insert into `lock` values(#&#123;id&#125;,#&#123;name&#125;) &lt;/insert&gt; &lt;delete id="unlock" parameterType="LockMsg"&gt; delete from `lock` where name=#&#123;name&#125; &lt;/delete&gt;&lt;/mapper&gt; 123456789101112131415package distributedLock.dao;import distributedLock.bean.LockMsg;import org.apache.ibatis.annotations.Mapper;/** * @author yang * @date 2020/5/10 14:59 */@Mapperpublic interface LockMapper &#123; public Integer tryLock(LockMsg lockMsg); public Integer lock(LockMsg lockMsg) throws Exception; public Integer unlock(LockMsg lockMsg);&#125; bean对象 123456789101112131415161718192021222324252627282930313233343536package distributedLock.bean;import org.springframework.stereotype.Component;/** * @author yang * @date 2020/5/10 14:54 */@Componentpublic class LockMsg &#123; private Integer id; private String name; public LockMsg() &#123; &#125; public LockMsg( String name) &#123; this.name = name; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; Stock库存对象 12345678910111213141516171819202122package distributedLock.data;/** * @author yang * @date 2020/5/10 14:50 */public class Stock &#123; private int num; public int subNum() &#123; if(num&gt;0)&#123; num--; &#125; else &#123; System.out.println("库存不足"); &#125; return num; &#125; public void setNum(int num)&#123; this.num=num; &#125;&#125; Sql锁对象 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package distributedLock;import distributedLock.bean.LockMsg;import distributedLock.dao.LockMapper;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;/** * @author yang * @date 2020/5/10 14:52 * 自定义分布式锁 */@Componentpublic class MyDistributedLock implements Lock &#123; @Autowired LockMapper lockMapper; LockMsg lockMsg=new LockMsg("lock"); @Override public void lock() &#123; Integer state; while (true)&#123; if(tryLock()==true)&#123; try &#123; state = lockMapper.lock(lockMsg); &#125; catch (Exception e) &#123; state=null; &#125; if (state!=null)&#123; System.out.println("加锁成功!"); return; &#125;// System.out.println("加锁失败!"); &#125;else &#123;// System.out.println("没有获取到锁循环等待!"); &#125; &#125; &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; &#125; @Override public boolean tryLock() &#123; Integer i = lockMapper.tryLock(lockMsg); if (i==null||i==0)&#123; return true; &#125; return false; &#125; @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return false; &#125; @Override public void unlock() &#123; Integer unlock = lockMapper.unlock(lockMsg); if (unlock!=null&amp;&amp;unlock!=0)&#123; System.out.println("解锁成功"); &#125; &#125; @Override public Condition newCondition() &#123; return null; &#125;&#125; 启动测试类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package distributedLock;import distributedLock.data.Stock;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Lock;/** * @author yang * @date 2020/5/10 14:50 */public class Application &#123; static ClassPathXmlApplicationContext applicationContext; static &#123; applicationContext=new ClassPathXmlApplicationContext("application.xml"); &#125; public static void main(String[] args) &#123; //Lock lock = applicationContext.getBean(MyDistributedLock.class);//使用mysql锁 Lock lock = applicationContext.getBean(RedisLock.class);//使用redis Stock stock = new Stock(); stock.setNum(4); new Thread(()-&gt;&#123; for (int i = 0; i &lt; 2; i++) &#123; try &#123; lock.lock(); TimeUnit.SECONDS.sleep(2); System.out.println(Thread.currentThread()+"获取,剩余"+stock.subNum()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; &#125;).start(); new Thread(()-&gt;&#123; for (int i = 0; i &lt; 2; i++) &#123; try &#123; lock.lock(); TimeUnit.SECONDS.sleep(2); System.out.println(Thread.currentThread()+"获取,剩余"+stock.subNum()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; &#125;).start(); &#125;&#125; redis实现分布式redis实现分布式主要借助setnx命令，不存在才能设置。 上述代码中新加入一个类 RedisLock 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package distributedLock;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;/** * @author yang * @date 2020/5/10 23:10 */@Componentpublic class RedisLock implements Lock &#123; @Autowired JedisPool jedisPool; String lockName="lock"; @Override public void lock() &#123; while(!tryLock())&#123; //获取锁失败 &#125; &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; &#125; @Override public boolean tryLock() &#123; Jedis resource = jedisPool.getResource(); Long lock = resource.setnx(lockName, String.valueOf(1)); resource.expire(lockName, 5);//设置超时时间 resource.close(); if (lock==1)&#123; return true; &#125; return false; &#125; @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return false; &#125; @Override public void unlock() &#123; Jedis resource = jedisPool.getResource(); resource.del(lockName); resource.close(); &#125; @Override public Condition newCondition() &#123; return null; &#125;&#125; 但是上面的方式有弊端，虽然设置了key超时时间，但是因为setnx和expire两条命令不是原子的，所以假设我们有一个redis集群，我们在给主节点发送了setnx命令，然后主节点闪崩，expire命令发送失败的话，会导致死锁的情况。]]></content>
      <categories>
        <category>java</category>
        <category>分布式</category>
        <category>框架</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>分布式</tag>
        <tag>框架</tag>
        <tag>CAP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo入门]]></title>
    <url>%2F2019%2F09%2F10%2FDubbo%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>RPC</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis入门教程]]></title>
    <url>%2F2019%2F08%2F30%2FMybatis%2F</url>
    <content type="text"><![CDATA[Mybatis1.Mybatis简介:​ ​ MyBatis 本是apache的一个开源项目iBatis, 2010年这个项目由apache software foundation 迁移到了google code，并且改名为MyBatis，是一个基于Java的持久层框架。 持久层： 可以将业务数据存储到磁盘，具备长期存储能力，只要磁盘不损坏，在断电或者其他情况下，重新开启系统仍然可以读取到这些数据。 优点： 可以使用巨大的磁盘空间存储相当量的数据，并且很廉价 缺点：慢（相对于内存而言） 2.为什么要使用mybatis​ 在我们传统的 JDBC 中，我们除了需要自己提供 SQL 外，还必须操作 Connection、Statment、ResultSet，不仅如此，为了访问不同的表，不同字段的数据，我们需要些很多雷同模板化的代码，闲的繁琐又枯燥。 而我们在使用了 MyBatis 之后，只需要提供 SQL 语句就好了，其余的诸如：建立连接、操作 Statment、ResultSet，处理 JDBC 相关异常等等都可以交给 MyBatis 去处理，我们的关注点于是可以就此集中在 SQL 语句上，关注在增删改查这些操作层面上。 并且 MyBatis 支持使用简单的 XML 或注解来配置和映射原生信息，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。 3.mybatisDemomybatis的环境搭建​ 第一步：创建maven工程并导入坐标 ​ 第二步：创建实体类和dao接口（mybatis可以只有接口就能实现对数据库的增删改查，而且实体类就是要实体类的属性和数据库的表对应起来） ​ 第三步：创建mybatis的主配置文件 SqlMapConfig.xml（名字可以随意） ​ 第四步：创建映射配置文件 IUserDao.xml（名字可以随意） ​ 搭建注意事项: ​ 第一个:创建IUserDao.xml和IUserDao.java 在mybatis中 他把持久层的操作接口名称和映射文件叫做:Mapper ​ 第二个：在idea中创建目录的时候，他和包是不一样的， ​ 第三个：mybatis的映射配置文件位置必须和dao接口的包结构相同 ​ 第四个：映射配置文件的操作配置（select）,id属性的取值必须是dao接口的方法名 ​ 第五个：映射配置文件的mapper标签和namespace属性的取值必须是dao接口的全限定类名 maven坐标 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 首先Bean包Account.java 12345678910111213141516171819202122232425262728293031323334353637383940package cn.Bean;public class Account &#123; private Integer id; private String name; private Double money; @Override public String toString() &#123; return "Account&#123;" + "id=" + id + ", name='" + name + '\'' + ", money=" + money + '&#125;'; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Double getMoney() &#123; return money; &#125; public void setMoney(Double money) &#123; this.money = money; &#125;&#125; 然后dao包下的IDao.java接口 123456789101112package cn.dao;import cn.Bean.Account;import java.util.List;/** * 获取所有的Account信息 */public interface IDao &#123; public List&lt;Account&gt; getAccountAll();&#125; 然后创建主配置文件MybatisConfig.xml 1234567891011121314151617181920212223242526&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;!--配置环境--&gt; &lt;environments default="mysql"&gt;&lt;!--defult填写的子类必须也有--&gt; &lt;!--配置mysql的环境--&gt; &lt;environment id="mysql"&gt; &lt;!--配置事务的类型--&gt; &lt;transactionManager type="JDBC"&gt;&lt;/transactionManager&gt; &lt;!--配置数据源--&gt; &lt;dataSource type="POOLED"&gt; &lt;!--配置连接数据库--&gt; &lt;property name="driver" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/ee"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="123456"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!--配置映射配置文件的位置，映射配置文件指的是每个dao独立的配置文件--&gt; &lt;mappers&gt; &lt;mapper resource="cn/config/IDao.xml"&gt;&lt;/mapper&gt; &lt;/mappers&gt;&lt;/configuration&gt; 然后穿件cn目录下config目录下的IDao.xml映射IDao.java的配置文件，注意xml文件和java文件必须是统一限定目录 1234567891011&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;!--namespace填写IDao接口的全限定类名--&gt;&lt;mapper namespace="cn.dao.IDao"&gt; &lt;!--配置查询所有 id必须是IDao方法的名称,resultType必须是实体类 --&gt; &lt;select id="getAccountAll" resultType="cn.Bean.Account"&gt; select * from account; &lt;/select&gt;&lt;/mapper&gt; 最后是测试类 12345678910111213141516171819202122232425262728293031import cn.Bean.Account;import cn.dao.IDao;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import java.io.File;import java.io.IOException;import java.io.InputStream;import java.util.List;public class Test &#123; @org.junit.Test public void getALl() throws IOException &#123; //1.读取配置文件 InputStream in= Resources.getResourceAsStream("MybatisConfig.xml"); //2.创建SqlSessionFactory工厂 SqlSessionFactoryBuilder builder=new SqlSessionFactoryBuilder(); SqlSessionFactory factory=builder.build(in); //3.使用工厂生产SqlSession对象 SqlSession session=factory.openSession(); //4.使用SqlSession创建Dao接口的代理对象 IDao dao=session.getMapper(IDao.class); //5.使用代理对象执行方法 List&lt;Account&gt; users=dao.getAccountAll(); for (Account user : users) &#123; System.out.println(user); &#125; &#125;&#125; 打印信息为 123456Sat Jul 27 15:54:14 CST 2019 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.Account&#123;id=1, name='aaa', money=600.0&#125;Account&#123;id=2, name='bbb', money=1200.0&#125;Account&#123;id=3, name='ccc', money=1000.0&#125;Account&#123;id=4, name='hhh', money=1000.0&#125;Account&#123;id=5, name='hhh', money=200.0&#125; 如果需要保存数据则把IDao.xml改成以下 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;!--namespace填写IDao接口的全限定类名--&gt;&lt;mapper namespace="cn.dao.IDao"&gt; &lt;!--配置查询所有 id必须是IDao方法的名称,resultType必须是实体类--&gt; &lt;select id="getAccountAll" resultType="cn.Bean.Account"&gt; select * from account; &lt;/select&gt; &lt;!--通过里面配置selectKey标签的方式可以获取插入数据后所对应的自增长id的值--&gt; &lt;select id="addAccount" parameterType="cn.Bean.Account"&gt; &lt;!--selectKey 会将 SELECT LAST_INSERT_ID()的结果放入到传入的model的主键里面， keyProperty 对应的model中的主键的属性名，这里是 user 中的id，因为它跟数据库的主键对应 order AFTER 表示 SELECT LAST_INSERT_ID() 在insert执行之后执行,多用与自增主键， BEFORE 表示 SELECT LAST_INSERT_ID() 在insert执行之前执行，这样的话就拿不到主键了， 这种适合那种主键不是自增的类型 resultType 主键类型 --&gt; &lt;selectKey keyProperty="id" keyColumn="id" resultType="int" order="AFTER"&gt;&lt;/selectKey&gt; insert INTO account(name,money) values(#&#123;name&#125;,#&#123;money&#125;) &lt;/select&gt;&lt;/mapper&gt; 值得一提的是：resultType属性可以类型有简单类型或者pojo对象，或者pojo对象的包装对象（pojo对象的列表）。pojo对象就是javabean或者说是实体类对象 ​ 然后上述xml文件配置中就是用了OGNL表达式 OGNL表达式中省略的get关键字，即user.getName()变成了user.name; 在mybatis中标签属性resultType中提供了user对象的包名，所以可以直接使用name来达到user.name相同的效果 测试类里面： 1234567891011121314151617181920212223242526272829303132333435363738import cn.Bean.Account;import cn.dao.IDao;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import java.io.File;import java.io.IOException;import java.io.InputStream;import java.util.List;public class Test &#123; @org.junit.Test public void getALl() throws IOException &#123; //1.读取配置文件 InputStream in= Resources.getResourceAsStream("MybatisConfig.xml"); //2.创建SqlSessionFactory工厂 SqlSessionFactoryBuilder builder=new SqlSessionFactoryBuilder(); SqlSessionFactory factory=builder.build(in); //3.使用工厂生产SqlSession对象 SqlSession session=factory.openSession(); //4.使用SqlSession创建Dao接口的代理对象 IDao dao=session.getMapper(IDao.class); //5.使用代理对象执行方法 Account ac=new Account(); ac.setName("hha"); ac.setMoney(99999.0); dao.addAccount(ac); List&lt;Account&gt; users=dao.getAccountAll(); for (Account user : users) &#123; System.out.println(user); &#125; //如果没有正确提交到数据库需要手动提交事务 //session.commit(); &#125;&#125; 注解配置​ 首先可以把IDao.xml移除，在dao接口的方法上使用@Select注解，并且指定SQL语句，同时需要在SqlMapConfig.xml中的mapper配置时，使用class属性指定dao接口的全限定类名 实体类对象的属性名称与mysql数据库里面的列名不同解决方案：原因：​ mysql数据库里面的列不能和实体类对象的属性进行对应，说以要解决这个问题必须从解决对应关系下手 使用mysql的别名进行对应 使用mybatis里面的resultMap标签进行对应匹配（然后标签里面的resultType属性换成resultMap属性来使用配置的resultMap标签里面的内容）]]></content>
      <categories>
        <category>数据库</category>
        <category>框架</category>
      </categories>
      <tags>
        <tag>语言</tag>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA快捷键操作]]></title>
    <url>%2F2019%2F06%2F27%2FIDEA%20%E5%BF%AB%E6%8D%B7%E9%94%AE%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[IDEA 快捷键操作1.搜索跳转 作用 快捷键 备注 多个窗口之间跳转 ctrl+alt+[或者] [跳转到上一个窗口,]跳转到下一个窗口 导航栏跳转 alt+数字键 侧边栏上面标注数字 万能搜索键 按两次shift键 可以打开万能的搜索窗口 跳转到上次编辑的地方 ctrl+shift+backspace 可以定位到上次编辑的地方 跳转到上次浏览的地方 ctrl+alt+左箭头 跳转到上次浏览的地方 跳转到上次浏览的地方返回 ctrl+alt+右箭头 跳转到上次浏览的地方返回 打开最近文件浏览列表 ctrl+E 方便快速的多文件跳转 文件标签 ctrl+F11 给文件添加标签 文件标签跳转 ctrl+标签名称 方便阅读别源代码 添加到喜爱代码库 alt+shift+f 放到类上面添加类到列表里面，放到方法上面添加方法到列表里面 搜索字符串 ctrl+shift+f 搜素所有的字符串 2.代码小助手注意定义 live Template动态模板还有postfix点模板 对选中的大小写进行转换 ctrl+shift+u 对选中的大小写进行转换 选中当前选中的元素进行多行处理 ctrl+shift+alt+j 选中当前选中的元素进行多行处理 格式化代码 ctrl+alt+L 格式化代码 重构变量 shift+f6 重构变量 重构方法 ctrl+f6 重构方法 抽取变量 ctrl+alt+v 抽取变量 将选中的代码块抽取成为函数 ctrl+alt+m 将选中的代码块抽取成为函数 查看选中的类或者接口的继承关系 Ctrl+shift+u 查看选中的类或者接口的继承关系]]></content>
      <categories>
        <category>技巧</category>
      </categories>
      <tags>
        <tag>日常学习</tag>
        <tag>IDEA</tag>
        <tag>IDE</tag>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法树状数组]]></title>
    <url>%2F2019%2F05%2F27%2F%E7%AE%97%E6%B3%95%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[算法:树状数组1.适用场景​ 可以解决大部分基于区间上的更新以及求和问题 2.介绍1.单点查询 我们先从数组讲起(这个就不需要普及了吧)； A数组是我们传入数据的数组 C数组使我们建立起来的树状数组 然后就能显而易见的发现一个规律 12345678C1 = A1C2 = A1+A2C3 = A3C4 = A1+A2+A3+A4C5 = A5C6 = A5+A6C7 = A7C8 = A1+A2+A3+A4+A5+A6+A7+A8 接下来我们引入lowbit这个概念：(这个地方有一点需要注意：lowbit(0)会陷入死循环 ) 1234inline int lowbit(int x)&#123; return x &amp; (-x);&#125; 这返回的是这个数字最高位的1; 在这之前，又要引入一个补码的概念： 补码的表示方法是: 正数的补码就是其本身 负数的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1. (即在反码的基础上+1) [+1] = [00000001]原 = [00000001]反 = [00000001]补 [-1] = [10000001]原 = [11111110]反 = [11111111]补 请注意，这里的第一位是指的是符号位，而不是数字位(这是1，因此数字位只有1) 对于负数, 补码表示方式也是人脑无法直观看出其数值的. 通常也需要转换成原码在计算其数值. 因此，&amp;是求与的一个符号，意思是 a 和 b 同时为 1 的时候返回这个最高位(不包括符号位) 在刚刚的找规律过程中，我们通过规律总结出了以下性质(lowbit是为了帮助程序代码的实现) 我们可以得到树状数组的一些性质：对于c[i]，他的儿子节点取决于i的所有因子中最多有2^j次幂，则向前取2^j个数作为儿子，即[i-2^j+1,i]。(这个时候就需要lowbit来帮助实现) 举一个栗子： 6的最大2次方因子为2，即2^1，则向前取2个数，则c[6]=a[5]+a[6]； 8的最大2次方因子为8，即2^3，则向前取8个数，则c[8]=a[1]+a[2]+…+a[8]。 2.单点修改 当我们要对最底层的值进行更新时，那么它相应的父亲节点存储的和也需要进行更新， 我们建立的树状数组结构是一个完整的结构，因此修改一个点也会需要所有相应的其父亲节点的点来修改，这样我们就实现了树状数组的修改。 代码如下： 12345678910void modify(int x,int k) //将 x 增加 k&#123; if(x &lt; 1) return ; while(x &lt;= n) &#123; c[i] += k; x += lowbit(x); //去寻找它的父亲 &#125; &#125; 3.单点查询 单点查询由于我们向前统计，因此需要向前查找，这个就不需要讲了吧(没弄明白请看上面) 1234567891011121314int query(int pos)&#123; int sum=0; for(int i=pos;i;i-=lowbit(i)) sum += c[pos]; /*两种写法 while(pos &gt; 0) &#123; sum += c[pos]; pos -= lowbit(pos); &#125; */ return sum;&#125; 1234567891011121314151617181920212223//这是完整的操作void change(int p, int x)&#123; //给位置p增加x while(p &lt;= n) &#123; sum[p] += x; p += p &amp; -p; &#125;&#125;int ask(int p)&#123; //求位置p的前缀和 int res = 0; while(p) &#123; res += sum[p]; p -= p &amp; -p; &#125; return res;&#125;int query(int l, int r)&#123; //区间求和 return ask(r) - ask(l - 1);&#125;]]></content>
      <categories>
        <category>学习</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>C++</tag>
        <tag>C</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ入门]]></title>
    <url>%2F2019%2F05%2F13%2FRabbitMQ%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[什么是RabbitMQ什么是MQ消息队列（Message Queue，简称MQ），从字面意思上看，本质是个队列，FIFO先入先出，只不过队列中存放的内容是message而已。其主要用途：不同进程Process/线程Thread之间通信。 为什么会产生消息队列？有几个原因：不同进程（process）之间传递消息时，两个进程之间耦合程度过高，改动一个进程，引发必须修改另一个进程，为了隔离这两个进程，在两进程间抽离出一层（一个模块），所有两进程之间传递的消息，都必须通过消息队列来传递，单独修改某一个进程，不会影响另一个； 不同进程（process）之间传递消息时，为了实现标准化，将消息的格式规范化了，并且，某一个进程接受的消息太多，一下子无法处理完，并且也有先后顺序，必须对收到的消息进行排队，因此诞生了事实上的消息队列； 什么是RabbitMQRabbitMQ是一个开源的，在AMQP(高级消息队列)基础上完整的，可复用的企业消息系统 他由Erlang语言开发。 什么是AMQPMQP，即Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端中间件不同产品，不同的开发语言等条件的限制。 消息队列的应用场景 任务异步处理 将不需要同步处理且耗时长的操作有消息队列通知消息接收方进行异步处理。可以提高应用程序的响应时间。 应用程序解耦合 MQ相当于一个中介，生产方通过MQ与消费方交互，它将应用程序进行解耦合。 流量削峰 引入消息队列则可以减少突发流量对应用系统的冲击。消息队列就像“水库”一样，拦蓄上游的洪水，削减进入下游河道的洪峰流量，从而达到减免洪水灾害的目的。 还有哪些消息队列呢ActiveMQ，RabbitMQ，ZeroMQ，Kafka,MetaMQ,RocketMQ,Redis。 那为什么使用RabbitMQ呢？ 使用简单，功能强大支持6种队列模型 基于AMQP协议 什么是JMS（可以理解为MYSQL的JDBC）MS即Java消息服务（JavaMessage Service）应用程序接口是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持。 RabbitMQ基本结构 - BrokerBroker概念比较简单，我们可以把Broker理解为一个RabitMQ Server。 Producer与Consumer生产者与消费者相对于RabbitMQ服务器来说，都是RabbitMQ服务器的客户端。 生产者(Producer)：连到RabbitMQ服务器，将消息发送到RabbitMQ服务器的队列，是消息的发送方。 消费者(Consumer)：连接到RabbitMQ则是为了消费队列中的消息，是消息的接收方。 生产者与消费者一般由我们的应用程序充当。 ConnectionConnection是RabbitMQ内部对象之一，用于管理每个到RabbitMQ的TCP网络连接。 ChannelChannel是我们与RabbitMQ打交道的最重要的一个接口，我们大部分的业务操作是在Channel这个接口中完成的，包括定义Queue、定义Exchange、绑定Queue与Exchange、发布消息等 Exchnage消息交换机，作用是接收来自生产者的消息，并根据路由键转发消息到所绑定的队列。 生产者发送上的消息，就是先通过Exchnage按照绑定(binding)规则转发到队列的。 交换机类型(Exchange Type)有四种：fanout、direct、topic，headers，其中headers并不常用。 fanout：这种类型不处理路由键(RoutingKey)，很像子网广播，每台子网内的主机都获得了一份复制的消息，发布/订阅模式就是指使用fanout交换机类型，fanout类型交换机转发消息是最快的。 direct：模式处理路由键，需要路由键完全匹配的队列才能收到消息，路由模式使用的是direct类型的交换机。 topic：将路由键和某模式进行匹配。主题模式使用的是topic类型的交换机。 路由模式，发布订阅模式，主题模式，这些工作模式我们下面会讲。 QueueQueue，即队列，RabbitMQ内部用于存储消息的对象，是真正用存储消息的结构，在生产端，生产者的消息最终发送到指定队列，而消费者也是通过订阅某个队列，达到获取消息的目的。 BindingBinding是一种操作，其作用是建立消息从Exchange转发到Queue的规则，在进行Exchange与Queue的绑定时，需要指定一个BindingKey，Binding操作一般用于RabbitMQ的路由工作模式和主题工作模式。 BindingKey的概念，我们下面在讲RabbitMQ的工作模式会详细讲解。 Virtual HostVirutal host也叫虚拟主机，一个VirtualHost下面有一组不同Exchnage与Queue，不同的Virtual host的Exchnage与Queue之间互相不影响。 应用隔离与权限划分，Virtual host是RabbitMQ中最小颗粒的权限单位划分。 如果要类比的话，我们可以把Virtual host比作MySQL中的数据库，通常我们在使用MySQL时，会为不同的项目指定不同的数据库，同样的，在使用RabbitMQ时，我们可以为不同的应用程序指定不同的Virtual host。 工作模式RabbitMQ一共有六种工作模式，分别为简单模式、工作队列模式、发布/订阅模式、路由模式、主题模式和RPC模式，RPC模式并不常用。 简单模式 只有一个生产者、一个消费者和一个队列。 生产者和消费者在发送和接收消息时，只需要指定队列名，而不需要指定发送到哪个Exchange，RabbitMQ服务器会自动使用Virtual host的默认的Exchange，默认Exchange的type为direct。 演示123456789101112131415161718192021222324252627282930313233343536package rabbitmq.simple;import com.rabbitmq.client.AMQP.Queue.DeclareOk;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;/** * @author yang * @date 2020/5/13 14:12 */public class RabbitTest &#123; public static void main(String[] args) throws IOException &#123; //获取连接 Connection connection = getConnection(); //创建管道 Channel channel = connection.createChannel(); //声明队列 DeclareOk demoQueue = channel.queueDeclare("demoQueue", false, false, false, null); //管道基本发布 channel.basicPublish("","demoQueue",null,"你好啊!223".getBytes() ); channel.close(); connection.close(); &#125; public static Connection getConnection() throws IOException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost("localhost"); connectionFactory.setPort(5672); connectionFactory.setVirtualHost("/"); connectionFactory.setUsername("root"); connectionFactory.setPassword("123456"); return connectionFactory.newConnection(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142package rabbitmq.simple;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.QueueingConsumer;import com.rabbitmq.client.QueueingConsumer.Delivery;import java.io.IOException;/** * @author yang * @date 2020/5/13 14:30 */public class RabbitConsumer &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; Connection connection = getConnection();//获取连接以及建立mq管道 Channel channel = connection.createChannel(); //声明队列 channel.queueDeclare("demoQueue", false, false,false,null ); //定义队列消费者 QueueingConsumer queueingConsumer = new QueueingConsumer(channel); //监听队列 channel.basicConsume("demoQueue",true, queueingConsumer); //获取消息 while (true)&#123; Delivery delivery = queueingConsumer.nextDelivery(); String s = new String(delivery.getBody()); System.out.println(s); &#125; &#125; public static Connection getConnection() throws IOException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost("localhost"); connectionFactory.setPort(5672); connectionFactory.setVirtualHost("/"); connectionFactory.setUsername("root"); connectionFactory.setPassword("123456"); return connectionFactory.newConnection(); &#125;&#125; work（工作模式） 提供者 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package rabbitmq.work;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;/** * @author yang * @date 2020/5/13 15:05 */enum RabbitMqFinal&#123; workQueue("queue"); private String value; RabbitMqFinal(String value) &#123; this.value = value; &#125; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; @Override public String toString() &#123; return "RabbitMqFinal&#123;" + "value='" + value + '\'' + '&#125;'; &#125;&#125;public class RabbitMqProducer &#123; public static void main(String[] args) throws IOException &#123; //获取连接 Connection connection = getConnection(); //建立管道 Channel channel = connection.createChannel(); //声明队列(队列名称,服务器关闭消息不存在,不是独占队列,不自动删除新,) channel.queueDeclare(String.valueOf(RabbitMqFinal.workQueue),false,false,false, null); //发送30条信息 for (int i = 0; i &lt; 30; i++) &#123; channel.basicPublish("", String.valueOf(RabbitMqFinal.workQueue),null,new Integer(i).toString().getBytes()); &#125; //关闭管道 channel.close(); //关闭连接 connection.close(); &#125; public static Connection getConnection() throws IOException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setUsername("root"); connectionFactory.setPassword("123456"); connectionFactory.setVirtualHost("/"); return connectionFactory.newConnection(); &#125;&#125; 消费者一 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package rabbitmq.work;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.QueueingConsumer;import com.rabbitmq.client.QueueingConsumer.Delivery;import java.io.IOException;import java.util.concurrent.TimeUnit;/** * @author yang * @date 2020/5/13 15:22 */public class RabbitMqConsumer1 &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; Connection connection = getConnection(); //建立管道 Channel channel = connection.createChannel(); //定义消费者 QueueingConsumer queueingConsumer = new QueueingConsumer(channel); channel.queueDeclare(String.valueOf(RabbitMqFinal.workQueue),false,false,false, null); //channel.basicQos(1); //监听队列 //自动模式 channel.basicConsume(String.valueOf(RabbitMqFinal.workQueue),true,queueingConsumer); //手动获取模式 //channel.basicConsume(String.valueOf(RabbitMqFinal.workQueue),false,queueingConsumer); //获取消息 while (true)&#123; TimeUnit.SECONDS.sleep(2);//两个消费者不同的地方 Delivery delivery = queueingConsumer.nextDelivery(); java.lang.String s = new java.lang.String(delivery.getBody()); System.out.println(s); //确认消息已经被消（手动模式才开启) //channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125; &#125; public static Connection getConnection() throws IOException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setVirtualHost("/"); return connectionFactory.newConnection(); &#125;&#125; 消费者2 123456789101112131415161718192021222324252627282930313233343536373839404142434445package rabbitmq.work;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.QueueingConsumer;import com.rabbitmq.client.QueueingConsumer.Delivery;import java.io.IOException;import java.util.concurrent.TimeUnit;/** * @author yang * @date 2020/5/13 15:22 */public class RabbitMqConsumer2 &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; Connection connection = getConnection(); //建立管道 Channel channel = connection.createChannel(); //定义消费者 QueueingConsumer queueingConsumer = new QueueingConsumer(channel); channel.queueDeclare(String.valueOf(RabbitMqFinal.workQueue),false,false,false, null); //channel.basicQos(1); //监听队列 //自动模式 channel.basicConsume(String.valueOf(RabbitMqFinal.workQueue),true,queueingConsumer); //手动获取模式 //channel.basicConsume(String.valueOf(RabbitMqFinal.workQueue),false,queueingConsumer); //获取消息 while (true)&#123; TimeUnit.SECONDS.sleep(1);//两个消费者不同的地方 Delivery delivery = queueingConsumer.nextDelivery(); java.lang.String s = new java.lang.String(delivery.getBody()); System.out.println(s); //确认消息已经被消（自动模式才开启) //channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125; &#125; public static Connection getConnection() throws IOException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setVirtualHost("/"); return connectionFactory.newConnection(); &#125;&#125; 我们可以将上面的消费者变成两个就是工作模式。值得注意的是，虽然消费者2比消费者1快，RabbitMQ采用的是轮询机制，你会发现两个消费者始终是交替执行，并且如果有一个消费者中间挂掉会导致消息丢失。显然这样是十分不合理的。 消息确认模式消费者从队列中获取消息，服务端如何知道消息已经被消费呢？ 模式1：自动确认只要消息从队列中获取，无论消费者获取到消息后是否成功消息，都认为是消息已经成功消费。 模式2：手动确认消费者从队列中获取消息后，服务器会将该消息标记为不可用状态，等待消费者的反馈，如果消费者一直没有反馈，那么该消息将一直处于不可用状态。 1channel.basicConsume(String.valueOf(RabbitMqFinal.workQueue),true,queueingConsumer);//自动确认 12channel.basicConsume(String.valueOf(RabbitMqFinal.workQueue),false,queueingConsumer);//手动确认channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);//确认消息被消费 如何解决上述的轮询不合理机制和消息丢失机制呢？Work模式的“能者多劳”12345678// 同一时刻服务器只会发一条消息给消费者channel.basicQos(1);//开启这行 表示使用手动确认模式channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);// 监听队列，false表示手动返回完成状态，true表示自动channel.basicConsume(QUEUE_NAME, false, consumer); 测试结果消费者2比消费者1获取的消息更多而且挂掉一个消费者并不会导致消息丢失，因为我们是手动确认消息的。 演示提供者 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package rabbitmq.work;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;/** * @author yang * @date 2020/5/13 15:05 */enum RabbitMqFinal&#123; workQueue("queue"); private String value; RabbitMqFinal(String value) &#123; this.value = value; &#125; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; @Override public String toString() &#123; return "RabbitMqFinal&#123;" + "value='" + value + '\'' + '&#125;'; &#125;&#125;public class RabbitMqProducer &#123; public static void main(String[] args) throws IOException &#123; //获取连接 Connection connection = getConnection(); //建立管道 Channel channel = connection.createChannel(); //声明队列(队列名称,服务器关闭消息不存在,不是独占队列,不自动删除新,) channel.queueDeclare(String.valueOf(RabbitMqFinal.workQueue),false,false,false, null); //发送30条信息 for (int i = 0; i &lt; 30; i++) &#123; channel.basicPublish("", String.valueOf(RabbitMqFinal.workQueue),null,new Integer(i).toString().getBytes()); &#125; //关闭管道 channel.close(); //关闭连接 connection.close(); &#125; public static Connection getConnection() throws IOException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setUsername("root"); connectionFactory.setPassword("123456"); connectionFactory.setVirtualHost("/"); return connectionFactory.newConnection(); &#125;&#125; 消费者一 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package rabbitmq.work;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.QueueingConsumer;import com.rabbitmq.client.QueueingConsumer.Delivery;import java.io.IOException;import java.util.concurrent.TimeUnit;/** * @author yang * @date 2020/5/13 15:22 */public class RabbitMqConsumer1 &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; Connection connection = getConnection(); //建立管道 Channel channel = connection.createChannel(); //定义消费者 QueueingConsumer queueingConsumer = new QueueingConsumer(channel); channel.queueDeclare(String.valueOf(RabbitMqFinal.workQueue),false,false,false, null); channel.basicQos(1); //监听队列 //自动模式 //channel.basicConsume(String.valueOf(RabbitMqFinal.workQueue),true,queueingConsumer); //手动获取模式 channel.basicConsume(String.valueOf(RabbitMqFinal.workQueue),false,queueingConsumer); //获取消息 while (true)&#123; TimeUnit.SECONDS.sleep(2); Delivery delivery = queueingConsumer.nextDelivery(); java.lang.String s = new java.lang.String(delivery.getBody()); System.out.println(s); //确认消息已经被消（手动模式才开启) channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125; &#125; public static Connection getConnection() throws IOException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setVirtualHost("/"); return connectionFactory.newConnection(); &#125;&#125; 消费者2123456789101112131415161718192021222324252627282930313233343536373839404142434445package rabbitmq.work;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.QueueingConsumer;import com.rabbitmq.client.QueueingConsumer.Delivery;import java.io.IOException;import java.util.concurrent.TimeUnit;/** * @author yang * @date 2020/5/13 15:22 */public class RabbitMqConsumer2 &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; Connection connection = getConnection(); //建立管道 Channel channel = connection.createChannel(); //定义消费者 QueueingConsumer queueingConsumer = new QueueingConsumer(channel); channel.queueDeclare(String.valueOf(RabbitMqFinal.workQueue),false,false,false, null); channel.basicQos(1); //监听队列 //自动模式 //channel.basicConsume(String.valueOf(RabbitMqFinal.workQueue),true,queueingConsumer); //手动获取模式 channel.basicConsume(String.valueOf(RabbitMqFinal.workQueue),false,queueingConsumer); //获取消息 while (true)&#123; TimeUnit.SECONDS.sleep(1); Delivery delivery = queueingConsumer.nextDelivery(); java.lang.String s = new java.lang.String(delivery.getBody()); System.out.println(s); //确认消息已经被消（手动模式才开启) channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125; &#125; public static Connection getConnection() throws IOException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setVirtualHost("/"); return connectionFactory.newConnection(); &#125;&#125; 发布订阅模式（fanout） 发布订阅模式相比之前多了一个路由器和队列，其实在Work模式中也有一个路由器，只是隐藏的路由器 在发布订阅模式中，我们需要创建多个队列，并且创建一个路由器，设置路由器的模式为fanout, 通过 1channel.queueBind(queue1,exchange,""); 方法将队列和路由器绑定，并且不适用路由键就可以实现发布订阅模式。 提供者12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package rabbitmq.publish;import com.rabbitmq.client.AMQP.Exchange;import com.rabbitmq.client.AMQP.Queue.DeclareOk;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;import java.util.Date;/** * @author yang * @date 2020/5/13 17:10 * 发布订阅模式:发布者 */public class Publish &#123; public static final String queue1="queue1"; public static final String queue2="queue2"; public static final String exchange="exchange"; public static void main(String[] args) throws IOException &#123; //获取连接 Connection connection = getConnection(); //建立管道 Channel channel = connection.createChannel(); //声明两个队列 DeclareOk declareOk = channel.queueDeclare(queue1, false, false, false, null); DeclareOk declareOk1 = channel.queueDeclare(queue2, false, false, false, null); //声明路由器并且设置为发布订阅模式 Exchange.DeclareOk fanout = channel.exchangeDeclare(exchange, "fanout"); //将队列和路由器绑定 channel.queueBind(queue1,exchange,""); channel.queueBind(queue2,exchange,""); //发送消息 channel.basicPublish(exchange,"",null,new Date().toString().getBytes()); channel.close(); connection.close(); &#125; public static Connection getConnection() throws IOException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setUsername("root"); connectionFactory.setPassword("123456"); return connectionFactory.newConnection(); &#125;&#125; 订阅者一1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package rabbitmq.publish;import com.rabbitmq.client.AMQP.Queue.DeclareOk;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.QueueingConsumer;import com.rabbitmq.client.QueueingConsumer.Delivery;import java.io.IOException;/** * @author yang * @date 2020/5/13 17:24 * 订阅者,订阅队列1 */public class Subscribe1 &#123; public static final String queue1="queue1"; public static final String exchange="exchange"; public static void main(String[] args) throws IOException, InterruptedException &#123; //获取连接 Connection connection = getConnection(); //建立管道 Channel channel = connection.createChannel(); //声明队列 DeclareOk declareOk = channel.queueDeclare(queue1, false, false, false, null); //声明路由器 channel.exchangeDeclare(exchange,"fanout"); //绑定路由器和队列 channel.queueBind(queue1,exchange,""); QueueingConsumer queueingConsumer = new QueueingConsumer(channel); //监听队列 channel.basicConsume(queue1,true,queueingConsumer); while (true)&#123; Delivery delivery = queueingConsumer.nextDelivery(); String s = new String(delivery.getBody()); System.out.println(s); &#125; &#125; public static Connection getConnection() throws IOException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setUsername("root"); connectionFactory.setPassword("123456"); return connectionFactory.newConnection(); &#125;&#125; 订阅者21234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package rabbitmq.publish;import com.rabbitmq.client.AMQP.Queue.DeclareOk;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.QueueingConsumer;import com.rabbitmq.client.QueueingConsumer.Delivery;import java.io.IOException;/** * @author yang * @date 2020/5/13 17:24 * 订阅者,订阅队列1 */public class Subscribe2 &#123; public static final String queue2="queue2"; public static final String exchange="exchange"; public static void main(String[] args) throws IOException, InterruptedException &#123; //获取连接 Connection connection = getConnection(); //建立管道 Channel channel = connection.createChannel(); //声明队列 DeclareOk declareOk = channel.queueDeclare(queue2, false, false, false, null); //声明路由器 channel.exchangeDeclare(exchange,"fanout"); //绑定路由器和队列 channel.queueBind(queue2,exchange,""); QueueingConsumer queueingConsumer = new QueueingConsumer(channel); //监听队列 channel.basicConsume(queue2,true,queueingConsumer); while (true)&#123; Delivery delivery = queueingConsumer.nextDelivery(); String s = new String(delivery.getBody()); System.out.println(s); &#125; &#125; public static Connection getConnection() throws IOException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setUsername("root"); connectionFactory.setPassword("123456"); return connectionFactory.newConnection(); &#125;&#125; 路由模式(direct) 相比发布订阅模式在于我们可以根据路由键选择不同的队列。 提供者1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package rabbitmq.direct;import com.rabbitmq.client.AMQP.Exchange;import com.rabbitmq.client.AMQP.Queue.DeclareOk;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;/** * @author yang * @date 2020/5/13 17:10 * 路由模式,一个生产者发送消息到路由键all里面和queue1以及queue2中 */public class Producer &#123; public static final String queue1="queue1direct"; public static final String queue2="queue2direct"; public static final String exchange="exchangedirect"; public static final String all="all"; public static void main(String[] args) throws IOException &#123; //获取连接 Connection connection = getConnection(); //建立管道 Channel channel = connection.createChannel(); //声明两个队列 DeclareOk declareOk = channel.queueDeclare(queue1, false, false, false, null); DeclareOk declareOk1 = channel.queueDeclare(queue2, false, false, false, null); //声明路由器并且设置为发布路由模式 Exchange.DeclareOk direct = channel.exchangeDeclare(exchange, "direct"); //将队列和路由器绑定 channel.queueBind(queue1,exchange,queue1); channel.queueBind(queue2,exchange,queue2); //并且两个通道都和all路由键绑定 channel.queueBind(queue1,exchange,all); channel.queueBind(queue2,exchange,all); //发送消息到all channel.basicPublish(exchange,all,null,"所有队列都要看到!".getBytes()); channel.basicPublish(exchange,queue1,null,"queue1要看到".getBytes()); channel.basicPublish(exchange,queue2,null,"queue2要看到".getBytes()); channel.close(); connection.close(); &#125; public static Connection getConnection() throws IOException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setUsername("root"); connectionFactory.setPassword("123456"); return connectionFactory.newConnection(); &#125;&#125; 消费者112345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package rabbitmq.direct;import com.rabbitmq.client.AMQP.Queue.DeclareOk;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.QueueingConsumer;import com.rabbitmq.client.QueueingConsumer.Delivery;import java.io.IOException;/** * @author yang * @date 2020/5/13 17:24 * 订阅者,订阅队列1 */public class Consumer1 &#123; public static final String queue1="queue1direct"; public static final String exchange="exchangedirect"; public static final String all="all"; public static void main(String[] args) throws IOException, InterruptedException &#123; //获取连接 Connection connection = getConnection(); //建立管道 Channel channel = connection.createChannel(); //声明队列 DeclareOk declareOk = channel.queueDeclare(queue1, false, false, false, null); //声明路由器 channel.exchangeDeclare(exchange,"direct"); //绑定路由器和队列 channel.queueBind(queue1,exchange,queue1); channel.queueBind(queue1,exchange,all); QueueingConsumer queueingConsumer = new QueueingConsumer(channel); //监听队列 channel.basicConsume(queue1,true,queueingConsumer); while (true)&#123; Delivery delivery = queueingConsumer.nextDelivery(); String s = new String(delivery.getBody()); System.out.println(s); &#125; &#125; public static Connection getConnection() throws IOException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setUsername("root"); connectionFactory.setPassword("123456"); return connectionFactory.newConnection(); &#125;&#125; 消费者212345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package rabbitmq.direct;import com.rabbitmq.client.AMQP.Queue.DeclareOk;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.QueueingConsumer;import com.rabbitmq.client.QueueingConsumer.Delivery;import java.io.IOException;/** * @author yang * @date 2020/5/13 17:24 * 订阅者,订阅队列1 */public class Consumer2 &#123; public static final String queue2="queue2direct"; public static final String exchange="exchangedirect"; public static final String all="all"; public static void main(String[] args) throws IOException, InterruptedException &#123; //获取连接 Connection connection = getConnection(); //建立管道 Channel channel = connection.createChannel(); //声明队列 DeclareOk declareOk = channel.queueDeclare(queue2, false, false, false, null); //声明路由器 channel.exchangeDeclare(exchange,"direct"); //绑定路由器和队列 channel.queueBind(queue2,exchange,queue2); channel.queueBind(queue2,exchange,all); QueueingConsumer queueingConsumer = new QueueingConsumer(channel); //监听队列 channel.basicConsume(queue2,true,queueingConsumer); while (true)&#123; Delivery delivery = queueingConsumer.nextDelivery(); String s = new String(delivery.getBody()); System.out.println(s); &#125; &#125; public static Connection getConnection() throws IOException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setUsername("root"); connectionFactory.setPassword("123456"); return connectionFactory.newConnection(); &#125;&#125; 主题模式(通配符模式)（topic）相比路由模式，主题模式可以通过通配符来选择不同的队列 #表示匹配一个或多个词 例如#.yang.# *表示正好一个词 设置路由器类型为topic，然后]]></content>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq在window下安装]]></title>
    <url>%2F2019%2F05%2F12%2Frabbitmq%E5%9C%A8window%E4%B8%8B%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[先下载并按照erlang因为rabbitMQ是使用爱立信的并发编程语言Erlang编写的，所以要使用RabbitMq必须先安装Erlang Erlang 网站https://www.erlang.org/downloads 因为是window安装，所以我下载window64bit的大约90mb 下载完成后一路next就行，但是要切记你的安装路径。 配置erlang 然后点击path 然后控制台输入erl查看是否安装正确 第二步安装RabbitMQ和之前一样，一直next 使用cmd打开RabbitMq的安装目录sbin目录 输入如下指令,来安装rabbitMq的插件 1rabbitmq-plugins enable rabbitmq_management 之后输入 1rabbitmqctl status 如果出现如下情况，说明安装成功 启动RabbitMq在刚才的sbin目录找到rabbitmq-server.bat就能启动 如果出现这种情况说明你已经运行了 然后打开地址http://localhost:15672/ 默认的账号和密码都是guest]]></content>
      <tags>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[加密入门]]></title>
    <url>%2F2019%2F05%2F12%2F%E5%8A%A0%E5%AF%86%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[一、Base64百度百科： Base64编码可用于在HTTP环境下传递较长的标识信息。例如，在Java Persistence系统Hibernate中，就采用了Base64来将一个较长的唯一标识符（一般为128-bit的UUID）编码为一个字符串，用作HTTP表单和HTTP GET URL中的参数。在其他应用程序中，也常常需要把二进制数据编码为适合放在URL（包括隐藏表单域）中的形式。此时，采用Base64编码不仅比较简短，同时也具有不可读性，即所编码的数据不会被人用肉眼所直接看到。然而，标准的Base64并不适合直接放在URL里传输，因为URL编码器会把标准Base64中的“/”和“+”字符变为形如“%XX”的形式，而这些“%”号在存入数据库时还需要再进行转换，因为ANSI SQL中已将“%”号用作通配符。为解决此问题，可采用一种用于URL的改进Base64编码，它不仅在末尾去掉填充的’=’号，并将标准Base64中的“+”和“/”分别改成了“-”和“”，这样就免去了在URL编解码和数据库存储时所要作的转换，避免了编码信息长度在此过程中的增加，并统一了数据库、表单等处对象标识符的格式。另有一种用于正则表达式的改进Base64变种，它将“+”和“/”改成了“!”和“-”，因为“+”,“”以及前面在IRCu中用到的“[”和“]”在正则表达式中都可能具有特殊含义。此外还有一些变种，它们将“+/”改为“-”或“.*”（用作编程语言中的标识符名称）或“.-”（用于XML中的Nmtoken）甚至“:”（用于XML中的Name）。其他应用Mozilla Thunderbird和Evolution用Base64来保密电子邮件密码Base64 也会经常用作一个简单的“加密”来保护某些数据，而真正的加密通常都比较繁琐。垃圾讯息传播者用Base64来避过反垃圾邮件工具，因为那些工具通常都不会翻译Base64的讯息。在LDIF档案，Base64用作编码字串。 Base64算法，它是电子邮件常用的传输算法。电子邮件只允许使用ASCII码，而对于非ASCII码（如中文）就显得无能为力了。因此，为了能在电子邮件中使用非ASCII码，就有了Base64算法。Base64算法算不上真正的加密算法，尽管Base64算法的编码和解码操作可充当加密和解密操作，还有一张字符映射表充当了秘钥。但是，Base64算法公开秘钥，而且加密强度并不高。尽管如此，经过改良的Base64算法常常作为加密算法使用，如修改字符映射表。Base64算法广泛用于电子邮件传输、网络数据传输、秘钥存储和数字证书存储。经过改良的Base64算法常作为网络数据传输二进制数据，甚至可以作为一种简单的加密手段。 二、验证数据完整性——信息摘要算法1、MD5算法百度百科： MD5即Message-Digest Algorithm 5（信息-摘要算法5），用于确保信息传输完整一致。是计算机广泛使用的杂凑算法之一（又译摘要算法、哈希算法），主流编程语言普遍已有MD5实现。将数据（如汉字）运算为另一固定长度值，是杂凑算法的基础原理，MD5的前身有MD2、MD3和MD4。MD5算法具有以下特点：1、压缩性：任意长度的数据，算出的MD5值长度都是固定的。2、容易计算：从原数据计算出MD5值很容易。3、抗修改性：对原数据进行任何改动，哪怕只修改1个字节，所得到的MD5值都有很大区别。4、强抗碰撞：已知原数据和其MD5值，想找到一个具有相同MD5值的数据（即伪造数据）是非常困难的。 MD5算法已被破解，虽然MD5算法的破解使其安全性大为降低，但在用户注册/登录模块中仍然是架构师首选的方案。各大软件厂商在其软件下载页面上仍然使用MD5算法作为数据完整性验证的首选方法。MD5算法常作为安全性要求不高的环境中的常用算法。 2、SHA算法百度百科： 安全哈希算法（Secure Hash Algorithm）主要适用于数字签名标准（Digital Signature Standard DSS）里面定义的数字签名算法（Digital Signature Algorithm DSA）。对于长度小于2^64位的消息，SHA1会产生一个160位的消息摘要。该算法经过加密专家多年来的发展和改进已日益完善，并被广泛使用。该算法的思想是接收一段明文，然后以一种不可逆的方式将它转换成一段（通常更小）密文，也可以简单的理解为取一串输入码（称为预映射或信息），并把它们转化为长度较短、位数固定的输出序列即散列值（也称为信息摘要或信息认证代码）的过程。散列函数值可以说是对明文的一种“指纹”或是“摘要”所以对散列值的数字签名就可以视为对此明文的数字签名。 SHA算法较之MD算法更为安全，常常出现在一些安全系数要求较高的环境中。一般的用户注册/登录模块，各大软件厂商用于校验数据完整性的页面中都常常用到SHA算法。这些领域既是MD5算法出没的地方，也是SHA算法盘踞之处。除此之外，MD5和SHA算法还常常作为数字证书的签名算法，而SHA算法则更为常见一些。 3、MAC算法百度百科： 消息认证码（带密钥的Hash函数）:密码学中，通信实体双方使用的一种验证机制，保证消息数据完整性的一种工具。构造方法由M.Bellare提出，安全性依赖于Hash函数，故也称带密钥的Hash函数。消息认证码是基于密钥和消息摘要所获得的一个值，可用于数据源发认证和完整性校验。 MAC是一种基于秘钥的散列函数算法，它吸收了MD算法和SHA算法的精髓，并将其发扬光大。 4、循环冗余校验算法——CRC算法百度百科： 循环冗余校验(Cyclic Redundancy Check, CRC)是一种根据网络数据包或电脑文件等数据产生简短固定位数校验码的一种散列函数，主要用来检测或校验数据传输或者保存后可能出现的错误。它是利用除法及余数的原理来作错误侦测的。 MD、SHA和MAC都是加密算法领域的信息摘要算法，与之功能相近的CRC-23算法则是最为古老的数据完整性验证算法。目前，CRC-23算法仍广泛用于通信领域，实现差别控制，其变种Adler-32算法则广泛适用于zlib压缩算法中。 三、初等数据加密——对称加密算法1、DES算法百度百科： DES全称为Data Encryption Standard，即数据加密标准，是一种使用密钥加密的块算法，1977年被美国联邦政府的国家标准局确定为联邦资料处理标准（FIPS），并授权在非密级政府通信中使用，随后该算法在国际上广泛流传开来。需要注意的是，在某些文献中，作为算法的DES称为数据加密算法（Data Encryption Algorithm,DEA），已与作为标准的DES区分开来。 DES算法有三点安全隐患：秘钥太短、迭代偏少和半公开性。针对秘钥太短和迭代偏少的问题，有人提出了多重DES的方式用来克服这些缺陷，在实际应用中一般采用3DES方案，它还有两个别名——Triple DES和DESede。DESede算法将秘钥长度增至112位或168位，抗穷举攻击的能力显著增强。但究其核心仍是DES算法，虽然增加迭代次数提高了安全性，但与此同时也造成了处理速度较慢，秘钥计算时间加长，加密效率不高的问题。 2、AES算法百度百科： 高级加密标准（英语：Advanced Encryption Standard，缩写：AES），在密码学中又称Rijndael加密法，是美国联邦政府采用的一种区块加密标准。这个标准用来替代原先的DES，已经被多方分析且广为全世界所使用。经过五年的甄选流程，高级加密标准由美国国家标准与技术研究院（NIST）于2001年11月26日发布于FIPS PUB 197，并在2002年5月26日成为有效的标准。2006年，高级加密标准已然成为对称密钥加密中最流行的算法之一。 DESede算法的种种劣势宣告DES算法改良路线失败，对称加密算法前途陷入困境，迫切需要产生新的对称加密算法，AES算法和IDEA算法呼之欲出。以其秘钥设置快、存储要求低、在硬件实现和限制存储的条件下性能优异当选AES算法。AES算法支持3种长度的秘钥，为128位、192位和256位。基于较高的安全性，AES常被用于通用移动t通信系统。 3、特点对称加密算法的特点是算法公开、计算量小、加密速度快、加密效率高。不足之处是，交易双方都使用同样钥匙，安全性得不到保证。此外，每对用户每次使用对称加密算法时，都需要使用其他人不知道的惟一钥匙，这会使得发收信双方所拥有的钥匙数量呈几何级数增长，密钥管理成为用户的负担。对称加密算法在分布式网络系统上使用较为困难，主要是因为密钥管理困难，使用成本较高。而与公开密钥加密算法比起来，对称加密算法能够提供加密和认证却缺乏了签名功能，使得使用范围有所缩小。在计算机专网系统中广泛使用的对称加密算法有DES和IDEA等。美国国家标准局倡导的AES即将作为新标准取代DES。 四、高等数据加密——非对称加密算法对称加密算法提高数据安全性的同时带来了秘钥管理的复杂性。消息收发双方若想发送加密消息，必须事先约定好加密算法并发放秘钥。加密算法在传递过程中，难免会被窃听。如果窃听者破译了秘钥，就可以破译、甚至篡改消息，而消息的收发双方却浑然不知。当然，我们可以通过消息摘要算法验证消息的完整性，但却不能避免消息被破译的可能。消息收发双方所要避免这种密码被破解的风险，就必须频繁更换秘钥，而秘钥的发送又是一个敏感的问题，操作起来具有一定的难度。非对称加密算法构建了两把秘钥：私钥保密，成为私钥；公钥公开，成为公钥。公钥和私钥一一对应，且不能相互推导得出，即便公钥在传输过程中被截获也不能推导出私钥。也就是说，即便公钥被截获或被破解，也无法推到对应的私钥。非对称加密算法普遍遵从“公钥加密，私钥解密”和“私钥加密，公钥解密”这两种加密方式。 主要算法：RSA、Elgamal、背包算法、Rabin、D-H、ECC（椭圆曲线加密算法）。使用最广泛的是RSA算法，Elgamal是另一种常用的非对称加密算法。Elgamal由Taher Elgamal于1985年发明，其基础是DiffieˉHellman密钥交换算法，后者使通信双方能通过公开通信来推导出只有他们知道的秘密密钥值[DiffieˉHellman]。与RSA相比，DiffieˉHellman的优势之一是每次交换密钥时都使用一组新值，而使用RSA算法时，如果攻击者获得了私钥，那么他不仅能解密之前截获的消息，还能解密之后的所有消息。然而，RSA可以通过认证（如使用X.509数字证书）来防止中间人攻击，但Diff ieˉHellman在应对中间人攻击时非常脆弱。 五、带秘钥的消息摘要算法——数字签名算法数字签名算法是公钥基础设置（PKI）以及许多网络安全机制（SSL/TLS、VPN等）的基础。数字签名算法要求能够验证数据完整性、认证数据来源，并起到抗否认的作用。基于数据完整性认证，我们希望数据的发送方（以下简称甲方）可以对自己所发送的数据做相应的处理（签名处理），同时给出对应的凭证（签名），并且数据的接收方（以下简称乙方）可以验证该签名是否与数据甲方发送的数据相符。如果任何机构都可以进行签名处理，那签名本身就失去了验证的意义。因此，签名操作只能由甲方来完成，验证签名操作则由乙方来完成。既然签名操作仅限于甲方，那么签名操作本身是基于甲方的某些私有信息完成的操作。并且，用于验证操作的相关信息是由甲方公布给乙方。用于签名的相关信息私有，用于验证的相关信息共有，且这两种信息必须成对出现。非对称加密算法中的私钥和公钥满足这种关系，成为数字签名算法中的重要元素。数字签名算法包含签名和验证两项操作，遵循“私钥签名，公钥验证”的签名/验证方式，签名时需要使用私钥和待签名数据，验证时则需要公钥、签名值和待签名数据，其核心算法主要是消息摘要算法。因此，我们可以把数字签名算法近似看成是一种附加了公钥和私钥的消息摘要算法。数字签名算法主要包括RSA、DSA和ECDSA共3种算法。RSA算法是目前使用最为广泛的非对称加密算法和数字签名算法，在电子商务和产品验证方面均有使用。DSA算法是继RSA算法后出现的基于DSS的数字签名算法，旨在形成数字签名标准。并且，DSA算法本身不包含任何信息摘要算。DSA算法主要为后续数字签名算法的形成奠定基础。ECDSA算法相对传统签名算法具有速度快、强度高、签名短等优点，其用途也越来越广泛。]]></content>
      <tags>
        <tag>加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[函数式接口]]></title>
    <url>%2F2019%2F05%2F10%2F%E5%87%BD%E6%95%B0%E5%BC%8F%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[函数式接口函数式接口是jdk8中提供的新特性，所谓的函数式接口就是只有一个抽象方法的接口，在jdk8中又提供了一些新的函数式接口，他们都在java.lang.function中，他们主要有4中类型接口 消费型接口，有参数无返回值123456789@FunctionalInterfacepublic interface Consumer&lt;T&gt; &#123; void accept(T t); default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) &#123; Objects.requireNonNull(after); return (T t) -&gt; &#123; accept(t); after.accept(t); &#125;; &#125;&#125; 演示12345678910111213141516171819/** * @author yang * @date 2020/5/10 23:57 * 消费型接口,把一段字符串转换为大写并打印,然后在转换为小写在打印 */public class ConsumerImplDemo &#123; public static void main(String[] args) &#123; print((s -&gt; &#123; System.out.println(s.toUpperCase()); &#125;),s -&gt; &#123; System.out.println(s.toLowerCase()); &#125;); &#125; public static void print(Consumer&lt;String&gt; consumerToUp,Consumer&lt;String&gt; consumerToLow)&#123; String str="Hello World!"; consumerToUp.accept(str); consumerToLow.accept(str); &#125;&#125; 函数型接口，有参数，有返回值12345678910111213141516171819@FunctionalInterfacepublic interface Function&lt;T, R&gt; &#123; R apply(T t); default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) &#123; Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v)); &#125; default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) &#123; Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t)); &#125; static &lt;T&gt; Function&lt;T, T&gt; identity() &#123; return t -&gt; t; &#125;&#125; 判断型接口，有参数，返回boolean类型1234567891011121314151617181920212223242526272829303132333435363738394041package java.util.function;import java.util.Objects;/** * Represents a predicate (boolean-valued function) of one argument. * * &lt;p&gt;This is a &lt;a href="package-summary.html"&gt;functional interface&lt;/a&gt; * whose functional method is &#123;@link #test(Object)&#125;. * * @param &lt;T&gt; the type of the input to the predicate * * @since 1.8 */@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123; boolean test(T t); default Predicate&lt;T&gt; and(Predicate&lt;? super T&gt; other) &#123; Objects.requireNonNull(other); return (t) -&gt; test(t) &amp;&amp; other.test(t); &#125; default Predicate&lt;T&gt; negate() &#123; return (t) -&gt; !test(t); &#125; default Predicate&lt;T&gt; or(Predicate&lt;? super T&gt; other) &#123; Objects.requireNonNull(other); return (t) -&gt; test(t) || other.test(t); &#125; static &lt;T&gt; Predicate&lt;T&gt; isEqual(Object targetRef) &#123; return (null == targetRef) ? Objects::isNull : object -&gt; targetRef.equals(object); &#125;&#125; 供给型接口，没有参数，有返回值12345@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; T get();&#125; 演示123456789101112131415public class SupplierImplDemo &#123; public static void main(String[] args) &#123; int[] arr=&#123;23,25,26,2,168,41,315&#125;; printMax(()-&gt;&#123; Arrays.sort(arr); return arr[arr.length-1]; &#125;); &#125; //使用供给型接口打印最大值 public static void printMax(Supplier&lt;Integer&gt; supplier)&#123; Integer integer = supplier.get();//获取到最大值 System.out.println(integer); &#125;&#125;]]></content>
      <tags>
        <tag>新特性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux安装java环境]]></title>
    <url>%2F2019%2F04%2F26%2Flinux%E5%AE%89%E8%A3%85java%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[首先我们需要去Oracle官网下载linux安装包然后解压安装包1tar zxvf jdk-8u181-linux-x64.tar.gz 接下来配置环境变量1vim /etc/profile 在尾部添加如下信息，当然根据你目录的不同调整你的JAVA_HOME路径 123export JAVA_HOME=/root/jdk/jdk1.8.0_241export CLASSPATH=$:CLASSPATH:$JAVA_HOME/lib/ export PATH=$PATH:$JAVA_HOME/bin 编辑完成保存退出后使用如下指令刷新环境配置1source /etc/profile 之后使用java -version查看安装是否成功了]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC框架教程]]></title>
    <url>%2F2019%2F03%2F10%2FSpringMVC%E6%A1%86%E6%9E%B6%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[SpringMVC框架教程前言为开发团队选择一款优秀的MVC框架是件难事儿，在众多可行的方案中决择需要很高的经验和水平。你的一个决定会影响团队未来的几年。要考虑方面太多： 1、简单易用，以提高开发效率。使小部分的精力在框架上，大部分的精力放在业务上。 2、性能优秀，这是一个最能吸引眼球的话题。 3、尽量使用大众的框架（避免使用小众的、私有的框架），新招聘来的开发人员有一些这方面技术积累，减低人员流动再适应的影响。 简介​ pring MVC属于SpringFrameWork的后续产品，已经融合在Spring Web Flow里面。Spring 框架提供了构建 Web 应用程序的全功能 MVC 模块。使用 Spring 可插入的 MVC 架构，从而在使用Spring进行WEB开发时，可以选择使用Spring的Spring MVC框架或集成其他MVC开发框架，如Struts]1(现在一般不用)，Struts 2(一般老项目使用)等。 SpringMVC框架优势1.清晰的角色划分：控制器(controller)、验证器(validator)、命令对象(command obect)、表单对象(form object)、模型对象(model object)、Servlet分发器(DispatcherServlet)、处理器映射(handler mapping)、试图解析器(view resoler)等等。每一个角色都可以由一个专门的对象来实现。 2.强大而直接的配置方式：将框架类和应用程序类都能作为JavaBean配置，支持跨多个context的引用，例如，在web控制器中对业务对象和验证器validator)的引用。 3.可适配、非侵入：可以根据不同的应用场景，选择何事的控制器子类(simple型、command型、from型、wizard型、multi-action型或者自定义)，而不是一个单一控制器(比如Action/ActionForm)继承。 4.可重用的业务代码：可以使用现有的业务对象作为命令或表单对象，而不需要去扩展某个特定框架的基类。 5.可定制的绑定(binding)和验证(validation)：比如将类型不匹配作为应用级的验证错误，这可以保证错误的值。再比如本地化的日期和数字绑定等等。在其他某些框架中，你只能使用字符串表单对象，需要手动解析它并转换到业务对象。 6.可定制的handler mapping和view resolution：Spring提供从最简单的URL映射，到复杂的、专用的定制策略。与某些web MVC框架强制开发人员使用单一特定技术相比，Spring显得更加灵活。 7.灵活的model转换：在Springweb框架中，使用基于Map的键/值对来达到轻易的与各种视图技术集成。 8.可定制的本地化和主题(theme)解析：支持在JSP中可选择地使用Spring标签库、支持JSTL、支持Velocity(不需要额外的中间层)等等。 9.简单而强大的JSP标签库(Spring Tag Library)：支持包括诸如数据绑定和主题(theme)之类的许多功能。他提供在标记方面的最大灵活性。 10.JSP表单标签库：在Spring2.0中引入的表单标签库，使用在JSP编写表单更加容易。 11.Spring Bean的生命周期：可以被限制在当前的HTTp Request或者HTTp Session。准确的说，这并非Spring MVC框架本身特性，而应归属于Spring MVC使用的WebApplicationContext容器。 SpringMVC与Struts2框架的对比拦截机制1、Struts2 a、Struts2框架是类级别的拦截，每次请求就会创建一个Action，和Spring整合时Struts2的ActionBean注入作用域是原型模式prototype（否则会出现线程并发问题），然后通过setter，getter吧request数据注入到属性。b、Struts2中，一个Action对应一个request，response上下文，在接收参数时，可以通过属性接收，这说明属性参数是让多个方法共享的。c、Struts2中Action的一个方法可以对应一个url，而其类属性却被所有方法共享，这也就无法用注解或其他方式标识其所属方法了2、SpringMVCa、SpringMVC是方法级别的拦截，一个方法对应一个Request上下文，所以方法直接基本上是独立的，独享request，response数据。而每个方法同时又何一个url对应，参数的传递是直接注入到方法中的，是方法所独有的。处理结果通过ModeMap返回给框架。b、在Spring整合时，SpringMVC的Controller Bean默认单例模式Singleton，所以默认对所有的请求，只会创建一个Controller，有应为没有共享的属性，所以是线程安全的，如果要改变默认的作用域，需要添加@Scope注解修改。 性能方面 SpringMVC实现了零配置，由于SpringMVC基于方法的拦截，有加载一次单例模式bean注入。而Struts2是类级别的拦截，每次请求对应实例一个新的Action，需要加载所有的属性值注入，所以，SpringMVC开发效率和性能高于Struts2。 四、拦截机制Struts2有自己的拦截Interceptor机制，SpringMVC这是用的是独立的Aop方式，这样导致Struts2的配置文件量还是比SpringMVC大。 配置方面spring MVC和Spring是无缝的。从这个项目的管理和安全上也比Struts2高（当然Struts2也可以通过不同的目录结构和相关配置做到SpringMVC一样的效果，但是需要xml配置的地方不少）。SpringMVC可以认为已经100%零配置。 设计思想Struts2更加符合OOP的编程思想， SpringMVC就比较谨慎，在servlet上扩展。 集成方面SpringMVC集成了Ajax，使用非常方便，只需一个注解@ResponseBody就可以实现，然后直接返回响应文本即可，而Struts2拦截器集成了Ajax，在Action中处理时一般必须安装插件或者自己写代码集成进去，使用起来也相对不方便。 注解详解RequestMapping介绍你可以使用@RequestMapping来映射URL，比如/test到某个Controller类，或者是某个具体的方法。通常类上的注解@RequestMapping用来标记请求的路径，方法上的@RequestMapping注解的作用将是映射到特定的URL到某个具体的处理方法。 作用被添加注解的方法参数就是发起请求的参数，返回值就是通过跳转的页面名字 参数： value,请求的URL路径，支持URL模板，正则表达式。这也是我们最常用的一种映射方 method(多个)，指定接收请求的方法，有GET,POST,PUT等，RequestMethod枚举类，如果没有按规则会抛405 Method Not Allowed params(多个) 指定请求的参数，例如parame=”user” ，那么请求中必须携带user参数的key，如果是parame=”user=123” ，那么参数就key必须是user,value必须是123,否则不能正常执行而且抛出400 错误的请求 headers(多个) 指定请求的头 consumes,允许的媒体类型Media Types ），如consumes ＝ ”application/ison ”， 对应于请求的HTTP 的Content-Type 。 @RequestParam作用：在SpringMVC中如果方法上被添加了·RequestMappring注解且方法有参数，那么必须传入与方法参数同名的的参数名，当使用了这个就可以实现传入产生非同名范围:参数内示例 123456789@RequestMapping("/list")/***传入的参数必须与user同名，而非必须和username同名*/public String test(@RequestParam("user") String username )&#123; return null;&#125; @RequestBady作用：获取请求体的内容，其格式是key:value的格式，其中get请求不适用（get请求没有请求体，它把的参数在url中）,该注解经常使用在异步的方式中范围：参数内注意:方法的名字不能与请求的任何参数同名，因为在Springmvc框架中，任何同名的都被看成同名封装.示例 12345678@RequestMapping("/list")/***注意，方法的名字不能与请求的任何参数同名，因为在Springmvc框架中，任何同名的都被看成同名封装，*/public String test(@RequestBady String bady)&#123; System.out.println(bady);//打印结果将会是key：value的形式 return null;&#125; @PathVariable(REST编程风格)作用: 带占位符的 URL 是 Spring3.0 新增的功能，该功能在SpringMVC 向 REST 目标挺进发展过程中具有里程碑的意义 通过 @PathVariable 可以将 URL 中占位符参数绑定到控制器处理方法的入参中：URL 中的 {xxx} 占位符可以通过@PathVariable(“xxx“) 绑定到操作方法的入参中。 主要是根据请求方法进行类的区别 范围：参数内 示例: 123456789/***通过使用PathVariable注解实现占位符上数据的获取*参数发送格式应该是请求的url例如xxx/list/12*/@RequestMapping("/list/&#123;sid&#125;")public String test(@PathVariable(name="sid") String id)&#123; System.out.println(id);//结果因该为12 return null;&#125; @ModelAttribute作用： ​ 来处理传入的参数少的问题 ​ 添加在方法上面时候，该方法会优先执行 ​ 添加在参数上面的时候，需要一个map集合来处理传入的参数少的问题 范围：方法上和参数上 示例： 假设有个user的javaBean对象 ​ 第一种，注解添加在方法上 123456789@RequestMapping("/list/modelAttribute")public String test(User user)&#123; System.out.println(user); return null;&#125;@ModelAttributepublic User modelAttribute(User user)&#123;//返回值必须三user类型才能保证接下来的方法接收到参数,参数时user类本方法才能获取到传入的参数 System.out.println("先执行,同时可以做一些其他操作，比如补全user对象不全的信息");&#125; 第二种,注解添加在参数内 123456789@RequestMapping("/list/modelAttribute")public String test(@ModelAttribute("abc") User user)&#123;//获取abc的对象存入user System.out.println(user); return null;&#125;public void modelAttribute(User user,Map&lt;String,User&gt; map)&#123;//返回值就不是必须的，但是参数必须有个map，,map&lt;String,User&gt; System.out.println("先执行,同时可以做一些其他操作，比如补全user对象不全的信息"); map.put("abc",user);//进行一些操作&#125; SessionAttributes作用:​ 向Session对象存入值，于在多个请求之间传递参数，类似于Session的Attribute，但不完全一样，一般来说@SessionAttributes设置的参数只用于暂时的传递，而不是长期的保存，长期保存的数据还是要放到Session中。（向Requests域存入对象需要使用Model接口的实现类） 范围：类spring 请求参数绑定绑定简述​ 在SpringMVC中，被添加@RequestMapping的方法的参数就是请求的参数 简要介绍首先javabean类对象 1234567891011121314151617181920212223242526272829package com.qs304;import java.util.List;import java.util.Map;public class Beans &#123; private Integer account; private String password; private Person person; private Map&lt;String,String&gt; map; private List&lt;String&gt; list;&#125;class Person&#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public String toString() &#123; return "Person&#123;" + "name='" + name + '\'' + '&#125;'; &#125;&#125; 参数绑定接收方法 123456789@Controller@RequestMapping("parme")public class HelloController &#123; @RequestMapping(value = "/hello",method = RequestMethod.POST) public String helloSpringMVC(Beans beans)&#123;//返回值表示要跳转的jsp页面的名字 System.out.println(beans); return "success"; &#125;&#125; jsp页面的提交 12345678&lt;form action="parme/hello" method="post"&gt; account&lt;input type="text" name="account"&gt;&lt;br/&gt; password&lt;input type="text" name="password"&gt;&lt;br/&gt; pseron.name&lt;input type="text" name="person.name"&gt;&lt;br/&gt; mapkey&lt;input type="text" name="map[key]"&gt;&lt;br/&gt; list&lt;input type="text" name="list[0]"&gt;&lt;br/&gt; &lt;input type="submit" value="提交"&gt;&lt;/form&gt; SpringMVC获取Servlet原生API在方法的上面的参数添加requests或者response的全限定类名即可 Spring MVC 自定义类型转换介绍​ 在SpringMVC框架中，视图层传递过来的参数都是String类型，但是在参数绑定的时候Spring框架会自动帮我们进行类型转换，但是当遇到无法转换的类型时，就需要我们自定义类型转换器 步骤：1.定义一个类，实现Converter接口，该接口有两个泛型，key表示接受类型，value表示转换后的类型 12345678public interface Converter&lt;S, T&gt; &#123;//S:表示接受的类型，T：表示目标类型 /** * 实现类型转换的方法 */ @Nullable T convert(S source); &#125; 1234567891011121314151617181920/** * 自定义类型转换器 */ public class StringToDateConverter implements Converter&lt;String, Date&gt; &#123; /* 用于把 String 类型转成日期类型 */ public Date convert(String source) &#123; DateFormat format = null; try &#123; if(StringUtils.isEmpty(source)) &#123; throw new NullPointerException("请输入要转换的日期"); &#125; format = new SimpleDateFormat("yyyy-MM-dd"); Date date = format.parse(source); return date; &#125; catch (Exception e) &#123; throw new RuntimeException("输入日期有误"); &#125; &#125; &#125; 2.在配置文件中，注册该组件并使他生效 1234567891011&lt;!-- 配置类型转换器工厂 --&gt; &lt;bean id="converterService" class="org.springframework.context.support.ConversionServiceFactoryBean"&gt; &lt;!-- 给工厂注入一个新的类型转换器 --&gt; &lt;property name="converters"&gt; &lt;array&gt; &lt;!-- 配置自定义类型转换器 --&gt; &lt;bean class="com.study.web.converter.StringToDateConverter"&gt;&lt;/bean&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; 123&lt;!-- 引用自定义类型转换器 --&gt; &lt;mvc:annotation-driven conversion-service="converterService"&gt;&lt;/mvc:annotation-driven&gt; SpringMVC五大组件DispatcherServlet:前端控制器​ 用户请求到达前端控制器，是整个流程控制的中心，当使用了静态文件，如js文件css文件，如果请求不到，要注意放弃前端控制器的请求拦截 HandlerMapping:处理器映射器HandlerMapping负责根据用户请求找到Handler即处理器，springmvc提供了不同的映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。 ViewResolver:视图解析器ViewResolver负责将处理结果生成View视图，ViewResolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。 Handler:处理器Handler是继DispatcherServlet前端控制器的后端控制器，在DispatcherServlet的控制下Handler对具体的用户请求进行处理。由于Handler涉及到具体的用户业务请求，所以一般情况需要程序员根据业务需求开发Handler。 View:视图SpringMVC框架提供了很多的View视图类型的支持，包括：jstlView、freemarkerView、pdfView等。我们最常用的视图就是jsp。一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由程序员根据业务需求开发具体的页面。 SpringMVC 框架快速搭建演示首先使用maven创建web项目 然后导入坐标 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;qs.304&lt;/groupId&gt; &lt;artifactId&gt;SpringMVCDemo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;name&gt;SpringMVCDemo Maven Webapp&lt;/name&gt; &lt;!-- FIXME change it to the project's website --&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;spring.version&gt;5.0.2.RELEASE&lt;/spring.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;SpringMVCDemo&lt;/finalName&gt; &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/plugin&gt; &lt;!-- see http://maven.apache.org/ref/current/maven-core/default-bindings.html#Plugin_bindings_for_war_packaging --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt; 然后在web.xml配置前端控制器并且设置为第一次加载的时候加载spring容器 1234567891011121314151617181920212223&lt;!DOCTYPE web-app PUBLIC "-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN" "http://java.sun.com/dtd/web-app_2_3.dtd" &gt;&lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;!--配置spring前端控制器--&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!--加载spring容器--&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!--设置启动项目就加载spring容器--&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 之后创建springmvc.xml文件配置视图解析器，并且指定视图解析器扫描的包和文件后缀 123456789101112131415161718192021&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:context="http://www.springframework.org/schema/context" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;context:component-scan base-package="com.qs304"/&gt; &lt;!--配置视图解析器--&gt; &lt;bean id="internalResourceViewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;!--配置参数--&gt; &lt;property name="prefix" value="/WEB-INF/pages/"&gt;&lt;/property&gt; &lt;property name="suffix" value=".jsp"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--开启springmvc注解支持--&gt; &lt;mvc:annotation-driven/&gt;&lt;/beans&gt; 之后配置控制器controller 12345678910111213package com.qs304.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;@Controllerpublic class HelloController &#123; @RequestMapping("/hello") public String helloSpringMVC()&#123;//返回值表示要跳转的jsp页面的名字 System.out.println("哈哈哈"); return "success"; &#125;&#125; 这是目录结构 springmvc框架运行流程 ModelAndVIew简介​ ModelAndView从这个名字我们不难看出，他的作用就是模型与视图之间进行交互。 而model,只能向request域进行存对象，所有就出现了，使用ModelAndView类用来存储处理完后的结果数据，以及显示该数据的视图。 用法 12345678public class testModelAndView&#123; @RequestMapping("/testModelAndView") public void testModelAndView()&#123; ModelAndView mv=new ModelAndView(); mv.addObject("asd","asd");//往request域存取数据 mv.setViewName("123");//使用前端控制器跳转到123页面 &#125;&#125; 使用关键字进行转发或者重定向在返回值前写forward:路径这样会进行转发功能，使用redirect进行重定向注意，这种方法使用较少，而且使用后不能使用前端控制器]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>Spring</tag>
        <tag>框架</tag>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA动态代理]]></title>
    <url>%2F2019%2F02%2F27%2FJAVA%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[JAVA动态代理前言：​ 最近在学习spring框架，但是在学习（切面编程）aop的时候老师讲到了一个动态代理，这个东西听着很晕乎，听说在学习javaweb的时候讲filter过滤器也是这个原理，╮(╯▽╰)╭无奈当时没有注意底层也就没有学会，现在正好有机会就把这个动态代理好好学习一下吧。 1.什么是代理代理模式的定义：​ 代理模式给某一个对象提供一个代理对象，并有代理对象控制原对象的引用（╮(╯▽╰)╭，定义都是这么的晦涩难懂） 例子：​ 假如你现在想购买一个笔记本，于是乎当然只关心价格和性能售后啊，而且购买渠道要方便啊，当然厂家生产笔记本后不可能把货物分发到全球各地因为地球太大了，但是消费者想要购买的方便啊，对于消费者来说他要购买方便也就是买电脑的地方离自己比较近，并不关心厂家怎么把电脑弄过来，而且对于厂家来说他只要把电脑做出来做好售后就行了，为什么费这么大劲在各地建立销售网点呢，好钢当然是用在刀刃上面啦。于是乎电脑城这个奸商聚集地就出来了（带着有色眼镜看待的这个问题，不要喷我），奸商正好把厂家和消费者连接起来。而且消费者想维修之类的必须经过代理商也就是电脑城的奸商才能和厂家联系，于是乎这个代理商就起到了代理的作用。 2. 要想知道动态代理首先要知道代理模式的应用场景### 需求和分析：​ 假设有个需求，需要你不修改原有代码的基础上对一个类（Person）的功能进行增强，这下怎么办呢？ ​ 其实可以这样，首先写一个用来增强那个Person那个类的类并且继承Person类实现的那个接口，就叫他Proxy类吧，然后在Proxy类创建的时候可以吧Person这个类当做参数传进去，然后在Proxy类中调用同名的方法（哒哒哒，这就完成啦），其实这个过程就是静态代理模式。也就是说代理对象 = 增强代码 + 目标对象（原对象） 大概就是这样样子，画图比较丑，而且不会用xmind（╮(╯▽╰)╭） 静态代理模式的缺点：​ 这样有什么缺点呢，假设我们有很多个类需要被增强，那么我们要给每一个类都写一个对应的代理类，那么这样也忒麻烦了，代理类你这么麻烦搞的大家都不想和你玩了。 3.动态代理前言​ 动态代理之前要说其实还有一个class类，这个东西比较复杂，（先埋个坑，以后在填坑），class这个类可以获取任意类的构造方法，属性等等等之类的，也就是说我们可以用来复制一个类，代理类和目标类理应实现同一组接口。之所以实现相同接口，是为了尽可能保证代理对象的内部结构和目标对象一致，这样我们对代理对象的操作最终都可以转移到目标对象身上，代理对象只需专注于增强代码的编写。也就是说接口拥有代理类对象和目标对象共同的类信息，但是类信息不能创建对象。于是乎jdk提供了java.lang.reflect.InvocationHandler接口和java.lan.reflect.Proxy类。 Proxy类​ Proxy有个静态方法：getProxyClass(ClassLoader,interfaces),只要你给他传入类加载器和一组接口，他就会给你返回代理Class对象。 ​ 通俗点说就是，你给他传入接口的Class中，复制类结构到新的Class对象中，但新的Class对象带有构造器，是可以创建对象的。 所以Proxy.getProxyClass()这个方法的本质就是用Class造Class 动态代理的作用：​ Proxy类的代码量被固定下来，不会因为业务的逐渐庞大而庞大； ​ 可以实现AOP编程，实际上静态代理也可以实现，总的来说，AOP可以算作是代理模式的一个典型应用； ​ 解耦，通过参数就可以判断真实类，不需要事先实例化，更加灵活多变。 ### 代码演示电脑生产厂家类（被代理对象） 12 电脑城坑人类（代理对象） 12 销售接口: 12 Main类 12]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vue入门]]></title>
    <url>%2F2019%2F02%2F26%2Fvue%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[vue入门12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html lang="zh"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Hello Vue&lt;/title&gt; &lt;!-- 开发环境版本，包含了有帮助的命令行警告 --&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt;leftleft msg rightright&lt;/div&gt;&lt;/body&gt;&lt;script&gt; var vue=new Vue(left el:"#app",//挂载点 data:left msg :"哈哈哈1" right right)&lt;/script&gt;&lt;/html&gt; 挂载点（el:）作用： 挂载点的作用就是设置vue的作用范围，如果leftleftrightright取值在选择器外部则原样显示，当然挂载点可以是id选择器，类选择器，还有class选择器，（开发中推荐使用id选择器） 特殊情况选择器不能作用到body标签和html标签以及单标签上 演示使用类选择器 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html lang="zh"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Hello Vue&lt;/title&gt; &lt;!-- 开发环境版本，包含了有帮助的命令行警告 --&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app" class="class"&gt;leftleft msg rightright&lt;/div&gt;&lt;/body&gt;&lt;script&gt; var vue=new Vue(left //el:"#app",id选择器 //el:"div",标签选择器 el:".class", data:left msg :"哈哈哈1" right right)&lt;/script&gt;&lt;/html&gt; 数据对象（data:）作用 vue中用到的数据定义在data中 data中可以写复杂类型的数据 12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html lang="zh"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Hello Vue&lt;/title&gt; &lt;!-- 开发环境版本，包含了有帮助的命令行警告 --&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;div&gt;leftleftmsgrightright&lt;/div&gt; &lt;div&gt;leftleftarr[0]rightright&lt;/div&gt; &lt;div&gt;leftleftmap.namerightright&lt;/div&gt; &lt;div&gt;leftleftisTruerightright&lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;script&gt; var vue=new Vue(left el:"div", data:left msg :"哈哈哈1",//字符串类型 arr:["1","2","3","4"],//数组 map:left"name":"张珊"right,//map isTrue:true//布尔类型 right right)&lt;/script&gt;&lt;/html&gt; 结果为 1234哈哈哈11张珊true v-text作用v-text指令的作用是设置标签的内容（textContext） 默认写法会替换全部内容，使用差值表达式leftleftrightright可以替换指定内容 1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html lang="zh"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Hello Vue&lt;/title&gt; &lt;!-- 开发环境版本，包含了有帮助的命令行警告 --&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;div v-text="msg"&gt;&lt;/div&gt; &lt;div&gt;leftleftmsgrightright差值表达式&lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;script&gt; var vue=new Vue(left el:"div", data:left msg :"哈哈哈1",//字符串类型 right right)&lt;/script&gt;&lt;/html&gt; 结果 12哈哈哈1哈哈哈1差值表达式 v-html和v-text区别:v-text会把元素内容替换为字符串，如果有特殊字符也会当做字符串， v-html会吧里面的标签解析出来 作用 v-html指令的作用是:设置元素的innerHTML 内容中有html结果会被解析为标签 v-text指令无论内容是什么，都会解析为文本 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang="zh"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Hello Vue&lt;/title&gt; &lt;!-- 开发环境版本，包含了有帮助的命令行警告 --&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;div v-text="msg"&gt;&lt;/div&gt; &lt;div v-html="msg"&gt;&lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;script&gt; var vue=new Vue(left el:"div", data:left msg :"&lt;a&gt;哈哈哈&lt;/a&gt;",//字符串类型 right right)&lt;/script&gt;&lt;/html&gt; 结果： 12&lt;a&gt;哈哈哈&lt;/a&gt;哈哈哈 v-on作用: v-on指令的作用是：为元素绑定事件 指令可以简写为@ 绑定的方法必须在methods属性中 事件名不需要写on 1234567891011121314151617181920212223242526272829303132&lt;!DOCTYPE html&gt;&lt;html lang="zh"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Hello Vue&lt;/title&gt; &lt;!-- 开发环境版本，包含了有帮助的命令行警告 --&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;button type="button" v-on:click="click(1)"&gt;v-on&lt;/button&gt; &lt;button type="button" @click="click(1)"&gt;@&lt;/button&gt; &lt;div&gt;leftleftmsgrightright&lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;script&gt; var vue=new Vue(left el:"div", data:left msg :"&lt;a&gt;哈哈哈&lt;/a&gt;",//字符串类型 right, methods:left click:function(num)left this.msg="被点击"+num; right right right)&lt;/script&gt;&lt;/html&gt; 结果 12v-on @被点击1 v-show作用 v-show指令的作用是：根据真假切换元素的显示状态 原理是修改元素的display，实现显示和隐藏 指令后面的内容都会被解析为布尔值 12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html lang="zh"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Hello Vue&lt;/title&gt; &lt;!-- 开发环境版本，包含了有帮助的命令行警告 --&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;div v-show="isTrue"&gt;leftleftmsgrightright&lt;/div&gt; &lt;div v-show="isFalse"&gt;leftleftmsgrightright&lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;script&gt; var vue=new Vue(left el:"div", data:left msg :"&lt;a&gt;哈哈哈&lt;/a&gt;",//字符串类型 isTrue:true, isFalse:false right right)&lt;/script&gt;&lt;/html&gt; 结果 1&lt;a&gt;哈哈哈&lt;/a&gt; v-if作用 v-if指令的作用是：根据表达式的真假切换元素的显示 本质是操作和移除dom元素 v-bind作用 属性绑定（因为标签内部不能使用差值表达式，所以要通过属性绑定的方式实现这个功能） 1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html lang="zh"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Hello Vue&lt;/title&gt; &lt;!-- 开发环境版本，包含了有帮助的命令行警告 --&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;a v-bind:href="msg"&gt;去b站&lt;/a&gt; &lt;a :href="msg"&gt;去b站&lt;/a&gt; &lt;/div&gt; &lt;/body&gt;&lt;script&gt; var vue=new Vue(left el:"div", data:left msg :"https://www.bilibili.com/",//字符串类型 right right)&lt;/script&gt;&lt;/html&gt; v-for作用 v-for根据数据生成列表结构 数组经常和v-for使用 语法是(item,index) in 数据 item和index可以结合其他指令一起使用 1234567891011121314151617181920212223242526272829303132&lt;!DOCTYPE html&gt;&lt;html lang="zh"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Hello Vue&lt;/title&gt; &lt;!-- 开发环境版本，包含了有帮助的命令行警告 --&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;ul&gt; &lt;li v-for="item in arr"&gt;leftleftitemrightright&lt;/li&gt; &lt;br /&gt; &lt;li v-for="(item,index) in arr"&gt;leftleftindexrightright:leftleftitemrightright&lt;/li&gt; &lt;br /&gt; &lt;li v-for="(item,index) in arr"&gt;leftleftindex+1rightright:leftleftitemrightright&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/body&gt;&lt;script&gt; var vue=new Vue(left el:"div", data:left msg :"https://www.bilibili.com/",//字符串类型 arr:[1,2,3,4,5,6,7,8] right right)&lt;/script&gt;&lt;/html&gt; 结果 1234567891011121314151617181920212223242526123456780:11:22:33:44:55:66:77:81:12:23:34:45:56:67:78:8 v-model（双向数据绑定，仅限表单）作用（也就是表单改变数据也改变，数据改变表单同时改变） v-model指令的作用是便捷的设置和获取表单元素的值 绑定的数据会和表单元素值想关联 1234567891011121314151617181920212223242526272829303132&lt;!DOCTYPE html&gt;&lt;html lang="zh"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Hello Vue&lt;/title&gt; &lt;!-- 开发环境版本，包含了有帮助的命令行警告 --&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;input type="text" v-model="msg" :placeholder="msg"&gt; &lt;button type="button" v-on:click="click"&gt;v-on&lt;/button&gt; msg结果:&lt;div&gt;leftleftmsgrightright&lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;script&gt; var vue=new Vue(left el:"div", data:left msg :"哈哈哈",//字符串类型 right, methods:left click:function()left this.msg="被点击"; right right right)&lt;/script&gt;&lt;/html&gt; 结构 123被点击 v-on msg结果:被点击]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>前端</tag>
        <tag>习惯</tag>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven入门教程]]></title>
    <url>%2F2019%2F02%2F20%2Fmaven%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[maven教程简介​ Maven 翻译为”专家”、”内行”，是 Apache 下的一个纯 Java 开发的开源项目。基于项目对象模型（缩写：POM）概念，Maven利用一个中央信息片断能管理一个项目的构建、报告和文档等步骤。 Maven 是一个项目管理工具，可以对 Java 项目进行构建、依赖管理。 Maven 也可被用于构建和管理各种项目，例如 C#，Ruby，Scala 和其他语言编写的项目。Maven 曾是 Jakarta 项目的子项目，现为由 Apache 软件基金会主持的独立 Apache 项目。（这是我百度复制过来的，╮(╯▽╰)╭，算是毛病吧） 特性跨平台：是指跨OS平台，跨IDE平台 标准化：项目构建标准化，和项目结构标准化 maven目录结构 命令4. 编译源代码： 1mvn compile 5. 编译测试代码： 1mvn test-compile 6. 运行测试: 1mvn test 7. 产生site： 1mvn site 8. 打包： 1mvn package 9. 在本地Repository中安装jar： 12mvn install例：installing D:\xxx\xx.jar to D:\xx\xxxx 10. 清除产生的项目： 1mvn clean 11. 生成eclipse项目： 1mvn eclipse:eclipse 12. 生成idea项目： 1mvn idea:idea 13. 组合使用goal命令，如只打包不测试： 1mvn -Dtest package 14. 编译测试的内容： 1mvn test-compile 15. 只打jar包: 1mvn jar:jar 16. 只测试而不编译，也不测试编译： 12mvn test -skipping compile -skipping test-compile ( -skipping 的灵活运用，当然也可以用于其他组合命令) 17. 清除eclipse的一些系统设置: 1mvn eclipse:clean 18.查看当前项目已被解析的依赖： 1mvn dependency:list 19.上传到私服： 1mvn deploy 20. 强制检查更新，由于快照版本的更新策略(一天更新几次、隔段时间更新一次)存在，如果想强制更新就会用到此命令: 1mvn clean install-U 21. 源码打包： 123mvn source:jar或mvn source:jar-no-fork]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>习惯</tag>
        <tag>maven</tag>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码注意细节]]></title>
    <url>%2F2019%2F02%2F20%2F%E4%BB%A3%E7%A0%81%E6%B3%A8%E6%84%8F%E7%BB%86%E8%8A%82%2F</url>
    <content type="text"><![CDATA[代码注意细节1.设计细节springspring配置类中父子关系的配置类更好 mysqlmysql中要严格遵守三大范式才能设计比较好的数据库 mysql中使用外键约束要注意进行级联操作，否则必须先修改依赖表 2.编码细节]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>习惯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql事务详解]]></title>
    <url>%2F2019%2F02%2F04%2Fmysql%E4%BA%8B%E5%8A%A1%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[为什么需要事务转账是生活中常见的操作,比如从A账户转账100元到B账号。站在用户角度而言,这是一个逻辑上的单一操作,然而在数据库系统中,至少会分成两个步骤来完成: 1.将A账户的金额减少100元 2.将B账户的金额增加100元 在这个过程中可能会出现以下问题: 1.转账操作的第一步执行成功,A账户上的钱减少了100元,但是第二步执行失败或者未执行便发生系统崩溃,导致B账户并没有相应增加100元。 2.转账操作刚完成就发生系统崩溃,系统重启恢复时丢失了崩溃前的转账记录。 3.同时又另一个用户转账给B账户,由于同时对B账户进行操作,导致B账户金额出现异常。 所以为了解决上述问题，需要引入数据库事务相关概念。 事务的特性原子性（Atomicity）：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。一致性（Consistency）：事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束。隔离性（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行。持久性（Durability）：一个事务一旦提交，他对数据库的修改应该永久保存在数据库中。 事务的四大特性理解“A账户向B账号汇钱”的例子来说明如何通过数据库事务保证数据的准确性和完整性。熟悉关系型数据库事务的都知道从帐号A到帐号B需要6个操作： 1、从A账号中把余额读出来（500）。2、对A账号做减法操作（500-100）。3、把结果写回A账号中（400）。4、从B账号中把余额读出来（500）。5、对B账号做加法操作（500+100）。6、把结果写回B账号中（600）。 原子性：保证1-6所有过程要么都执行，要么都不执行。一旦在执行某一步骤的过程中发生问题，就需要执行回滚操作。 假如执行到第五步的时候，B账户突然不可用（比如被注销），那么之前的所有操作都应该回滚到执行事务之前的状态。 一致性在转账之前，A和B的账户中共有500+500=1000元钱。在转账之后，A和B的账户中共有400+600=1000元。也就是说，数据的状态在执行该事务操作之后从一个状态改变到了另外一个状态。同时一致性还能保证账户余额不会变成负数等。 隔离性在A向B转账的整个过程中，只要事务还没有提交（commit），查询A账户和B账户的时候，两个账户里面的钱的数量都不会有变化。如果在A给B转账的同时，有另外一个事务执行了C给B转账的操作，那么当两个事务都结束的时候，B账户里面的钱应该是A转给B的钱加上C转给B的钱再加上自己原有的钱。 持久性一旦转账成功（事务提交），两个账户的里面的钱就会真的发生变化（会把数据写入数据库做持久化保存）！ 事务隔离级别读未提交：read uncommitted 事物A和事物B，事物A未提交的数据，事物B可以读取到 这里读取到的数据叫做“脏数据” 这种隔离级别最低，这种级别一般是在理论上存在，数据库隔离级别一般都高于该级别 读已提交：read committed 事物A和事物B，事物A提交的数据，事物B才能读取到 这种隔离级别高于读未提交 换句话说，对方事物提交之后的数据，我当前事物才能读取到 这种级别可以避免“脏数据” 这种隔离级别会导致“不可重复读取” Oracle默认隔离级别 可重复读：repeatable read 事务A和事务B，事务A提交之后的数据，事务B读取不到 事务B是可重复读取数据 这种隔离级别高于读已提交 换句话说，对方提交之后的数据，我还是读取不到 这种隔离级别可以避免“不可重复读取”，达到可重复读取 比如1点和2点读到数据是同一个 MySQL默认级别 虽然可以达到可重复读取，但是会导致“幻像读” 串行化：serializable 事务A和事务B，事务A在操作数据库时，事务B只能排队等待 这种隔离级别很少使用，吞吐量太低，用户体验差 这种级别可以避免“幻像读”，每一次读取的都是数据库中真实存在数据，事务A与事务B串行，而不并发 事务并发带来的问题脏读：一个事务读取了另一个事务未提交的数据。事务A：张三妻子给张三转账 100元。事务B：张三查询余额。事务A转账后（还未提交），事务B查询多了100元。事务A由于某种问题，比如超时，进行回滚。事务B查询到的数据是假 数据。脏读本质上是读写操作的冲突，解决办法是写完之后再读。 不可重复读：一个事务两次读取同一个数据，两次读取的数据不一致。事务 A：张 三妻子给张三转账100元。事务B：张三两次查询余额。事务B第一次查询余额，事务A还没有转账，第二次查询余额，事务A已经转账了，导致一个事务中，两 次读取同一个数据，读取的数据不一致。不可重复读本质上是读写操作的冲突，解决办法是读完再写。 幻读：一个事务两次读取一个范围的 记录，两次读取的记录数不一致。事务A： 张三妻子两次查询张三有几张银行卡。事务B：张三新办一张银行卡。事务A第一次查询银行卡数的时候，张三还没有新办银行卡，第二次查询银行卡数的时候，张 三已经新办了一张银行卡，导致两次读取的银行卡数不一样。幻象读本质上是读写操作的冲突，解决办法是读完再写。 隔离级别 脏读 不可重复读 幻读 更新丢失 READ UNCOMMITED 允许 允许 允许 允许 READ COMMITTED 不允许 允许 允许 允许 REPEATABLE READ 不允许 不允许 允许 允许 SERIALIZABLE 不允许 不允许 不允许 不允许 mysql事务带来的问题演示12345678910111213141516//查看当前事物级别：SELECT @@tx_isolation;//设置mysql的隔离级别：set session transaction isolation level 设置事务隔离级别//设置read uncommitted级别：set session transaction isolation level read uncommitted;//设置read committed级别：set session transaction isolation level read committed;//设置repeatable read级别：set session transaction isolation level repeatable read;//设置serializable级别：set session transaction isolation level serializable; 每次更改事务的隔离级别只针对当前会话有效。 假设有张表 123456CREATE TABLE `user` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) DEFAULT NULL, `money` double(255,0) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8mb4; 脏读首先要把两个窗口的事务隔离级别都更改为读为提交（read uncommitted）级别，这样才能发生脏读问题 窗口A 窗口B 然后窗口A开启一个事务，并且更改表中的某个字段，但是不要提交该事务， 窗口B开启了一个事务，并且把id为3的小红的钱变成了999，但是没有提交事务。 此时窗口A查询到的结果就是窗口A还没有提交的事务的结果。 之后窗口B回滚事务，这个时候小红的钱又回到了之前的状态，这就发生了脏读，因为A读到了假数据，所以就称为脏读； 不可重复读首先要把两个窗口的事务隔离级别都更改为读为提交（read uncommitted）级别，这样才能发生脏读问题 A开启一个事务查询余额，但是不提交事务，然后B直接修改余额，之后A再次查询余额 开启了一个事务并且第一次查询余额。 B修改了一条数据 A在同一个事务中读取到的前后顺序不一样，这就是因为发送了不可重复读的现象。 可以发现，两次查询的结果不一致，这种操作是没错的，但是，如果银行统计报表时，这种情况是不符合需求的，演示完成，将b账户中的事务提交 我们，不希望在一个事务中，看到的查询结果不一致，这就是不可重复读 幻读A窗口开启一个事务，统计数据库中记录的条数 然后B窗口插入一条数据 之后A窗口再次查询 这就出现了幻读现象，好像出现了幻觉一样 一个事务两次读取一个范围的 记录，两次读取的记录数不一致。]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpEL表达式详解]]></title>
    <url>%2F2019%2F01%2F18%2FSpEL%E8%A1%A8%E8%BE%BE%E5%BC%8F%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[前言SpEL（Spring Expression Language），即Spring表达式语言，是比JSP的EL更强大的一种表达式语言。为什么要总结SpEL，因为它可以在运行时查询和操作数据，尤其是数组列表型数据，因此可以缩减代码量，优化代码结构。 位置SpEL有三种用法，一种是在注解@Value中；一种是XML配置；最后一种是在代码块中使用Expression。 一. 用法 SpEL有三种用法，一种是在注解@Value中；一种是XML配置；最后一种是在代码块中使用Expression。 关于无法使用@Value来获取问题解决123456 @Value("#&#123;123&#125;") private int age;@Value("#&#123;123&#125;") private static int age;//不允许 @Value("#&#123;123&#125;") private final int age;//不允许 被注入变量不能私有，也不能被final修饰 是不是使用了ClassPathXmlApplicationContext这个容器类，忘记了开启包扫描 1&lt;context:component-scan base-package="config"&gt;&lt;/context:component-scan&gt; @Value1234//@Value能修饰成员变量和方法形参//#&#123;&#125;内就是表达式的内容@Value("#&#123;表达式&#125;")public String arg; 关于无法使用@Value来获取问题解决123456 @Value("#&#123;123&#125;") private int age;@Value("#&#123;123&#125;") private static int age;//不允许 @Value("#&#123;123&#125;") private final int age;//不允许 被注入变量不能私有，也不能被final修饰 是不是使用了ClassPathXmlApplicationContext这个容器类，忘记了开启包扫描 1&lt;context:component-scan base-package="config"&gt;&lt;/context:component-scan&gt; 不能使用final和static修饰的原因 spring的注入是一般是发生在调用构造方法后进行注入，除非使用的是构造方法注入。其实也就是set方法注入，也就是说@Value的注入也是发生在构造方法调用后进行注入的。 也就是说spring的注入是针对对象进行的注入，静态方法不属于对象是属于类的 为什么private也可以注入，就算没有set方法？我们在使用反射技术的时候可以关闭语言访问检查来强制注入私有属性的，所以@Autowired和@Value是属于这种注入。 但是使用xml文件property是一栏set方法注入的。 @Value&lt; bean &gt;配置1234&lt;bean id="xxx" class="com.java.XXXXX.xx"&gt; &lt;!-- 同@Value,#&#123;&#125;内是表达式的值，可放在property或constructor-arg内 --&gt; &lt;property name="arg" value="#&#123;表达式&#125;"&gt;&lt;/bean&gt; Expression123456789101112131415161718192021222324252627282930import org.springframework.expression.Expression;import org.springframework.expression.ExpressionParser;import org.springframework.expression.spel.standard.SpelExpressionParser;import org.springframework.expression.spel.support.StandardEvaluationContext; public class SpELTest &#123; public static void main(String[] args) &#123; //创建ExpressionParser解析表达式 ExpressionParser parser = new SpelExpressionParser(); //表达式放置 Expression exp = parser.parseExpression("表达式"); //执行表达式，默认容器是spring本身的容器：ApplicationContext Object value = exp.getValue(); /**如果使用其他的容器，则用下面的方法*/ //创建一个虚拟的容器EvaluationContext StandardEvaluationContext ctx = new StandardEvaluationContext(); //向容器内添加bean BeanA beanA = new BeanA(); ctx.setVariable("bean_id", beanA); //setRootObject并非必须；一个EvaluationContext只能有一个RootObject，引用它的属性时，可以不加前缀 ctx.setRootObject(XXX); //getValue有参数ctx，从新的容器中根据SpEL表达式获取所需的值 Object value = exp.getValue(ctx); &#125;&#125; 字面量语法12345678910&lt;!-- 整数 --&gt;&lt;property name="intger" value="#&#123;5&#125;" /&gt;&lt;!-- 小数 --&gt;&lt;property name="double" value="#&#123;13.2&#125;" /&gt;&lt;!-- 科学计数法 --&gt;&lt;property name="capacity" value="#&#123;1e4&#125;" /&gt;&lt;!-- 字符串 #&#123;"字符串"&#125; 或 #&#123;'字符串'&#125; --&gt;&lt;property name="str" value="#&#123;'我是字符串'&#125;" /&gt;&lt;!-- Boolean --&gt;&lt;property name="bool" value="#&#123;false&#125;" /&gt; 字面量赋值必须要和对应的属性类型兼容，否则会报异常。 一般情况下我们不会使用 SpEL字面量赋值，因为我们可以直接赋值。 引用Bean、属性和方法（必须是public修饰的）12345&lt;property name="car" value="#&#123;car&#125;" /&gt;&lt;!-- 引用其他对象的属性 --&gt;&lt;property name="carName" value="#&#123;car.name&#125;" /&gt;&lt;!-- 引用其他对象的方法 --&gt;&lt;property name="carPrint" value="#&#123;car.print()&#125;" /&gt; 运算符算术运算符：+,-,*,/,%,^123456789101112&lt;!-- 3 --&gt;&lt;property name="num" value="#&#123;2+1&#125;" /&gt;&lt;!-- 1 --&gt;&lt;property name="num" value="#&#123;2-1&#125;" /&gt;&lt;!-- 4 --&gt;&lt;property name="num" value="#&#123;2*2&#125;" /&gt;&lt;!-- 3 --&gt;&lt;property name="num" value="#&#123;9/3&#125;" /&gt;&lt;!-- 1 --&gt;&lt;property name="num" value="#&#123;10%3&#125;" /&gt;&lt;!-- 1000 --&gt;&lt;property name="num" value="#&#123;10^3&#125;" /&gt; 字符串连接符：+12&lt;!-- 10年3个月 --&gt;&lt;property name="numStr" value="#&#123;10+'年'+3+'个月'&#125;" /&gt; 比较运算符：&lt;(&lt;),&gt;(&gt;),==,&lt;=,&gt;=,lt,gt,eq,le,ge1234567891011121314151617181920&lt;!-- false --&gt;&lt;property name="numBool" value="#&#123;10&amp;lt;0&#125;" /&gt;&lt;!-- false --&gt;&lt;property name="numBool" value="#&#123;10 lt 0&#125;" /&gt;&lt;!-- true --&gt;&lt;property name="numBool" value="#&#123;10&amp;gt;0&#125;" /&gt;&lt;!-- true --&gt;&lt;property name="numBool" value="#&#123;10 gt 0&#125;" /&gt;&lt;!-- true --&gt;&lt;property name="numBool" value="#&#123;10==10&#125;" /&gt;&lt;!-- true --&gt;&lt;property name="numBool" value="#&#123;10 eq 10&#125;" /&gt;&lt;!-- false --&gt;&lt;property name="numBool" value="#&#123;10&amp;lt;=0&#125;" /&gt;&lt;!-- false --&gt;&lt;property name="numBool" value="#&#123;10 le 0&#125;" /&gt;&lt;!-- true --&gt;&lt;property name="numBool" value="#&#123;10&amp;gt;=0&#125;" /&gt;&lt;!-- true --&gt;&lt;property name="numBool" value="#&#123;10 ge 0&#125;" /&gt; 逻辑运算符：and,or,not,&amp;&amp;(&amp;&amp;),||,!123456789101112&lt;!-- false --&gt;&lt;property name="numBool" value="#&#123;true and false&#125;" /&gt;&lt;!-- false --&gt;&lt;property name="numBool" value="#&#123;true&amp;amp;&amp;amp;false&#125;" /&gt;&lt;!-- true --&gt;&lt;property name="numBool" value="#&#123;true or false&#125;" /&gt;&lt;!-- true --&gt;&lt;property name="numBool" value="#&#123;true||false&#125;" /&gt;&lt;!-- false --&gt;&lt;property name="numBool" value="#&#123;not true&#125;" /&gt;&lt;!-- false --&gt;&lt;property name="numBool" value="#&#123;!true&#125;" /&gt; 条件运算符：?true:false12&lt;!-- 真 --&gt;&lt;property name="numStr" value="#&#123;(10&gt;3)?'真':'假'&#125;" /&gt; 正则表达式：matches12&lt;!-- true --&gt;&lt;property name="numBool" value="#&#123;user.email matches '[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+.[a-zA-Z]&#123;2,4&#125;'&#125;" /&gt; 调用静态方法或静态属性 通过 T() 调用一个类的静态方法，它将返回一个 Class Object，然后再调用相应的方法或属性： 12&lt;!-- 3.141592653589793 --&gt;&lt;property name="PI" value="#&#123;T(java.lang.Math).PI&#125;" /&gt; 获取容器内的变量，可以使用“#bean_id”来获取。有两个特殊的变量，可以直接使用。this 使用当前正在计算的上下文root 引用容器的root对象12345String result2 = parser.parseExpression("#root").getValue(ctx, String.class); String s = new String("abcdef"); ctx.setVariable("abc",s); //取id为abc的bean，然后调用其中的substring方法 parser.parseExpression("#abc.substring(0,1)").getValue(ctx, String.class); 方法调用 与Java代码没有什么区别，可见上面的例子 可以自定义方法，如下： 123Method parseInt = Integer.class.getDeclaredMethod("parseInt", String.class); ctx.registerFunction("parseInt", parseInt); ctx.setVariable("parseInt2", parseInt); “registerFunction”和“setVariable”都可以注册自定义函数，但是两个方法的含义不一样，推荐使用“registerFunction”方法注册自定义函数。 Elvis运算符 是三目运算符的特殊写法，可以避免null报错的情况 123name != null? name : "other"//简写为：name?:"other" 安全保证 为了避免操作对象本身可能为null，取属性时报错，定义语法 语法： “对象?.变量|方法” 1list?.length 直接使用java代码new/instance of 此方法只能是java.lang 下的类才可以省略包名 1Expression exp = parser.parseExpression("new Spring('Hello World')"); 集合定义 使用“{表达式，……}”定义List，如“{1,2,3}” 对于字面量表达式列表，SpEL会使用java.util.Collections.unmodifiableList 方法将列表设置为不可修改。 对于列表中只要有一个不是字面量表达式，将只返回原始List， //不会进行不可修改处理，也就是可以修改 12List&lt;list&gt; result3 = parser.parseExpression(expression3).getValue(List.class);result3.get(0).set(0, 1); List result1 = parser.parseExpression(“{1,2,3}”).getValue(List.class); 集合访问SpEL目前支持所有集合类型和字典类型的元素访问 语法：“集合[索引]”、“map[key]” 12345678910111213141516171819EvaluationContext context = new StandardEvaluationContext();//即list.get(0) int result1 = parser.parseExpression("&#123;1,2,3&#125;[0]").getValue(int.class);//list获取某一项 Collection&lt;Integer&gt; collection = new HashSet&lt;Integer&gt;(); collection.add(1); collection.add(2);context.setVariable("collection", collection); int result2 = parser.parseExpression("#collection[1]").getValue(context, int.class);//map获取 Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;(); map.put("a", 1);context.setVariable("map", map); int result3 = parser.parseExpression("#map['a']").getValue(context, int.class); 集合修改可以使用赋值表达式或Expression接口的setValue方法修改； 12345//赋值语句 int result = parser.parseExpression("#array[1] = 3").getValue(context, int.class);//serValue方法 parser.parseExpression("#array[2]").setValue(context, 4); 集合选择 通过一定的规则对及格进行筛选，构造出另一个集合 语法：“(list|map).?[选择表达式]” 选择表达式结果必须是boolean类型，如果true则选择的元素将添加到新集合中，false将不添加到新集合中 1parser.parseExpression("#collection.?[#this&gt;2]").getValue(context, Collection.class); 上面的例子从数字的collection集合中选出数字大于2的值，重新组装成了一个新的集合 上面的例子从数字的collection集合中选出数字大于2的值，重新组装成了一个新的集合 根据集合中的元素中通过选择来构造另一个集合，该集合和原集合具有相同数量的元素 语法：“SpEL使用“（list|map）.![投影表达式]” 123456789101112public class Book &#123; public String name; //书名 public String author; //作者 public String publisher; //出版社 public double price; //售价 public boolean favorite; //是否喜欢 &#125; public class BookList &#123; @Autowired protected ArrayList&lt;Book&gt; list = new ArrayList&lt;Book&gt;() ; protected int num = 0;&#125; 将BookList的实例映射为bean：readList，在另一个bean中注入时，进行投影 123//从readList的list下筛选出favorite为true的子集合，再将他们的name字段投为新的list@Value("#&#123;list.?[favorite eq true].![name]&#125;")private ArrayList&lt;String&gt; favoriteBookName; Bean引用：SpEL支持使用“@”符号来引用Bean，在引用Bean时需要使用BeanResolver接口实现来查找Bean，Spring提供BeanFactoryResolver实现； 123456789101112131415161718192021222324@Testpublicvoid testBeanExpression() &#123; ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext(); ctx.refresh(); ExpressionParser parser = new SpelExpressionParser(); StandardEvaluationContext context = new StandardEvaluationContext(); context.setBeanResolver(new BeanFactoryResolver(ctx)); Properties result1 = parser.parseExpression("@systemProperties").getValue(context, Properties.class); Assert.assertEquals(System.getProperties(), result1);&#125;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>Spring</tag>
        <tag>框架</tag>
        <tag>代理模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring框架]]></title>
    <url>%2F2019%2F01%2F15%2FSpring%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[Spring框架1.Spring简介: 为从大小与开销两方面而言Spring都是轻量的 通过控制反转（IoC）的技术达到松耦合的目的 提供了面向切面编程的丰富支持，允许通过分离应用的业务逻辑与系统级服务进行内聚性的开发 包含并管理应用对象的配置和生命周期，所以spring是一种容器 将简单的组件配置、组合成为复杂的应用，这个意义上是框架 2.spring的核心 控制反转（IoC）和面向切面编程（AOP） 1.什么事控制反转呢？​ 控制反转loC主要是用来解决耦合的问题的，一个类直接依赖另一个类，这样耦合性是很高的，但是我们可以通过创建一个工厂模式，对象创建另一个对象的时候通过查找map容器，如果map容器不存在，就在本地配置文件中查找类的类名来获取类。这样就把类与类之间的关系转化为了类与工厂与类的关系，从而解决了耦合性的问题。 控制反转loC演示首先创建两个类 Main类是主方法类用来调用Demo方法类里面的toString方法，通过loC控制反转调用 在resources包下面创建一个xml配置文件 12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- id表示调用这个类的时候写的类名，class表示类的包名加类名,其中Java目录下的表示根目录 使用注解@Component 类型首字母要小写 --&gt; &lt;bean id="Demo" class="Demo"&gt; &lt;!-- collaborators and configuration for this bean go here --&gt; &lt;/bean&gt;&lt;/beans&gt; 12345//ApplicationContext接口的实现对象ClassPathXmlApplicationContext来获取容器ApplicationContext ac= new ClassPathXmlApplicationContext("bean.xml");//通过反射机制获取Bean对象Demo de=ac.getBean("Demo",Demo.class);de.toString(); ApplicationContext接口的继承关系 ApplicationContext:读取配置文件的时候立即加载对象（单例对象适用，经常使用）BeanFatory:遇见getBean的时候才加载对象（多例对象适用）ApplicationConxt接口常用的实现类ClassPathXmlAppliationContext:加载类路径下的配置文件，要求配置文件必须在类路径下FileSystemXmlApplicationContext:加载磁盘任意路径下的配置文件AnnotationConfigAppliationContext:读取注解创建容器3.spring的核心容器Beans(管理bean)Core(核心)Context(上下文（配置文件）)Expresslon Language(SpEl表达式)3.SpringBeanSpringBean创建的三种方式12345678910&lt;!--第一种创建方式id表示调用这个类的时候写的类名，class表示类的包名加类名,其中Java目录下的表示根目录--&gt;&lt;!--使用默认无参构造方法创建--&gt; &lt;bean id="Demo" class="Demo"&gt;&lt;/bean&gt;&lt;!--第二种，使用普通工厂中的方法创建对象,并存入spring容器--&gt; &lt;!--创建Fatory工厂类--&gt; &lt;bean id="Fatory" class="DeFatorymo"&gt; &lt;/bean&gt; &lt;!--获得Service类通过Fatory工厂里面的getService方法--&gt; &lt;bean id="Service" fatory-bean="Fatory" fatory-method="getService"&gt;&lt;/bean&gt;&lt;!--第三种，使用工厂中静态方法创建对象，并存入spring容器--&gt; &lt;bean id="Service" class="Service" facctory-method="getService"&gt;&lt;/bean&gt; SpringBean的作用范围和生存周期Bean标签的scope属性可以指定对象的作用范围 singleton单例对象（默认）解析xml出生，也就是和容器一样 prototype多例对象 ，使用时出生，当对象长时间不使用，而且没有对象引用 的时候被垃圾回收器销毁 request作用于web应用的请求范围 session作用于web的应用的会话范围 global-session:作用于集群环境的会话范围，全局的会话范围 4.Spring注入概述（经常变化的数据不适合注入）​ 平常的Java开发中，程序员在某个类中需要依赖其它类的方法。 ​ 通常是new一个依赖类再调用类实例的方法，这种开发存在的问题是new的类实例不好统一管理。 ​ Spring提出了依赖注入的思想，即依赖类不由程序员实例化，而是通过Spring容器帮我们new指定实例并且将实例注入到需要该对象的类中。 ​ 依赖注入的另一种说法是”控制反转”。通俗的理解是：平常我们new一个实例，这个实例的控制权是我们程序员。 ​ 而控制反转是指new实例工作不由我们程序员来做而是交给Spring容器来做。 详解如果使用注解的方式首先要在xml约束中添加 12345678910&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;!--然后告诉spring创建容器时时要扫描的包--&gt; &lt;context:component-scan base-package="&lt;包名&gt;"&gt;&lt;/context:component-scan&gt; ​ 基本数据类型包装类型和String ​ 其他Bean类型（在配置文件中或者注解配置过的Bean） ​ 其他类型/集合类型 注入的方式使用构造函数​ 首先创建一个类,通过构造方法给成员变量进行赋值 12345678910111213141516171819202122import java.util.Date;public class Bean &#123; private int age; private String name; private Date newDate; @Override public String toString() &#123; return "Bean&#123;" + "age=" + age + ", name='" + name + '\'' + ", newDate=" + newDate + '&#125;'; &#125; private Bean(int age, String name, Date newDate)&#123; this.age=age; this.name=name; this.newDate=newDate; &#125;&#125; XML里面这样配置 123456789101112131415161718192021222324252627&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- constructor-arg标签属性详解-------------------------------------------------查找构造方法属性： type通过指定数据类型进行查找 index通过指定下标进行查找，下标从0开始 name通过名字进行查找（最常用的方式）---------------------------------------------------赋值： value给对象进行赋值，非String类型能自动转换，特殊类型需要使用rel rel指定其他Ioc核心容器里面的bean对象进行赋值--------------------------------------------------- 优势：在获取bean对象时，注入数据是必须的操作，否则对象无法创建成功 弊端：改变了bean实例化的方式，使我们在创建对象时，如果用不大这些数据，也必须提供 --&gt; &lt;bean id="Bean" class="Bean"&gt; &lt;constructor-arg name="age" value="12"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="name" value="哈哈哈哈"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="newDate" ref="newDate"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id="newDate" class="java.util.Date"&gt;&lt;/bean&gt;&lt;/beans&gt; 使用set方法（更常用）首先创建如下Bean对象 给里面的成员属性进行赋值 123456789101112131415161718192021222324252627import java.util.Date;public class Bean &#123; private int age; private String name; private Date newDate; public void setAge(int age) &#123; this.age = age; &#125; public void setName(String name) &#123; this.name = name; &#125; public void setNewDate(Date newDate) &#123; this.newDate = newDate; &#125; @Override public String toString() &#123; return "Bean&#123;" + "age=" + age + ", name='" + name + '\'' + ", newDate=" + newDate + '&#125;'; &#125;&#125; 然后XML配置文件写 1234567891011121314151617181920212223242526&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="Bean" class="Bean"&gt; &lt;!-- constructor-arg标签属性详解-------------------------------------------------查找构造方法属性： name通过set方法名字进行查找---------------------------------------------------赋值： value给对象进行赋值，非String类型能自动转换，特殊类型需要使用rel rel指定其他Ioc核心容器里面的bean对象进行赋值--------------------------------------------------- 优势：创建对象的时候没有明显的限制，可以直接使用默认的无参构造方法进行构建 弊端：如果某个成员变量必须被赋值，则获取对象是有可能set方法没有被执行 --&gt; &lt;property name="age" value="12"&gt;&lt;/property&gt; &lt;property name="name" value="哈哈哈哈"&gt;&lt;/property&gt; &lt;property name="newDate" ref="newDate"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id="newDate" class="java.util.Date"&gt;&lt;/bean&gt;&lt;/beans&gt; 针对复杂的集合数据类型进行set注入Bean类 12345678910111213141516171819202122232425262728293031import java.util.Arrays;import java.util.Date;import java.util.List;import java.util.Map;public class Bean &#123; private String[] strs; private List&lt;String&gt; list; private Map&lt;String, String&gt; map; @Override public String toString() &#123; return "Bean&#123;" + "strs=" + Arrays.toString(strs) + ", list=" + list + ", map=" + map + '&#125;'; &#125; public void setMap(Map&lt;String, String&gt; map) &#123; this.map = map; &#125; public void setStrs(String[] strs) &#123; this.strs = strs; &#125; public void setList(List&lt;String&gt; list) &#123; this.list = list; &#125;&#125; XML配置 123456789101112131415161718192021222324252627&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="Bean" class="Bean"&gt; &lt;property name="strs"&gt; &lt;array&gt; &lt;value&gt;aaa&lt;/value&gt; &lt;value&gt;BBB&lt;/value&gt; &lt;value&gt;CCC&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;property name="list"&gt; &lt;list&gt; &lt;value&gt;aaa&lt;/value&gt; &lt;value&gt;BBB&lt;/value&gt; &lt;value&gt;CCC&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name="map"&gt; &lt;map&gt; &lt;entry key="123" value="aaa"&gt;&lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 使用注解代替xml配置的注解@Configuration：说明当前类是一个配置类​ @ComponentScan:指定spring在创建容器时要扫描的包 ​ 属性 value和basePackages作用一样 ​ 等同于在xml中的: 1&lt;context:component-scan base-package="&lt;类路径&gt;"&gt;&lt;/context:component-scan&gt; 当使用了AnnotationConfigApplicationContext();这个类的时候可以不使用这个标签，但是如果有多个配置类，需要在ComponentScan注解中包含另一个配置类，并且另一个配置类必须使用Configuration注解来表示他是一个注解类，或者使用import来避免使用Configuration注解这个问题 演示 1234567891011package com.cofing;import org.springframework.beans.factory.annotation.Configurable;import org.springframework.context.annotation.ComponentScan;//首先要声明当前类是一个注解类@Configurable@ComponentScan("类路径")public class Config &#123;&#125; @import导入其他配置类 （有这个注解的配置类也被称为父配置类，那么被包含的配置类被称为子配置类）如果使用AnnotationConfigApplicationContext();导入了主配置类，那么可以通过在主配置类上面填写@import导入其他配置类，而且此时不能被@ComponentScan注解替代 创建对象的注解@Component 作用把当前类对象存入spring容器中​ 属性：value,用于指定bean的id，当我们不写的时候，默认值是当前类名的首字小写 和上面作用一样Controller:用在表现层 Service:用在业务层 Repository:用在持久层 注入数据的注解@Autowired:​ 作用：自动按照类型注入，只要容器中有唯一的一个bean对象类型和要注入的变量类型匹配，或者和他的接口父类类型匹配，就注入成功，如果有多个匹配类型按照名字相同的进行匹配，否则匹配失败。 出现位置:可以是变量上，也可以是方法上细节：在使用注解注入时，set方法就不说必须的了。@Qualifier:在按照类型注入的基础之上再按照名称注入，给类成员注入时不能单独使用，给方法参数注入是可以单独使用​ 属性： value:要注入bean的id @Resource: 可以单独使用​ 属性为：name直接按照id进行注入 上面的三个注入都只能对其他bean类型进行注入，不能对基本类型和String类型进行注入，而且集合类型只能使用xml进行注入。 Autowired和Resource区别 Resource是jdk1.6提供的，Autowired是spring框架提供的 Resource因为是jdk提供的标准，所以可移植性更强，但是Autowired的功能更强大 @Value作用，用于注入基本类型和String类型的数据而且可以使用spEL表达式@Bean:作用把当前方法的返回值作为bean对象存入spring的ioc容器中​ 属性：name用于指定bean的id,当不写时，默认值是当前方法的名称 改变作用范围的注解@Scope :用于指定bean的作用范围 不声明默认是单例的​ 属性:value:指定范围的取值，常用取值:singleton prototype ​ 和生命周期相关的注解@PreDestroy​ 作用:用于指定销毁方法 @PostConstruct​ 作用:用于自定初始化方法 @PropertySource 作用:用来指定properties文件的位置（然后@Value标签就可以用spEL表达式去获取值）​ 属性value：指定文件的名称和路径 ​ 关键字classpath表示类路径下 JAVA的动态代理代理模式 （可以进一步增强代码的复用性）​ 代理模式是常用的java设计模式，他的特征是代理类与委托类有同样的接口，代理类主要负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后处理消息等。代理类与委托类之间通常会存在关联关系，一个代理类的对象与一个委托类的对象关联，代理类的对象本身并不真正实现服务，而是通过调用委托类的对象的相关方法，来提供特定的服务。​ 按照代理的创建时期，代理类可以分为两种。 ​ 静态代理：由程序员创建或特定工具自动生成源代码，再对其编译。在程序运行前，代理类的.class文件就已经存在了。​ 动态代理：在程序运行时，运用反射机制动态创建而成。 接下来代码演示 Main.java 123456789101112131415161718192021222324252627282930import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;public class Main &#123; public static void main(String[] args) &#123; final Factory fatory=new Factory(); //消费者通过动态代理购买商品 //ClassLoader:类加载器，加载代理对象的字节码，和被代理对象相同的类加载器 //Class[] 让代理对象和被代理对象有相同方法，固定写法 //InvoactionHandler 用于代理的方法 IProxy proxy=(IProxy) Proxy.newProxyInstance(fatory.getClass().getClassLoader(), fatory.getClass().getInterfaces(), new InvocationHandler() &#123; /** * 执行被代理对象的热河接口和方法都会经过该方法 * @param proxy 代理对象的引用 * @param method 当前执行的方法 * @param args 当前执行方法所需要的参数 * @return 和配代理对象具有相同的返回值 * @throws Throwable */ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if(method.getName().equals("salfMoney")==true)&#123; System.out.print("代理商坑人了"); &#125; return method.invoke(fatory,args); &#125; &#125;); proxy.salfMoney(5000); &#125;&#125; Factory.java 123456789/** * 生产厂家,被代理类 * 要想使用动态代理模式必须要继承一个接口 */public class Factory implements IProxy&#123; public void salfMoney(float money) &#123; System.out.print("卖了"+money+"元"); &#125;&#125; Iproxy.java 1234567/** * 代理接口 */public interface IProxy &#123; //销售商品接口 public void salfMoney(float money);&#125; AOP编程实例Spring中的AOP，就是通过配置的方式实现的 相关术语： Joinpoin（连接点）：所谓连接点就是值那些被拦截到的点。在spring中，这些点指的是方法，因为spring只支持方法类型的连接点。所有的方法都是连接点 Pointcut（切入点）：所谓切入点是指我们要对哪些Joinpoint进行拦截的定义。只有被增强的方法才是切入点 Advice（通知/增强）：所谓通知是指拦截到Joinpoint之后要做的事情就是通知 通知类型：前置通知、后置通知、异常通知、最终通知、环绕通知 Introduction（引介）：引介是一种特殊情况下的通知，在不修改类代码的前提下，Introduction可以在运行期为类动态地添加一些方法或Field Target（目标对象）：代理的目标对象 Weaving（织入）：是指把增强应用到目标对象来创建新的代理对象的过程 spring采用动态代理织入，而AspectJ采用编译期织入和类装载期织入 Proxy（代理）：一个类被AOP织入增强后，就产生一个结果代理类 Aspect（切面）：是切入点和通知（引介）的结合 ​ 使用spring Aop编程除了要加入Spring的spring-aop jar包，还要加入aspectjrt.jar，aspectjweaver.jar，以及aopalliance_1.0.jar 以下两个是与aspectj相关的包,用来支持切面编程的 aspectjrt包是aspectj的runtime包 aspectjweaver是aspectj的织入包 Cglib包是用来动态代理用的,基于类的代理 1.切入点表达式​ 例如：dao包下public void addAccount(int i);和dao包下的public int reAccount(); ​ 手写访问修饰符可以省略不写 12//匹配public void addAccount(int i)可以写成void addAccount(int) 1.返回值类型可以使用通配符* 表示任意返回值2.包名必须用·进行分割 比如 * . * . *形式3.或者使用* .. 匹配多级目录4.方法名称也可以使用通配符 *5.参数列表可以使用float之类的基本数据类型，如果是复杂数据类型需要些包名加类名如果参数列表使用 * 进行通配符匹配只能匹配有参数的方法，要想匹配所有参数列表的需要使用 ..进行匹配2. 4种通知类型1234&lt;aop:before method="通知的方法名" pointcut="execution(包名.类名.方法名)"&gt;&lt;/aop:before&gt;&lt;!--前置通知--&gt;&lt;aop:after-returning method="通知的方法名" pointcut="execution(包名.类名.方法名)"&gt;&lt;/aop:after-returning&gt;&lt;!--后置通知--&gt;&lt;aop:after-throwing method="通知的方法名" pointcut="execution(包名.类名.方法名)"&gt;&lt;/aop:after-throwing&gt;&lt;!--异常通知--&gt;&lt;aop:after method="通知的方法名" pointcut="execution(包名.类名.方法名)"&gt;&lt;/aop:after&gt;&lt;!--最终通知--&gt; 环绕通知是spring框架为我们提供的一种可以做在代码中手动控制增强方法合适执行的一种方式如果觉得配置execution比较麻烦可以使用切入点表达式解决通知方法的执行顺序1234前置通知切入方法后置通知最终通知 项目目录通过xml的方式实现AOP开发步骤​ 1.把通知bean交给spring来管理（LogMessage类） ​ 2.使用aop:config标签表明开始配置切面 ​ 3.使用aop:aspet标签表明配置切面 ​ id属性，是给切面提供一个唯一标识 ​ ref属性：是指定通知类bean的id ​ 4.在aop:aspet标签的内部使用对应标签来配置通知的类型 ​ aop:before标识前置通知 ​ method属性，用于指定Logger类中那个方法是前置通知 pom.xml 123456789101112131415161718192021222324&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;AOPDmo&lt;/groupId&gt; &lt;artifactId&gt;AOPDmo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.7&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; LogMessage.java 用于增强service类的前置 123456789101112package log;/** * 打印日志类 * 用来增强其他类 */public class LogMessage &#123; public void logMessage()&#123; System.out.print("执行了争抢方法的内容"); &#125;&#125; Iservice接口 123456789package service;/** * service接口 */public interface Iservice &#123; public void addAccout(); public void deletAccount(int i);&#125; Service类 123456789101112package service;public class Service implements Iservice&#123; public void addAccout() &#123; System.out.print("添加了账户"); &#125; public void deletAccount(int i) &#123; System.out.print("删除了账户信息"); &#125;&#125; springconfig.xml 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; &lt;bean id="logmessage" class="log.LogMessage"&gt;&lt;/bean&gt; &lt;bean id="service" class="service.Service"&gt;&lt;/bean&gt; &lt;!--开始aop配置--&gt; &lt;aop:config&gt; &lt;!--开始配置切面--&gt; &lt;aop:aspect id="aoplog" ref="logmessage"&gt; &lt;!--进行前置切面配置--&gt; &lt;aop:before method="logMessage" pointcut="execution(public void service.Service.addAccout())"&gt;&lt;/aop:before&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; main.java 12345678910111213import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import service.Iservice;import service.Service;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext ac=new ClassPathXmlApplicationContext("springconfig.xml"); //注意--必须是service的接口类型， Iservice ser= (Iservice) ac.getBean("service"); ser.addAccout(); &#125;&#125;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>JAVA</tag>
        <tag>Spring</tag>
        <tag>框架</tag>
        <tag>代理模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lambda入门]]></title>
    <url>%2F2019%2F01%2F04%2Flambda%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[lambad是JDK1.8新增的一个新特性，他可以极大的简化我们的开发。Lambda表达式在运行时会生成一个私有的静态函数。lambad本质上就是一个内部类。 使用前提 方法的参数或者局部变量的类型必须是函数式接口才能使用lambad 函数式接口就是有且只有一个抽象方法(default方法也不行) 函数式接口可以使用@FunctionalInterface注解检测 演示123456789101112public class LambdaTest &#123; public static void main(String[] args) &#123; FunctionInter functionInter=name -&gt; &#123;System.out.println(name);return name;&#125;; FunctionInter functionInter1=name-&gt;name; functionInter.get("gg"); &#125;&#125;//检查这个接口是不是函数式接口@FunctionalInterfaceinterface FunctionInter&#123; String get(String name);&#125; 语法lambad表达式可以替换部分内部类的写法，所以我们在介绍语法的同时可以对比内部类。 123456789101112 //内部类写法new Thread(new Runnable()&#123; @Override public void run() &#123; &#125; &#125;);//lambad写法new Thread(()-&gt;&#123; &#125; &#125;); 123(参数列表)-&gt;&#123; 被重写的方法体&#125; 当然lambad还可以在语法上简化 简化可以省略参数列表类型12345678910111213public class LambdaTest &#123; public static void main(String[] args) &#123; //标准格式 FunctionInter functionInter=(String name) -&gt; &#123;System.out.println(name);return name;&#125;; //省略参数列表类型 FunctionInter functionInter=(name) -&gt; &#123;System.out.println(name);return name;&#125;; &#125;&#125;//检查这个接口是不是函数式接口@FunctionalInterfaceinterface FunctionInter&#123; String get(String name);&#125; 只有一个参数可以不加括号12345678910public class LambdaTest &#123; public static void main(String[] args) &#123; FunctionInter functionInter=name-&gt; &#123;System.out.println(name);return name;&#125;; &#125;&#125;//检查这个接口是不是函数式接口@FunctionalInterfaceinterface FunctionInter&#123; String get(String name);&#125; 方法体内只有一条代码可以省略return，大括号12345public class LambdaTest &#123; public static void main(String[] args) &#123; FunctionInter functionInter=name-&gt; name-&gt;name; &#125;&#125;]]></content>
      <tags>
        <tag>lambad</tag>
        <tag>新特性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql基础]]></title>
    <url>%2F2018%2F10%2F01%2Fmysql%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[一、语法select 查询列表from 表名; 二、特点1、查询列表可以是字段、常量、表达式、函数，也可以是多个2、查询结果是一个虚拟表 三、示例1、查询单个字段select 字段名 from 表名; 2、查询多个字段select 字段名，字段名 from 表名; 3、查询所有字段select * from 表名 4、查询常量select 常量值;注意：字符型和日期型的常量值必须用单引号引起来，数值型不需要 5、查询函数select 函数名(实参列表);6、查询表达式select 100/1234; 7、起别名①as②空格 8、去重select distinct 字段名 from 表名; 9、+作用：做加法运算select 数值+数值; 直接运算select 字符+数值;先试图将字符转换成数值，如果转换成功，则继续运算；否则转换成0，再做运算select null+值;结果都为null 10、【补充】concat函数功能：拼接字符select concat(字符1，字符2，字符3,…); 11、【补充】ifnull函数功能：判断某字段或表达式是否为null，如果为null 返回指定的值，否则返回原本的值select ifnull(commission_pct,0) from employees; 12、【补充】isnull函数功能：判断某字段或表达式是否为null，如果是，则返回1，否则返回0 一、语法select 查询列表from 表名where 筛选条件 二、筛选条件的分类1、简单条件运算符 &lt; = &lt;&gt; != &gt;= &lt;= &lt;=&gt;安全等于2、逻辑运算符&amp;&amp; and|| or! not3、模糊查询like:一般搭配通配符使用，可以判断字符型或数值型通配符：%任意多个字符，_任意单个字符 between andinis null /is not null：用于判断null值 is null PK &lt;=&gt; 普通类型的数值 null值 可读性is null × √ √&lt;=&gt; √ √ × 一、语法select 查询列表from 表where 筛选条件order by 排序列表 【asc}desc】 二、特点1、asc ：升序，如果不写默认升序 desc：降序 2、排序列表 支持 单个字段、多个字段、函数、表达式、别名 3、order by的位置一般放在查询语句的最后（除limit语句之外） 一、概述功能：类似于java中的方法好处：提高重用性和隐藏实现细节调用：select 函数名(实参列表); 二、单行函数1、字符函数concat:连接substr:截取子串upper:变大写lower：变小写replace：替换length：获取字节长度trim:去前后空格lpad：左填充rpad：右填充instr:获取子串第一次出现的索引 2、数学函数ceil:向上取整round：四舍五入mod:取模floor：向下取整truncate:截断rand:获取随机数，返回0-1之间的小数 3、日期函数now：返回当前日期+时间year:返回年month：返回月day:返回日date_format:将日期转换成字符curdate:返回当前日期str_to_date:将字符转换成日期curtime：返回当前时间hour:小时minute:分钟second：秒datediff:返回两个日期相差的天数monthname:以英文形式返回月 4、其他函数version 当前数据库服务器的版本database 当前打开的数据库user当前用户password(‘字符’)：返回该字符的密码形式md5(‘字符’):返回该字符的md5加密形式 5、流程控制函数①if(条件表达式，表达式1，表达式2)：如果条件表达式成立，返回表达式1，否则返回表达式2②case情况1case 变量或表达式或字段when 常量1 then 值1when 常量2 then 值2…else 值nend ③case情况2casewhen 条件1 then 值1when 条件2 then 值2…else 值nend 三、分组函数1、分类max 最大值min 最小值sum 和avg 平均值count 计算个数 2、特点①语法select max(字段) from 表名; ②支持的类型sum和avg一般用于处理数值型max、min、count可以处理任何数据类型 ③以上分组函数都忽略null④都可以搭配distinct使用，实现去重的统计select sum(distinct 字段) from 表;⑤count函数count(字段)：统计该字段非空值的个数count(*):统计结果集的行数案例：查询每个部门的员工个数1 xx 102 dd 203 mm 204 aa 405 hh 40 count(1):统计结果集的行数 效率上：MyISAM存储引擎，count()最高InnoDB存储引擎，count()和count(1)效率&gt;count(字段) ⑥ 和分组函数一同查询的字段，要求是group by后出现的字段 一、语法select 分组函数，分组后的字段from 表【where 筛选条件】group by 分组的字段【having 分组后的筛选】【order by 排序列表】 二、特点使用关键字 筛选的表 位置分组前筛选 where 原始表 group by的前面分组后筛选 having 分组后的结果 group by 的后面 一、含义当查询中涉及到了多个表的字段，需要使用多表连接select 字段1，字段2from 表1，表2,…; 笛卡尔乘积：当查询多个表时，没有添加有效的连接条件，导致多个表所有行实现完全连接如何解决：添加有效的连接条件 二、分类按年代分类： sql92： 等值 非等值 自连接 也支持一部分外连接（用于oracle、sqlserver，mysql不支持） sql99【推荐使用】 内连接 等值 非等值 自连接 外连接 左外 右外 全外（mysql不支持） 交叉连接三、SQL92语法1、等值连接语法： select 查询列表 from 表1 别名,表2 别名 where 表1.key=表2.key 【and 筛选条件】 【group by 分组字段】 【having 分组后的筛选】 【order by 排序字段】 特点： ① 一般为表起别名 ②多表的顺序可以调换 ③n表连接至少需要n-1个连接条件 ④等值连接的结果是多表的交集部分 2、非等值连接语法：​ select 查询列表​ from 表1 别名,表2 别名​ where 非等值的连接条件​ 【and 筛选条件】​ 【group by 分组字段】​ 【having 分组后的筛选】​ 【order by 排序字段】 3、自连接语法：​ select 查询列表​ from 表 别名1,表 别名2​ where 等值的连接条件​ 【and 筛选条件】​ 【group by 分组字段】​ 【having 分组后的筛选】​ 【order by 排序字段】 四、SQL99语法1、内连接语法：select 查询列表from 表1 别名【inner】 join 表2 别名 on 连接条件where 筛选条件group by 分组列表having 分组后的筛选order by 排序列表limit 子句; 特点：①表的顺序可以调换②内连接的结果=多表的交集③n表连接至少需要n-1个连接条件 分类：等值连接非等值连接自连接 2、外连接语法：select 查询列表from 表1 别名left|right|full【outer】 join 表2 别名 on 连接条件where 筛选条件group by 分组列表having 分组后的筛选order by 排序列表limit 子句; 特点：①查询的结果=主表中所有的行，如果从表和它匹配的将显示匹配行，如果从表没有匹配的则显示null②left join 左边的就是主表，right join 右边的就是主表 full join 两边都是主表③一般用于查询除了交集部分的剩余的不匹配的行 3、交叉连接语法：select 查询列表from 表1 别名cross join 表2 别名; 特点：类似于笛卡尔乘积 一、含义嵌套在其他语句内部的select语句称为子查询或内查询，外面的语句可以是insert、update、delete、select等，一般select作为外面语句较多外面如果为select语句，则此语句称为外查询或主查询 二、分类1、按出现位置select后面： 仅仅支持标量子查询from后面： 表子查询where或having后面： 标量子查询 列子查询 行子查询exists后面： 标量子查询 列子查询 行子查询 表子查询 2、按结果集的行列标量子查询（单行子查询）：结果集为一行一列列子查询（多行子查询）：结果集为多行一列行子查询：结果集为多行多列表子查询：结果集为多行多列 三、示例where或having后面1、标量子查询案例：查询最低工资的员工姓名和工资①最低工资select min(salary) from employees ②查询员工的姓名和工资，要求工资=①select last_name,salaryfrom employeeswhere salary=( select min(salary) from employees); 2、列子查询案例：查询所有是领导的员工姓名①查询所有员工的 manager_idselect manager_idfrom employees ②查询姓名，employee_id属于①列表的一个select last_namefrom employeeswhere employee_id in( select manager_id from employees); 一、应用场景当要查询的条目数太多，一页显示不全 二、语法select 查询列表from 表limit 【offset，】size; 注意：offset代表的是起始的条目索引，默认从0卡死size代表的是显示的条目数 公式：假如要显示的页数为page，每一页条目数为sizeselect 查询列表from 表limit (page-1)*size,size; 一、含义union：合并、联合，将多次查询结果合并成一个结果 二、语法查询语句1union 【all】查询语句2union 【all】… 三、意义1、将一条比较复杂的查询语句拆分成多条语句2、适用于查询多个表的时候，查询的列基本是一致 四、特点1、要求多条查询语句的查询列数必须一致2、要求多条查询语句的查询的各列类型、顺序最好一致3、union 去重，union all包含重复项 语法：select 查询列表 ⑦from 表1 别名 ①连接类型 join 表2 ②on 连接条件 ③where 筛选 ④group by 分组列表 ⑤having 筛选 ⑥order by排序列表 ⑧limit 起始条目索引，条目数; ⑨]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/C++语言位运算基本用法和骚操作]]></title>
    <url>%2F2018%2F08%2F27%2FCC%2B%2B%E8%AF%AD%E8%A8%80%E4%BD%8D%E8%BF%90%E7%AE%97%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95%E5%92%8C%E9%AA%9A%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[C/C++语言位运算基本用法和骚操作前言:​ 前几天打了徐州ACM的网络模拟赛，其中有个题觉得很容易做出来，但是死活都是卡时间和卡内存，于是乎就百度了一下题解（╮(╯▽╰)╭手动狗头），结果学到了一个新的算法，叫做区间数组，然后就学了学，结果学的云里雾里的，其中区间数组核心的一个确定区间的函数 123lowbit(int x)&#123; return x&amp;(-x);&#125; 更是云里雾里。然后就结束今天的新的吧。 位运算基本用法 操作符 作用 解释 &amp; 位AND 如果 x 和 y 都为 1，则得到 1；如果 x 或 y 任何一个为 0，或都为0，则得到 0 | 位OR 如果 x 或 y 为 1，或都为 1，则得到 1；如果 x 和 y 都为 0，则得到 0 ^ 位 XOR 如果 x 或 y 的值不同，则得到 1；如果两个值相同，则得到 0 ~ 位 NOT（I的补码） 如果 x 为 0，则得到 1，如果 x 是 1，则得到 0 运算符 意义 示例 结果 &lt;&lt; 向左移位 x&lt;&lt;y x 的每个位向左移动 y 个位 &gt;&gt; 向右移位 x&gt;&gt;y x 的每个位向右移动 y 个位 骚操作判断一个整形最后一位是否是1(用来判断奇偶数)123if(n&amp;1)&#123; printf("是奇数");&#125; ### 演示​ 将输入的一个n（int类型整数）转换成二进制小数（n&gt;=0） 123456789101112131415161718192021222324252627#include&lt;iostream&gt;#include&lt;stack&gt;using namespace std;int main(void)&#123; int n; while(true) &#123; cin&gt;&gt;n; stack&lt;int&gt; sta; while(n&gt;0)//输出二进制末尾小数打印出并且进行移位 &#123; if(n&amp;1) sta.push(1); else sta.push(0); n&gt;&gt;=1; &#125; while(!sta.empty()) &#123; cout&lt;&lt;sta.top(); sta.pop(); &#125; cout&lt;&lt;endl; &#125; return 0;&#125; 实现两个数互换12345int num1=10;int num2=10;num1=num1^num2;num2=num1^num2;num1=num1^num2;]]></content>
      <categories>
        <category>C语言</category>
      </categories>
      <tags>
        <tag>语言</tag>
        <tag>编程</tag>
        <tag>日常学习</tag>
        <tag>C++</tag>
        <tag>C</tag>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow入门教程]]></title>
    <url>%2F2018%2F05%2F27%2F1.tensorflow%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[1.tensorflow基本介绍1.TensorFlow 简介​ TensorFlow是一个基于数据流编程的符号数学系统，被广泛应用于各类机器学习算法的编程实现，其前身是谷歌的神经网络算法库 2.TensorFlow基本术语张量（tensor）：​ 张量就是基于向量和矩阵的推广，通俗点理解就是可以将标量看成零阶张量，向量看成一阶张量，矩阵就是二阶张量。 图（graph）​ 代表着一段内存地址，也可以理解成所有的节点和张量的集合 节点（op）​ 每个运算和张量都是一个节点，每个节点就是一个op 会话(Session)​ 会话的作用就是执行图的计算，众所周知在TensorFlow中会话之前的都是图的定义或者是op的定义，只能表示关系不参与计算，所以需要用会话让图真正的执行起来 2.张量（tensor）的使用以及注意事项1.张量的基本概念​ 张量就是基于向量和矩阵的推广，通俗点理解就是可以将标量看成零阶张量，向量看成一阶张量，矩阵就是二阶张量。 2.张量的数据类型 数据类型 Python类型 描述 DT_FLOAT tf.float32 32位浮点数 DT_DOUBLE tf.float64 64位浮点数（精度和float32精度一致） DT_INT64 tf.int64 64位有符号整数 DT_INT32 tf.int32 32位有符号整数（精度和int32精度一致） DT_INT13 tf.int16 16位有符号整数 DT_INT8 tf.int8 8位有符号整数 DT_STRING tf.string 可变长度的字节数组，每一个张量元素都是一个字节数组。 DT_BOOL tf.bool 布尔型 DT_COMPLEX64 tf.compiex64 由两个32位浮点数组组成的复数：实数和虚数 DT_QINT32 tf.qint32 用于量化Ops的8位有符号整数 DT.QINT8 tf.qint8 用于量化Ops的8位有符号整形 DT_QUINT8 tf.quint8 用于量化Ops的8位无符号整形 3.张量的代码12345678#导入tensorflow包，简写为tfimport tensorflow as tf#定义一个3.0的常量的张量tensor=tf.constant(3.0)#显示tensor的结果print(tensor)#结果将会是：Tensor("Const:0", shape=(), dtype=float32) 其中Const表示进行的op操作名字shape表示张量的维度,()表示标量，（1）表示向量，（2，3）表示2行3列的张量dtype表示张量的数据类型4.生成张量创建一个常数张量tf.constant(value,dtype=None,shape=None,name=”Const”) 创建一个dtype类型的维度为shape的常数张量 固定值初始化tf.zeros([n,m],tf.dtype)获取一个n行m列的零元素tf.dtype类型的张量 tf.ones([n,m],tf.dtype)获取一个n行m列的1元素tf.dtype类型的张量 随机值初始化tf.random_normal([n,m],mean=2.0,stddev=4,seed=12)创建一个n行m列的正态分布（高斯分布）平均值为2.0，方差为4,随机种子为12张量 5.占位符1tf.placeholder(dtype,shape,name) dtype张量的数据类型 shape张量的维度 [2,3]生成一个2行3列的占位符,[None,3]表示生成一个不确定行和3列的占位符 6.张量的维度调整区别如果调整的过程中生成了新的张量，这种调整称作动态调整 静态调整语法: 张量名字.set_shape([n,m]) 调整张量为n行m列 注意 静态张量只能调整之前不确定维度的张量，比如shape=[None,3]的张量 动态调整语法: tf.reshape(tensor,shape,name=None)动态张量会生成新的张量而且可以跨维度修改，也就是二阶张量可以向n阶张量改变，但是改变前和改变后其总个数必须一致，如果不知道具体维度，需要填写成-1 7.改变张量的类型1tf.cast(x,dtype,name="None") 将x张量转换为dtype类型的张量 1tf.cast([[1,2,3],[4,5,6],[7,8,9]],tf.float32) 将列表从整形转换成float32类型 8.张量的切片和扩展 1tf.concat(value,axis,name="concat") 可以将连个张量拼接起来 value 可以是个列表 axis 表示按行合并还是按列合并 0表示按行合并，1表示按列合并 1234567891011121314151617181920212223242526import tensorflow as tf#定义两个列表a=[[1,2,3],[4,5,6]]b=[[7,8,9],[10,11,12]]#合并两个列表hangCat=tf.concat([a,b],axis=0)lieCat=tf.concat([a,b],axis=1)#由于上面只是搭建了个图结果并没有实际运行,接下来进行实际运行。with tf.Session() as sess: print("行合并") print(sess.run(hangCat)) print("列合并") print(sess.run(lieCat)) #运行结果为：行合并[[ 1 2 3] [ 4 5 6] [ 7 8 9] [10 11 12]]列合并[[ 1 2 3 7 8 9] [ 4 5 6 10 11 12]] 3.会话（Session）​ 会话的作用就是执行图的计算，众所周知在TensorFlow中会话之前的都是图的定义或者是op的定义，只能表示关系不参与计算，所以需要用会话让图真正的运行起来 基本写法12with tf.Session() as sess: sess.run(fetches,feed_dict=None,options=None,run_metadata=None) 1.run方法fetches 运行ops和计算tensorfeed_dict 可选项（字典类型），提取使用占位符之后给图提供数据4.变量（Variable）​ 变量是一种特殊的张量，也是一种op,它能够被存储持久化，他们的值就是张量，默认被训练 1.变量的定义1tf.Variable(initial_balue=None,name=None,trainable=True) initial_value 值 可以用正态分布或者固定生成张量的值 注意：使用变量的时候必须先运行全局初始化初始化 tf.global_variables_initializer() 例子： 12345678910import tensorflow as tf#使用正态分布分配变量的值var=tf.Variable(tf.random_normal([2,3],mean=2.0,stddev=1.0))#开启会话并运行初始化with tf.Session() as sess: #运行初始化(运行全局初始化变量前变量var并未被真正赋值) sess.run(tf.global_variables_initializer()) print(sess.run(var)) 4.TensorBoard 的使用和用法1.TensorBoard的简介​ TensorBoard是Tensorflow的可视化工具，它可以通过Tensorflow程序运行过程中输出的日志文件可视化Tensorflow程序的运行状态。TensorBoard和Tensorflow程序跑在不同的进程中，TensorBoard会自动读取最新的TensorFlow日志文件，并呈现当前TensorFlow程序运行的最新状态。 2.TensorBoard代码写入事务文件需要找到TensorFlow包里面的事务包summary里面的FileWriter方法 1tf.summary.FileWriter(logdir,graph=None) logdir事务文件的绝对路径graph写出事务文件的图1234#收集变量tf.summary.scalar(name="",tensor)#收集损失函数和准确率tf.summary.histogram(name="",tensor)#收集高纬度的变量参数tf.summary.image(name="",tensor)#收集输入的图片张量，能显示图片 name 表示TensorBoard里面显示的名称tensor表示要收集的张量123mergin=tf.summary.merge_all()#收集所有的张量summary=sess.run(mergin)#每次迭代都要运行的合并FileWriter.add_summary(summary,i)#每次迭代都要添加到事务文件 3.TensorBoard的演示​ 首先代码 1234567891011121314151617#通过两个变量的相加演示tensorboard的用法import tensorflow as tf#定义两个正态分布的随机变量var1=tf.Variable(tf.random_normal([2,3],mean=2.0,stddev=1.0))var2=tf.Variable(tf.random_normal([2,3],mean=3.0,stddev=2.0))#定义加法opadd=tf.add(var1,var2)init_variable=tf.global_variables_initializer()#开启会话with tf.Session() as sess: #初始化变量 sess.run(init_variable) #导出事务文件 tf.summary.FileWriter("./board",graph=sess.graph) print(sess.run(add)) ​ 然后启动命令行，打出下列命令 1tensorboard --logdir="D:\code\python\tensortflow\board" ​ 之后显示命令行下面显示如下信息 1TensorBoard 1.5.1 at http://By:6006 (Press CTRL+C to quit) 这就表示TensorBoard正常启动了，在浏览器输入（http://By:6006）就能正常访问tensorboard了 5.损失函数1.均方误差​ 计算方法是求预测值与真实值之间距离的平方和 ​ 公式如图所示： 6.梯度下降算法1.基本思想梯度下降法的基本思想可以类比为一个下山的过程。假设这样一个场景：一个人被困在山上，需要从山上下来(i.e. 找到山的最低点，也就是山谷)。但此时山上的浓雾很大，导致可视度很低。因此，下山的路径就无法确定，他必须利用自己周围的信息去找到下山的路径。这个时候，他就可以利用梯度下降算法来帮助自己下山。具体来说就是，以他当前的所处的位置为基准，寻找这个位置最陡峭的地方，然后朝着山的高度下降的地方走，同理，如果我们的目标是上山，也就是爬到山顶，那么此时应该是朝着最陡峭的方向往上走。然后每走一段距离，都反复采用同一个方法，最后就能成功的抵达山谷。2.代码1tf.tarin.GradientDescentOptimizer(learning_rate) learning_rate 学习率 通常填写0.0到1.0之间的浮点数6.简单的线性回归案例12345678910111213141516171819202122232425262728293031#假设有一个函数关系式y=x*0.7+0.2 也就是y=x*w+b这个关系，若只知道y的结果和x的结果若干组，那么能否正确让w为0.7 b为0.2呢?import tensorflow as tf#1.生成100组x的xDist=tf.random_normal([100,1],mean=0.5,stddev=0.5,name="xDist")#生成目标值y的结果y_true=tf.matmul(xDist,[[0.7]])+0.2#2.建立线性回归模型#因为权重和偏置是需要不断训练改变的，所有需要定义成变量w=tf.Variable(tf.random_normal([1,1],mean=0.0,stddev=1.0),name="w")b=tf.Variable(tf.random_normal([1,1],mean=0.0,stddev=0.0),name="b")y=tf.matmul(xDist,w)+b#损失函数和使用梯度下降优化器优化，使用最小损失优化，学习率为0.1loss=tf.reduce_mean(tf.square(y_true-y))train_op=tf.train.GradientDescentOptimizer(0.1).minimize(loss)#4.定义全局变量全局初始化init_var=tf.global_variables_initializer()#4.开启会话开始训练with tf.Session() as sess: #运行初始化变量 sess.run(init_var) #打印训练前权重和偏值,因为权重和偏置并没有被运行，所以需要使用eval方法实时获取权重和偏置 print("训练前权重:%f权重:%f" % (w.eval(),b.eval())) for i in range(300): sess.run(train_op) print("%d轮，权重为:%f,偏置为:%f" % (i,w.eval(),b.eval())) 7.梯度爆炸12345678910111213141516171819202122232425262728293031#假设有一个函数关系式y=x*0.7+0.2 也就是y=x*w+b这个关系，若只知道y的结果和x的结果若干组，那么能否正确让w为0.7 b为0.2呢?import tensorflow as tf#1.生成100组x的xDist=tf.random_normal([100,1],mean=0.5,stddev=0.5,name="xDist")#生成目标值y的结果y_true=tf.matmul(xDist,[[0.7]])+0.2#2.建立线性回归模型#因为权重和偏置是需要不断训练改变的，所有需要定义成变量w=tf.Variable(tf.random_normal([1,1],mean=0.0,stddev=1.0),name="w")b=tf.Variable(tf.random_normal([1,1],mean=0.0,stddev=0.0),name="b")y=tf.matmul(xDist,w)+b#损失函数和使用梯度下降优化器优化，使用最小损失优化，学习率为0.1loss=tf.reduce_mean(tf.square(y_true-y))train_op=tf.train.GradientDescentOptimizer(1).minimize(loss)#4.定义全局变量全局初始化init_var=tf.global_variables_initializer()#4.开启会话开始训练with tf.Session() as sess: #运行初始化变量 sess.run(init_var) #打印训练前权重和偏值,因为权重和偏置并没有被运行，所以需要使用eval方法实时获取权重和偏置 print("训练前权重:%f权重:%f" % (w.eval(),b.eval())) for i in range(300): sess.run(train_op) print("%d轮，权重为:%f,偏置为:%f" % (i,w.eval(),b.eval())) 1.简述​ 上述代码学习率是1，运行后就会发现权重和偏置变成了NAV，这就是梯度爆炸，也就是说学习率过大或者神经网络模型的某些原因就会导致梯度爆炸，但是学习率也不能过小，过小会得不到好的效果。 2.解决方法 重新设计神经网络 调整学习率 使用梯度阶段（在训练过程中检查和限制梯度的大小） 使用激活函数 8.模型的保存和加载1.代码1234saver=tf.train.Saver(var_list=None,max_to_keep=5)#在会话里面saver.restpre(sess,"")#读取模型saver.save(sess,"")#保存模型 var_list:自定要保持和还原的变量。他可以作为一个dict或者一个列表传进去max_to_keep:制定要保留的最近检查点文件的最大数量，创建新的文件的时候会删除比较旧的文件，默认值5“” 这个路径包含路径和文件名1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#假设有一个函数关系式y=x*0.7+0.2 也就是y=x*w+b这个关系，若只知道y的结果和x的结果若干组，那么能否正确让w为0.7 b为0.2呢import tensorflow as tfimport os#1.生成100组x的xDist=tf.random_normal([100,1],mean=0.5,stddev=0.5,name="xDist")#生成目标值y的结果y_true=tf.matmul(xDist,[[0.7]])+0.2#2.建立线性回归模型#因为权重和偏置是需要不断训练改变的，所有需要定义成变量w=tf.Variable(tf.random_normal([1,1],mean=0.0,stddev=1.0),name="w")b=tf.Variable(tf.random_normal([1,1],mean=0.0,stddev=0.0),name="b")y=tf.matmul(xDist,w)+b#损失函数和使用梯度下降优化器优化，使用最小损失优化，学习率为0.1loss=tf.reduce_mean(tf.square(y_true-y))train_op=tf.train.GradientDescentOptimizer(0.1).minimize(loss)#收集张量tf.summary.scalar("loss",loss)tf.summary.histogram("W",w)#合并所有的收集到的张量margin=tf.summary.merge_all()#4.定义全局变量全局初始化init_var=tf.global_variables_initializer()#定义保存saver=tf.train.Saver()#4.开启会话开始训练with tf.Session() as sess: #运行初始化变量 sess.run(init_var) # 读取模型 if os.path.exists("./model/checkpoint"): saver.restore(sess, "./model/123") #写出事务文件 fileWiter=tf.summary.FileWriter("./board",graph=sess.graph) #打印训练前权重和偏值,因为权重和偏置并没有被运行，所以需要使用eval方法实时获取权重和偏置 print("训练前权重:%f权重:%f" % (w.eval(),b.eval())) for i in range(300): summary = sess.run(margin) sess.run(train_op) fileWiter.add_summary(summary,i) # 运行变量的合并 print("%d轮，权重为:%f,偏置为:%f" % (i,w.eval(),b.eval())) saver.save(sess,"./model/123") 2.保存的文件格式​ .data-00000-of-00001和.index文件 ​ checkpoint文件：checkpoint_dir目录下还有checkpoint文件，该文件是个文本文件，里面记录了保存的最新的checkpoint文件以及其它checkpoint文件列表。在inference时，可以通过修改这个文件，指定使用哪个model。加载restore时的文件路径名是以checkpoint文件中的“model_checkpoint_path”值决定的。 ​ 保存模型时，只会保存变量的值，placeholder里面的值不会被保存。 9.队列机制1.简述​ TensorFlow提供了专门的队列机制,专门用来处理文件读取的问题 2.代码1queue=tf.FIFOQueue(capatity,dtype)#定义一个队列 capatity 队列的容量dtype队列存储的数据类型1queue.dequeue()#出队列并且移除 12queue.enqueue()#入队列int=queue.enqueue_many(list)#入队一个列表元素 演示:1234567891011121314151617181920#定义一个队列，不断出队列和入队列import tensorflow as tf#定义一个队列queue=tf.FIFOQueue()#添加队列元素int=queue.enqueue_many([[1.0,2.0,3.0],])#定义图结构item=queue.dequeue()data=item+1en=queue.enqueue(data)#开始执行图结构with tf.Session() as sess: #运行添加元素结构 sess.run(int) for i in range(20): sess.run(en) for i in range(queue.size().eval()): print(queue.dequeue().eval()) 10.文件读取1.文件读取的过程1.构造文件队列2.构造阅读器3.对于每个样本进行解码4.批处理文件2.文件读取的API介绍构造文件队列1tf.tarin.string_inpput_producer(string_tensor,shuffle=True) string_tensor 含有文件名的一阶张量（包含路径以及文件名的列表）shuffle 是否乱序 默认乱序num_epochs 过几遍数据，默认无限过数据构造文件阅读器 所有阅读器解码出来形状都是不固定的，注意后边进行形状固定 要根据文件类型选择对应的文件阅读区 每个read方法返回key，和value参数，其中key表示文件名称，value表示每个样本 文本文件和CSV文件: 12class reader=tf.TextLineReader()#构造文件阅读器 reader.read(file_queue)#读取一个样本 文本文件阅读器，默认按行读取，（因为对于csv文件和文本文件来说，一行就是一个样本）return 返回阅读器实例read(file_queue)file_queue 从队列里面读取内容二进制文件阅读器12class reader=tf.FixedLengthRecordReader(record_bytes)#构造文件阅读器 reader.read(file_queue)#读取一个样本文件 读取每个样本是按固定数量的字节读取的二进制文件record_bytes:整形，指定每次读取的字节数return 返回阅读器实例图片文件阅读器12class reader=tf.WholeFileReader()#构造图片文件阅读器 reader.read(file_queue)#读取一个图片样本 每个样本进行解码CSV文件解码1tf.decode_csv(value,record_defaults=None) value表示待解码的内容record_defaults 表示每个样本如何解码，并且缺失的时候的默认值 [[1]]表示一个样本按整形解码，缺失的时候为1，[[“None”],[1.0]] 表示样本有两个第一个按string类型解码，缺失的时候是None,第二个按float类型解码，丢失按1.0处理图片文件解码 123456tf.image.decode_jpeg(contents)#将JPEG编码的图像解码为uint8的张亮#return:uint8张量3-D形状[height,width,hannels]tf.image.decode_png(contents)#将PNG图片的图像解码为uint8或者uint16的张量#return:张量类型，3-D形状[height,width,hannels] 图片文件缩放 123tf.image.resize_images(images,size)images:4-D形状[batch,height,width,channels]或者3-D的形状的张量[height,width,channels]size图片的新尺寸，new_height,new_width 管道批处理文件 12#批处理 batch_size表示每批的数量，num_threads进行的线程数量，capacity批处理管道的容量 ones,twos=tf.train.batch([one,two],batch_size=6,num_threads=1,capacity=9) 3.文件读取的简单演示1234567891011121314151617181920212223242526272829303132333435363738394041424344#1.构造文件队列（路径加文件名）#2.构造文件阅读器#3.按每个样本解码（转化为张量 ）#4.构造批处理###在同目录下有个data文件夹，里面的csv文件里面都有两行且都是string类型import tensorflow as tfimport os#找到对应的文件目录获取文件路径加列表def fileRead(path): fileName=os.listdir(path) filePath=[os.path.join(path,file) for file in fileName] return filePathdef csvRead(fileList): #构造文件队列 fileQueue=tf.train.string_input_producer(fileList) #构造阅读器 reader=tf.TextLineReader() key,value=reader.read(fileQueue) #对文件进行解码 #设定每行的类型以及每行的默认值 cord=[["None"],["None"]] one,two=tf.decode_csv(value,record_defaults=cord) #批处理 batch_size表示每批的数量，num_threads进行的线程数量，capacity批处理管道的容量 ones,twos=tf.train.batch([one,two],batch_size=6,num_threads=1,capacity=9) return ones,twosif __name__ == "__main__": fileList=fileRead("./data") one,two=csvRead(fileList) with tf.Session() as sess: #定义一个线程协调器 coord=tf.train.Coordinator() #开启一个线程 thread=tf.train.start_queue_runners(sess,coord=coord) print(sess.run([one,two])) #回收子线程 coord.request_stop() coord.join(thread) 图片文件的读取简单演示12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#读取当前文件夹下面的data目录下面所有的jpg格式图片的信息#步骤# 1.获取path文件下面的所有图片的全路径列表# 2.构造文件队列# 3.构造图片阅读器# 4.图片解码# 5.图片缩放# 6.图片调整维度# 7.批处理import tensorflow as tfimport os#读取path目录下所有的图片信息def getPath(path): fileNames=os.listdir(path) filePath=[os.path.join(path,fileName) for fileName in fileNames] return filePath#读取图片并进行批处理def readImg(filePathList): #1.构造文件队列 fileQueue=tf.train.string_input_producer(filePathList) #1.构造图片阅读器 reader=tf.WholeFileReader() key,value=reader.read(fileQueue) print("构造完阅读器",value) #3.图片解码 image=tf.image.decode_jpeg(value) print("解码",image) #4.图片缩放 reImage=tf.image.resize_images(image,[200,200]) print("图片放缩后",reImage) #5.图片定型 静态调整 reImage.set_shape([200,200,3]) print("图片静态调整后",reImage) #文件批处理 jpg=tf.train.batch([reImage],batch_size=5,num_threads=2,capacity=5) return reImageif __name__ == "__main__": filePathList=getPath("./data") jpg=readImg(filePathList) #开启会话 with tf.Session() as sess: #定义一个线程协调器 coord=tf.train.Coordinator() #定义一个线程 thread=tf.train.start_queue_runners(sess,coord=coord) print(sess.run(jpg)) #回收子线程 coord.request_stop() coord.join(thread) 注意打印结果: 构造完阅读器 Tensor(“ReaderReadV2:1”, shape=(), dtype=string)解码 Tensor(“DecodeJpeg:0”, shape=(?, ?, ?), dtype=uint8)图片放缩后 Tensor(“Squeeze:0”, shape=(200, 200, ?), dtype=float32)图片静态调整后 Tensor(“Squeeze:0”, shape=(200, 200, 3), dtype=float32) 11.交叉熵损失计算和softMax计算1.softMax计算​ 假设我们有一个数组，V，Vi表示V中的第i个元素，那么这个元素的Softmax值就是 ​ 可以计算n个结果之间发生的概率 2.交叉熵损失​ 可以和onehost编码与softMax计算损失 123456#SoftMax和交叉熵损失计算tf.nn.softmax_cross_entropy_with_logits(babels=None,logits=None,name)#计算logits和labels之间的交叉熵损失#labels:真实值#logits:预测值#return:返回所有样本的损失值列表 3.演示12345678910111213141516def argmax(input, axis=None, name=None, dimension=None, output_type=dtypes.int64)numpy.argmax(a, axis=None, out=None) 返回沿轴axis最大值的索引。Parameters: input: array_like，数组axis : int, 可选，默认情况下，索引的是平铺的数组，否则沿指定的轴。 out : array, 可选 如果提供，结果以合适的形状和类型被插入到此数组中。 Returns: index_array : ndarray of ints 索引数组。它具有与a.shape相同的形状，其中axis被移除。 12345678910111213141516171819202122232425262728293031323334353637383940#简单的神经网络识别手写数字#1.定义占位符#2.搭建神经网络#3.计算损失#4.反向传播优化损失#5.计算准确率#6.开启会话训练import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("./MNIST_data", one_hot=True)def imgNn(): #1.定义占位符 xDist=tf.placeholder(tf.float32,[None,784]) yTrue=tf.placeholder(tf.float32,[None,10]) #2.初始化变量搭建神经网络 w=tf.Variable(tf.random_normal([784,10],mean=0.0,stddev=1.0)) b=tf.Variable(tf.random_normal([10],mean=0.0,stddev=1.0)) y=tf.matmul(xDist,w)+b #3.计算平均交叉熵损失率 loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=yTrue,logits=y)) #4.反向传播最小优化学习率0.1 trainOp=tf.train.GradientDescentOptimizer(0.1).minimize(loss) #5.计算准确率 arg_max会反正正确结果的下标 1表示按同行比较 0表示同列 equal_list=tf.equal(tf.arg_max(yTrue,1),tf.arg_max(y,1)) acuracy=tf.reduce_mean(tf.cast(equal_list,tf.float32)) initOp=tf.global_variables_initializer() #6.开启会话开始训练 with tf.Session() as sess: sess.run(initOp) for i in range(3000): #取出特征值和目标值 minstX,minstY=mnist.train.next_batch(50) sess.run(trainOp,feed_dict=&#123;xDist:minstX,yTrue:minstY&#125;) print("%d步准确率%f" % (i,sess.run(acuracy,feed_dict=&#123;xDist:minstX,yTrue:minstY&#125;)))if __name__ =="__main__": imgNn() 12.卷积神经网络1.概述​ 卷积神经网络（Convolutional Neural Networks / CNNs / ConvNets）与普通神经网络非常相似，它们都由具有可学习的权重和偏置常量(biases)的神经元组成。每个神经元都接收一些输入，并做一些点积计算，输出是每个分类的分数，普通神经网络里的一些计算技巧到这里依旧适用。 具有三维体积的神经元(3D volumes of neurons) ​ 卷积神经网络利用输入是图片的特点，把神经元设计成三个维度 ： width, height, depth(注意这个depth不是神经网络的深度，而是用来描述神经元的) 。比如输入的图片大小是 32 × 32 × 3 (rgb)，那么输入神经元就也具有 32×32×3 的维度。 2.卷积神经网络分层卷积层—&gt;激活层—&gt;池化层—&gt;全连接层##### 卷积层：​ 卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法优化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。 激活层：​ 通过Relu激活函数可以增加网络的非线性分割能力 池化层：​ 用来减少数据量 3.填充算法SAME：​ 当filter过滤到边缘的时候自动填充0 - 越过边缘取样，取样的面积和输入的图像像素长度和宽度相同VALID： 当filter过滤到边缘的时候跳过，所有会丢失部分特征，取样的面积和输入的图像像素长度和宽度会略小 计算公式为：输入体积大小h1 * w1 * d1 ，filter数量为k,filter大小为f,步长为s,填充大小为p 那么 h2=(h1-f+2p)/s+1 w2=(w1-f+2p)/s+1 d2=k 4.API介绍12#卷积层tf.nn.conv2d(input,filter,strides=,padding=,name=None) input: 输入的4-D张量，具有[batch,height,width,channel],类型为float32，或者float64([每批数,图片长度，图片宽度，图片通道数])filter:指定过滤器4-D随机初始化的张量：,类型为float32或者float64([过滤器长度，过滤器宽度，输入的通道数，输出的通道数])，——- 注意需要传入4-D张量，而不是简单的填入维度strides:strides=[1,stride,stride,1],步长（[1，长上步长，宽上步长，1]）padding=:”SAME”，“VALID”，使用的填充算法类型.12#relu激活函数tf.nn.relu(feacutes,name=None) features:卷积后加上偏置的结果return :结果12#池化tf.nn.max_pool(value,ksize=,strides=,padding=,name=None) value:4-D tensor形状[batch,height,width,channels]，也就是激活函数处理后的结果ksize池化窗口大小，[1,ksize,ksize,1]步长大小,[1,strides,strides,1]padding :”SAME”,”VALID”填充算法5.演示两层卷积神经网络识别手写数字​ 1.输入数据形状[None,784] ##### 第一层卷积神经网络卷积层​ 2.因为卷积API的input即输入为4-D张量，所以动态改变形状改为[None,28,28,1],使用32个filter的5*5大小，步长为1，SAME填充算法的过滤器且卷积后输出的形状为[None,28,28,32]，有多少个filter就有多少个偏置所以为32，权重就是每个filter的值. ###### 激活层​ 3.不改变数据大小，所以输出还是[None,28,28,32] ###### 池化​ 4.大小为2 *2，步长为2，填充算法为“SAME”(这里SAME后的大小比原来小)将[None,28,28,32]的图像池化为[None,14,14,32] 第一层卷积神经网络卷积层​ 2.因为卷积API的input即输入为4-D张量，输入为[None,14,14,32],使用64个filter的5*5大小，步长为1，SAME填充算法的过滤器且卷积后输出的形状为[None,14,14,64]，有多少个filter就有多少个偏置所以为64,权重就是每个filter的值. 激活层​ 3.不改变数据大小，所以输出还是[None,14,14,64] 池化​ 4.大小为2*2，步长为2，填充算法为“SAME”(这里SAME后的大小比原来小)将[None,14,14,64]的图像池化为[None,7,7,64] 全连接层​ 因为池化后数据为[None,7,7,64],而且矩阵乘法只能处理二维数据，所以动态调整形状为[None,7 * 7 *64],又因为输出是10种结果，所以全连接层为[7 * 7 *64,10],所以权重[7 * 7 *64,10]偏置有10个 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475##### 两层卷积神经网络识别手写数字import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datadef getVarRandom_normal(shape): return tf.Variable(tf.random_normal(shape=shape,mean=0.0,stddev=1.0))#搭建神经网络def conV(): #1.定义占位符 xDist=tf.placeholder(tf.float32,[None,784]) yTrue=tf.placeholder(tf.float32,[None,10]) #2.搭建第一层卷积网络 filter 有32个 大小为5*5，步长为1， with tf.name_scope("con1"): xshape=tf.reshape(xDist,[-1,28,28,1]) filterW=getVarRandom_normal([5,5,1,32]) b=getVarRandom_normal([32]) #卷积层 con1=tf.nn.conv2d(xshape,filterW,strides=[1,1,1,1],padding="SAME")+b #激活层 relu=tf.nn.relu(con1) #池化层 大小为2*2 步长为2 [None,28,28,32]----&gt;[None,14,14,32] pool=tf.nn.max_pool(relu,ksize=[1,2,2,1],strides=[1,2,2,1],padding="SAME") #3.搭建第二层卷积网络 filter有64个，大小为5*5，步长为1 with tf.name_scope("con2"): filterW2=getVarRandom_normal([5,5,32,64]) b1=getVarRandom_normal([64]) #卷积层 con2=tf.nn.conv2d(pool,filterW2,strides=[1,1,1,1],padding="SAME")+b1 #激活层 relu2=tf.nn.relu(con2) #池化层 pool2=tf.nn.max_pool(relu2,ksize=[1,2,2,1],strides=[1,2,2,1],padding="SAME") #全连接层 w3=getVarRandom_normal([7*7*64,10]) b3=getVarRandom_normal([10]) shape = tf.reshape(pool2, [-1, 7*7*64]) grop=tf.matmul(shape,w3)+b3 return xDist,yTrue,gropif __name__ == "__main__": xDist,yTrue,opInt=conV() mnist = input_data.read_data_sets("./MNIST_data", one_hot=True) #计算平均交叉熵损失 loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=yTrue,logits=opInt)) #反向传播 trainOp=tf.train.GradientDescentOptimizer(0.00001).minimize(loss) #计算准确率 equal_list = tf.equal(tf.argmax(yTrue, 1), tf.argmax(opInt, 1)) acuracy = tf.reduce_mean(tf.cast(equal_list, tf.float32)) initOp = tf.global_variables_initializer() # 6.开启会话开始训练 with tf.Session() as sess: sess.run(initOp) for i in range(3000000): # 取出特征值和目标值 minstX, minstY = mnist.train.next_batch(50) sess.run(trainOp, feed_dict=&#123;xDist: minstX, yTrue: minstY&#125;) print("%d步准确率%f" % (i, sess.run(acuracy, feed_dict=&#123;xDist: minstX, yTrue: minstY&#125;)))]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
        <tag>语言</tag>
        <tag>Python</tag>
        <tag>编程</tag>
        <tag>日常学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git使用入门]]></title>
    <url>%2F2018%2F05%2F27%2FGit%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Git使用入门前言​ 之前在网上接私活的时候使用了一下github,当时一下都惊艳到我了，（见识短╮(╯▽╰)╭），当时因为用的c#语言开发，使用的vs2017，他继承的那个git是中文的，特别好用，但是也导致了我啥也没学会，正好今天有空，就填补一下这个大坑吧 简介​ 是一个开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理。Git 是 Linus Torvalds为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。（百度粘贴过来的，╮(╯▽╰)╭） 概念介绍​ git可以将工作区（Working Directory）的代码放到暂存区，最后统一把暂存区的代码合并到我们的git仓库中（这个仓库其实还是本地的仓库）。（╮(╯▽╰)╭我觉得解释的很不清楚） 12345st=&gt;start: git仓库e=&gt;end: 工作空间item=&gt;subroutine: 暂存区e-&gt;item-&gt;st 使用git工具要先进行初始化1234git config --global user.name "yang295513"//这个name一定要填写github上面的名称git config --global user.email "15993343299@163.com"//对应的邮箱//这个不是必须的但是新建git仓库就要进去进行这个命令，然后git工具会生成一个隐藏文件.gitgit init 就这样，之后就可以愉快的玩耍了 指令介绍 指令名 作用 注释 git status 显示当前文件的状态 用来确定文件在三个区的位置 git add 文件名.文件类型 将文件添加到暂存区 把工作空间的文件添加到暂存区 git commit -m “提交描述” 把暂存区所有的文件提交到仓库 提交描述用来标识文件的改动，也就是说本次提交的注释 git push 将本地代码提交到git远程 仓库中 将本地代码提交到git远程仓库中 git clone 仓库地址 将远程git的代码下载下来 案例演示首先这里新建了一个演示项目 然后我们通过git clone命令把这个项目下载下来，其中项目的链接在这里： 然后我们使用git工具克隆下来 这是本地生成的文件 其中那个.git的隐藏文件就隐藏着配置信息 githubTest就是咱们的测试信息 githubTest文件里面的信息可以看到和我们的远端github仓库中的一模一样 接下来我们在本地创建一个Test.java的类，来模拟我们的项目 然后使用git add命令和git commit -m和git push命令依次提交到git远端仓库中 然后去github来查看是否已经被提交了 完美,收场，学习新东西去不不不，还有一些使用细节得介绍一下 你提交了那些文件那些文件才会被替换，也就是说你同时修改了A和B文件，那三连 都是针对B文件的，那么你提交到远端git仓库在只会修改你提交的B文件，没有B文件进行创建,有B文件更新 如果提交到远端失败的话，要注意是否是name和Email书写错误，或者说该仓库是priavte（私有的）如果是私有的去对应配置文件下修改账号密码即可]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>日常学习</tag>
        <tag>git</tag>
      </tags>
  </entry>
</search>
