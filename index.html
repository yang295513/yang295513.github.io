<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>Hexo</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home //首页"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags //标签"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th //分类"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive //归档"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar //日程"></i> <br>
            
            日程表
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap //站点"></i> <br>
            
            站点地图
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br>
            
            公益404
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/11/远行星号修改心得/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/11/远行星号修改心得/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-11T19:17:11+08:00">
                2019-09-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="远行星号修改心得"><a href="#远行星号修改心得" class="headerlink" title="远行星号修改心得"></a>远行星号修改心得</h1><p>123</p>
<table>
<thead>
<tr>
<th>tags</th>
<th>large</th>
<th>message</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>energy</td>
<td>激光武器炮塔</td>
</tr>
<tr>
<td>ship.weapon.mount</td>
<td>TURRET</td>
<td>固定武器</td>
</tr>
<tr>
<td>ship.weapon.mount</td>
<td>HARDPOINT</td>
<td>不固定武器</td>
</tr>
<tr>
<td>ship.weapon.mount</td>
<td>HIDDEN</td>
<td>混合炮塔</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/11/Mybatis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/11/Mybatis/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-11T19:17:11+08:00">
                2019-09-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>title: Mybatis入门教程<br>date: 2018-08-30 5:4:30<br>categories:</p>
<ul>
<li>学习<br>tags:</li>
<li>JAVA</li>
<li>语言</li>
<li>数据库</li>
<li>编程</li>
<li>日常学习<h1 id="Mybatis"><a href="#Mybatis" class="headerlink" title="Mybatis"></a>Mybatis</h1></li>
</ul>
<h2 id="1-Mybatis简介"><a href="#1-Mybatis简介" class="headerlink" title="1.Mybatis简介:"></a>1.Mybatis简介:</h2><p>​    </p>
<p>​        MyBatis 本是apache的一个开源项目iBatis, 2010年这个项目由apache software foundation 迁移到了google code，并且改名为MyBatis，是一个基于Java的持久层框架。</p>
<ul>
<li><strong>持久层：</strong> 可以将业务数据<strong>存储到磁盘，具备长期存储能力</strong>，只要磁盘不损坏，在断电或者其他情况下，重新开启系统仍然可以读取到这些数据。</li>
<li><strong>优点：</strong> 可以<strong>使用巨大的磁盘空间</strong>存储相当量的数据，并且很<strong>廉价</strong> </li>
<li><strong>缺点：慢</strong>（相对于内存而言）</li>
</ul>
<h2 id="2-为什么要使用mybatis"><a href="#2-为什么要使用mybatis" class="headerlink" title="2.为什么要使用mybatis"></a>2.为什么要使用mybatis</h2><p>​        在我们<strong>传统的 JDBC 中</strong>，我们除了需要自己提供 SQL 外，还必须操作 Connection、Statment、ResultSet，不仅如此，为了访问不同的表，不同字段的数据，我们需要些很多雷同模板化的代码，闲的<strong>繁琐又枯燥</strong>。</p>
<p>而我们在使用了 <strong>MyBatis</strong> 之后，<strong>只需要提供 SQL 语句就好了</strong>，其余的诸如：建立连接、操作 Statment、ResultSet，处理 JDBC 相关异常等等都可以交给 MyBatis 去处理，我们的<strong>关注点于是可以就此集中在 SQL 语句上</strong>，关注在增删改查这些操作层面上。</p>
<p>并且 MyBatis 支持使用简单的 XML 或注解来配置和映射原生信息，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。</p>
<h2 id="3-mybatisDemo"><a href="#3-mybatisDemo" class="headerlink" title="3.mybatisDemo"></a>3.mybatisDemo</h2><h5 id="mybatis的环境搭建"><a href="#mybatis的环境搭建" class="headerlink" title="mybatis的环境搭建"></a>mybatis的环境搭建</h5><p>​                    第一步：创建maven工程并导入坐标</p>
<p>​                    第二步：创建实体类和dao接口（mybatis可以只有接口就能实现对数据库的增删改查，而且实体类就是要实体类的属性和数据库的表对应起来）</p>
<p>​                    第三步：创建mybatis的主配置文件    SqlMapConfig.xml（名字可以随意）</p>
<p>​                    第四步：创建映射配置文件  IUserDao.xml（名字可以随意）</p>
<p>​    搭建注意事项:</p>
<p>​                    第一个:创建IUserDao.xml和IUserDao.java 在mybatis中</p>
<p>他把持久层的操作接口名称和映射文件叫做:Mapper</p>
<p>​                    第二个：在idea中创建目录的时候，他和包是不一样的，</p>
<p>​                    第三个：mybatis的映射配置文件位置必须和dao接口的包结构相同</p>
<p>​                    第四个：映射配置文件的操作配置（select）,id属性的取值必须是dao接口的方法名</p>
<p>​                    第五个：映射配置文件的mapper标签和namespace属性的取值必须是dao接口的全限定类名</p>
<p><img src="C:%5CUsers%5Chp%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564214111928.png" alt="1564214111928"></p>
<p>首先Bean包Account.java</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.Bean;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Account</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Integer id;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> Double money;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"Account&#123;"</span> +</span><br><span class="line">                <span class="string">"id="</span> + id +</span><br><span class="line">                <span class="string">", name='"</span> + name + <span class="string">'\''</span> +</span><br><span class="line">                <span class="string">", money="</span> + money +</span><br><span class="line">                <span class="string">'&#125;'</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Integer <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setId</span><span class="params">(Integer id)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Double <span class="title">getMoney</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> money;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMoney</span><span class="params">(Double money)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.money = money;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后dao包下的IDao.java接口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.dao;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cn.Bean.Account;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 获取所有的Account信息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IDao</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Account&gt; <span class="title">getAccountAll</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后创建主配置文件MybatisConfig.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE configuration</span></span><br><span class="line"><span class="meta">        PUBLIC "-//mybatis.org//DTD Config 3.0//EN"</span></span><br><span class="line"><span class="meta">        "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--配置环境--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">environments</span> <span class="attr">default</span>=<span class="string">"mysql"</span>&gt;</span><span class="comment">&lt;!--defult填写的子类必须也有--&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--配置mysql的环境--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">environment</span> <span class="attr">id</span>=<span class="string">"mysql"</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--配置事务的类型--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">transactionManager</span> <span class="attr">type</span>=<span class="string">"JDBC"</span>&gt;</span><span class="tag">&lt;/<span class="name">transactionManager</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--配置数据源--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">dataSource</span> <span class="attr">type</span>=<span class="string">"POOLED"</span>&gt;</span></span><br><span class="line">                <span class="comment">&lt;!--配置连接数据库--&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"driver"</span> <span class="attr">value</span>=<span class="string">"com.mysql.jdbc.Driver"</span>/&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"url"</span> <span class="attr">value</span>=<span class="string">"jdbc:mysql://localhost:3306/ee"</span>/&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"username"</span> <span class="attr">value</span>=<span class="string">"root"</span>/&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"password"</span> <span class="attr">value</span>=<span class="string">"123456"</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">dataSource</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">environment</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">environments</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--配置映射配置文件的位置，映射配置文件指的是每个dao独立的配置文件--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mappers</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mapper</span> <span class="attr">resource</span>=<span class="string">"cn/config/IDao.xml"</span>&gt;</span><span class="tag">&lt;/<span class="name">mapper</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">mappers</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>然后穿件cn目录下config目录下的IDao.xml映射IDao.java的配置文件，注意xml文件和java文件必须是统一限定目录</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8" ?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE mapper</span></span><br><span class="line"><span class="meta">        PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"</span></span><br><span class="line"><span class="meta">        "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;</span></span><br><span class="line"><span class="comment">&lt;!--namespace填写IDao接口的全限定类名--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mapper</span> <span class="attr">namespace</span>=<span class="string">"cn.dao.IDao"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--配置查询所有 id必须是IDao方法的名称,resultType必须是实体类 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">"getAccountAll"</span> <span class="attr">resultType</span>=<span class="string">"cn.Bean.Account"</span>&gt;</span></span><br><span class="line">    select * from account;</span><br><span class="line">  <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mapper</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>最后是测试类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cn.Bean.Account;</span><br><span class="line"><span class="keyword">import</span> cn.dao.IDao;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.io.Resources;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.session.SqlSession;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.session.SqlSessionFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.session.SqlSessionFactoryBuilder;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="meta">@org</span>.junit.Test</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getALl</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//1.读取配置文件</span></span><br><span class="line">        InputStream in= Resources.getResourceAsStream(<span class="string">"MybatisConfig.xml"</span>);</span><br><span class="line">        <span class="comment">//2.创建SqlSessionFactory工厂</span></span><br><span class="line">        SqlSessionFactoryBuilder builder=<span class="keyword">new</span> SqlSessionFactoryBuilder();</span><br><span class="line">        SqlSessionFactory factory=builder.build(in);</span><br><span class="line">        <span class="comment">//3.使用工厂生产SqlSession对象</span></span><br><span class="line">        SqlSession session=factory.openSession();</span><br><span class="line">        <span class="comment">//4.使用SqlSession创建Dao接口的代理对象</span></span><br><span class="line">        IDao dao=session.getMapper(IDao.class);</span><br><span class="line">        <span class="comment">//5.使用代理对象执行方法</span></span><br><span class="line">        List&lt;Account&gt; users=dao.getAccountAll();</span><br><span class="line">        <span class="keyword">for</span> (Account user : users) &#123;</span><br><span class="line">            System.out.println(user);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>打印信息为</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Sat Jul <span class="number">27</span> <span class="number">15</span>:<span class="number">54</span>:<span class="number">14</span> CST <span class="number">2019</span> WARN: Establishing SSL connection without server<span class="string">'s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn'</span>t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to <span class="string">'false'</span>. You need either to explicitly disable SSL by setting useSSL=<span class="keyword">false</span>, or set useSSL=<span class="keyword">true</span> and provide truststore <span class="keyword">for</span> server certificate verification.</span><br><span class="line">Account&#123;id=<span class="number">1</span>, name=<span class="string">'aaa'</span>, money=<span class="number">600.0</span>&#125;</span><br><span class="line">Account&#123;id=<span class="number">2</span>, name=<span class="string">'bbb'</span>, money=<span class="number">1200.0</span>&#125;</span><br><span class="line">Account&#123;id=<span class="number">3</span>, name=<span class="string">'ccc'</span>, money=<span class="number">1000.0</span>&#125;</span><br><span class="line">Account&#123;id=<span class="number">4</span>, name=<span class="string">'hhh'</span>, money=<span class="number">1000.0</span>&#125;</span><br><span class="line">Account&#123;id=<span class="number">5</span>, name=<span class="string">'hhh'</span>, money=<span class="number">200.0</span>&#125;</span><br></pre></td></tr></table></figure>

<p>如果需要保存数据则把IDao.xml改成以下</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8" ?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE mapper</span></span><br><span class="line"><span class="meta">        PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"</span></span><br><span class="line"><span class="meta">        "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;</span></span><br><span class="line"><span class="comment">&lt;!--namespace填写IDao接口的全限定类名--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mapper</span> <span class="attr">namespace</span>=<span class="string">"cn.dao.IDao"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--配置查询所有 id必须是IDao方法的名称,resultType必须是实体类--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">"getAccountAll"</span> <span class="attr">resultType</span>=<span class="string">"cn.Bean.Account"</span>&gt;</span></span><br><span class="line">    select * from account;</span><br><span class="line">  <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--通过里面配置selectKey标签的方式可以获取插入数据后所对应的自增长id的值--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">"addAccount"</span> <span class="attr">parameterType</span>=<span class="string">"cn.Bean.Account"</span>&gt;</span></span><br><span class="line">      <span class="comment">&lt;!--selectKey  会将 SELECT LAST_INSERT_ID()的结果放入到传入的model的主键里面，  </span></span><br><span class="line"><span class="comment">        keyProperty 对应的model中的主键的属性名，这里是 user 中的id，因为它跟数据库的主键对应  </span></span><br><span class="line"><span class="comment">        order AFTER 表示 SELECT LAST_INSERT_ID() 在insert执行之后执行,多用与自增主键，  </span></span><br><span class="line"><span class="comment">              BEFORE 表示 SELECT LAST_INSERT_ID() 在insert执行之前执行，这样的话就拿不到主键了，  </span></span><br><span class="line"><span class="comment">                    这种适合那种主键不是自增的类型  </span></span><br><span class="line"><span class="comment">        resultType 主键类型 --&gt;</span>  </span><br><span class="line">      <span class="tag">&lt;<span class="name">selectKey</span> <span class="attr">keyProperty</span>=<span class="string">"id"</span> <span class="attr">keyColumn</span>=<span class="string">"id"</span> <span class="attr">resultType</span>=<span class="string">"int"</span> <span class="attr">order</span>=<span class="string">"AFTER"</span>&gt;</span><span class="tag">&lt;/<span class="name">selectKey</span>&gt;</span></span><br><span class="line">      insert INTO account(name,money) values(#&#123;name&#125;,#&#123;money&#125;)</span><br><span class="line">  <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mapper</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="值得一提的是："><a href="#值得一提的是：" class="headerlink" title="值得一提的是："></a>值得一提的是：</h5><h6 id="resultType属性可以类型有简单类型或者pojo对象，或者pojo对象的包装对象（pojo对象的列表）。"><a href="#resultType属性可以类型有简单类型或者pojo对象，或者pojo对象的包装对象（pojo对象的列表）。" class="headerlink" title="resultType属性可以类型有简单类型或者pojo对象，或者pojo对象的包装对象（pojo对象的列表）。"></a>resultType属性可以类型有简单类型或者pojo对象，或者pojo对象的包装对象（pojo对象的列表）。</h6><p>pojo对象就是javabean或者说是实体类对象</p>
<p>​    然后上述xml文件配置中就是用了OGNL表达式</p>
<ul>
<li>OGNL表达式中省略的get关键字，即user.getName()变成了user.name;</li>
<li>在mybatis中标签属性resultType中提供了user对象的包名，所以可以直接使用name来达到user.name相同的效果</li>
</ul>
<p>测试类里面：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cn.Bean.Account;</span><br><span class="line"><span class="keyword">import</span> cn.dao.IDao;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.io.Resources;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.session.SqlSession;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.session.SqlSessionFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.session.SqlSessionFactoryBuilder;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="meta">@org</span>.junit.Test</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getALl</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//1.读取配置文件</span></span><br><span class="line">        InputStream in= Resources.getResourceAsStream(<span class="string">"MybatisConfig.xml"</span>);</span><br><span class="line">        <span class="comment">//2.创建SqlSessionFactory工厂</span></span><br><span class="line">        SqlSessionFactoryBuilder builder=<span class="keyword">new</span> SqlSessionFactoryBuilder();</span><br><span class="line">        SqlSessionFactory factory=builder.build(in);</span><br><span class="line">        <span class="comment">//3.使用工厂生产SqlSession对象</span></span><br><span class="line">        SqlSession session=factory.openSession();</span><br><span class="line">        <span class="comment">//4.使用SqlSession创建Dao接口的代理对象</span></span><br><span class="line">        IDao dao=session.getMapper(IDao.class);</span><br><span class="line">        <span class="comment">//5.使用代理对象执行方法</span></span><br><span class="line">        Account ac=<span class="keyword">new</span> Account();</span><br><span class="line">        ac.setName(<span class="string">"hha"</span>);</span><br><span class="line">        ac.setMoney(<span class="number">99999.0</span>);</span><br><span class="line">        dao.addAccount(ac);</span><br><span class="line">        List&lt;Account&gt; users=dao.getAccountAll();</span><br><span class="line">        <span class="keyword">for</span> (Account user : users) &#123;</span><br><span class="line">            System.out.println(user);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//如果没有正确提交到数据库需要手动提交事务</span></span><br><span class="line">        <span class="comment">//session.commit();</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="注解配置"><a href="#注解配置" class="headerlink" title="注解配置"></a>注解配置</h2><p>​            首先可以把IDao.xml移除，在dao接口的方法上使用@Select注解，并且指定SQL语句，同时需要在SqlMapConfig.xml中的mapper配置时，使用class属性指定dao接口的全限定类名</p>
<h2 id="实体类对象的属性名称与mysql数据库里面的列名不同解决方案："><a href="#实体类对象的属性名称与mysql数据库里面的列名不同解决方案：" class="headerlink" title="实体类对象的属性名称与mysql数据库里面的列名不同解决方案："></a>实体类对象的属性名称与mysql数据库里面的列名不同解决方案：</h2><pre><code>####     原因：</code></pre><p>​        mysql数据库里面的列不能喝实体类对象的属性进行对应，说以要解决这个问题必须从解决对应关系下手</p>
<pre><code>- 使用mysql的别名进行对应
- 使用mybatis里面的resultMap标签进行对应匹配（然后标签里面的resultType属性换成resultMap属性来使用配置的resultMap标签里面的内容）

## mybatis连接池

   ### 连接池数据源分类</code></pre><ul>
<li>UNPOOLED 不使用连接池的数据源</li>
<li>POOLED 使用连接池的数据源</li>
<li>JNDI 使用JNDI实现的数据源</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/27/Git使用入门/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/27/Git使用入门/" itemprop="url">git使用入门</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-27T13:47:40+08:00">
                2018-05-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Git使用入门"><a href="#Git使用入门" class="headerlink" title="Git使用入门"></a>Git使用入门</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​        之前在网上接私活的时候使用了一下github,当时一下都惊艳到我了，（见识短╮(╯▽╰)╭），当时因为用的c#语言开发，使用的vs2017，他继承的那个git是中文的，特别好用，但是也导致了我啥也没学会，正好今天有空，就填补一下这个大坑吧</p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>​        是一个开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理。Git 是 Linus Torvalds为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。（百度粘贴过来的，╮(╯▽╰)╭）</p>
<h2 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h2><p>​    git可以将工作区（Working Directory）的代码放到暂存区，最后统一把暂存区的代码合并到我们的git仓库中（这个仓库其实还是本地的仓库）。（╮(╯▽╰)╭我觉得解释的很不清楚）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">st=&gt;start: git仓库</span><br><span class="line">e=&gt;end: 工作空间</span><br><span class="line">item=&gt;subroutine: 暂存区</span><br><span class="line"></span><br><span class="line">e-&gt;item-&gt;st</span><br></pre></td></tr></table></figure>

<h2 id="使用git工具要先进行初始化"><a href="#使用git工具要先进行初始化" class="headerlink" title="使用git工具要先进行初始化"></a>使用git工具要先进行初始化</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name <span class="string">"yang295513"</span>//这个name一定要填写github上面的名称</span><br><span class="line">git config --global user.email <span class="string">"15993343299@163.com"</span>//对应的邮箱</span><br><span class="line">//这个不是必须的但是新建git仓库就要进去进行这个命令，然后git工具会生成一个隐藏文件.git</span><br><span class="line">git init</span><br></pre></td></tr></table></figure>

<p><img src="assets/1567999850542.png" alt="1567999850542"></p>
<p>就这样，之后就可以愉快的玩耍了</p>
<h2 id="指令介绍"><a href="#指令介绍" class="headerlink" title="指令介绍"></a>指令介绍</h2><table>
<thead>
<tr>
<th align="center">指令名</th>
<th align="center">作用</th>
<th align="center">注释</th>
</tr>
</thead>
<tbody><tr>
<td align="center">git status</td>
<td align="center">显示当前文件的状态</td>
<td align="center">用来确定文件在三个区的位置</td>
</tr>
<tr>
<td align="center">git add 文件名.文件类型</td>
<td align="center">将文件添加到暂存区</td>
<td align="center">把工作空间的文件添加到暂存区</td>
</tr>
<tr>
<td align="center">git commit -m “提交描述”</td>
<td align="center">把暂存区所有的文件提交到仓库</td>
<td align="center">提交描述用来标识文件的改动，也就是说本次提交的注释</td>
</tr>
<tr>
<td align="center">git push</td>
<td align="center">将本地代码提交到git远程 仓库中</td>
<td align="center">将本地代码提交到git远程仓库中</td>
</tr>
<tr>
<td align="center">git clone 仓库地址</td>
<td align="center">将远程git的代码下载下来</td>
<td align="center"></td>
</tr>
</tbody></table>
<h2 id="案例演示"><a href="#案例演示" class="headerlink" title="案例演示"></a>案例演示</h2><p>首先这里新建了一个演示项目</p>
<p><img src="assets/1568012570966.png" alt="1568012570966"></p>
<p>然后我们通过git clone命令把这个项目下载下来，其中项目的链接在这里：</p>
<p><img src="assets/1568012654191.png" alt="1568012654191"></p>
<p>然后我们使用git工具克隆下来</p>
<p><img src="assets/1568012777172.png" alt="1568012777172"></p>
<p>这是本地生成的文件</p>
<p><img src="assets/1568012817099.png" alt="1568012817099"></p>
<p>其中那个.git的隐藏文件就隐藏着配置信息</p>
<p>githubTest就是咱们的测试信息</p>
<p><img src="assets/1568012868219.png" alt="1568012868219"></p>
<p>githubTest文件里面的信息可以看到和我们的远端github仓库中的一模一样</p>
<p>接下来我们在本地创建一个Test.java的类，来模拟我们的项目</p>
<p>然后使用git add命令和git commit -m和git push命令依次提交到git远端仓库中</p>
<p><img src="assets/1568013628870.png" alt="1568013628870"></p>
<p>然后去github来查看是否已经被提交了</p>
<p><img src="assets/1568013663654.png" alt="1568013663654"></p>
<h4 id="完美-收场，学习新东西去"><a href="#完美-收场，学习新东西去" class="headerlink" title="完美,收场，学习新东西去"></a>完美,收场，学习新东西去</h4><p>不不不，还有一些使用细节得介绍一下</p>
<ul>
<li>你提交了那些文件那些文件才会被替换，也就是说你同时修改了A和B文件，那三连</li>
</ul>
<p>都是针对B文件的，那么你提交到远端git仓库在只会修改你提交的B文件，没有B文件进行创建,有B文件更新</p>
<ul>
<li>如果提交到远端失败的话，要注意是否是name和Email书写错误，或者说该仓库是priavte（私有的）如果是私有的去对应配置文件下修改账号密码即可</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/27/1.tensorflow基本介绍/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/27/1.tensorflow基本介绍/" itemprop="url">Tensorflow入门教程</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-27T13:47:40+08:00">
                2018-05-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-tensorflow基本介绍"><a href="#1-tensorflow基本介绍" class="headerlink" title="1.tensorflow基本介绍"></a>1.tensorflow基本介绍</h1><h3 id="1-TensorFlow-简介"><a href="#1-TensorFlow-简介" class="headerlink" title="1.TensorFlow 简介"></a>1.TensorFlow 简介</h3><p>​    TensorFlow是一个基于数据流编程的符号数学系统，被广泛应用于各类机器学习算法的编程实现，其前身是谷歌的神经网络算法库</p>
<h3 id="2-TensorFlow基本术语"><a href="#2-TensorFlow基本术语" class="headerlink" title="2.TensorFlow基本术语"></a>2.TensorFlow基本术语</h3><h4 id="张量（tensor）："><a href="#张量（tensor）：" class="headerlink" title="张量（tensor）："></a>张量（tensor）：</h4><p>​    张量就是基于向量和矩阵的推广，通俗点理解就是可以将标量看成零阶张量，向量看成一阶张量，矩阵就是二阶张量。</p>
<h4 id="图（graph）"><a href="#图（graph）" class="headerlink" title="图（graph）"></a>图（graph）</h4><p>​    代表着一段内存地址，也可以理解成所有的节点和张量的集合</p>
<h4 id="节点（op）"><a href="#节点（op）" class="headerlink" title="节点（op）"></a>节点（op）</h4><p>​    每个运算和张量都是一个节点，每个节点就是一个op</p>
<h4 id="会话-Session"><a href="#会话-Session" class="headerlink" title="会话(Session)"></a>会话(Session)</h4><p>​    会话的作用就是执行图的计算，众所周知在TensorFlow中会话之前的都是图的定义或者是op的定义，只能表示关系不参与计算，所以需要用会话让图真正的执行起来</p>
<h1 id="2-张量（tensor）的使用以及注意事项"><a href="#2-张量（tensor）的使用以及注意事项" class="headerlink" title="2.张量（tensor）的使用以及注意事项"></a>2.张量（tensor）的使用以及注意事项</h1><h4 id="1-张量的基本概念"><a href="#1-张量的基本概念" class="headerlink" title="1.张量的基本概念"></a>1.张量的基本概念</h4><p>​    张量就是基于向量和矩阵的推广，通俗点理解就是可以将标量看成零阶张量，向量看成一阶张量，矩阵就是二阶张量。</p>
<h4 id="2-张量的数据类型"><a href="#2-张量的数据类型" class="headerlink" title="2.张量的数据类型"></a>2.张量的数据类型</h4><table>
<thead>
<tr>
<th align="center">数据类型</th>
<th align="center">Python类型</th>
<th align="center">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>DT_FLOAT</strong></td>
<td align="center"><strong>tf.float32</strong></td>
<td align="center"><strong>32位浮点数</strong></td>
</tr>
<tr>
<td align="center">DT_DOUBLE</td>
<td align="center">tf.float64</td>
<td align="center">64位浮点数（精度和float32精度一致）</td>
</tr>
<tr>
<td align="center">DT_INT64</td>
<td align="center">tf.int64</td>
<td align="center">64位有符号整数</td>
</tr>
<tr>
<td align="center"><strong>DT_INT32</strong></td>
<td align="center"><strong>tf.int32</strong></td>
<td align="center"><strong>32位有符号整数（精度和int32精度一致）</strong></td>
</tr>
<tr>
<td align="center">DT_INT13</td>
<td align="center">tf.int16</td>
<td align="center">16位有符号整数</td>
</tr>
<tr>
<td align="center"><strong>DT_INT8</strong></td>
<td align="center"><strong>tf.int8</strong></td>
<td align="center"><strong>8位有符号整数</strong></td>
</tr>
<tr>
<td align="center">DT_STRING</td>
<td align="center">tf.string</td>
<td align="center">可变长度的字节数组，每一个张量元素都是一个字节数组。</td>
</tr>
<tr>
<td align="center">DT_BOOL</td>
<td align="center">tf.bool</td>
<td align="center">布尔型</td>
</tr>
<tr>
<td align="center">DT_COMPLEX64</td>
<td align="center">tf.compiex64</td>
<td align="center">由两个32位浮点数组组成的复数：实数和虚数</td>
</tr>
<tr>
<td align="center">DT_QINT32</td>
<td align="center">tf.qint32</td>
<td align="center">用于量化Ops的8位有符号整数</td>
</tr>
<tr>
<td align="center">DT.QINT8</td>
<td align="center">tf.qint8</td>
<td align="center">用于量化Ops的8位有符号整形</td>
</tr>
<tr>
<td align="center">DT_QUINT8</td>
<td align="center">tf.quint8</td>
<td align="center">用于量化Ops的8位无符号整形</td>
</tr>
</tbody></table>
<h4 id="3-张量的代码"><a href="#3-张量的代码" class="headerlink" title="3.张量的代码"></a>3.张量的代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入tensorflow包，简写为tf</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义一个3.0的常量的张量</span></span><br><span class="line">tensor=tf.constant(<span class="number">3.0</span>)</span><br><span class="line"><span class="comment">#显示tensor的结果</span></span><br><span class="line">print(tensor)</span><br><span class="line"><span class="comment">#结果将会是：Tensor("Const:0", shape=(), dtype=float32)</span></span><br></pre></td></tr></table></figure>

<h5 id="其中Const表示进行的op操作名字"><a href="#其中Const表示进行的op操作名字" class="headerlink" title="其中Const表示进行的op操作名字"></a>其中Const表示进行的op操作名字</h5><h5 id="shape表示张量的维度-表示标量，（1）表示向量，（2，3）表示2行3列的张量"><a href="#shape表示张量的维度-表示标量，（1）表示向量，（2，3）表示2行3列的张量" class="headerlink" title="shape表示张量的维度,()表示标量，（1）表示向量，（2，3）表示2行3列的张量"></a>shape表示张量的维度,()表示标量，（1）表示向量，（2，3）表示2行3列的张量</h5><h5 id="dtype表示张量的数据类型"><a href="#dtype表示张量的数据类型" class="headerlink" title="dtype表示张量的数据类型"></a>dtype表示张量的数据类型</h5><h3 id="4-生成张量"><a href="#4-生成张量" class="headerlink" title="4.生成张量"></a>4.生成张量</h3><h5 id="创建一个常数张量"><a href="#创建一个常数张量" class="headerlink" title="创建一个常数张量"></a>创建一个常数张量</h5><p>tf.constant(value,dtype=None,shape=None,name=”Const”)</p>
<p>创建一个dtype类型的维度为shape的常数张量</p>
<h5 id="固定值初始化"><a href="#固定值初始化" class="headerlink" title="固定值初始化"></a>固定值初始化</h5><h6 id="tf-zeros-n-m-tf-dtype"><a href="#tf-zeros-n-m-tf-dtype" class="headerlink" title="tf.zeros([n,m],tf.dtype)"></a>tf.zeros([n,m],tf.dtype)</h6><p>获取一个n行m列的零元素tf.dtype类型的张量</p>
<h6 id="tf-ones-n-m-tf-dtype"><a href="#tf-ones-n-m-tf-dtype" class="headerlink" title="tf.ones([n,m],tf.dtype)"></a>tf.ones([n,m],tf.dtype)</h6><p>获取一个n行m列的1元素tf.dtype类型的张量</p>
<h5 id="随机值初始化"><a href="#随机值初始化" class="headerlink" title="随机值初始化"></a>随机值初始化</h5><h6 id="tf-random-normal-n-m-mean-2-0-stddev-4-seed-12"><a href="#tf-random-normal-n-m-mean-2-0-stddev-4-seed-12" class="headerlink" title="tf.random_normal([n,m],mean=2.0,stddev=4,seed=12)"></a>tf.random_normal([n,m],mean=2.0,stddev=4,seed=12)</h6><p>创建一个n行m列的<a href="[https://baike.baidu.com/item/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83/829892?fr=aladdin](https://baike.baidu.com/item/正态分布/829892?fr=aladdin)">正态分布</a>（高斯分布）平均值为2.0，方差为4,随机种子为12张量</p>
<h3 id="5-占位符"><a href="#5-占位符" class="headerlink" title="5.占位符"></a>5.占位符</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.placeholder(dtype,shape,name)</span><br></pre></td></tr></table></figure>

<p>dtype张量的数据类型</p>
<p>shape张量的维度 [2,3]生成一个2行3列的占位符,[None,3]表示生成一个不确定行和3列的占位符</p>
<h3 id="6-张量的维度调整"><a href="#6-张量的维度调整" class="headerlink" title="6.张量的维度调整"></a>6.张量的维度调整</h3><h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><p>如果调整的过程中生成了新的张量，这种调整称作动态调整</p>
<h4 id="静态调整"><a href="#静态调整" class="headerlink" title="静态调整"></a>静态调整</h4><h5 id="语法-张量名字-set-shape-n-m-调整张量为n行m列"><a href="#语法-张量名字-set-shape-n-m-调整张量为n行m列" class="headerlink" title="语法: 张量名字.set_shape([n,m]) 调整张量为n行m列"></a>语法: 张量名字.set_shape([n,m]) 调整张量为n行m列</h5><ul>
<li>注意 静态张量只能调整之前不确定维度的张量，比如shape=[None,3]的张量</li>
</ul>
<h4 id="动态调整"><a href="#动态调整" class="headerlink" title="动态调整"></a>动态调整</h4><h5 id="语法-tf-reshape-tensor-shape-name-None"><a href="#语法-tf-reshape-tensor-shape-name-None" class="headerlink" title="语法: tf.reshape(tensor,shape,name=None)"></a>语法: tf.reshape(tensor,shape,name=None)</h5><p>动态张量会生成新的张量而且可以跨维度修改，也就是二阶张量可以向n阶张量改变，但是改变前和改变后其总个数必须一致，如果不知道具体维度，需要填写成-1</p>
<h3 id="7-改变张量的类型"><a href="#7-改变张量的类型" class="headerlink" title="7.改变张量的类型"></a>7.改变张量的类型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.cast(x,dtype,name=<span class="string">"None"</span>)</span><br></pre></td></tr></table></figure>

<p>将x张量转换为dtype类型的张量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.cast([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]],tf.float32)</span><br></pre></td></tr></table></figure>

<p>将列表从整形转换成float32类型</p>
<h3 id="8-张量的切片和扩展"><a href="#8-张量的切片和扩展" class="headerlink" title="8.张量的切片和扩展"></a>8.张量的切片和扩展</h3> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.concat(value,axis,name=<span class="string">"concat"</span>)</span><br></pre></td></tr></table></figure>

<p>可以将连个张量拼接起来</p>
<p>value 可以是个列表</p>
<p>axis 表示按行合并还是按列合并 0表示按行合并，1表示按列合并</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义两个列表</span></span><br><span class="line">a=[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]</span><br><span class="line">b=[[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>],[<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment">#合并两个列表</span></span><br><span class="line">hangCat=tf.concat([a,b],axis=<span class="number">0</span>)</span><br><span class="line">lieCat=tf.concat([a,b],axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#由于上面只是搭建了个图结果并没有实际运行,接下来进行实际运行。</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(<span class="string">"行合并"</span>)</span><br><span class="line">    print(sess.run(hangCat))</span><br><span class="line">    print(<span class="string">"列合并"</span>)</span><br><span class="line">    print(sess.run(lieCat))</span><br><span class="line">    </span><br><span class="line"><span class="comment">#运行结果为：</span></span><br><span class="line">行合并</span><br><span class="line">[[ <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>]</span><br><span class="line"> [ <span class="number">4</span>  <span class="number">5</span>  <span class="number">6</span>]</span><br><span class="line"> [ <span class="number">7</span>  <span class="number">8</span>  <span class="number">9</span>]</span><br><span class="line"> [<span class="number">10</span> <span class="number">11</span> <span class="number">12</span>]]</span><br><span class="line">列合并</span><br><span class="line">[[ <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>  <span class="number">7</span>  <span class="number">8</span>  <span class="number">9</span>]</span><br><span class="line"> [ <span class="number">4</span>  <span class="number">5</span>  <span class="number">6</span> <span class="number">10</span> <span class="number">11</span> <span class="number">12</span>]]</span><br></pre></td></tr></table></figure>

<h1 id="3-会话（Session）"><a href="#3-会话（Session）" class="headerlink" title="3.会话（Session）"></a>3.会话（Session）</h1><p>​    会话的作用就是执行图的计算，众所周知在TensorFlow中会话之前的都是图的定义或者是op的定义，只能表示关系不参与计算，所以需要用会话让图真正的运行起来</p>
<h3 id="基本写法"><a href="#基本写法" class="headerlink" title="基本写法"></a>基本写法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">   sess.run(fetches,feed_dict=<span class="literal">None</span>,options=<span class="literal">None</span>,run_metadata=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<h3 id="1-run方法"><a href="#1-run方法" class="headerlink" title="1.run方法"></a>1.run方法</h3><h6 id="fetches-运行ops和计算tensor"><a href="#fetches-运行ops和计算tensor" class="headerlink" title="fetches 运行ops和计算tensor"></a>fetches 运行ops和计算tensor</h6><h6 id="feed-dict-可选项（字典类型），提取使用占位符之后给图提供数据"><a href="#feed-dict-可选项（字典类型），提取使用占位符之后给图提供数据" class="headerlink" title="feed_dict 可选项（字典类型），提取使用占位符之后给图提供数据"></a>feed_dict 可选项（字典类型），提取使用占位符之后给图提供数据</h6><h1 id="4-变量（Variable）"><a href="#4-变量（Variable）" class="headerlink" title="4.变量（Variable）"></a>4.变量（Variable）</h1><p>​    变量是一种特殊的张量，也是一种op,它能够被存储持久化，他们的值就是张量，默认被训练</p>
<h5 id="1-变量的定义"><a href="#1-变量的定义" class="headerlink" title="1.变量的定义"></a>1.变量的定义</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.Variable(initial_balue=<span class="literal">None</span>,name=<span class="literal">None</span>,trainable=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h6 id="initial-value-值-可以用正态分布或者固定生成张量的值"><a href="#initial-value-值-可以用正态分布或者固定生成张量的值" class="headerlink" title="initial_value 值 可以用正态分布或者固定生成张量的值"></a>initial_value 值 可以用正态分布或者固定生成张量的值</h6><ul>
<li>注意：使用变量的时候必须先运行全局初始化初始化 tf.global_variables_initializer()</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用正态分布分配变量的值</span></span><br><span class="line">var=tf.Variable(tf.random_normal([<span class="number">2</span>,<span class="number">3</span>],mean=<span class="number">2.0</span>,stddev=<span class="number">1.0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#开启会话并运行初始化</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment">#运行初始化(运行全局初始化变量前变量var并未被真正赋值)</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    print(sess.run(var))</span><br></pre></td></tr></table></figure>

<h1 id="4-TensorBoard-的使用和用法"><a href="#4-TensorBoard-的使用和用法" class="headerlink" title="4.TensorBoard 的使用和用法"></a>4.TensorBoard 的使用和用法</h1><h5 id="1-TensorBoard的简介"><a href="#1-TensorBoard的简介" class="headerlink" title="1.TensorBoard的简介"></a>1.TensorBoard的简介</h5><p>​    TensorBoard是Tensorflow的可视化工具，它可以通过Tensorflow程序运行过程中输出的日志文件可视化Tensorflow程序的运行状态。TensorBoard和Tensorflow程序跑在不同的进程中，TensorBoard会自动读取最新的TensorFlow日志文件，并呈现当前TensorFlow程序运行的最新状态。</p>
<h5 id="2-TensorBoard代码"><a href="#2-TensorBoard代码" class="headerlink" title="2.TensorBoard代码"></a>2.TensorBoard代码</h5><p>写入事务文件需要找到TensorFlow包里面的事务包summary里面的FileWriter方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.summary.FileWriter(logdir,graph=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<h6 id="logdir事务文件的绝对路径"><a href="#logdir事务文件的绝对路径" class="headerlink" title="logdir事务文件的绝对路径"></a>logdir事务文件的绝对路径</h6><h6 id="graph写出事务文件的图"><a href="#graph写出事务文件的图" class="headerlink" title="graph写出事务文件的图"></a>graph写出事务文件的图</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#收集变量</span></span><br><span class="line">tf.summary.scalar(name=<span class="string">""</span>,tensor)<span class="comment">#收集损失函数和准确率</span></span><br><span class="line">tf.summary.histogram(name=<span class="string">""</span>,tensor)<span class="comment">#收集高纬度的变量参数</span></span><br><span class="line">tf.summary.image(name=<span class="string">""</span>,tensor)<span class="comment">#收集输入的图片张量，能显示图片</span></span><br></pre></td></tr></table></figure>

<h6 id="name-表示TensorBoard里面显示的名称"><a href="#name-表示TensorBoard里面显示的名称" class="headerlink" title="name 表示TensorBoard里面显示的名称"></a>name 表示TensorBoard里面显示的名称</h6><h6 id="tensor表示要收集的张量"><a href="#tensor表示要收集的张量" class="headerlink" title="tensor表示要收集的张量"></a>tensor表示要收集的张量</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mergin=tf.summary.merge_all()<span class="comment">#收集所有的张量</span></span><br><span class="line">summary=sess.run(mergin)<span class="comment">#每次迭代都要运行的合并</span></span><br><span class="line">FileWriter.add_summary(summary,i)<span class="comment">#每次迭代都要添加到事务文件</span></span><br></pre></td></tr></table></figure>

<h5 id="3-TensorBoard的演示"><a href="#3-TensorBoard的演示" class="headerlink" title="3.TensorBoard的演示"></a>3.TensorBoard的演示</h5><p>​    首先代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过两个变量的相加演示tensorboard的用法</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义两个正态分布的随机变量</span></span><br><span class="line">var1=tf.Variable(tf.random_normal([<span class="number">2</span>,<span class="number">3</span>],mean=<span class="number">2.0</span>,stddev=<span class="number">1.0</span>))</span><br><span class="line">var2=tf.Variable(tf.random_normal([<span class="number">2</span>,<span class="number">3</span>],mean=<span class="number">3.0</span>,stddev=<span class="number">2.0</span>))</span><br><span class="line"><span class="comment">#定义加法op</span></span><br><span class="line">add=tf.add(var1,var2)</span><br><span class="line">init_variable=tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="comment">#开启会话</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment">#初始化变量</span></span><br><span class="line">    sess.run(init_variable)</span><br><span class="line">    <span class="comment">#导出事务文件</span></span><br><span class="line">    tf.summary.FileWriter(<span class="string">"./board"</span>,graph=sess.graph)</span><br><span class="line">    print(sess.run(add))</span><br></pre></td></tr></table></figure>

<p>​    然后启动命令行，打出下列命令</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir="D:\code\python\tensortflow\board"</span><br></pre></td></tr></table></figure>

<p>​    之后显示命令行下面显示如下信息</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TensorBoard <span class="number">1</span>.<span class="number">5</span>.<span class="number">1</span> <span class="built_in">at</span> http://By:<span class="number">6006</span> (Press CTRL+C to quit)</span><br></pre></td></tr></table></figure>

<p>这就表示TensorBoard正常启动了，在浏览器输入（<a href="http://By:6006）就能正常访问tensorboard了" target="_blank" rel="noopener">http://By:6006）就能正常访问tensorboard了</a></p>
<h1 id="5-损失函数"><a href="#5-损失函数" class="headerlink" title="5.损失函数"></a>5.损失函数</h1><h3 id="1-均方误差"><a href="#1-均方误差" class="headerlink" title="1.均方误差"></a>1.均方误差</h3><p>​    计算方法是求预测值与真实值之间距离的平方和</p>
<p>​    公式如图所示：<img src="C:%5CUsers%5CAdministrator%5CPictures%5C1529558773906.png" alt></p>
<h1 id="6-梯度下降算法"><a href="#6-梯度下降算法" class="headerlink" title="6.梯度下降算法"></a>6.梯度下降算法</h1><h3 id="1-基本思想"><a href="#1-基本思想" class="headerlink" title="1.基本思想"></a>1.基本思想</h3><pre><code>梯度下降法的基本思想可以类比为一个下山的过程。假设这样一个场景：一个人被困在山上，需要从山上下来(i.e. 找到山的最低点，也就是山谷)。但此时山上的浓雾很大，导致可视度很低。因此，下山的路径就无法确定，他必须利用自己周围的信息去找到下山的路径。这个时候，他就可以利用梯度下降算法来帮助自己下山。具体来说就是，以他当前的所处的位置为基准，寻找这个位置最陡峭的地方，然后朝着山的高度下降的地方走，同理，如果我们的目标是上山，也就是爬到山顶，那么此时应该是朝着最陡峭的方向往上走。然后每走一段距离，都反复采用同一个方法，最后就能成功的抵达山谷。</code></pre><h3 id="2-代码"><a href="#2-代码" class="headerlink" title="2.代码"></a>2.代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.tarin.GradientDescentOptimizer(learning_rate)</span><br></pre></td></tr></table></figure>

<h6 id="learning-rate-学习率-通常填写0-0到1-0之间的浮点数"><a href="#learning-rate-学习率-通常填写0-0到1-0之间的浮点数" class="headerlink" title="learning_rate 学习率 通常填写0.0到1.0之间的浮点数"></a>learning_rate 学习率 通常填写0.0到1.0之间的浮点数</h6><h1 id="6-简单的线性回归案例"><a href="#6-简单的线性回归案例" class="headerlink" title="6.简单的线性回归案例"></a>6.简单的线性回归案例</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#假设有一个函数关系式y=x*0.7+0.2  也就是y=x*w+b这个关系，若只知道y的结果和x的结果若干组，那么能否正确让w为0.7 b为0.2呢?</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#1.生成100组x的</span></span><br><span class="line">xDist=tf.random_normal([<span class="number">100</span>,<span class="number">1</span>],mean=<span class="number">0.5</span>,stddev=<span class="number">0.5</span>,name=<span class="string">"xDist"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成目标值y的结果</span></span><br><span class="line">y_true=tf.matmul(xDist,[[<span class="number">0.7</span>]])+<span class="number">0.2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2.建立线性回归模型</span></span><br><span class="line"><span class="comment">#因为权重和偏置是需要不断训练改变的，所有需要定义成变量</span></span><br><span class="line">w=tf.Variable(tf.random_normal([<span class="number">1</span>,<span class="number">1</span>],mean=<span class="number">0.0</span>,stddev=<span class="number">1.0</span>),name=<span class="string">"w"</span>)</span><br><span class="line">b=tf.Variable(tf.random_normal([<span class="number">1</span>,<span class="number">1</span>],mean=<span class="number">0.0</span>,stddev=<span class="number">0.0</span>),name=<span class="string">"b"</span>)</span><br><span class="line">y=tf.matmul(xDist,w)+b</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失函数和使用梯度下降优化器优化，使用最小损失优化，学习率为0.1</span></span><br><span class="line">loss=tf.reduce_mean(tf.square(y_true-y))</span><br><span class="line">train_op=tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.定义全局变量全局初始化</span></span><br><span class="line">init_var=tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.开启会话开始训练</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment">#运行初始化变量</span></span><br><span class="line">    sess.run(init_var)</span><br><span class="line">    <span class="comment">#打印训练前权重和偏值,因为权重和偏置并没有被运行，所以需要使用eval方法实时获取权重和偏置</span></span><br><span class="line">    print(<span class="string">"训练前权重:%f权重:%f"</span> % (w.eval(),b.eval()))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">300</span>):</span><br><span class="line">        sess.run(train_op)</span><br><span class="line">        print(<span class="string">"%d轮，权重为:%f,偏置为:%f"</span> % (i,w.eval(),b.eval()))</span><br></pre></td></tr></table></figure>

<h1 id="7-梯度爆炸"><a href="#7-梯度爆炸" class="headerlink" title="7.梯度爆炸"></a>7.梯度爆炸</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#假设有一个函数关系式y=x*0.7+0.2  也就是y=x*w+b这个关系，若只知道y的结果和x的结果若干组，那么能否正确让w为0.7 b为0.2呢?</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#1.生成100组x的</span></span><br><span class="line">xDist=tf.random_normal([<span class="number">100</span>,<span class="number">1</span>],mean=<span class="number">0.5</span>,stddev=<span class="number">0.5</span>,name=<span class="string">"xDist"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成目标值y的结果</span></span><br><span class="line">y_true=tf.matmul(xDist,[[<span class="number">0.7</span>]])+<span class="number">0.2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2.建立线性回归模型</span></span><br><span class="line"><span class="comment">#因为权重和偏置是需要不断训练改变的，所有需要定义成变量</span></span><br><span class="line">w=tf.Variable(tf.random_normal([<span class="number">1</span>,<span class="number">1</span>],mean=<span class="number">0.0</span>,stddev=<span class="number">1.0</span>),name=<span class="string">"w"</span>)</span><br><span class="line">b=tf.Variable(tf.random_normal([<span class="number">1</span>,<span class="number">1</span>],mean=<span class="number">0.0</span>,stddev=<span class="number">0.0</span>),name=<span class="string">"b"</span>)</span><br><span class="line">y=tf.matmul(xDist,w)+b</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失函数和使用梯度下降优化器优化，使用最小损失优化，学习率为0.1</span></span><br><span class="line">loss=tf.reduce_mean(tf.square(y_true-y))</span><br><span class="line">train_op=tf.train.GradientDescentOptimizer(<span class="number">1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.定义全局变量全局初始化</span></span><br><span class="line">init_var=tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.开启会话开始训练</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment">#运行初始化变量</span></span><br><span class="line">    sess.run(init_var)</span><br><span class="line">    <span class="comment">#打印训练前权重和偏值,因为权重和偏置并没有被运行，所以需要使用eval方法实时获取权重和偏置</span></span><br><span class="line">    print(<span class="string">"训练前权重:%f权重:%f"</span> % (w.eval(),b.eval()))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">300</span>):</span><br><span class="line">        sess.run(train_op)</span><br><span class="line">        print(<span class="string">"%d轮，权重为:%f,偏置为:%f"</span> % (i,w.eval(),b.eval()))</span><br></pre></td></tr></table></figure>

<h3 id="1-简述"><a href="#1-简述" class="headerlink" title="1.简述"></a>1.简述</h3><p>​        上述代码学习率是1，运行后就会发现权重和偏置变成了NAV，这就是梯度爆炸，也就是说学习率过大或者神经网络模型的某些原因就会导致梯度爆炸，但是学习率也不能过小，过小会得不到好的效果。</p>
<h3 id="2-解决方法"><a href="#2-解决方法" class="headerlink" title="2.解决方法"></a>2.解决方法</h3><ul>
<li>重新设计神经网络</li>
<li>调整学习率</li>
<li>使用梯度阶段（在训练过程中检查和限制梯度的大小）</li>
<li>使用激活函数</li>
</ul>
<h1 id="8-模型的保存和加载"><a href="#8-模型的保存和加载" class="headerlink" title="8.模型的保存和加载"></a>8.模型的保存和加载</h1><h3 id="1-代码"><a href="#1-代码" class="headerlink" title="1.代码"></a>1.代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">saver=tf.train.Saver(var_list=<span class="literal">None</span>,max_to_keep=<span class="number">5</span>)</span><br><span class="line"><span class="comment">#在会话里面</span></span><br><span class="line">saver.restpre(sess,<span class="string">""</span>)<span class="comment">#读取模型</span></span><br><span class="line">saver.save(sess,<span class="string">""</span>)<span class="comment">#保存模型</span></span><br></pre></td></tr></table></figure>

<h6 id="var-list-自定要保持和还原的变量。他可以作为一个dict或者一个列表传进去"><a href="#var-list-自定要保持和还原的变量。他可以作为一个dict或者一个列表传进去" class="headerlink" title="var_list:自定要保持和还原的变量。他可以作为一个dict或者一个列表传进去"></a>var_list:自定要保持和还原的变量。他可以作为一个dict或者一个列表传进去</h6><h6 id="max-to-keep-制定要保留的最近检查点文件的最大数量，创建新的文件的时候会删除比较旧的文件，默认值5"><a href="#max-to-keep-制定要保留的最近检查点文件的最大数量，创建新的文件的时候会删除比较旧的文件，默认值5" class="headerlink" title="max_to_keep:制定要保留的最近检查点文件的最大数量，创建新的文件的时候会删除比较旧的文件，默认值5"></a>max_to_keep:制定要保留的最近检查点文件的最大数量，创建新的文件的时候会删除比较旧的文件，默认值5</h6><h6 id="“”-这个路径包含路径和文件名"><a href="#“”-这个路径包含路径和文件名" class="headerlink" title="“” 这个路径包含路径和文件名"></a>“” 这个路径包含路径和文件名</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#假设有一个函数关系式y=x*0.7+0.2  也就是y=x*w+b这个关系，若只知道y的结果和x的结果若干组，那么能否正确让w为0.7 b为0.2呢</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#1.生成100组x的</span></span><br><span class="line">xDist=tf.random_normal([<span class="number">100</span>,<span class="number">1</span>],mean=<span class="number">0.5</span>,stddev=<span class="number">0.5</span>,name=<span class="string">"xDist"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成目标值y的结果</span></span><br><span class="line">y_true=tf.matmul(xDist,[[<span class="number">0.7</span>]])+<span class="number">0.2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2.建立线性回归模型</span></span><br><span class="line"><span class="comment">#因为权重和偏置是需要不断训练改变的，所有需要定义成变量</span></span><br><span class="line">w=tf.Variable(tf.random_normal([<span class="number">1</span>,<span class="number">1</span>],mean=<span class="number">0.0</span>,stddev=<span class="number">1.0</span>),name=<span class="string">"w"</span>)</span><br><span class="line">b=tf.Variable(tf.random_normal([<span class="number">1</span>,<span class="number">1</span>],mean=<span class="number">0.0</span>,stddev=<span class="number">0.0</span>),name=<span class="string">"b"</span>)</span><br><span class="line">y=tf.matmul(xDist,w)+b</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失函数和使用梯度下降优化器优化，使用最小损失优化，学习率为0.1</span></span><br><span class="line">loss=tf.reduce_mean(tf.square(y_true-y))</span><br><span class="line">train_op=tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#收集张量</span></span><br><span class="line">tf.summary.scalar(<span class="string">"loss"</span>,loss)</span><br><span class="line">tf.summary.histogram(<span class="string">"W"</span>,w)</span><br><span class="line"><span class="comment">#合并所有的收集到的张量</span></span><br><span class="line">margin=tf.summary.merge_all()</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.定义全局变量全局初始化</span></span><br><span class="line">init_var=tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义保存</span></span><br><span class="line">saver=tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.开启会话开始训练</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment">#运行初始化变量</span></span><br><span class="line">    sess.run(init_var)</span><br><span class="line">    <span class="comment"># 读取模型</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">"./model/checkpoint"</span>):</span><br><span class="line">        saver.restore(sess, <span class="string">"./model/123"</span>)</span><br><span class="line">    <span class="comment">#写出事务文件</span></span><br><span class="line">    fileWiter=tf.summary.FileWriter(<span class="string">"./board"</span>,graph=sess.graph)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#打印训练前权重和偏值,因为权重和偏置并没有被运行，所以需要使用eval方法实时获取权重和偏置</span></span><br><span class="line">    print(<span class="string">"训练前权重:%f权重:%f"</span> % (w.eval(),b.eval()))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">300</span>):</span><br><span class="line">        summary = sess.run(margin)</span><br><span class="line">        sess.run(train_op)</span><br><span class="line">        fileWiter.add_summary(summary,i)</span><br><span class="line">        <span class="comment"># 运行变量的合并</span></span><br><span class="line">        print(<span class="string">"%d轮，权重为:%f,偏置为:%f"</span> % (i,w.eval(),b.eval()))</span><br><span class="line">    saver.save(sess,<span class="string">"./model/123"</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-保存的文件格式"><a href="#2-保存的文件格式" class="headerlink" title="2.保存的文件格式"></a>2.保存的文件格式</h3><p>​    .data-00000-of-00001和.index文件</p>
<p>​    checkpoint文件：checkpoint_dir目录下还有checkpoint文件，该文件是个文本文件，里面记录了保存的最新的checkpoint文件以及其它checkpoint文件列表。在inference时，可以通过修改这个文件，指定使用哪个model。加载restore时的文件路径名是以checkpoint文件中的“model_checkpoint_path”值决定的。</p>
<p>​    保存模型时，只会保存变量的值，placeholder里面的值不会被保存。</p>
<h1 id="9-队列机制"><a href="#9-队列机制" class="headerlink" title="9.队列机制"></a>9.队列机制</h1><h3 id="1-简述-1"><a href="#1-简述-1" class="headerlink" title="1.简述"></a>1.简述</h3><p>​    TensorFlow提供了专门的队列机制,专门用来处理文件读取的问题</p>
<h3 id="2-代码-1"><a href="#2-代码-1" class="headerlink" title="2.代码"></a>2.代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">queue=tf.FIFOQueue(capatity,dtype)<span class="comment">#定义一个队列</span></span><br></pre></td></tr></table></figure>

<h6 id="capatity-队列的容量"><a href="#capatity-队列的容量" class="headerlink" title="capatity 队列的容量"></a>capatity 队列的容量</h6><h6 id="dtype队列存储的数据类型"><a href="#dtype队列存储的数据类型" class="headerlink" title="dtype队列存储的数据类型"></a>dtype队列存储的数据类型</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">queue.dequeue()<span class="comment">#出队列并且移除</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">queue.enqueue()<span class="comment">#入队列</span></span><br><span class="line">int=queue.enqueue_many(list)<span class="comment">#入队一个列表元素</span></span><br></pre></td></tr></table></figure>

<h4 id="演示"><a href="#演示" class="headerlink" title="演示:"></a>演示:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义一个队列，不断出队列和入队列</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#定义一个队列</span></span><br><span class="line">queue=tf.FIFOQueue()</span><br><span class="line"><span class="comment">#添加队列元素</span></span><br><span class="line">int=queue.enqueue_many([[<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>],])</span><br><span class="line"><span class="comment">#定义图结构</span></span><br><span class="line">item=queue.dequeue()</span><br><span class="line">data=item+<span class="number">1</span></span><br><span class="line">en=queue.enqueue(data)</span><br><span class="line"></span><br><span class="line"><span class="comment">#开始执行图结构</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment">#运行添加元素结构</span></span><br><span class="line">    sess.run(int)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">        sess.run(en)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(queue.size().eval()):</span><br><span class="line">        print(queue.dequeue().eval())</span><br></pre></td></tr></table></figure>

<h1 id="10-文件读取"><a href="#10-文件读取" class="headerlink" title="10.文件读取"></a>10.文件读取</h1><h3 id="1-文件读取的过程"><a href="#1-文件读取的过程" class="headerlink" title="1.文件读取的过程"></a>1.文件读取的过程</h3><h5 id="1-构造文件队列"><a href="#1-构造文件队列" class="headerlink" title="1.构造文件队列"></a>1.构造文件队列</h5><h5 id="2-构造阅读器"><a href="#2-构造阅读器" class="headerlink" title="2.构造阅读器"></a>2.构造阅读器</h5><h5 id="3-对于每个样本进行解码"><a href="#3-对于每个样本进行解码" class="headerlink" title="3.对于每个样本进行解码"></a>3.对于每个样本进行解码</h5><h5 id="4-批处理文件"><a href="#4-批处理文件" class="headerlink" title="4.批处理文件"></a>4.批处理文件</h5><h3 id="2-文件读取的API介绍"><a href="#2-文件读取的API介绍" class="headerlink" title="2.文件读取的API介绍"></a>2.文件读取的API介绍</h3><h5 id="构造文件队列"><a href="#构造文件队列" class="headerlink" title="构造文件队列"></a>构造文件队列</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.tarin.string_inpput_producer(string_tensor,shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h6 id="string-tensor-含有文件名的一阶张量（包含路径以及文件名的列表）"><a href="#string-tensor-含有文件名的一阶张量（包含路径以及文件名的列表）" class="headerlink" title="string_tensor 含有文件名的一阶张量（包含路径以及文件名的列表）"></a>string_tensor 含有文件名的一阶张量（包含路径以及文件名的列表）</h6><h6 id="shuffle-是否乱序-默认乱序"><a href="#shuffle-是否乱序-默认乱序" class="headerlink" title="shuffle 是否乱序 默认乱序"></a>shuffle 是否乱序 默认乱序</h6><h6 id="num-epochs-过几遍数据，默认无限过数据"><a href="#num-epochs-过几遍数据，默认无限过数据" class="headerlink" title="num_epochs 过几遍数据，默认无限过数据"></a>num_epochs 过几遍数据，默认无限过数据</h6><h5 id="构造文件阅读器"><a href="#构造文件阅读器" class="headerlink" title="构造文件阅读器"></a>构造文件阅读器</h5><ul>
<li><p>所有阅读器解码出来形状都是不固定的，注意后边进行形状固定</p>
</li>
<li><p>要根据文件类型选择对应的文件阅读区</p>
</li>
<li><p>每个read方法返回key，和value参数，其中key表示文件名称，value表示每个样本</p>
<p>文本文件和CSV文件:</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">class reader=tf.TextLineReader()#构造文件阅读器</span><br><span class="line">	reader.read(file_queue)<span class="comment">#读取一个样本</span></span><br></pre></td></tr></table></figure>

<h6 id="文本文件阅读器，默认按行读取，（因为对于csv文件和文本文件来说，一行就是一个样本）"><a href="#文本文件阅读器，默认按行读取，（因为对于csv文件和文本文件来说，一行就是一个样本）" class="headerlink" title="文本文件阅读器，默认按行读取，（因为对于csv文件和文本文件来说，一行就是一个样本）"></a>文本文件阅读器，默认按行读取，（因为对于csv文件和文本文件来说，一行就是一个样本）</h6><h6 id="return-返回阅读器实例"><a href="#return-返回阅读器实例" class="headerlink" title="return 返回阅读器实例"></a>return 返回阅读器实例</h6><h5 id="read-file-queue"><a href="#read-file-queue" class="headerlink" title="read(file_queue)"></a>read(file_queue)</h5><h6 id="file-queue-从队列里面读取内容"><a href="#file-queue-从队列里面读取内容" class="headerlink" title="file_queue 从队列里面读取内容"></a>file_queue 从队列里面读取内容</h6><h5 id="二进制文件阅读器"><a href="#二进制文件阅读器" class="headerlink" title="二进制文件阅读器"></a>二进制文件阅读器</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">class reader=tf.FixedLengthRecordReader(record_bytes)#构造文件阅读器</span><br><span class="line">	reader.read(file_queue)<span class="comment">#读取一个样本文件</span></span><br></pre></td></tr></table></figure>

<h6 id="读取每个样本是按固定数量的字节读取的二进制文件"><a href="#读取每个样本是按固定数量的字节读取的二进制文件" class="headerlink" title="读取每个样本是按固定数量的字节读取的二进制文件"></a>读取每个样本是按固定数量的字节读取的二进制文件</h6><h6 id="record-bytes-整形，指定每次读取的字节数"><a href="#record-bytes-整形，指定每次读取的字节数" class="headerlink" title="record_bytes:整形，指定每次读取的字节数"></a>record_bytes:整形，指定每次读取的字节数</h6><h6 id="return-返回阅读器实例-1"><a href="#return-返回阅读器实例-1" class="headerlink" title="return 返回阅读器实例"></a>return 返回阅读器实例</h6><h5 id="图片文件阅读器"><a href="#图片文件阅读器" class="headerlink" title="图片文件阅读器"></a>图片文件阅读器</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">class reader=tf.WholeFileReader()#构造图片文件阅读器</span><br><span class="line">	reader.read(file_queue)<span class="comment">#读取一个图片样本</span></span><br></pre></td></tr></table></figure>

<h5 id="每个样本进行解码"><a href="#每个样本进行解码" class="headerlink" title="每个样本进行解码"></a>每个样本进行解码</h5><h5 id="CSV文件解码"><a href="#CSV文件解码" class="headerlink" title="CSV文件解码"></a>CSV文件解码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.decode_csv(value,record_defaults=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<h6 id="value表示待解码的内容"><a href="#value表示待解码的内容" class="headerlink" title="value表示待解码的内容"></a>value表示待解码的内容</h6><h6 id="record-defaults-表示每个样本如何解码，并且缺失的时候的默认值-1-表示一个样本按整形解码，缺失的时候为1，-“None”-1-0-表示样本有两个第一个按string类型解码，缺失的时候是None-第二个按float类型解码，丢失按1-0处理"><a href="#record-defaults-表示每个样本如何解码，并且缺失的时候的默认值-1-表示一个样本按整形解码，缺失的时候为1，-“None”-1-0-表示样本有两个第一个按string类型解码，缺失的时候是None-第二个按float类型解码，丢失按1-0处理" class="headerlink" title="record_defaults 表示每个样本如何解码，并且缺失的时候的默认值 [[1]]表示一个样本按整形解码，缺失的时候为1，[[“None”],[1.0]] 表示样本有两个第一个按string类型解码，缺失的时候是None,第二个按float类型解码，丢失按1.0处理"></a>record_defaults 表示每个样本如何解码，并且缺失的时候的默认值 [[1]]表示一个样本按整形解码，缺失的时候为1，[[“None”],[1.0]] 表示样本有两个第一个按string类型解码，缺失的时候是None,第二个按float类型解码，丢失按1.0处理</h6><h5 id="图片文件解码"><a href="#图片文件解码" class="headerlink" title="图片文件解码"></a>图片文件解码</h5> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tf.image.decode_jpeg(contents)</span><br><span class="line"><span class="comment">#将JPEG编码的图像解码为uint8的张亮</span></span><br><span class="line"><span class="comment">#return:uint8张量3-D形状[height,width,hannels]</span></span><br><span class="line">tf.image.decode_png(contents)</span><br><span class="line"><span class="comment">#将PNG图片的图像解码为uint8或者uint16的张量</span></span><br><span class="line"><span class="comment">#return:张量类型，3-D形状[height,width,hannels]</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>图片文件缩放</p>
</li>
<li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tf.image.resize_images(images,size)</span><br><span class="line">images:<span class="number">4</span>-D形状[batch,height,width,channels]或者<span class="number">3</span>-D的形状的张量[height,width,channels]</span><br><span class="line">size图片的新尺寸，new_height,new_width</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h5 id="管道批处理文件"><a href="#管道批处理文件" class="headerlink" title="管道批处理文件"></a>管道批处理文件</h5> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#批处理 batch_size表示每批的数量，num_threads进行的线程数量，capacity批处理管道的容量</span></span><br><span class="line">    ones,twos=tf.train.batch([one,two],batch_size=<span class="number">6</span>,num_threads=<span class="number">1</span>,capacity=<span class="number">9</span>)</span><br></pre></td></tr></table></figure>

<h3 id="3-文件读取的简单演示"><a href="#3-文件读取的简单演示" class="headerlink" title="3.文件读取的简单演示"></a>3.文件读取的简单演示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.构造文件队列（路径加文件名）</span></span><br><span class="line"><span class="comment">#2.构造文件阅读器</span></span><br><span class="line"><span class="comment">#3.按每个样本解码（转化为张量 ）</span></span><br><span class="line"><span class="comment">#4.构造批处理</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###在同目录下有个data文件夹，里面的csv文件里面都有两行且都是string类型</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">#找到对应的文件目录获取文件路径加列表</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fileRead</span><span class="params">(path)</span>:</span></span><br><span class="line">    fileName=os.listdir(path)</span><br><span class="line">    filePath=[os.path.join(path,file) <span class="keyword">for</span> file <span class="keyword">in</span> fileName]</span><br><span class="line">    <span class="keyword">return</span> filePath</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">csvRead</span><span class="params">(fileList)</span>:</span></span><br><span class="line">    <span class="comment">#构造文件队列</span></span><br><span class="line">    fileQueue=tf.train.string_input_producer(fileList)</span><br><span class="line">    <span class="comment">#构造阅读器</span></span><br><span class="line">    reader=tf.TextLineReader()</span><br><span class="line">    key,value=reader.read(fileQueue)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#对文件进行解码</span></span><br><span class="line">    <span class="comment">#设定每行的类型以及每行的默认值</span></span><br><span class="line">    cord=[[<span class="string">"None"</span>],[<span class="string">"None"</span>]]</span><br><span class="line">    one,two=tf.decode_csv(value,record_defaults=cord)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#批处理 batch_size表示每批的数量，num_threads进行的线程数量，capacity批处理管道的容量</span></span><br><span class="line">    ones,twos=tf.train.batch([one,two],batch_size=<span class="number">6</span>,num_threads=<span class="number">1</span>,capacity=<span class="number">9</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ones,twos</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    fileList=fileRead(<span class="string">"./data"</span>)</span><br><span class="line">    one,two=csvRead(fileList)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment">#定义一个线程协调器</span></span><br><span class="line">        coord=tf.train.Coordinator()</span><br><span class="line">        <span class="comment">#开启一个线程</span></span><br><span class="line">        thread=tf.train.start_queue_runners(sess,coord=coord)</span><br><span class="line">        print(sess.run([one,two]))</span><br><span class="line">        <span class="comment">#回收子线程</span></span><br><span class="line">        coord.request_stop()</span><br><span class="line">        coord.join(thread)</span><br></pre></td></tr></table></figure>

<h3 id="图片文件的读取简单演示"><a href="#图片文件的读取简单演示" class="headerlink" title="图片文件的读取简单演示"></a>图片文件的读取简单演示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#读取当前文件夹下面的data目录下面所有的jpg格式图片的信息</span></span><br><span class="line"><span class="comment">#步骤</span></span><br><span class="line"><span class="comment"># 1.获取path文件下面的所有图片的全路径列表</span></span><br><span class="line"><span class="comment"># 2.构造文件队列</span></span><br><span class="line"><span class="comment"># 3.构造图片阅读器</span></span><br><span class="line"><span class="comment"># 4.图片解码</span></span><br><span class="line"><span class="comment"># 5.图片缩放</span></span><br><span class="line"><span class="comment"># 6.图片调整维度</span></span><br><span class="line"><span class="comment"># 7.批处理</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取path目录下所有的图片信息</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPath</span><span class="params">(path)</span>:</span></span><br><span class="line">    fileNames=os.listdir(path)</span><br><span class="line">    filePath=[os.path.join(path,fileName) <span class="keyword">for</span> fileName <span class="keyword">in</span> fileNames]</span><br><span class="line">    <span class="keyword">return</span> filePath</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取图片并进行批处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readImg</span><span class="params">(filePathList)</span>:</span></span><br><span class="line">    <span class="comment">#1.构造文件队列</span></span><br><span class="line">    fileQueue=tf.train.string_input_producer(filePathList)</span><br><span class="line">    <span class="comment">#1.构造图片阅读器</span></span><br><span class="line">    reader=tf.WholeFileReader()</span><br><span class="line">    key,value=reader.read(fileQueue)</span><br><span class="line">    print(<span class="string">"构造完阅读器"</span>,value)</span><br><span class="line">    <span class="comment">#3.图片解码</span></span><br><span class="line">    image=tf.image.decode_jpeg(value)</span><br><span class="line">    print(<span class="string">"解码"</span>,image)</span><br><span class="line">    <span class="comment">#4.图片缩放</span></span><br><span class="line">    reImage=tf.image.resize_images(image,[<span class="number">200</span>,<span class="number">200</span>])</span><br><span class="line">    print(<span class="string">"图片放缩后"</span>,reImage)</span><br><span class="line">    <span class="comment">#5.图片定型 静态调整</span></span><br><span class="line">    reImage.set_shape([<span class="number">200</span>,<span class="number">200</span>,<span class="number">3</span>])</span><br><span class="line">    print(<span class="string">"图片静态调整后"</span>,reImage)</span><br><span class="line">    <span class="comment">#文件批处理</span></span><br><span class="line">    jpg=tf.train.batch([reImage],batch_size=<span class="number">5</span>,num_threads=<span class="number">2</span>,capacity=<span class="number">5</span>)</span><br><span class="line">    <span class="keyword">return</span> reImage</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    filePathList=getPath(<span class="string">"./data"</span>)</span><br><span class="line">    jpg=readImg(filePathList)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#开启会话</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment">#定义一个线程协调器</span></span><br><span class="line">        coord=tf.train.Coordinator()</span><br><span class="line">        <span class="comment">#定义一个线程</span></span><br><span class="line">        thread=tf.train.start_queue_runners(sess,coord=coord)</span><br><span class="line">        print(sess.run(jpg))</span><br><span class="line"></span><br><span class="line">        <span class="comment">#回收子线程</span></span><br><span class="line">        coord.request_stop()</span><br><span class="line">        coord.join(thread)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>注意打印结果:</p>
<p>构造完阅读器 Tensor(“ReaderReadV2:1”, shape=(), dtype=string)<br>解码 Tensor(“DecodeJpeg:0”, shape=(?, ?, ?), dtype=uint8)<br>图片放缩后 Tensor(“Squeeze:0”, shape=(200, 200, ?), dtype=float32)<br>图片静态调整后 Tensor(“Squeeze:0”, shape=(200, 200, 3), dtype=float32)</p>
</li>
</ul>
<h1 id="11-交叉熵损失计算和softMax计算"><a href="#11-交叉熵损失计算和softMax计算" class="headerlink" title="11.交叉熵损失计算和softMax计算"></a>11.交叉熵损失计算和softMax计算</h1><h3 id="1-softMax计算"><a href="#1-softMax计算" class="headerlink" title="1.softMax计算"></a>1.softMax计算</h3><p>​    假设我们有一个数组，V，Vi表示V中的第i个元素，那么这个元素的Softmax值就是</p>
<p>​    <img src="C:%5CUsers%5Chp%5CPictures%5Cequation.svg" alt></p>
<p>可以计算n个结果之间发生的概率</p>
<h3 id="2-交叉熵损失"><a href="#2-交叉熵损失" class="headerlink" title="2.交叉熵损失"></a>2.交叉熵损失</h3><p>​    可以和onehost编码与softMax计算损失</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#SoftMax和交叉熵损失计算</span></span><br><span class="line">tf.nn.softmax_cross_entropy_with_logits(babels=<span class="literal">None</span>,logits=<span class="literal">None</span>,name)</span><br><span class="line"><span class="comment">#计算logits和labels之间的交叉熵损失</span></span><br><span class="line"><span class="comment">#labels:真实值</span></span><br><span class="line"><span class="comment">#logits:预测值</span></span><br><span class="line"><span class="comment">#return:返回所有样本的损失值列表</span></span><br></pre></td></tr></table></figure>

<h3 id="3-演示"><a href="#3-演示" class="headerlink" title="3.演示"></a>3.演示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">argmax</span><span class="params">(input,</span></span></span><br><span class="line"><span class="function"><span class="params">           axis=None,</span></span></span><br><span class="line"><span class="function"><span class="params">           name=None,</span></span></span><br><span class="line"><span class="function"><span class="params">           dimension=None,</span></span></span><br><span class="line"><span class="function"><span class="params">           output_type=dtypes.int64)</span></span></span><br><span class="line"><span class="function"><span class="title">numpy</span>.<span class="title">argmax</span><span class="params">(a, axis=None, out=None)</span> </span></span><br><span class="line"><span class="function">返回沿轴<span class="title">axis</span>最大值的索引。</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">Parameters</span>:</span> </span><br><span class="line">input: array_like，数组</span><br><span class="line">axis : int, 可选，默认情况下，索引的是平铺的数组，否则沿指定的轴。 </span><br><span class="line">out : array, 可选 如果提供，结果以合适的形状和类型被插入到此数组中。 </span><br><span class="line"></span><br><span class="line">Returns: </span><br><span class="line">index_array : ndarray of ints </span><br><span class="line">索引数组。它具有与a.shape相同的形状，其中axis被移除。</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#简单的神经网络识别手写数字</span></span><br><span class="line"><span class="comment">#1.定义占位符</span></span><br><span class="line"><span class="comment">#2.搭建神经网络</span></span><br><span class="line"><span class="comment">#3.计算损失</span></span><br><span class="line"><span class="comment">#4.反向传播优化损失</span></span><br><span class="line"><span class="comment">#5.计算准确率</span></span><br><span class="line"><span class="comment">#6.开启会话训练</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"./MNIST_data"</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imgNn</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#1.定义占位符</span></span><br><span class="line">    xDist=tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">784</span>])</span><br><span class="line">    yTrue=tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">10</span>])</span><br><span class="line">    <span class="comment">#2.初始化变量搭建神经网络</span></span><br><span class="line">    w=tf.Variable(tf.random_normal([<span class="number">784</span>,<span class="number">10</span>],mean=<span class="number">0.0</span>,stddev=<span class="number">1.0</span>))</span><br><span class="line">    b=tf.Variable(tf.random_normal([<span class="number">10</span>],mean=<span class="number">0.0</span>,stddev=<span class="number">1.0</span>))</span><br><span class="line">    y=tf.matmul(xDist,w)+b</span><br><span class="line">    <span class="comment">#3.计算平均交叉熵损失率</span></span><br><span class="line">    loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=yTrue,logits=y))</span><br><span class="line">    <span class="comment">#4.反向传播最小优化学习率0.1</span></span><br><span class="line">    trainOp=tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line">    <span class="comment">#5.计算准确率 arg_max会反正正确结果的下标 1表示按同行比较 0表示同列</span></span><br><span class="line">    equal_list=tf.equal(tf.arg_max(yTrue,<span class="number">1</span>),tf.arg_max(y,<span class="number">1</span>))</span><br><span class="line">    acuracy=tf.reduce_mean(tf.cast(equal_list,tf.float32))</span><br><span class="line">    initOp=tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#6.开启会话开始训练</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(initOp)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3000</span>):</span><br><span class="line">            <span class="comment">#取出特征值和目标值</span></span><br><span class="line">            minstX,minstY=mnist.train.next_batch(<span class="number">50</span>)</span><br><span class="line">            sess.run(trainOp,feed_dict=&#123;xDist:minstX,yTrue:minstY&#125;)</span><br><span class="line">            print(<span class="string">"%d步准确率%f"</span> % (i,sess.run(acuracy,feed_dict=&#123;xDist:minstX,yTrue:minstY&#125;)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">"__main__"</span>:</span><br><span class="line">    imgNn()</span><br></pre></td></tr></table></figure>

<h1 id="12-卷积神经网络"><a href="#12-卷积神经网络" class="headerlink" title="12.卷积神经网络"></a>12.卷积神经网络</h1><h3 id="1-概述"><a href="#1-概述" class="headerlink" title="1.概述"></a>1.概述</h3><p>​    卷积神经网络（Convolutional Neural Networks / CNNs / ConvNets）与普通神经网络非常相似，它们都由具有可学习的权重和偏置常量(biases)的神经元组成。每个神经元都接收一些输入，并做一些点积计算，输出是每个分类的分数，普通神经网络里的一些计算技巧到这里依旧适用。</p>
<p>具有三维体积的神经元(3D volumes of neurons) </p>
<p>​    卷积神经网络利用输入是图片的特点，把神经元设计成三个维度 ： width, height, depth(注意这个depth不是神经网络的深度，而是用来描述神经元的) 。比如输入的图片大小是 32 × 32 × 3 (rgb)，那么输入神经元就也具有 32×32×3 的维度。</p>
<h3 id="2-卷积神经网络分层"><a href="#2-卷积神经网络分层" class="headerlink" title="2.卷积神经网络分层"></a>2.卷积神经网络分层</h3><h4 id="卷积层—-gt-激活层—-gt-池化层—-gt-全连接层"><a href="#卷积层—-gt-激活层—-gt-池化层—-gt-全连接层" class="headerlink" title="卷积层—&gt;激活层—&gt;池化层—&gt;全连接层"></a>卷积层—&gt;激活层—&gt;池化层—&gt;全连接层</h4><pre><code>##### 卷积层：</code></pre><p>​    卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法优化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。</p>
<h5 id="激活层："><a href="#激活层：" class="headerlink" title="激活层："></a>激活层：</h5><p>​    通过Relu激活函数可以增加网络的非线性分割能力</p>
<h5 id="池化层："><a href="#池化层：" class="headerlink" title="池化层："></a>池化层：</h5><p>​    用来减少数据量</p>
<h3 id="3-填充算法"><a href="#3-填充算法" class="headerlink" title="3.填充算法"></a>3.填充算法</h3><h4 id="SAME："><a href="#SAME：" class="headerlink" title="SAME："></a>SAME：</h4><p>​    当filter过滤到边缘的时候自动填充0</p>
<pre><code>- 越过边缘取样，取样的面积和输入的图像像素长度和宽度相同</code></pre><h4 id="VALID："><a href="#VALID：" class="headerlink" title="VALID："></a>VALID：</h4><ul>
<li><p>当filter过滤到边缘的时候跳过，所有会丢失部分特征，取样的面积和输入的图像像素长度和宽度会略小</p>
<p>计算公式为：输入体积大小h1 * w1 * d1 ，filter数量为k,filter大小为f,步长为s,填充大小为p</p>
<p>那么</p>
<p>h2=(h1-f+2p)/s+1</p>
<p>w2=(w1-f+2p)/s+1</p>
<p>d2=k    </p>
</li>
</ul>
<h3 id="4-API介绍"><a href="#4-API介绍" class="headerlink" title="4.API介绍"></a>4.API介绍</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#卷积层</span></span><br><span class="line">tf.nn.conv2d(input,filter,strides=,padding=,name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<h6 id="input-输入的4-D张量，具有-batch-height-width-channel-类型为float32，或者float64-每批数-图片长度，图片宽度，图片通道数"><a href="#input-输入的4-D张量，具有-batch-height-width-channel-类型为float32，或者float64-每批数-图片长度，图片宽度，图片通道数" class="headerlink" title="input: 输入的4-D张量，具有[batch,height,width,channel],类型为float32，或者float64([每批数,图片长度，图片宽度，图片通道数])"></a>input: 输入的4-D张量，具有[batch,height,width,channel],类型为float32，或者float64([每批数,图片长度，图片宽度，图片通道数])</h6><h6 id="filter-指定过滤器4-D随机初始化的张量：-类型为float32或者float64-过滤器长度，过滤器宽度，输入的通道数，输出的通道数-，"><a href="#filter-指定过滤器4-D随机初始化的张量：-类型为float32或者float64-过滤器长度，过滤器宽度，输入的通道数，输出的通道数-，" class="headerlink" title="filter:指定过滤器4-D随机初始化的张量：,类型为float32或者float64([过滤器长度，过滤器宽度，输入的通道数，输出的通道数])，"></a>filter:指定过滤器4-D随机初始化的张量：,类型为float32或者float64([过滤器长度，过滤器宽度，输入的通道数，输出的通道数])，</h6><h6 id="——-注意需要传入4-D张量，而不是简单的填入维度"><a href="#——-注意需要传入4-D张量，而不是简单的填入维度" class="headerlink" title="——- 注意需要传入4-D张量，而不是简单的填入维度"></a>——- 注意需要传入4-D张量，而不是简单的填入维度</h6><h6 id="strides-strides-1-stride-stride-1-步长（-1，长上步长，宽上步长，1-）"><a href="#strides-strides-1-stride-stride-1-步长（-1，长上步长，宽上步长，1-）" class="headerlink" title="strides:strides=[1,stride,stride,1],步长（[1，长上步长，宽上步长，1]）"></a>strides:strides=[1,stride,stride,1],步长（[1，长上步长，宽上步长，1]）</h6><h6 id="padding-”SAME”，“VALID”，使用的填充算法类型"><a href="#padding-”SAME”，“VALID”，使用的填充算法类型" class="headerlink" title="padding=:”SAME”，“VALID”，使用的填充算法类型."></a>padding=:”SAME”，“VALID”，使用的填充算法类型.</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#relu激活函数</span></span><br><span class="line">tf.nn.relu(feacutes,name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<h6 id="features-卷积后加上偏置的结果"><a href="#features-卷积后加上偏置的结果" class="headerlink" title="features:卷积后加上偏置的结果"></a>features:卷积后加上偏置的结果</h6><h6 id="return-结果"><a href="#return-结果" class="headerlink" title="return :结果"></a>return :结果</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#池化</span></span><br><span class="line">tf.nn.max_pool(value,ksize=,strides=,padding=,name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<h6 id="value-4-D-tensor形状-batch-height-width-channels-，也就是激活函数处理后的结果"><a href="#value-4-D-tensor形状-batch-height-width-channels-，也就是激活函数处理后的结果" class="headerlink" title="value:4-D tensor形状[batch,height,width,channels]，也就是激活函数处理后的结果"></a>value:4-D tensor形状[batch,height,width,channels]，也就是激活函数处理后的结果</h6><h6 id="ksize池化窗口大小，-1-ksize-ksize-1"><a href="#ksize池化窗口大小，-1-ksize-ksize-1" class="headerlink" title="ksize池化窗口大小，[1,ksize,ksize,1]"></a>ksize池化窗口大小，[1,ksize,ksize,1]</h6><h6 id="步长大小-1-strides-strides-1"><a href="#步长大小-1-strides-strides-1" class="headerlink" title="步长大小,[1,strides,strides,1]"></a>步长大小,[1,strides,strides,1]</h6><h6 id="padding-”SAME”-”VALID”填充算法"><a href="#padding-”SAME”-”VALID”填充算法" class="headerlink" title="padding :”SAME”,”VALID”填充算法"></a>padding :”SAME”,”VALID”填充算法</h6><h3 id="5-演示"><a href="#5-演示" class="headerlink" title="5.演示"></a>5.演示</h3><h5 id="两层卷积神经网络识别手写数字"><a href="#两层卷积神经网络识别手写数字" class="headerlink" title="两层卷积神经网络识别手写数字"></a>两层卷积神经网络识别手写数字</h5><p>​    1.输入数据形状[None,784]</p>
<pre><code>##### 第一层卷积神经网络</code></pre><h6 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h6><p>​    2.因为卷积API的input即输入为4-D张量，所以动态改变形状改为[None,28,28,1],使用32个filter的5*5大小，步长为1，SAME填充算法的过滤器且卷积后输出的形状为[None,28,28,32]，有多少个filter就有多少个偏置所以为32，权重就是每个filter的值.</p>
<pre><code>######     激活层</code></pre><p>​    3.不改变数据大小，所以输出还是[None,28,28,32]</p>
<pre><code>######     池化</code></pre><p>​    4.大小为2 *2，步长为2，填充算法为“SAME”(这里SAME后的大小比原来小)将[None,28,28,32]的图像池化为[None,14,14,32]</p>
<h5 id="第一层卷积神经网络"><a href="#第一层卷积神经网络" class="headerlink" title="第一层卷积神经网络"></a>第一层卷积神经网络</h5><h6 id="卷积层-1"><a href="#卷积层-1" class="headerlink" title="卷积层"></a>卷积层</h6><p>​    2.因为卷积API的input即输入为4-D张量，输入为[None,14,14,32],使用64个filter的5*5大小，步长为1，SAME填充算法的过滤器且卷积后输出的形状为[None,14,14,64]，有多少个filter就有多少个偏置所以为64,权重就是每个filter的值.</p>
<h6 id="激活层"><a href="#激活层" class="headerlink" title="激活层"></a>激活层</h6><p>​    3.不改变数据大小，所以输出还是[None,14,14,64]</p>
<h6 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h6><p>​    4.大小为2*2，步长为2，填充算法为“SAME”(这里SAME后的大小比原来小)将[None,14,14,64]的图像池化为[None,7,7,64]</p>
<h5 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h5><p>​    因为池化后数据为[None,7,7,64],而且矩阵乘法只能处理二维数据，所以动态调整形状为[None,7 * 7 *64],又因为输出是10种结果，所以全连接层为[7 * 7 *64,10],所以权重[7 * 7 *64,10]偏置有10个</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##### 两层卷积神经网络识别手写数字</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getVarRandom_normal</span><span class="params">(shape)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.Variable(tf.random_normal(shape=shape,mean=<span class="number">0.0</span>,stddev=<span class="number">1.0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#搭建神经网络</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conV</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#1.定义占位符</span></span><br><span class="line">    xDist=tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">784</span>])</span><br><span class="line">    yTrue=tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment">#2.搭建第一层卷积网络 filter 有32个 大小为5*5，步长为1，</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"con1"</span>):</span><br><span class="line">        xshape=tf.reshape(xDist,[<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>])</span><br><span class="line">        filterW=getVarRandom_normal([<span class="number">5</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">32</span>])</span><br><span class="line">        b=getVarRandom_normal([<span class="number">32</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment">#卷积层</span></span><br><span class="line">        con1=tf.nn.conv2d(xshape,filterW,strides=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)+b</span><br><span class="line"></span><br><span class="line">        <span class="comment">#激活层</span></span><br><span class="line">        relu=tf.nn.relu(con1)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#池化层 大小为2*2 步长为2 [None,28,28,32]----&gt;[None,14,14,32]</span></span><br><span class="line">        pool=tf.nn.max_pool(relu,ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#3.搭建第二层卷积网络 filter有64个，大小为5*5，步长为1</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"con2"</span>):</span><br><span class="line">        filterW2=getVarRandom_normal([<span class="number">5</span>,<span class="number">5</span>,<span class="number">32</span>,<span class="number">64</span>])</span><br><span class="line">        b1=getVarRandom_normal([<span class="number">64</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment">#卷积层</span></span><br><span class="line">        con2=tf.nn.conv2d(pool,filterW2,strides=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)+b1</span><br><span class="line"></span><br><span class="line">        <span class="comment">#激活层</span></span><br><span class="line">        relu2=tf.nn.relu(con2)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#池化层</span></span><br><span class="line">        pool2=tf.nn.max_pool(relu2,ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#全连接层</span></span><br><span class="line">    w3=getVarRandom_normal([<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>,<span class="number">10</span>])</span><br><span class="line">    b3=getVarRandom_normal([<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">    shape = tf.reshape(pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</span><br><span class="line"></span><br><span class="line">    grop=tf.matmul(shape,w3)+b3</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> xDist,yTrue,grop</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    xDist,yTrue,opInt=conV()</span><br><span class="line">    mnist = input_data.read_data_sets(<span class="string">"./MNIST_data"</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#计算平均交叉熵损失</span></span><br><span class="line">    loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=yTrue,logits=opInt))</span><br><span class="line">    <span class="comment">#反向传播</span></span><br><span class="line">    trainOp=tf.train.GradientDescentOptimizer(<span class="number">0.00001</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#计算准确率</span></span><br><span class="line">    equal_list = tf.equal(tf.argmax(yTrue, <span class="number">1</span>), tf.argmax(opInt, <span class="number">1</span>))</span><br><span class="line">    acuracy = tf.reduce_mean(tf.cast(equal_list, tf.float32))</span><br><span class="line">    initOp = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6.开启会话开始训练</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(initOp)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3000000</span>):</span><br><span class="line">            <span class="comment"># 取出特征值和目标值</span></span><br><span class="line">            minstX, minstY = mnist.train.next_batch(<span class="number">50</span>)</span><br><span class="line">            sess.run(trainOp, feed_dict=&#123;xDist: minstX, yTrue: minstY&#125;)</span><br><span class="line">            print(<span class="string">"%d步准确率%f"</span> % (i, sess.run(acuracy, feed_dict=&#123;xDist: minstX, yTrue: minstY&#125;)))</span><br></pre></td></tr></table></figure>


          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">John Doe</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
